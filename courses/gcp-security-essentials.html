



<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Roboto+Mono:wght@400;700&family=Exo+2:wght@700;800;900&display=swap"
      rel="stylesheet"
    />
    <script src="https://cdn.jsdelivr.net/npm/@supabase/supabase-js@2.39.7/dist/umd/supabase.min.js"></script>
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-okaidia.min.css"
    />
    <link rel="stylesheet" href="assets/css/coursepages.css">
    <!-- ========== Start: SEO & Schema Enhancement ========== -->
    <title>GCP Security Essentials Course | CipherHall</title>
    <meta name="description" content="Enroll in our expert-led Google Cloud Platform (GCP) Security course. Master IAM, VPC security, GKE hardening, and build a secure cloud environment.">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon.png" />
    <link rel="shortcut icon" href="/favicon.png" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="/favicon.png" />
    <link rel="canonical" href="https://www.cipherhall.com/courses/gcp-security-essentials" />

    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Course",
      "name": "GCP Security Essentials",
      "description": "A comprehensive 50-lesson deep dive into Google Cloud Platform security, guiding you from foundational principles to the expert-level implementation of a secure and compliant cloud environment.",
      "provider": {
        "@type": "Organization",
        "name": "CipherHall",
        "sameAs": "https://www.cipherhall.com"
      },
      "hasCourseInstance": {
        "@type": "CourseInstance",
        "courseMode": "Online",
        "instructor": {
          "@type": "Person",
          "name": "Dr. Ben Carter"
        }
      }
    }
    </script>
    <!-- ========== End: SEO & Schema Enhancement ========== -->
</head>
  <body>
    <!-- Loading Screen -->
    <div id="loadingScreen" class="loading-screen">
      <div class="loader-icon">
        <i class="fas fa-graduation-cap"></i>
      </div>
      <div class="loader-text">Loading Course Content...</div>
    </div>

    <!-- Sidebar Overlay for Mobile -->
    <div class="sidebar-overlay" id="sidebarOverlay"></div>

    <!-- Music Player (fixed at top right) -->
    <div class="header-controls">
      <div class="music-dropdown" id="music-dropdown">
        <button class="btn btn-secondary">
          <span id="music-button-text">STUDY MUSIC</span>
          <i id="music-icon" class="fa-solid fa-music"></i>
        </button>
        <div class="music-dropdown-content" id="music-dropdown-content">
          <a
            href="#"
            data-src="https://www.learningcontainer.com/wp-content/uploads/2020/02/Kalimba.mp3"
            >1. Coffee Shop Vibes</a
          >
          <a
            href="#"
            data-src="https://www.soundhelix.com/examples/mp3/SoundHelix-Song-16.mp3"
            >2. City Lights Lofi</a
          >
          <a
            href="#"
            data-src="https://www.soundhelix.com/examples/mp3/SoundHelix-Song-15.mp3"
            >3. Mellow Thoughts</a
          >
          <a
            href="#"
            data-src="https://www.soundhelix.com/examples/mp3/SoundHelix-Song-13.mp3"
            >4. Rainy Mood</a
          >
          <a
            href="#"
            data-src="https://www.soundhelix.com/examples/mp3/SoundHelix-Song-10.mp3"
            >5. Time Alone</a
          >
          <a href="#" id="stop-music-link"
            ><i class="fa-solid fa-stop-circle"></i> Stop Music</a
          >
        </div>
      </div>

      <button class="btn btn-secondary" id="resetProgressBtn">
        <i class="fas fa-redo"></i>
        Reset Progress
      </button>
    </div>

    <!-- Auth Modal -->
    <div id="authModal" class="modal" style="display: none">
      <div class="modal-overlay"></div>
      <div class="modal-content">
        <span class="close" id="closeAuthModal">&times;</span>
        <div class="auth-tabs">
          <button id="tabSignIn" class="auth-tab active">Sign In</button>
          <button id="tabSignUp" class="auth-tab">Sign Up</button>
        </div>
        <div
          id="authLoader"
          style="display: none; text-align: center; padding: 2rem"
        >
          <i
            class="fas fa-spinner fa-spin fa-2x"
            style="color: var(--color-green)"
          ></i>
          <p style="margin-top: 0.5rem">Authenticating...</p>
        </div>
        <div id="signInForm" class="auth-form">
          <h2>Sign In to CipherHall</h2>
          <button id="googleSignIn" class="btn btn-google">
            <i class="fab fa-google"></i> Continue with Google
          </button>
          <div class="divider"><span>or</span></div>
          <form id="emailSignInForm">
            <input
              type="email"
              id="signInEmail"
              placeholder="Email Address"
              required
            />
            <input
              type="password"
              id="signInPassword"
              placeholder="Password"
              required
            />
            <button type="submit" class="btn btn-primary">Sign In</button>
          </form>
        </div>
        <div id="signUpForm" class="auth-form" style="display: none">
          <h2>Join CipherHall</h2>
          <button id="googleSignUp" class="btn btn-google">
            <i class="fab fa-google"></i> Continue with Google
          </button>
          <div class="divider"><span>or</span></div>
          <form id="emailSignUpForm">
            <input
              type="text"
              id="signUpName"
              placeholder="Full Name"
              required
            />
            <input
              type="email"
              id="signUpEmail"
              placeholder="Email Address"
              required
            />
            <input
              type="password"
              id="signUpPassword"
              placeholder="Password (min. 8 characters)"
              required
            />
            <button type="submit" class="btn btn-secondary">
              Create Account
            </button>
          </form>
        </div>
        <div id="authMessage"></div>
      </div>
    </div>

    <!-- Sidebar -->
    <aside class="sidebar" id="sidebar">
      <div class="sidebar-header">
        <div class="course-info">
          <h1 class="course-title" id="courseTitle">Loading...</h1>
          <div class="course-progress">
            <div class="progress-header">
              <span class="progress-label">Course Progress</span>
              <span class="progress-percentage" id="courseProgressPercent"
                >0%</span
              >
            </div>
            <div class="progress-bar">
              <div
                class="progress-fill"
                id="courseProgressFill"
                style="width: 0%"
              ></div>
            </div>
            <div class="progress-stats">
              <span id="completedLessons">0</span>
              <span id="totalLessons">0</span>
            </div>
          </div>
          <a href="/dashboard" class="back-to-dashboard">
            <i class="fas fa-arrow-left"></i>
            Back to Dashboard
          </a>
        </div>
      </div>

      <nav class="lesson-nav" id="lessonNav">
        <!-- Lessons will be loaded dynamically -->
      </nav>
    </aside>

    <!-- Main Content -->
    <main class="main-content">
      <header class="content-header">
        <div class="lesson-header">
          <div class="lesson-header-left">
            <span class="lesson-number" id="currentLessonNumber">1</span>
            <h1 class="lesson-header-title" id="currentLessonTitle">
              Loading...
            </h1>
          </div>
          <div class="lesson-actions">
            <button class="mbtn btn-primary" id="menuToggle">
              <i class="fas fa-bars"></i>
            </button>
          </div>
        </div>
      </header>

      <div class="content-body" id="contentBody">
        <div class="lesson-content" id="lessonContent">
          <!-- Lesson content will be loaded dynamically -->
        </div>
      </div>

      <footer class="lesson-navigation">
        <div class="nav-info" id="navInfo">Lesson 1 of 10</div>
        <div class="nav-controls">
          <button class="btn btn-secondary" id="prevLessonBtn" disabled>
            <i class="fas fa-chevron-left"></i>
            Previous
          </button>
          <button class="btn btn-primary" id="nextLessonBtn" disabled>
            Next
            <i class="fas fa-chevron-right"></i>
          </button>
        </div>
      </footer>
    </main>

    <!-- Achievement Notification -->
    <div id="achievementNotification" class="achievement-notification">
      <div class="notification-header">
        <div class="notification-icon" id="notificationIcon">
          <i class="fas fa-trophy"></i>
        </div>
        <div class="notification-content">
          <h3 id="notificationTitle">Achievement Unlocked!</h3>
          <p id="notificationDescription">Description here...</p>
        </div>
      </div>
      <div class="notification-reward" id="notificationReward">
        <i class="fas fa-coins"></i>
        <span id="notificationPoints">+100 Points</span>
      </div>
    </div>

    <!-- Toast Notification -->
    <div id="toast" class="toast">
      <span id="toastMessage"></span>
    </div>

    <script>
      // =====================================================
      // SYNCHRONIZED COURSE SYSTEM WITH DASHBOARD INTEGRATION
      // =====================================================

      // Supabase Configuration - Replace with your config
      const supabaseUrl = "https://lzcmzulemfubjaksoqor.supabase.co";
      const supabaseKey =
        "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Imx6Y216dWxlbWZ1Ympha3NvcW9yIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTUzMzM5MDgsImV4cCI6MjA3MDkwOTkwOH0.crhPH4YWtRsr1BJTpAQcmPbWSpwIWRbzoI4sRb2_fPI";
      const supabase = window.supabase.createClient(supabaseUrl, supabaseKey);

      // =====================================================
      // COURSE DATA STRUCTURE - REPLACE WITH YOUR COURSE JSON
      // =====================================================
      const COURSE_DATA = {
        "id": "gcp-security-essentials",
        "title": "GCP Security Essentials",
        "description": "A comprehensive 50-lesson deep dive into Google Cloud Platform security, guiding you from foundational principles to the expert-level implementation of a secure and compliant cloud environment.",
        "category": "cloud-security",
        "difficulty": "Beginner to Advanced",
        "duration": "100 hours",
        "instructor": "Dr. Ben Carter",
        "lessons": [
            {
                "id": "lesson-1-gcp-security-overview",
                "title": "Lesson 1: GCP Security Overview",
                "duration": "120 min",
                "objectives": [
                    "Define the Google Cloud Security Model and its layers",
                    "Understand the Shared Responsibility and Shared Fate frameworks",
                    "Recognize GCP's 'Security by Default' principles like default traffic encryption",
                    "Learn how to use Google's Trust and Transparency reports for due diligence"
                ],
                "content": {
                    "overview": "This crucial first lesson establishes the foundation of Google Cloud security. We will deconstruct the Shared Responsibility Model to understand your role versus Google's, explore the principles that guide Google's secure-by-design approach, and learn how to leverage Google's transparency documentation for your own compliance and risk assessments.",
                    "sections": [
                        {
                            "title": "Google Cloud Security Model",
                            "content": "<p>Google's security model is built on over 20 years of experience protecting one of the world's largest infrastructures, including services like Search and Gmail. It is a layered defense-in-depth approach that starts with the physical hardware and extends all the way to the operational processes.</p><h3>The Layers of Security:</h3><ul><li><strong>Physical Infrastructure Security:</strong> Google designs and builds its own data centers, which include multiple layers of physical security like custom-designed electronic access cards, biometric authentication, and metal detectors. The hardware itself has a secure boot stack, from the custom Titan security chip to the firmware, ensuring the integrity of the hardware.</li><li><strong>Network Security:</strong> Google operates one of the world's largest private fiber networks. A significant amount of traffic between Google Cloud services stays on this private network, reducing exposure to the public internet. Furthermore, all VM-to-VM traffic within a VPC network is encrypted by default, protecting against snooping within the cloud.</li><li><strong>Operational Security:</strong> Google employs a global team of security and privacy professionals, including dedicated threat intelligence and incident response teams (e.g., Google's Threat Analysis Group - TAG) to protect the platform.</li><li><strong>Platform Security:</strong> Services are designed with security in mind, from the KVM-based hypervisor that provides workload isolation to features like default encryption for all data at rest.</li></ul><div class='info-box tip'><div class='info-box-header'><i class='fas fa-lightbulb'></i><strong>Shared Fate</strong></div><p>Beyond shared responsibility, Google operates on a 'Shared Fate' model. This means Google is an active partner in your security journey, providing you with secure defaults, best practice blueprints (like the Cloud Foundation Toolkit), and intelligent tools to help you configure and operate securely. Your success and security are tied to theirs.</p></div>",
                            "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Shared Responsibility Framework",
                            "content": "<p>This framework is the cornerstone of cloud security. It is essential to understand what Google secures and what you must secure. The line of responsibility shifts depending on the service model.</p><h3>The Division of Labor:</h3><ul><li><strong>Google is responsible for Security 'OF the Cloud':</strong> They secure the physical datacenter, the network hardware, the hypervisor, and the foundational services that make up the cloud platform. This never changes.</li><li><strong>You are responsible for Security 'IN the Cloud':</strong> Your responsibilities include:<ul><li><strong>Identity & Access:</strong> Who has access to your environment (IAM). You decide who gets to be an Owner or an Editor.</li><li><strong>Data:</strong> The security of the data you store and process. You control its classification, labeling, and encryption (with your own keys if desired).</li><li><strong>Application Code:</strong> The security of the applications you build, including dependencies and vulnerabilities.</li><li><strong>Networking:</strong> Your VPC firewall rules and network configuration. You decide which ports to open.</li><li><strong>OS & Workloads (in IaaS):</strong> Patching and hardening the guest operating system on your Compute Engine VMs.</li></ul></ul>",
                            "image": "https://images.unsplash.com/photo-1510915228340-29c85a43dcfe?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "List Active Security Findings for Your Organization (gcloud CLI)",
                        "language": "bash",
                        "code": "# This command uses the Security Command Center (SCC) API to list all active findings.\n# This is a great first command to run to get a sense of your current security posture.\ngcloud scc findings list YOUR_ORGANIZATION_ID --filter=\"state=\\\"ACTIVE\\\"\" --format=json"
                    },
                    {
                        "title": "List All Assets in a Project (gcloud CLI)",
                        "language": "bash",
                        "code": "# You can't protect what you don't know you have. Cloud Asset Inventory gives you a snapshot of all your resources.\n# This helps you understand your attack surface.\ngcloud asset list --project=\"your-project-id\" --asset-types=\"compute.googleapis.com/Instance,storage.googleapis.com/Bucket\" --format=yaml"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "Under the GCP Shared Responsibility Model for IaaS (e.g., a Compute Engine VM), who is responsible for patching the guest operating system?", "options": ["Google", "The Customer", "The hardware manufacturer", "The internet service provider"], "correct": 1, "explanation": "In an IaaS model, Google secures the hypervisor and physical host, but the customer is fully responsible for everything from the guest OS upwards, including patching, firewall rules, and application security." },
                        { "id": 2, "question": "Google's concept of being an active partner in helping you achieve a strong security posture is called:", "options": ["Shared Responsibility", "Shared Fate", "Security by Default", "Zero Trust"], "correct": 1, "explanation": "'Shared Fate' extends the idea of shared responsibility, positioning Google as a proactive partner in your security outcomes by providing secure-by-default services and blueprints." },
                        { "id": 3, "question": "The fact that all VM-to-VM traffic within a VPC is automatically encrypted by Google is an example of what principle?", "options": ["Shared Responsibility", "Security by Default", "Shared Fate", "Customer Responsibility"], "correct": 1, "explanation": "Google implements many security controls 'by default' to provide a secure starting point for all customers, reducing the chance of common misconfigurations. This is a key part of their security philosophy." }
                    ]
                }
            },
            {
                "id": "lesson-2-gcp-iam",
                "title": "Lesson 2: Google Cloud Identity and Access Management",
                "duration": "150 min",
                "objectives": [
                    "Understand the GCP Resource Hierarchy and IAM policy inheritance",
                    "Differentiate between user accounts, service accounts, and groups for assigning permissions",
                    "Apply Basic, Predefined, and Custom IAM roles following the principle of least privilege",
                    "Analyze and understand an IAM policy binding in its JSON format"
                ],
                "content": {
                    "overview": "Cloud IAM controls who can do what on which Google Cloud resources. It is the most critical security service to master. This lesson provides a deep dive into the three pillars of GCP IAM: the 'who' (identities), the 'can do what' (roles), and the 'on which resource' (the resource hierarchy). A misconfiguration here can lead to a total compromise.",
                    "sections": [
                        {
                            "title": "IAM Concepts and Hierarchy",
                            "content": "<p>GCP uses a hierarchical model for organizing resources, and IAM policies are inherited down this hierarchy. A policy set at a high level cannot be taken away by a policy at a lower level.</p><h3>The Hierarchy:</h3><ol><li><strong>Organization:</strong> The root node, representing your company. Policies applied here apply to everything below it. Granting `Project Creator` here allows a user to create projects in any folder.</li><li><strong>Folders:</strong> Allow you to group projects (e.g., by department like 'Finance' or environment like 'Production'). Policies applied here are inherited by projects within the folder. This is a powerful tool for large-scale policy application.</li><li><strong>Projects:</strong> The primary boundary for resource ownership, billing, and services. Most day-to-day IAM policies are applied at the project level.</li><li><strong>Resources:</strong> Individual resources within a project (e.g., a specific VM instance, a particular storage bucket, or a Pub/Sub topic). You can apply even more granular policies here for very fine-grained control.</li></ol><p>An IAM policy is a collection of bindings that link members to roles. If you grant a user the `roles/compute.viewer` role at the project level, they can view all Compute Engine resources inside that project.</p>",
                            "image": "https://images.unsplash.com/photo-1542744173-8e7e53415bb0?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "IAM Identities (The 'Who')",
                            "content": "<ul><li><strong>User Accounts (Google Account):</strong> An identity for an individual person, such as `employee@yourcompany.com`.</li><li><strong>Service Accounts:</strong> An identity for a non-human workload, like an application or a VM. Service accounts have keys (which should be avoided where possible) and are the primary way applications authenticate to Google Cloud APIs. They are a critical security boundary.</li><li><strong>Google Groups:</strong> A collection of user accounts. Granting a role to a group (e.g., `gcp-network-admins@yourcompany.com`) is the recommended best practice, rather than granting it to individual users. This simplifies management.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1554224155-83e8b835d07a?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "IAM Roles (The 'Can Do What')",
                            "content": "<ul><li><strong>Basic Roles (Owner, Editor, Viewer):</strong> These are the original, legacy, highly permissive roles. You should avoid using these in favor of more granular roles. Granting `Editor` allows a user to create, modify, and delete most resources in a project.</li><li><strong>Predefined Roles:</strong> A large collection of over 200 roles curated by Google for specific services or job functions (e.g., `roles/compute.instanceAdmin`, `roles/storage.objectViewer`). This is where you should always start when granting permissions.</li><li><strong>Custom Roles:</strong> If no predefined role meets your exact needs, you can create a custom role with a specific, curated set of permissions to achieve true least privilege. For example, a role that can only start and stop VMs, but not delete them.</li></ul><div class='info-box warning'><div class='info-box-header'><i class='fas fa-exclamation-triangle'></i><strong>The Danger of Basic Roles</strong></div><p>Granting the `Editor` role at the project level gives that person permission to do almost anything, including deleting VMs and storage buckets. Always use predefined roles to enforce the principle of least privilege.</p></div>",
                            "image": "https://images.unsplash.com/photo-1522252234503-e356032cafd5?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Grant a Predefined Role to a User (gcloud CLI)",
                        "language": "bash",
                        "code": "# This command adds an IAM policy binding to grant a specific role to a specific user on a project.\ngcloud projects add-iam-policy-binding your-project-id \\\n    --member=\"user:bob@example.com\" \\\n    --role=\"roles/compute.instanceAdmin.v1\""
                    },
                    {
                        "title": "View a Project's IAM Policy (gcloud CLI)",
                        "language": "bash",
                        "code": "# See the current policy, which lists all role bindings for the project.\ngcloud projects get-iam-policy your-project-id --format=json"
                    },
                    {
                        "title": "Create a Custom Role for a VM Operator (YAML file)",
                        "language": "yaml",
                        "code": "# my-custom-role.yaml\ntitle: \"Virtual Machine Operator\"\ndescription: \"Custom role that can only start and stop, but not create or delete, VMs.\"\nstage: \"GA\"\nincludedPermissions:\n- compute.instances.start\n- compute.instances.stop\n- compute.instances.get\n\n# Command to create the role from the YAML file:\ngcloud iam roles create vmOperator --project=your-project-id \\\n  --file=my-custom-role.yaml"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "If you grant a user the `Editor` role at the Folder level, what permissions do they have on the Projects inside that Folder?", "options": ["None", "They automatically inherit the Editor role for all Projects in the Folder", "They are granted the Viewer role", "They must request access for each Project"], "correct": 1, "explanation": "IAM policies are inherited down the resource hierarchy. Permissions granted at a parent node (like a Folder) are automatically inherited by all its children (the Projects within it)." },
                        { "id": 2, "question": "What is the primary identity type used by an application running on a Compute Engine VM to authenticate to GCP APIs?", "options": ["A user account", "A Google Group", "A Service Account", "A project ID"], "correct": 2, "explanation": "Service accounts are designed specifically for non-human identities like applications, providing a secure way to authenticate without using a person's long-term credentials." },
                        { "id": 3, "question": "To follow the principle of least privilege, you should always prefer to use _____ over _____.", "options": ["Basic Roles / Predefined Roles", "Predefined Roles / Basic Roles", "Editor Role / Owner Role", "Owner Role / Viewer Role"], "correct": 1, "explanation": "Basic roles (Owner, Editor, Viewer) are extremely broad and should be avoided in production. Predefined roles offer much more granular control, making them the standard for secure configurations." }
                    ]
                }
            },
            {
                "id": "lesson-3-project-organization-security",
                "title": "Lesson 3: Project and Organization Security",
                "duration": "120 min",
                "objectives": [
                    "Use the Organization Policy Service to enforce high-level security constraints",
                    "Apply project-level controls like liens to prevent accidental deletion",
                    "Secure your billing accounts with appropriate IAM roles",
                    "Configure Essential Contacts to receive security notifications"
                ],
                "content": {
                    "overview": "Security in GCP is not just about IAM roles; it's also about setting broad, preventative guardrails at the highest levels of your organization. This lesson covers how to use the Organization Policy Service to enforce security constraints and how to secure your projects and billing as a whole.",
                    "sections": [
                        {
                            "title": "Organization Policy Service",
                            "content": "<p>The Organization Policy Service allows you to set broad constraints on *how* your cloud resources can be configured and used. It is a critical tool for central governance and preventing entire classes of misconfiguration.</p><h3>IAM vs. Organization Policy:</h3><ul><li><strong>IAM asks: 'Who can do what on this resource?'</strong> It's about authorization for identities.</li><li><strong>Organization Policy asks: 'What configurations are allowed for this resource?'</strong> It's about constraints on the resources themselves.</li></ul><h3>Example Constraints:</h3><ul><li><strong>`iam.disableServiceAccountKeyCreation` (CRITICAL):</strong> Disables the creation of static, long-lived JSON keys for service accounts, forcing the use of more secure, temporary credentials.</li><li><strong>`compute.vmExternalIpAccess` (NETWORK):</strong> Restrict VMs from being created with public IP addresses, enforcing a private-by-default stance.</li><li><strong>`storage.uniformBucketLevelAccess` (DATA):</strong> Enforces that all new Cloud Storage buckets use the modern, simpler IAM-based access control model.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1521791136064-7986c2920216?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Project and Billing Security",
                            "content": "<p>Projects are the core organizational unit in GCP.</p><ul><li><strong>Project Liens:</strong> A lien is a property you can place on a project that prevents it from being deleted, even by a project owner. This is a critical safeguard for your production projects to prevent catastrophic accidental deletion.</li><li><strong>Billing Account Security:</strong> Access to billing is controlled by its own set of IAM roles (`roles/billing.admin`, `roles/billing.user`). These should be granted with least privilege. You should also set up billing alerts in Cloud Monitoring to be notified of unexpected cost spikes, which can be an early indicator of a security compromise or resource abuse.</li><li><strong>Essential Contacts:</strong> This service lets you define a curated list of contacts (separate from IAM) who will receive notifications from Google Cloud about important technical and security issues, like a project suspension.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1556742044-15b56a42a033?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Enforce Disabling of Service Account Key Creation (gcloud CLI)",
                        "language": "bash",
                        "code": "# This is one of the most important security policies you can set.\n# First, describe the current policy.\ngcloud resource-manager org-policies describe constraints/iam.disableServiceAccountKeyCreation --project=your-project-id\n\n# Create a policy file to enforce the constraint.\necho \"constraint: constraints/iam.disableServiceAccountKeyCreation\nbooleanPolicy:\n  enforced: true\" > policy.yaml\n\n# Apply the policy to your project.\ngcloud resource-manager org-policies set-policy policy.yaml --project=your-project-id"
                    },
                    {
                        "title": "Place a Lien on a Project (gcloud CLI)",
                        "language": "bash",
                        "code": "# A lien is an indefinite block on project deletion. It must be removed before the project can be deleted.\ngcloud alpha resource-manager liens create --project=\"my-production-project\" \\\n    --restrictions=\"resourcemanager.projects.delete\" \\\n    --reason=\"This is a critical production project and must not be deleted without a formal change request.\""
                    },
                    {
                        "title": "Set an Essential Contact for Security Notifications (gcloud CLI)",
                        "language": "bash",
                        "code": "gcloud essential-contacts create \\\n    --email=security-alerts@yourcompany.com \\\n    --project=your-project-id \\\n    --notification-categories=SECURITY"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the key difference between IAM and the Organization Policy Service?", "options": ["There is no difference", "IAM controls 'who' has access, while Org Policy controls 'what' actions and configurations are allowed on resources", "IAM is for users, Org Policy is for service accounts", "IAM is more secure"], "correct": 1, "explanation": "This is a fundamental concept. IAM is about authorization for principals (who). Org Policy is about constraints on the resources themselves (what)." },
                        { "id": 2, "question": "To prevent the accidental deletion of a critical production project, what should you use?", "options": ["An IAM Owner role", "A custom IAM role", "A Project Lien", "A billing alert"], "correct": 2, "explanation": "A lien is a specific safeguard designed to prevent project deletion. Not even a project Owner can delete a project with a lien on it without first removing the lien." },
                        { "id": 3, "question": "To ensure that security alerts from Google are sent to your security operations team, you should configure:", "options": ["A project lien", "A billing account", "An Organization Policy", "Essential Contacts"], "correct": 3, "explanation": "Essential Contacts is the designated service for managing who receives formal notifications from Google Cloud, ensuring they reach the correct teams." }
                    ]
                }
            },
            {
                "id": "lesson-4-authentication-identity",
                "title": "Lesson 4: Authentication and Identity",
                "duration": "120 min",
                "objectives": [
                    "Set up Cloud Identity as your central identity provider for managing users and groups",
                    "Understand how Google Workspace directories can be used for IAM",
                    "Federate your on-premises Active Directory or other IdP with Google Cloud using Cloud Identity"
                ],
                "content": {
                    "overview": "Cloud Identity is Google's Identity as a Service (IDaaS) solution. It provides the foundation for managing all the identities that will access your GCP resources. This lesson covers how to set it up and how to connect it with your existing identity systems for a seamless single sign-on experience.",
                    "sections": [
                        {
                            "title": "Cloud Identity and Google Workspace",
                            "content": "<p>Cloud Identity provides the core user and group management features needed to manage access to GCP, without requiring the full suite of collaboration tools from Google Workspace.</p><ul><li><strong>`Cloud Identity Free` Edition:</strong> Provides the essential identity services you need to manage users, groups, and SSO for GCP.</li><li><strong>`Cloud Identity Premium` Edition:</strong> A paid service that adds advanced security and device management features, such as automated user provisioning and device management policies.</li></ul><p>If your organization already uses Google Workspace (formerly G Suite) for email and documents, then you already have a full-featured Cloud Identity directory. You can use your existing Workspace users and groups to assign IAM roles in GCP.</p>",
                            "image": "https://images.unsplash.com/photo-1521791136064-7986c2920216?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "External Identity Provider Federation",
                            "content": "<p>Most enterprises already have an identity provider (IdP), like on-premises Active Directory or a cloud-based one like Azure AD or Okta. Federation allows your users to sign in to Google Cloud using their existing corporate credentials. This is the standard for enterprise environments.</p><h3>The Federation Workflow:</h3><ol><li>You establish a trust relationship between your external IdP and Google Cloud (which acts as the Service Provider).</li><li>When a user browses to the GCP console, they are redirected to your IdP's familiar sign-in page.</li><li>They authenticate using their corporate credentials and MFA.</li><li>Upon success, your IdP sends a signed SAML or OIDC token back to Google, asserting the user's identity.</li><li>Google verifies the token and grants the user access based on the IAM roles you have assigned to their identity in GCP.</li></ol><p>This provides a seamless single sign-on (SSO) experience and allows you to manage user lifecycles (creation, deletion) in one central place: your existing IdP.</p>",
                            "image": "https://images.unsplash.com/photo-1556742044-15b56a42a033?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary benefit of federating your on-premises Active Directory with Google Cloud?", "options": ["It costs less", "It allows users to log in to GCP with their existing corporate credentials, enabling single sign-on (SSO) and centralized user management", "It makes your on-premises AD less secure", "It replaces the need for IAM"], "correct": 1, "explanation": "Federation is key for enterprise adoption, as it leverages your existing identity source of truth and provides a seamless, secure login experience for users." },
                        { "id": 2, "question": "True or False: If my company uses Google Workspace, I already have a Cloud Identity directory.", "options": ["True", "False"], "correct": 0, "explanation": "True. A Google Workspace account is a full-featured Cloud Identity account. You can immediately begin using your Workspace users and groups to assign IAM roles in GCP." }
                    ]
                }
            },
            {
                "id": "lesson-5-vpc-network-security",
                "title": "Lesson 5: VPC Security Fundamentals",
                "duration": "150 min",
                "objectives": [
                    "Design a secure Virtual Private Cloud (VPC) with custom subnets for network segmentation",
                    "Implement Private Google Access for instances with no external IPs",
                    "Securely connect VPCs using VPC Network Peering and Shared VPC models"
                ],
                "content": {
                    "overview": "The GCP Virtual Private Cloud (VPC) is a global, software-defined network that provides the foundational security boundary for your resources. This lesson covers the fundamentals of building a secure network foundation, focusing on segmentation, firewalling, and private access to Google services.",
                    "sections": [
                        {
                            "title": "VPC Architecture and Subnets",
                            "content": "<p>A GCP VPC is a global resource, containing subnets in different regions. You should always use 'custom mode' VPCs to define your own IP address ranges and subnets, which gives you full control over your network design.</p><h3>Segmentation Best Practices:</h3><p>The core of secure network design is segmentation. A standard three-tier web application architecture involves:</p><ul><li>A **Web Subnet** containing your load balancers and web servers. This is the only subnet that might allow inbound traffic from the internet (on port 443).</li><li>An **App Subnet** containing your backend application servers. Firewall rules should restrict traffic to this subnet to only come from the Web Subnet.</li><li>A **DB Subnet** containing your database servers. This is the most secure subnet and should only allow traffic from the App Subnet on the specific database port.</li></ul><p>This tiered segmentation limits the blast radius of a compromise.</p>",
                            "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Private Google Access",
                            "content": "<p>If you have a VM with no external IP address (a 'private' instance), how can it reach Google Cloud APIs like BigQuery or Cloud Storage? By default, it can't.</p><p>You can enable 'Private Google Access' on a subnet. This allows VMs in that subnet with no external IPs to connect to the public endpoints of Google Cloud services and APIs by routing through Google's internal private network. This allows you to keep your instances isolated from the internet while still letting them access necessary Google services for tasks like downloading packages or interacting with other services.</p>",
                            "image": "https://images.unsplash.com/photo-1542744173-8e7e53415bb0?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Shared VPC",
                            "content": "<p>For larger organizations, a Shared VPC provides a way to centralize network administration. A central 'host project' owns the VPC and its subnets. Other 'service projects' can then launch resources (like VMs) into the subnets of the host project. This allows a central network security team to manage the firewall and connectivity, while application teams can manage their own instances within those controlled networks.</p>",
                            "image": "https://images.unsplash.com/photo-1521791136064-7986c2920216?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Create a Custom VPC and Tiered Subnets (gcloud CLI)",
                        "language": "bash",
                        "code": "# First, create the custom VPC network\ngcloud compute networks create my-secure-vpc --subnet-mode=custom\n\n# Then, create the subnets in the desired regions\ngcloud compute networks subnets create web-subnet-us-central1 \\\n    --network=my-secure-vpc --range=10.1.1.0/24 --region=us-central1\n\ngcloud compute networks subnets create app-subnet-us-central1 \\\n    --network=my-secure-vpc --range=10.1.2.0/24 --region=us-central1\n\n# Create a database subnet and enable Private Google Access on it\ngcloud compute networks subnets create db-subnet-us-central1 \\\n    --network=my-secure-vpc --range=10.1.3.0/24 --region=us-central1 --enable-private-ip-google-access"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "Are GCP VPCs regional or global resources?", "options": ["Regional", "Global", "Zonal", "Multi-regional"], "correct": 1, "explanation": "A key feature of GCP VPCs is that they are global, meaning a single VPC can contain subnets in multiple different regions worldwide, simplifying multi-region communication." },
                        { "id": 2, "question": "What does enabling 'Private Google Access' on a subnet allow?", "options": ["It gives VMs in that subnet public IP addresses", "It allows VMs with no external IPs to reach Google Cloud APIs over Google's private network", "It blocks all traffic to Google", "It encrypts the subnet"], "correct": 1, "explanation": "Private Google Access is the primary mechanism for allowing private instances to communicate with the Google service ecosystem without requiring an internet gateway." },
                        { "id": 3, "question": "Which networking model allows a central project to own the VPCs and share subnets with other service projects?", "options": ["VPC Peering", "Shared VPC", "Cloud Interconnect", "VPN"], "correct": 1, "explanation": "Shared VPC is the recommended model for large enterprises, as it centralizes network control and security policy." }
                    ]
                }
            },
            {
                "id": "lesson-6-firewall-rules",
                "title": "Lesson 6: Firewall Rules and Security",
                "duration": "120 min",
                "objectives": [
                    "Implement stateful VPC firewall rules for fine-grained access control",
                    "Apply hierarchical firewall policies for organizational governance",
                    "Use network tags and service accounts to dynamically apply firewall rules",
                    "Use Firewall Insights to analyze and optimize firewall rules"
                ],
                "content": {
                    "overview": "GCP's distributed firewall is a core component of network security. This lesson provides a deep dive into creating effective firewall rules, using network tags for scalability, enforcing high-level policies with hierarchical firewalls, and using Firewall Insights to detect misconfigurations.",
                    "sections": [
                        {
                            "title": "VPC Firewall Rules",
                            "content": "<p>GCP firewall rules are stateful. This means if you allow an ingress (inbound) connection, the return egress (outbound) traffic for that established connection is automatically allowed, regardless of egress rules.</p><h3>Rule Components:</h3><ul><li><strong>Direction:</strong> `Ingress` or `Egress`.</li><li><strong>Action on match:</strong> `Allow` or `Deny`.</li><li><strong>Source/Destination:</strong> Can be an IP CIDR range, another network tag, or a service account.</li><li><strong>Protocol/Ports:</strong> e.g., `tcp:443`, `icmp`.</li><li><strong>Priority:</strong> A number from 0 to 65535. Lower numbers have higher priority.</li></ul><p>The implied rules in every VPC are a `priority 65535 allow all` egress rule and a `priority 65535 deny all` ingress rule. This means you must explicitly create `allow` rules for any inbound traffic you want to permit.</p>",
                            "image": "https://images.unsplash.com/photo-1544890225-2fde1e46f71b?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Network Tags and Service Accounts for Targeting",
                            "content": "<p>Instead of creating rules based on static IP addresses of VMs, it is much more scalable and secure to use network tags or service accounts as targets and sources.</p><ul><li><strong>Network Tags:</strong> You can apply a string tag (e.g., `web-server`) to a group of VMs. You can then create a firewall rule that says 'Allow ingress traffic on `tcp:443` from any source to any VM with the tag `web-server`'.</li><li><strong>Service Accounts:</strong> An even more secure and identity-based method. You can create a rule that says 'Allow ingress traffic on `tcp:8080` from any VM with the source service account `frontend-sa` to any VM with the destination service account `backend-sa`'. This provides strong micro-segmentation based on workload identity, not just network labels.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1516321497487-e288fb19713f?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Firewall Insights",
                            "content": "<p>Firewall Insights is a service that uses machine learning to analyze your firewall usage and provide recommendations. It can find things like:</p><ul><li><strong>Overly permissive rules:</strong> For example, it might identify a rule that allows SSH from `0.0.0.0/0` and has been hit by a very small number of IP addresses, and recommend you tighten the source range.</li><li><strong>Shadowed rules:</strong> A rule that will never be hit because a higher-priority rule completely covers its conditions.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1551288049-bebda4e38f71?w=800&h=400&fit-crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Create an Ingress Allow Firewall Rule using Tags (gcloud CLI)",
                        "language": "bash",
                        "code": "# This rule allows ingress TCP traffic on port 443 from any IP to any VM with the 'https-server' tag.\ngcloud compute firewall-rules create allow-https-ingress \\\n    --network=my-secure-vpc \\\n    --allow=tcp:443 \\\n    --direction=INGRESS \\\n    --priority=1000 \\\n    --source-ranges=0.0.0.0/0 \\\n    --target-tags=https-server"
                    },
                    {
                        "title": "Create a Deny Egress Rule for a Specific IP (gcloud CLI)",
                        "language": "bash",
                        "code": "# Create a high-priority (low number) egress rule to explicitly block outbound traffic to a known malicious IP.\ngcloud compute firewall-rules create deny-egress-to-bad-ip \\\n    --network=my-secure-vpc \\\n    --action=DENY \\\n    --rules=all \\\n    --direction=EGRESS \\\n    --priority=900 \\\n    --destination-ranges=203.0.113.10/32"
                    },
                    {
                        "title": "Create a Rule Using Service Accounts for Micro-segmentation",
                        "language": "bash",
                        "code": "# This rule allows the frontend app to talk to the backend app on port 8080.\n# It's an identity-based control, more secure than tags or IPs.\ngcloud compute firewall-rules create frontend-to-backend-app \\\n    --network=my-secure-vpc \\\n    --allow=tcp:8080 \\\n    --source-service-accounts=frontend-sa@my-project.iam.gserviceaccount.com \\\n    --target-service-accounts=backend-sa@my-project.iam.gserviceaccount.com"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "GCP VPC firewall rules are _____, meaning if you allow an ingress connection, the return traffic is automatically allowed.", "options": ["stateless", "stateful"], "correct": 1, "explanation": "Stateful filtering is a key feature of GCP's firewall, simplifying rule creation as you don't need to create a corresponding outbound rule for established connections." },
                        { "id": 2, "question": "To dynamically apply a firewall rule to a group of web server VMs, which is the most scalable, cloud-native approach?", "options": ["Create a separate rule for each VM's static IP address", "Apply a network tag like 'web-server' to the VMs and use that tag as the target in a single firewall rule", "Use MAC addresses in the rule", "Allow traffic from all sources to all VMs"], "correct": 1, "explanation": "This allows for a much more scalable and cloud-native approach to firewall management, as you don't have to update rules every time a VM's IP address changes or a new VM is added." },
                        { "id": 3, "question": "A firewall rule with priority 100 will be evaluated _______ a rule with priority 1000.", "options": ["after", "at the same time as", "before", "only if"], "correct": 2, "explanation": "In GCP firewalls, lower numbers have higher priority, so the rule with priority 100 will be matched and applied first." }
                    ]
                }
            },
            {
                "id": "lesson-7-load-balancer",
                "title": "Lesson 7: Cloud Load Balancing Security",
                "duration": "120 min",
                "objectives": [
                    "Select the correct load balancer for a given security requirement",
                    "Terminate SSL/TLS traffic using Google-managed certificates for centralized management",
                    "Secure backend services to ensure they only accept traffic from the load balancer",
                    "Use Identity-Aware Proxy (IAP) to implement Zero Trust access to applications"
                ],
                "content": {
                    "overview": "Cloud Load Balancing is not just for scalability; it's a critical component of your security architecture that acts as the front door to your application. This lesson covers the security features of GCP's different load balancers, with a focus on SSL termination, backend security, and the powerful Identity-Aware Proxy.",
                    "sections": [
                        {
                            "title": "SSL/TLS Termination and Policies",
                            "content": "<p>You should terminate user TLS connections at the global external load balancer. This provides several critical security benefits:</p><ul><li><strong>Centralized Certificate Management:</strong> You can provision and manage Google-managed SSL certificates in one central place. These certificates are automatically renewed by Google, removing a significant operational burden.</li><li><strong>Offload SSL Processing:</strong> Your backend VMs don't have to spend CPU cycles on expensive encryption and decryption operations.</li><li><strong>Stronger Security:</strong> The load balancer allows you to create and enforce a central SSL Policy. An SSL Policy lets you define a minimum TLS version (e.g., TLS 1.2) and a specific set of modern, secure cipher suites, ensuring weak protocols and ciphers are not used to connect to your application.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1544890225-2fde1e46f71b?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Identity-Aware Proxy (IAP)",
                            "content": "<p>IAP is a Zero Trust security service that lets you manage access to your applications based on a user's identity and context, rather than their network location. It is a game-changer for protecting internal applications without the hassle of a traditional VPN.</p><h3>How IAP Works:</h3><ol><li>You deploy your internal web application on a VM or GKE.</li><li>You place this application behind an external HTTPS Load Balancer and enable IAP on the load balancer's backend service.</li><li>In IAM, you grant a user or group the `IAP-secured Web App User` role for your application.</li><li>When a user tries to access the public URL, IAP intercepts the request.</li><li>It forces the user to authenticate with their Google Identity (which could be federated with your corporate IdP).</li><li>IAP then checks if that authenticated user has the necessary IAM role.</li><li>Only if the user is authenticated and authorized does IAP let the request pass through to your application.</li></ol>",
                            "image": "https://images.unsplash.com/photo-1556742044-15b56a42a033?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Create a Google-Managed SSL Certificate",
                        "language": "bash",
                        "code": "# Certificates are automatically provisioned and renewed when attached to a load balancer.\ngcloud compute ssl-certificates create my-ssl-cert \\\n    --domains=app.yourdomain.com \\\n    --global"
                    },
                    {
                        "title": "Create a Secure SSL Policy",
                        "language": "bash",
                        "code": "# Create an SSL policy that enforces a minimum of TLS 1.2 and a modern cipher profile.\ngcloud compute ssl-policies create my-secure-tls-policy \\\n    --profile=MODERN \\\n    --min-tls-version=1.2"
                    },
                    {
                        "title": "Enable IAP for a Backend Service",
                        "language": "bash",
                        "code": "# Assuming you have already gone through the OAuth consent screen setup.\ngcloud compute backend-services update my-app-backend-service \\\n    --iap=enabled"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary function of Identity-Aware Proxy (IAP)?", "options": ["To act as a firewall", "To load balance traffic", "To enable identity-based, Zero Trust access to applications, often replacing the need for a VPN", "To scan for vulnerabilities"], "correct": 2, "explanation": "IAP is a core component of Google's BeyondCorp (Zero Trust) offering, shifting access control from the network perimeter to the individual user identity, which is verified for every request." },
                        { "id": 2, "question": "When using a load balancer, your backend VM's firewall rule should be configured to:", "options": ["Allow traffic from all sources (0.0.0.0/0)", "Deny all traffic", "Allow traffic only from the Google Cloud health check IP ranges and the load balancer's IP range", "Allow all outbound traffic"], "correct": 2, "explanation": "This is a critical defense-in-depth step to ensure that users cannot bypass the load balancer (and your WAF/IAP controls) and connect directly to your backend instances." },
                        { "id": 3, "question": "An SSL Policy on a Google Cloud load balancer allows you to enforce what?", "options": ["The cost of the load balancer", "The geographic location of users", "The minimum TLS version and a specific set of strong cipher suites", "The type of backend instances"], "correct": 2, "explanation": "SSL Policies provide centralized, fine-grained control over the TLS/SSL configuration, ensuring that weak, legacy protocols are not used to connect to your application." }
                    ]
                }
            },
            {
                "id": "lesson-8-cloud-armor",
                "title": "Lesson 8: Cloud Armor and DDoS Protection",
                "duration": "120 min",
                "objectives": [
                    "Deploy Cloud Armor security policies to protect applications behind a global load balancer",
                    "Configure pre-built and custom WAF rules to mitigate risks like the OWASP Top 10",
                    "Implement rate limiting to defend against application-layer DoS and abuse",
                    "Understand how Cloud Armor helps mitigate DDoS attacks"
                ],
                "content": {
                    "overview": "Cloud Armor is Google Cloud's Web Application Firewall (WAF) and DDoS mitigation service. It works in conjunction with the global external HTTP(S) Load Balancer to protect your applications from attacks at the very edge of Google's global network, as close to the user as possible. This lesson covers how to configure and deploy Cloud Armor for robust application protection.",
                    "sections": [
                        {
                            "title": "Cloud Armor Security Policies",
                            "content": "<p>A Cloud Armor security policy is a set of rules that are evaluated for traffic hitting your external load balancer. You can configure rules to allow, deny, or rate-limit traffic based on a rich set of attributes. This provides a flexible way to build your application's security posture.</p><h3>Rule Attributes:</h3><ul><li><strong>Source IP CIDR range:</strong> Block known bad actors or allow only trusted ranges.</li><li><strong>Geographic origin (country code):</strong> Block or allow traffic based on the user's country of origin.</li><li><strong>Request headers:</strong> Filter based on headers like `User-Agent`, `Referer`, etc.</li><li><strong>Request path & method:</strong> Apply rules to specific parts of your application, like `/login`.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1605379399642-870262d3d051?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "WAF Rule Configuration",
                            "content": "<p>Cloud Armor includes pre-configured WAF rules that you can enable to protect against common application-layer attacks. These rules are based on the OWASP ModSecurity Core Rule Set and are tuned by Google's security experts.</p><h3>Pre-configured Rules:</h3><ul><li><strong>SQL Injection (SQLi):</strong> Detects common patterns used to exploit SQL databases via web input.</li><li><strong>Cross-Site Scripting (XSS):</strong> Detects attempts to inject malicious scripts into your web pages.</li><li><strong>Remote Code Execution (RCE), Local File Inclusion (LFI):</strong> Detects patterns associated with executing code or including local files on your server.</li></ul><p>You can deploy these rules in 'preview' mode first, which logs potential violations without blocking them, allowing you to tune for false positives before moving to an enforcement (`deny`) action.</p>",
                            "image": "https://images.unsplash.com/photo-1544197150-b99a5808e7ee?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Rate Limiting",
                            "content": "<p>Rate limiting is a critical defense against application-layer Denial of Service attacks, credential stuffing, and other forms of abuse. Cloud Armor provides two main types of rate limiting:</p><ul><li><strong>`throttle` action:</strong> Temporarily block a client (e.g., an IP address) once they exceed a defined request threshold for a set period.</li><li><strong>`rate-based-ban` action:</strong> Ban a client for a longer duration once they exceed a threshold, optionally redirecting them to a different endpoint.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1599691888286-93e433f064b8?w=800&h=400&fit-crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Create a Rate-Limiting Rule (gcloud CLI)",
                        "language": "bash",
                        "code": "# This rule will throttle any single IP that sends more than 100 requests in 60 seconds.\ngcloud compute security-policies rules create 1000 \\\n    --security-policy my-webapp-policy \\\n    --expression \"true\" \\\n    --action \"throttle\" \\\n    --rate-limit-threshold-count 100 \\\n    --rate-limit-threshold-interval-sec 60 \\\n    --conform-action \"allow\" \\\n    --exceed-action \"deny-429\""
                    },
                    {
                        "title": "Enable a Pre-configured WAF Rule (gcloud CLI)",
                        "language": "bash",
                        "code": "# Enable the SQL Injection rule set in preview mode to start.\ngcloud compute security-policies rules update 2000 \\\n    --security-policy my-webapp-policy \\\n    --expression \"evaluatePreconfiguredExpr('sqli-stable')\" \\\n    --action \"deny-403\" \\\n    --preview"
                    },
                    {
                        "title": "Attach the Policy to a Backend Service (gcloud CLI)",
                        "language": "bash",
                        "code": "# A policy does nothing until it's attached to a backend service that's part of a load balancer.\ngcloud compute backend-services update my-backend-service \\\n    --security-policy my-webapp-policy \\\n    --global"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "Google Cloud Armor primarily functions as a what?", "options": ["Network Firewall", "Web Application Firewall (WAF) and DDoS Mitigation Service", "SIEM", "Key Management Service"], "correct": 1, "explanation": "Cloud Armor operates at Layer 7 to protect web applications and services from both application-level attacks (like XSS) and volumetric DDoS attacks, integrated directly with the Global External Load Balancer." },
                        { "id": 2, "question": "To test a new WAF rule without actually blocking legitimate users, you should deploy it in which mode?", "options": ["Deny mode", "Allow mode", "Preview mode", "Disabled mode"], "correct": 2, "explanation": "Preview mode is a critical feature that allows you to evaluate a rule's impact and tune for false positives by logging potential matches without taking any blocking action." },
                        { "id": 3, "question": "To protect your login page from a credential stuffing attack, which Cloud Armor feature would be most effective?", "options": ["Geo-blocking", "A rule with a rate-limiting action", "An SSL policy", "A custom firewall rule"], "correct": 1, "explanation": "Rate limiting is the specific defense against this type of abuse, as it can block an IP address that is attempting thousands of logins in a short period of time." }
                    ]
                }
            },
            {
                "id": "lesson-9-cloud-storage",
                "title": "Lesson 9: Cloud Storage Security",
                "duration": "120 min",
                "objectives": [
                    "Differentiate between and apply fine-grained (ACL) and uniform bucket-level access control",
                    "Prevent accidental public data exposure by enforcing public access prevention",
                    "Securely delegate temporary access using signed URLs",
                    "Understand how to log and monitor access to storage buckets"
                ],
                "content": {
                    "overview": "Cloud Storage buckets are a common source of data leaks due to misconfiguration. This lesson is dedicated to the multi-layered security model for Cloud Storage, emphasizing the modern 'uniform bucket-level access' model and preventative controls to stop public data exposure before it can happen.",
                    "sections": [
                        {
                            "title": "Uniform Bucket-Level Access",
                            "content": "<p>Cloud Storage has two access control models. The modern best practice is to use the simpler, more secure model.</p><ul><li><strong>Fine-grained (Legacy):</strong> Uses a combination of IAM roles (which apply to all objects in the bucket) and old-style Access Control Lists (ACLs) that can be applied to individual objects. This model is complex and can lead to unexpected permissions.</li><li><strong>Uniform Bucket-Level Access (Recommended):</strong> This is the modern best practice. It **disables** ACLs completely for the bucket and all objects within it. The *only* way to grant access is through Cloud IAM roles. This provides a single, simple, and consistent access control system that is much easier to manage and audit. You should enable this on all new buckets.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1542382156942-0268579cf259?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Public Access Prevention",
                            "content": "<p>To provide a strong safeguard against accidental data exposure, GCP has an organization-level policy constraint (`constraints/storage.publicAccessPrevention`) that can be enforced. When this constraint is enforced on a project or folder, it becomes impossible for *any* user, regardless of their IAM permissions, to make a storage bucket public. This is a powerful, preventative guardrail that should be enabled in almost all cases.</p>",
                            "image": "https://images.unsplash.com/photo-1518932945647-7a1c969f8be2?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Signed URLs",
                            "content": "<p>A signed URL is a URL that provides limited, time-bound permission to perform an action (like read or write an object). You generate a signed URL using credentials from a service account and give it to a client. They can then use that URL for a short period. This is the standard, secure way to grant temporary, delegated access to a specific object without needing the client to have a Google account or permanent credentials.</p>",
                            "image": "https://images.unsplash.com/photo-1599373922312-5b9340d8a5a5?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Enable Uniform Bucket-Level Access (gcloud CLI)",
                        "language": "bash",
                        "code": "# This disables object ACLs for the bucket, making IAM authoritative.\ngcloud storage buckets update gs://my-secure-bucket --uniform-bucket-level-access"
                    },
                    {
                        "title": "Enable Public Access Prevention on a Project (gcloud CLI)",
                        "language": "bash",
                        "code": "# Creates a policy file to enforce the constraint\necho \"constraint: constraints/storage.publicAccessPrevention\nbooleanPolicy:\n  enforced: true\" > pap_policy.yaml\n\n# Apply the organization policy to the project\ngcloud resource-manager org-policies set-policy pap_policy.yaml --project=your-project-id"
                    },
                    {
                        "title": "Generate a Signed URL for a File (Python)",
                        "language": "python",
                        "code": "import datetime\nfrom google.cloud import storage\n\ndef generate_download_signed_url_v4(bucket_name, blob_name):\n    storage_client = storage.Client()\n    bucket = storage_client.bucket(bucket_name)\n    blob = bucket.blob(blob_name)\n\n    # Generate a signed URL that expires in 15 minutes.\n    url = blob.generate_signed_url(\n        version=\"v4\",\n        expiration=datetime.timedelta(minutes=15),\n        method=\"GET\",\n    )\n    return url"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the recommended, modern access control model for Cloud Storage buckets?", "options": ["Fine-grained access with ACLs", "Making the bucket public", "Uniform bucket-level access (which uses IAM exclusively)", "Storing an access key in the bucket"], "correct": 2, "explanation": "Uniform bucket-level access simplifies security by disabling legacy ACLs and making IAM the single, auditable source of truth for all permissions on the bucket and its objects." },
                        { "id": 2, "question": "To prevent anyone (even a project owner) from making a Cloud Storage bucket public, what should you use?", "options": ["An IAM role", "A signed URL", "The `storage.publicAccessPrevention` organization policy constraint", "A firewall rule"], "correct": 2, "explanation": "This organization policy acts as a powerful, preventative guardrail that enforces a critical security best practice across your projects, preventing a common source of data breaches." },
                        { "id": 3, "question": "You need to grant a client application temporary, read-only access to a specific file in a private bucket for 1 hour. What is the most secure and appropriate tool for this?", "options": ["Making the entire bucket public", "Creating a new IAM user for the application", "Generating a time-limited Signed URL", "Putting the file on a public website"], "correct": 2, "explanation": "Signed URLs are specifically designed for this delegated, short-term access scenario, providing secure and auditable access without long-term credentials." }
                    ]
                }
            },
            {
                "id": "lesson-10-kms",
                "title": "Lesson 10: Cloud KMS and Encryption",
                "duration": "120 min",
                "objectives": [
                    "Understand the Cloud Key Management Service (KMS) hierarchy and key types",
                    "Implement Customer-Managed Encryption Keys (CMEK) for GCP services",
                    "Grasp the concept of envelope encryption and its benefits",
                    "Explore Cloud HSM for FIPS 140-2 Level 3 protection"
                ],
                "content": {
                    "overview": "Cloud KMS is the central service for managing cryptographic keys in GCP. This lesson covers how to use KMS to manage your own encryption keys and integrate them with other GCP services to protect your data at rest. Properly managing keys is the foundation of any data protection strategy.",
                    "sections": [
                        {
                            "title": "Cloud KMS Concepts and Hierarchy",
                            "content": "<p>Cloud KMS is a centralized, global service for managing cryptographic keys.</p><h3>The Hierarchy:</h3><ul><li><strong>Key Ring:</strong> A logical grouping of keys. A key ring exists in a specific geographic location (e.g., `us-central1`). You can set IAM policies on a key ring to manage permissions for all keys within it.</li><li><strong>Key:</strong> A named object that represents a cryptographic key. A key has a purpose (e.g., `ENCRYPT_DECRYPT` for symmetric keys, or `ASYMMETRIC_SIGN` for signing keys) and a protection level.</li><li><strong>Key Version:</strong> Each key can have multiple versions. When you 'rotate' a key, KMS creates a new version and makes it the primary version for new encryptions. Old versions are kept enabled so that data encrypted with them can still be decrypted. This enables seamless key rotation.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1599373922312-5b9340d8a5a5?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Customer-Managed Encryption Keys (CMEK)",
                            "content": "<p>By default, most GCP services encrypt data at rest using Google-managed keys. CMEK allows you to use a key that you control in Cloud KMS to protect your data in other services (like Cloud Storage, BigQuery, or Compute Engine). </p><p>To enable CMEK, you grant the service's own service account the `roles/cloudkms.cryptoKeyEncrypterDecrypter` role on your specific key. The service can then use your key for envelope encryption. This gives you full control over the key, including the ability to rotate it or revoke access at any time. If you revoke access, the data becomes inaccessible, even to Google.</p>",
                            "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Create a Key Ring and a Key (gcloud CLI)",
                        "language": "bash",
                        "code": "# Create the key ring in a specific location\ngcloud kms keyrings create my-app-keyring --location=us-central1\n\n# Create a symmetric encryption/decryption key within that key ring\ngcloud kms keys create my-database-key \\\n    --keyring=my-app-keyring \\\n    --location=us-central1 \\\n    --purpose=encryption"
                    },
                    {
                        "title": "Set an Automatic Rotation Schedule (gcloud CLI)",
                        "language": "bash",
                        "code": "# Rotate the key every 90 days (7776000 seconds)\ngcloud kms keys set-rotation-schedule my-database-key \\\n    --keyring=my-app-keyring \\\n    --location=us-central1 \\\n    --rotation-period=7776000s \\\n    --next-rotation-time=\"YYYY-MM-DDTHH:MM:SSZ\""
                    },
                    {
                        "title": "Encrypt Data with the KMS API (gcloud CLI)",
                        "language": "bash",
                        "code": "# This demonstrates using the KMS service directly to encrypt a file\ngcloud kms encrypt \\\n    --key=my-database-key \\\n    --keyring=my-app-keyring \\\n    --location=us-central1 \\\n    --plaintext-file=my-secret.txt \\\n    --ciphertext-file=my-secret.txt.encrypted"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What does CMEK stand for and what does it allow you to do?", "options": ["Cloud Managed Encryption Keys, which are fully managed by Google.", "Customer Managed Encryption Keys, which allows you to use your own KMS key to protect data in other GCP services.", "Continuous Monitoring and Event Keys for logging.", "Compute Machine Engine Keys for VMs."], "correct": 1, "explanation": "CMEK is the feature that provides you, the customer, with control over the keys used by services like BigQuery and Cloud Storage, which is a key requirement for many compliance frameworks." },
                        { "id": 2, "question": "What happens when you 'rotate' a key in Cloud KMS?", "options": ["The existing key material is changed, breaking all old encryptions.", "A new key 'version' is created and set as the primary for new encryptions, while the old version is kept to decrypt old data.", "The key is deleted permanently.", "The key is exported for you to store on-premises."], "correct": 1, "explanation": "KMS's versioning system enables seamless key rotation without requiring a massive data re-encryption effort." },
                        { "id": 3, "question": "For the highest level of assurance, meeting FIPS 140-2 Level 3, you would use which KMS feature?", "options": ["Standard software-backed keys", "Cloud HSM (Hardware Security Module)", "External Key Manager", "Default encryption"], "correct": 1, "explanation": "Cloud HSM is the premium offering for organizations that require the high security and compliance guarantees of a dedicated hardware security module to protect their keys." }
                    ]
                }
            },
            {
                "id": "lesson-11-dlp-deep-dive",
                "title": "Lesson 11: Data Loss Prevention",
                "duration": "120 min",
                "objectives": [
                    "Use Cloud DLP to automatically scan for and classify sensitive data in storage and databases",
                    "Understand and use built-in and custom infoTypes for precise data detection",
                    "Apply de-identification techniques like masking, tokenization, and redaction",
                    "Create DLP templates for reusable and consistent scanning configurations"
                ],
                "content": {
                    "overview": "Cloud Data Loss Prevention (DLP) is a fully managed service designed to help you discover, classify, and protect your most sensitive data. This lesson covers how to use DLP to find sensitive data in services like Cloud Storage and BigQuery and how to de-identify it to reduce risk.",
                    "sections": [
                        {
                            "title": "Sensitive Data Discovery with infoTypes",
                            "content": "<p>You can configure a DLP job to scan a repository like a Cloud Storage bucket or a BigQuery table. DLP will inspect the data and use a large library of built-in pattern detectors called 'infoTypes' to find sensitive data.</p><h3>InfoTypes:</h3><p>An infoType is a definition for a specific type of sensitive data. DLP has over 150 built-in infoTypes for different geographies.</p><ul><li><strong>Globally common types:</strong> `CREDIT_CARD_NUMBER`, `EMAIL_ADDRESS`, `PHONE_NUMBER`.</li><li><strong>Country-specific types:</strong> `US_SOCIAL_SECURITY_NUMBER`, `UK_DRIVERS_LICENSE_NUMBER`, `FRENCH_PASSPORT`.</li></ul><p>If a built-in infoType isn't enough, you can create your own `CustomInfoTypes` using large dictionaries of words, smaller keyword lists, or complex regular expressions.</p>",
                            "image": "https://images.unsplash.com/photo-1542382156942-0268579cf259?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "De-identification Techniques",
                            "content": "<p>DLP can not only find sensitive data, but it can also de-identify it. This is the process of redacting, masking, or tokenizing data to reduce its sensitivity while preserving its utility. For example, you can create a de-identified copy of a production database for use in a development environment where developers don't need to see real PII.</p><h3>Common Transformations:</h3><ul><li><strong>Redaction:</strong> Completely remove the sensitive data.</li><li><strong>Masking:</strong> Replace a portion of the data with a character, like `(555) XXX-1234`.</li><li><strong>Tokenization:</strong> Replaces the sensitive data with a non-sensitive, format-preserving token. The token can be reversed to the original data only by users with specific permissions, using a key.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1555099962-4199c345e541?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Run a DLP Scan on a GCS Bucket (gcloud CLI)",
                        "language": "bash",
                        "code": "gcloud dlp jobs create inspect \\ \n    --storage-config='cloudStorageOptions={fileSet={url=\"gs://my-sensitive-data-bucket/*\"}}' \\\n    --info-types='PERSON_NAME,CREDIT_CARD_NUMBER,US_SOCIAL_SECURITY_NUMBER' \\\n    --location='global' \\\n    --async"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary function of Cloud DLP?", "options": ["To act as a firewall", "To discover, classify, and de-identify sensitive data", "To manage user identities", "To scan for software vulnerabilities"], "correct": 1, "explanation": "DLP is a data-centric security service focused on finding and protecting your most sensitive information assets, helping you understand where your risk is." },
                        { "id": 2, "question": "In Cloud DLP, what is an 'infoType'?", "options": ["A type of firewall rule", "A type of user account", "A detector for a specific type of sensitive data, like a credit card number", "A type of storage bucket"], "correct": 2, "explanation": "InfoTypes are the core detection mechanism in DLP, providing a rich, pre-built library of patterns for identifying PII, financial data, credentials, and more." },
                        { "id": 3, "question": "The process of replacing sensitive data with a non-sensitive but format-preserving substitute is called:", "options": ["Redaction", "Masking", "Tokenization", "Encryption"], "correct": 2, "explanation": "Tokenization (or pseudonymization) is a powerful de-identification technique because it allows systems to still use the data for analytics while protecting the sensitive source information." }
                    ]
                }
            },
            {
                "id": "lesson-12-secret-manager",
                "title": "Lesson 12: Secret Manager",
                "duration": "120 min",
                "objectives": [
                    "Use Secret Manager to securely store and manage application secrets at scale",
                    "Configure fine-grained access control using IAM roles at the secret and project levels",
                    "Implement secret versioning for controlled updates and rollbacks",
                    "Automate secret rotation using Pub/Sub notifications and Cloud Functions"
                ],
                "content": {
                    "overview": "Secret Manager is Google Cloud's dedicated service for storing and managing sensitive application secrets like API keys, passwords, and certificates. This lesson covers its core features and how to integrate it securely with your applications for a modern, password-less security posture.",
                    "sections": [
                        {
                            "title": "Secret Storage and Versioning",
                            "content": "<p>Secret Manager provides a global, secure, and highly available place to store your secrets. Its architecture is built for security and manageability.</p><ul><li><strong>Secrets:</strong> A 'secret' is a logical container for its versions. You apply IAM policies at the secret level.</li><li><strong>Versions:</strong> When you update the value of a secret, you are actually creating a new 'version' of that secret. Each version is immutable. Your application can be configured to retrieve a specific, numbered version (e.g., for pinning) or to always retrieve the 'latest' version, which is the most common pattern. This versioning allows for safe, auditable updates and easy rollbacks if a new secret causes problems.</li><li><strong>State:</strong> Each version has a state (`Enabled`, `Disabled`, `Destroyed`). Disabling a version makes it inaccessible without deleting it, providing a fast way to turn off access if a compromise is suspected.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1599373922312-5b9340d8a5a5?w=800&h=400&fit-crop"
                        },
                        {
                            "title": "Rotation Automation",
                            "content": "<p>Manually rotating secrets is an operational burden and is often neglected. Secret Manager can automate this process.</p><h3>The Automation Workflow:</h3><ol><li>You can set an expiration time for a secret.</li><li>Secret Manager can then be configured to send a message to a Pub/Sub topic a specified amount of time before the secret expires.</li><li>A Cloud Function can be subscribed to this topic. When it receives the message, its code will execute the rotation logic: generate a new credential (e.g., by calling a database API to change a password), add this new password as a new version to Secret Manager, and optionally disable the old version.</li></ol>",
                            "image": "https://images.unsplash.com/photo-1542708944-9721d234a413?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Create a Secret and Add a Version (gcloud CLI)",
                        "language": "bash",
                        "code": "# Create the parent secret container with automatic replication\ngcloud secrets create my-database-password --replication-policy=\"automatic\"\n\n# Add the first version of the secret value.\n# NOTE: Using a file (`--data-file=-`) and piping the secret in via printf prevents\n# the secret value from being logged in your shell's command history, which is a security best practice.\nprintf \"SuperS3cr3t-P@ssw0rd-v1\" | gcloud secrets versions add my-database-password --data-file=-"
                    },
                    {
                        "title": "Access a Secret Version (gcloud CLI)",
                        "language": "bash",
                        "code": "# This command accesses the latest version of the secret and prints its value.\ngcloud secrets versions access latest --secret=\"my-database-password\""
                    },
                    {
                        "title": "Grant Access to a Service Account (gcloud CLI)",
                        "language": "bash",
                        "code": "# Grant the specific role that allows a service account to *only* access secret values.\ngcloud secrets add-iam-policy-binding my-database-password \\\n    --member=\"serviceAccount:my-app-sa@your-project-id.iam.gserviceaccount.com\" \\\n    --role=\"roles/secretmanager.secretAccessor\""
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "When you update a secret's value in Secret Manager, what actually happens?", "options": ["The existing secret is overwritten", "A new, immutable 'version' of the secret is created and set as the latest", "The secret is deleted", "The secret is emailed to you"], "correct": 1, "explanation": "The versioning system is a core feature that provides a full audit trail of changes and allows for safe updates and quick rollbacks." },
                        { "id": 2, "question": "To allow a Cloud Function to read a specific secret, you should grant its service account which IAM role on that secret?", "options": ["`roles/owner`", "`roles/editor`", "`roles/secretmanager.admin`", "`roles/secretmanager.secretAccessor`"], "correct": 3, "explanation": "Following the principle of least privilege, the `secretAccessor` role grants the absolute minimum permission needed: the ability to read the secret's value and nothing more." },
                        { "id": 3, "question": "The recommended way to automate secret rotation is by using Secret Manager notifications with what two other services?", "options": ["Compute Engine and Cloud Storage", "Cloud SQL and BigQuery", "Pub/Sub and Cloud Functions", "VPC and Cloud Armor"], "correct": 2, "explanation": "This event-driven, serverless pattern (Secret Manager -> Pub/Sub -> Cloud Function) is the standard and most efficient way to build custom rotation logic." }
                    ]
                }
            },
            {
                "id": "lesson-13-logging",
                "title": "Lesson 13: Cloud Logging",
                "duration": "150 min",
                "objectives": [
                    "Understand the architecture of Cloud Logging, including log routers and sinks",
                    "Configure log sinks to export logs to Cloud Storage, BigQuery, and Pub/Sub for long-term storage and analysis",
                    "Use Log-Based Metrics and Alerts for real-time security event notification",
                    "Differentiate between and analyze the four types of audit logs"
                ],
                "content": {
                    "overview": "Cloud Logging is the centralized, real-time log management service for Google Cloud. This lesson covers how to configure logging for comprehensive visibility, how to route logs to different destinations for security analytics and long-term archival, and how to create alerts based on specific log entries to detect suspicious activity.",
                    "sections": [
                        {
                            "title": "Log Router and Sinks",
                            "content": "<p>All logs in GCP (from services, VMs, and applications) flow through a central service called the Log Router. The Log Router checks each log entry against a set of configured rules, called 'sinks', to determine where the log entry should be sent. This provides a powerful, centralized way to manage your log flow.</p><h3>The Log Routing Workflow:</h3><ul><li><strong>Source:</strong> A log is generated by a GCP service (e.g., an audit log from a VM creation).</li><li><strong>Log Router:</strong> The log entry arrives at the central Log Router for your project or organization.</li><li><strong>Sink:</strong> A sink is a rule that contains a filter and a destination. For example, a sink might have a filter for `severity=ERROR` and a destination of a Pub/Sub topic for real-time alerting. Another sink might have a filter for all audit logs (`logName:\"/logs/cloudaudit.googleapis.com\"`) and a destination of a long-term, immutable Cloud Storage bucket.</li><li><strong>Destinations:</strong> The most common destinations are:<ul><li>**Cloud Storage:** For cheap, long-term archival to meet compliance requirements.</li><li>**BigQuery:** For powerful, SQL-based analytics and threat hunting.</li><li>**Pub/Sub:** For real-time streaming integration with other services, like a third-party SIEM or a Cloud Function for automated response.</li></ul></ul>",
                            "image": "https://images.unsplash.com/photo-1542438408-abb2021e1837?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Cloud Audit Logs Deep Dive",
                            "content": "<p>Cloud Audit Logs are a critical source of security information. Understanding the four main types is essential.</p><ul><li><strong>Admin Activity:</strong> Logs of administrative actions that modify configuration or metadata. These are always on, cannot be disabled, and have a 400-day retention. This is your core 'change control' log.</li><li><strong>Data Access:</strong> Logs of API calls that create, modify, or read user-provided data (e.g., `storage.objects.get`). These are high-volume and are disabled by default (except for BigQuery). You must enable them to get a full audit trail for security investigations.</li><li><strong>System Event:</strong> Logs of Google Cloud system actions, such as a live migration of a VM.</li><li><strong>Access Transparency:</strong> Logs of actions taken by Google personnel when they access your resources (e.g., in response to a support ticket). This provides the ultimate level of transparency.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1510915228340-29c85a43dcfe?w=800&h=400&fit-crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Create a Log Sink to Archive All Logs to Cloud Storage (gcloud CLI)",
                        "language": "bash",
                        "code": "# This creates a sink at the project level that will send a copy of every log entry to a GCS bucket.\n# In a real enterprise, you would create this sink at the Organization level to centralize all logs.\ngcloud logging sinks create my-project-archive-sink \\\n    storage.googleapis.com/my-log-archive-bucket \\\n    --project=your-project-id"
                    },
                    {
                        "title": "Create a Log Sink to Send Security Audit Logs to BigQuery (gcloud CLI)",
                        "language": "bash",
                        "code": "# This sink uses a filter to select only security-relevant audit logs and sends them to a BigQuery dataset for analysis.\ngcloud logging sinks create my-security-audit-sink \\\n    bigquery.googleapis.com/projects/your-project-id/datasets/security_logs_dataset \\\n    --log-filter='protoPayload.@type=\"type.googleapis.com/google.cloud.audit.AuditLog\" AND protoPayload.serviceName!=\"dataflow.googleapis.com\"' \\\n    --project=your-project-id"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "In Cloud Logging, what is a 'sink'?", "options": ["The place where logs are deleted", "A rule containing a filter and a destination that tells the Log Router where to send specific log entries", "A type of log entry", "A dashboard for viewing logs"], "correct": 1, "explanation": "Sinks are the core component of the Log Router, allowing you to control the flow and destination of all your log data. A sink says, 'if a log matches this filter, send it to this destination'." },
                        { "id": 2, "question": "To get a detailed audit trail of who is reading the data in your Cloud Storage buckets, which type of audit log must you enable?", "options": ["Admin Activity", "Data Access", "System Event", "Access Transparency"], "correct": 1, "explanation": "Data Access logs are often disabled by default due to their volume, but they are essential for detailed security monitoring and incident response. Enabling them for critical services is a key best practice." },
                        { "id": 3, "question": "What is the best destination for cheap, long-term archival of logs to meet compliance requirements?", "options": ["BigQuery", "Cloud Storage", "Pub/Sub", "Cloud SQL"], "correct": 1, "explanation": "Cloud Storage offers various storage classes (like Archive) that provide extremely low-cost storage, which is ideal for long-term retention of audit logs." }
                    ]
                }
            },
            {
                "id": "lesson-14-monitoring",
                "title": "Lesson 14: Cloud Monitoring",
                "duration": "120 min",
                "objectives": [
                    "Use Cloud Monitoring to collect metrics and create security-focused dashboards",
                    "Configure alerting policies based on metrics, logs, and uptime checks",
                    "Use Monitoring Query Language (MQL) for advanced metric analysis"
                ],
                "content": {
                    "overview": "While Cloud Logging handles logs (discrete events), Cloud Monitoring handles metrics (numerical, time-series data). This lesson covers how to use Cloud Monitoring to gain visibility into the performance and health of your systems and, critically, how to create alerts based on that data to detect security anomalies.",
                    "sections": [
                        {
                            "title": "Monitoring and Alerting Policies",
                            "content": "<ul><li><strong>Metrics:</strong> The core of Cloud Monitoring. This is time-series data like VM CPU utilization, load balancer request count, or database memory usage. You can also create your own custom metrics.</li><li><strong>Dashboards:</strong> You can create custom dashboards with charts and graphs to visualize your metrics and logs together, providing a single view of your application's health.</li><li><strong>Alerting Policies:</strong> An alerting policy watches a metric. When the metric crosses a threshold you define for a certain duration (e.g., 'if CPU is above 90% for 5 minutes'), it creates an incident and sends a notification. A powerful feature is that you can also create alerts based on log entries (by first creating a log-based metric).</li></ul>",
                            "image": "https://images.unsplash.com/photo-1551288049-bebda4e38f71?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Create an Alerting Policy for High CPU Usage (gcloud CLI)",
                        "language": "bash",
                        "code": "# This example requires a notification channel to be created first.\n# It creates a policy that triggers if the CPU utilization is above 90% for 60 seconds.\ngcloud alpha monitoring policies create \\\n    --policy-from-file=\"cpu-alert-policy.json\""
                    },
                    {
                        "title": "JSON for the CPU Alert Policy",
                        "language": "json",
                        "code": "{\n  \"displayName\": \"High CPU Utilization\",\n  \"combiner\": \"OR\",\n  \"conditions\": [\n    {\n      \"displayName\": \"CPU Utilization > 90% for 1 min\",\n      \"conditionThreshold\": {\n        \"filter\": \"metric.type=\\\"compute.googleapis.com/instance/cpu/utilization\\\" AND resource.type=\\\"gce_instance\\\"\",\n        \"comparison\": \"COMPARISON_GT\",\n        \"thresholdValue\": 0.9,\n        \"duration\": \"60s\",\n        \"aggregations\": [{\n            \"alignmentPeriod\": \"60s\",\n            \"perSeriesAligner\": \"ALIGN_MEAN\"\n        }]\n      }\n    }\n  ],\n  \"notificationChannels\": [\n    \"projects/your-project-id/notificationChannels/your_channel_id\"\n  ]\n}"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary function of Cloud Monitoring?", "options": ["To store logs", "To collect, visualize, and alert on numerical, time-series metric data", "To manage user identities", "To scan for vulnerabilities"], "correct": 1, "explanation": "Cloud Monitoring is focused on metrics, which are key indicators of system health, performance, and can also be used to detect security anomalies (like a sudden spike in network traffic)." },
                        { "id": 2, "question": "An alert that triggers when 'the number of firewall denies is greater than 100 per minute' is an example of a:", "options": ["Metric-based alert", "Uptime check", "Process health alert", "Log-based alert"], "correct": 3, "explanation": "This requires creating a log-based metric that counts the firewall log entries matching the 'deny' condition, and then creating an alert based on that metric." }
                    ]
                }
            },
            {
                "id": "lesson-15-error-reporting",
                "title": "Lesson 15: Error Reporting and Debugging",
                "duration": "120 min",
                "objectives": [
                    "Use Error Reporting to automatically group and analyze application errors",
                    "Use Cloud Trace to follow a request's path through a distributed system for performance analysis",
                    "Correlate errors with security events to identify potential exploitation attempts"
                ],
                "content": {
                    "overview": "Securing applications also means making them reliable. A spike in application errors can be an early indicator of a security event, like an attacker probing for vulnerabilities. GCP's suite of observability tools helps you find, triage, and fix these errors.",
                    "sections": [
                        {
                            "title": "The Operations (formerly Stackdriver) Suite",
                            "content": "<p>These services work together to give you a full picture of your application's health.</p><ul><li><strong>Cloud Logging:</strong> For event logs.</li><li><strong>Cloud Monitoring:</strong> For metrics.</li><li><strong>Error Reporting:</strong> This service automatically ingests crash and error data (e.g., stack traces) from your applications running on GCP. It intelligently groups similar errors together using their stack traces, alerts you to new errors you haven't seen before, and helps you prioritize fixing them. A sudden spike in new, unusual errors can be a signal of a security probe.</li><li><strong>Cloud Trace:</strong> Provides distributed tracing. In a microservices architecture, a single user request might flow through dozens of different services. Trace follows this request and shows you a detailed latency graph of every call, helping you pinpoint performance bottlenecks.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1542337829-9173cace55f1?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "Which service automatically aggregates application crashes and exceptions, groups them by root cause, and alerts you to newly occurring errors?", "options": ["Cloud Trace", "Cloud Monitoring", "Error Reporting", "Cloud Logging"], "correct": 2, "explanation": "Error Reporting is specifically designed to manage application error data at scale, helping you surface the signal from the noise of thousands of individual exceptions." },
                        { "id": 2, "question": "To diagnose a latency issue in a complex microservices application, which tool would be most effective?", "options": ["Cloud Asset Inventory", "Cloud Trace", "Secret Manager", "Cloud KMS"], "correct": 1, "explanation": "Distributed tracing is the specific technology for this use case, and Cloud Trace is GCP's managed service for it." }
                    ]
                }
            },
            {
                "id": "lesson-16-audit-logs",
                "title": "Lesson 16: Cloud Audit Logs",
                "duration": "120 min",
                "objectives": [
                    "Perform a deep dive into the four types of Cloud Audit Logs",
                    "Analyze Admin Activity and Data Access logs for security events using the Logs Explorer",
                    "Understand the purpose and use of Access Transparency logs for third-party risk"
                ],
                "content": {
                    "overview": "This lesson provides a dedicated deep dive into Cloud Audit Logs, the definitive source of truth for your GCP environment. We will break down the different log types and analyze their content using Kusto Query Language (KQL) in the Logs Explorer to answer critical security questions.",
                    "sections": [
                        {
                            "title": "Admin Activity vs. Data Access",
                            "content": "<p>This is the most important distinction in audit logging. Understanding the difference is crucial for effective investigation.</p><ul><li><strong>Admin Activity Logs:</strong> Record API calls that change the configuration or metadata of a resource. This is your 'change control' log. *Example: A user creates a new firewall rule or deletes a VM.* These logs are always on and have a 400-day retention period.</li><li><strong>Data Access Logs:</strong> Record API calls that read the configuration of a resource, or that create, modify, or read the data stored *within* a resource. *Example: A user reads a file from a Cloud Storage bucket.* These logs must be explicitly enabled because they can be high-volume.</li></ul><p>For a security investigation, Data Access logs are often the most valuable, as they show you exactly what data an attacker viewed or stole.</p>",
                            "image": "https://images.unsplash.com/photo-1510915228340-29c85a43dcfe?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Access Transparency",
                            "content": "<p>Access Transparency (AT) logs provide you with a near real-time audit trail of actions taken by Google staff when they access your resources. This is typically done in response to a support ticket you have filed. AT logs give you the ability to verify that Google is accessing your data for legitimate business reasons. This is a key feature for organizations in highly regulated industries.</p>",
                            "image": "https://images.unsplash.com/photo-1499750310107-5fef28a66643?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Query for Firewall Rule Creation in Logs Explorer (KQL)",
                        "language": "sql",
                        "code": "protoPayload.methodName=\"beta.compute.firewalls.insert\""
                    },
                    {
                        "title": "Query for Failed Data Access Attempts in GCS (KQL)",
                        "language": "sql",
                        "code": "protoPayload.@type=\"type.googleapis.com/google.cloud.audit.AuditLog\"\nresource.type=\"gcs_bucket\"\nprotoPayload.status.message=\"caller does not have permission\""
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "An entry for a user creating a new firewall rule would be found in which audit log?", "options": ["Data Access Log", "System Event Log", "Admin Activity Log", "Access Transparency Log"], "correct": 2, "explanation": "Creating a rule is a metadata/configuration change, which is considered an Admin Activity and is logged by default." },
                        { "id": 2, "question": "What is the purpose of Access Transparency logs?", "options": ["To log your own admin's activity", "To provide you with logs of actions taken by Google personnel when they access your resources for support purposes", "To log all data access", "To make your resources more transparent to the public"], "correct": 1, "explanation": "Access Transparency provides a verifiable audit trail of Google's own support access to your environment, fulfilling a key compliance and trust requirement." }
                    ]
                }
            },
            {
                "id": "lesson-17-security-command-center",
                "title": "Lesson 17: Security Command Center (SCC)",
                "duration": "120 min",
                "objectives": [
                    "Activate and use Security Command Center (SCC) as your central security management platform",
                    "Manage assets, findings, and compliance from a single dashboard",
                    "Understand the different capabilities of the Standard and Premium tiers",
                    "Integrate SCC with third-party tools like a SIEM"
                ],
                "content": {
                    "overview": "Security Command Center (SCC) is GCP's centralized security and risk management platform. It acts as the 'single pane of glass' for security in GCP, ingesting findings from numerous Google Cloud and third-party services, providing a unified view of your assets, vulnerabilities, threats, and compliance posture.",
                    "sections": [
                        {
                            "title": "Finding and Asset Management",
                            "content": "<p>The core of SCC is the 'Findings' view. SCC aggregates findings from many built-in and third-party services, including:</p><ul><li><strong>Security Health Analytics:</strong> A built-in scanner that finds common misconfigurations (e.g., public GCS buckets, overly permissive firewall rules) in your GCP resources.</li><li><strong>Web Security Scanner:</strong> Scans your App Engine, GKE, and Compute Engine applications for vulnerabilities like XSS.</li><li><strong>Cloud DLP:</strong> Reports findings of sensitive data discovered in your storage.</li><li><strong>Threat Detection Services (Premium):</strong> Ingests threat findings from services like Event Threat Detection and Container Threat Detection.</li></ul><p>SCC de-duplicates, enriches these findings with asset information from Cloud Asset Inventory, and prioritizes them, giving you a central place to manage your security risk.</p>",
                            "image": "https://images.unsplash.com/photo-1551288049-bebda4e38f71?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary role of Security Command Center?", "options": ["To store logs", "To act as a centralized platform for managing security assets, findings, and compliance across GCP", "To manage user identities", "To deploy virtual machines"], "correct": 1, "explanation": "SCC is the canonical 'single pane of glass' security tool in GCP, aggregating data from multiple other security services into one manageable view." },
                        { "id": 2, "question": "The built-in SCC service that scans for common GCP resource misconfigurations is called:", "options": ["Web Security Scanner", "Security Health Analytics", "Cloud DLP", "Event Threat Detection"], "correct": 1, "explanation": "Security Health Analytics is the primary Cloud Security Posture Management (CSPM) scanner within SCC." }
                    ]
                }
            },
            {
                "id": "lesson-18-asset-inventory",
                "title": "Lesson 18: Cloud Asset Inventory",
                "duration": "120 min",
                "objectives": [
                    "Use Cloud Asset Inventory to maintain a near real-time inventory of all your resources",
                    "Track changes to assets over time using the asset history API",
                    "Export asset data for analysis, security research, and compliance",
                    "Receive real-time notifications of asset changes"
                ],
                "content": {
                    "overview": "'You can't protect what you don't know you have.' Cloud Asset Inventory is a foundational governance service that provides a complete inventory of all your GCP resources, including their configurations and IAM policies. This lesson covers how to use it to achieve comprehensive visibility and track changes.",
                    "sections": [
                        {
                            "title": "Asset Discovery and Change Tracking",
                            "content": "<p>Cloud Asset Inventory keeps a 5-week history of your resource metadata. This allows you to not only see what resources you have right now, but also to see how their configuration has changed over time. For example, you can query the history of a specific firewall rule to see exactly when a port was opened and by whom.</p><h3>Real-time Notifications:</h3><p>You can configure Cloud Asset Inventory to publish real-time notifications to a Pub/Sub topic whenever an asset is created, deleted, or modified. This is an incredibly powerful feature for security. A security automation workflow can listen to this topic and immediately inspect any new resource (like a storage bucket) to ensure it complies with your security policies.</p>",
                            "image": "https://images.unsplash.com/photo-1499750310107-5fef28a66643?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Search for All Public Cloud Storage Buckets (gcloud CLI)",
                        "language": "bash",
                        "code": "# This powerful search uses the asset inventory to find any GCS bucket that has an IAM policy containing 'allUsers' or 'allAuthenticatedUsers'.\ngcloud asset search-all-iam-policies --scope=organizations/YOUR_ORGANIZATION_ID \\\n  --query=\"policy:allUsers OR policy:allAuthenticatedUsers\""
                    },
                    {
                        "title": "Get History of a Specific Asset (gcloud CLI)",
                        "language": "bash",
                        "code": "# Show the complete configuration history of a specific firewall rule.\ngcloud asset get-history --content-type resource \\\n    --project=your-project-id \\\n    --asset-names=\"//compute.googleapis.com/projects/your-project-id/global/firewalls/my-firewall-rule\""
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary purpose of Cloud Asset Inventory?", "options": ["To analyze logs", "To provide a comprehensive, time-series inventory of all your GCP resources and their configurations", "To manage IAM policies", "To protect against DDoS attacks"], "correct": 1, "explanation": "Asset inventory is a foundational governance and security service, providing the 'what do I have?' visibility that is essential for security." },
                        { "id": 2, "question": "The feature that sends a message to Pub/Sub every time a resource is modified is called:", "options": ["Asset History", "Real-time Notifications", "Search API", "Export API"], "correct": 1, "explanation": "Real-time notifications are a powerful tool for event-driven security, allowing you to react instantly to changes in your environment." }
                    ]
                }
            },
            {
                "id": "lesson-19-binary-authorization",
                "title": "Lesson 19: Binary Authorization",
                "duration": "120 min",
                "objectives": [
                    "Understand the principles of software supply chain security for containers",
                    "Create and enforce a Binary Authorization policy for GKE",
                    "Use attestations from your CI/CD pipeline to verify that images have passed required security checks"
                ],
                "content": {
                    "overview": "Binary Authorization is a powerful, policy-based security control for your container pipeline. It provides a way to ensure that only trusted, verified container images are deployed to your Google Kubernetes Engine (GKE) clusters. This lesson covers how to set up and enforce this critical supply chain security control.",
                    "sections": [
                        {
                            "title": "Policy-Based Deployment",
                            "content": "<p>Binary Authorization is a 'deploy-time' security control that is implemented as an 'admission controller' in your GKE cluster. Before a pod is allowed to start, the admission controller intercepts the request and checks if the container image it's trying to use complies with the Binary Authorization policy. If the image does not comply, the pod is not allowed to run.</p><h3>Attestations and Verifiers:</h3><p>The system works using cryptographic signatures called 'attestations'.</p><ol><li>In your CI/CD pipeline (e.g., Cloud Build), after an image passes a security gate (like a vulnerability scan or a QA test), a system (the 'attestor') signs the image's digest, creating an attestation and storing it.</li><li>In your Binary Authorization policy, you specify that to be deployed, an image must have a valid attestation from one or more specific, trusted attestors.</li></ol><p>This creates a verifiable chain of trust. An image cannot be deployed to production unless it has the cryptographic proof that it has passed all the required security gates in your pipeline.</p>",
                            "image": "https://images.unsplash.com/photo-1579543183319-a16eee1b1fd3?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary security benefit of Binary Authorization?", "options": ["It makes containers run faster", "It provides a deploy-time policy check to ensure that only trusted container images that have passed required security gates can be deployed to GKE", "It scans running containers for threats", "It manages network access for containers"], "correct": 1, "explanation": "Binary Authorization is a crucial software supply chain security control that acts as the final gatekeeper for your GKE deployments, ensuring only vetted images enter your production environment." },
                        { "id": 2, "question": "The cryptographic signature that proves a container image has passed a certain check (like a vulnerability scan) is called a(n):", "options": ["Container", "Policy", "Attestation", "Firewall rule"], "correct": 2, "explanation": "Attestations are the verifiable, signed proof that your Binary Authorization policy relies upon to make its allow/deny decisions." }
                    ]
                }
            },
            {
                "id": "lesson-20-web-security-scanner",
                "title": "Lesson 20: Web Security Scanner",
                "duration": "120 min",
                "objectives": [
                    "Use Web Security Scanner to automatically find common vulnerabilities in your web applications",
                    "Configure custom scans with specific authentication credentials and user agents",
                    "Analyze findings in Security Command Center and prioritize remediation",
                    "Integrate scanning into your CI/CD pipeline for automated DAST"
                ],
                "content": {
                    "overview": "Web Security Scanner is GCP's built-in Dynamic Application Security Testing (DAST) tool. It automatically crawls your App Engine, Compute Engine, and GKE web applications and probes them to find common security vulnerabilities from an external, black-box perspective. This lesson covers how to set up and use this scanner.",
                    "sections": [
                        {
                            "title": "Vulnerability Scanning Capabilities",
                            "content": "<p>Web Security Scanner can detect a range of vulnerabilities, including many from the OWASP Top 10:</p><ul><li><strong>Cross-Site Scripting (XSS):</strong> Both reflected and stored.</li><li><strong>Outdated Libraries:</strong> It can detect if your application is using a front-end JavaScript library with a known CVE.</li><li><strong>Mixed Content:</strong> Detects when an HTTPS page loads insecure HTTP resources like scripts or images.</li><li><strong>Insecure Password Transmission:</strong> Finds login forms that send passwords in cleartext.</li></ul><h3>Scan Configuration:</h3><p>You can create scan configs that specify the starting URLs to crawl, the authentication method to use (e.g., by providing a username and password for the scanner to use), and a schedule for the scans (e.g., weekly). All findings are reported directly into the Security Command Center for centralized triage and remediation.</p>",
                            "image": "https://images.unsplash.com/photo-1614064548237-02f8f17374b2?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Create and Run a Web Security Scan (gcloud Beta CLI)",
                        "language": "bash",
                        "code": "# The gcloud commands for web security scanner are currently in beta.\n# This command creates and immediately runs a scan config for an App Engine app.\ngcloud beta web-security-scanner scan-configs create \\\n    --display-name \"Weekly Production Scan\" \\\n    --starting-urls \"https://your-project-id.appspot.com/\" \\\n    --target-platforms \"APP_ENGINE\""
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "Web Security Scanner is what type of security testing tool?", "options": ["SAST (Static Application Security Testing)", "DAST (Dynamic Application Security Testing)", "SCA (Software Composition Analysis)", "A firewall"], "correct": 1, "explanation": "It is a DAST tool because it interacts with the *running* application from the outside, just as a user or attacker would, to probe it for vulnerabilities without having access to the source code." }
                    ]
                }
            },
            {
                "id": "lesson-21-gke-security",
                "title": "Lesson 21: GKE Security Fundamentals",
                "duration": "150 min",
                "objectives": [
                    "Implement a defense-in-depth security architecture for a GKE cluster",
                    "Harden GKE nodes using Shielded Nodes and Container-Optimized OS",
                    "Use Network Policies for fine-grained pod-level network segmentation",
                    "Apply the principle of least privilege using Kubernetes RBAC and IAM"
                ],
                "content": {
                    "overview": "Google Kubernetes Engine (GKE) is a powerful, managed Kubernetes service, but its security is a shared responsibility. This lesson provides a deep dive into the practical steps for hardening a GKE cluster at every layer, from the node to the pod to the network.",
                    "sections": [
                        {
                            "title": "Cluster and Node Hardening",
                            "content": "<p>Securing GKE starts with securing its underlying infrastructure during cluster creation. These are critical choices that are difficult to change later.</p><h3>Key Best Practices:</h3><ul><li><strong>Private Clusters:</strong> This is a critical security control. It configures your cluster's control plane (the Kubernetes API server) to be on a private IP address, making it inaccessible from the public internet. Nodes are also created without public IPs.</li><li><strong>Shielded GKE Nodes:</strong> This enables a verifiable integrity chain for your nodes using secure boot and integrity monitoring, protecting against boot-level and kernel-level rootkits.</li><li><strong>Use Container-Optimized OS (COS):</strong> COS is a minimal, hardened operating system designed by Google specifically for running containers. It has a smaller attack surface than a general-purpose OS.</li><li><strong>Least Privilege for Node Service Accounts:</strong> By default, nodes use a very permissive service account. You should create and specify a custom service account with the absolute minimum set of IAM permissions required for your nodes to function (e.g., pulling images from Artifact Registry and writing logs).</li></ul>",
                            "image": "https://images.unsplash.com/photo-1579543183319-a16eee1b1fd3?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Network Policies",
                            "content": "<p>A Network Policy is the Kubernetes equivalent of a firewall, operating at Layer 3/4. It allows you to specify how groups of pods are allowed to communicate with each other and other network endpoints. By default, there is no network policy, and all pods can communicate with all other pods. You must enable network policy enforcement on your cluster and create a 'deny by default' policy, then explicitly 'punch holes' to allow required traffic paths. This is essential for preventing lateral movement within a cluster.</p>",
                            "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Create a Secure, Private GKE Cluster (gcloud CLI)",
                        "language": "bash",
                        "code": "# This command creates a highly secure GKE cluster with key best practices enabled.\ngcloud container clusters create \"my-secure-cluster\" \\\n    --zone us-central1-c \\\n    --enable-private-nodes \\\n    --enable-private-endpoint \\\n    --master-ipv4-cidr \"172.16.0.0/28\" \\\n    --enable-network-policy \\\n    --enable-ip-alias \\\n    --image-type \"COS_CONTAINERD\" \\\n    --shielded-secure-boot \\\n    --service-account=\"least-privilege-sa@my-project.iam.gserviceaccount.com\""
                    },
                    {
                        "title": "Kubernetes Network Policy to Isolate a Backend (YAML)",
                        "language": "yaml",
                        "code": "# This policy selects 'backend' pods and only allows ingress traffic from 'frontend' pods on TCP port 6379.\n# It blocks all other ingress traffic to the backend pods.\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: backend-policy\n  namespace: default\nspec:\n  podSelector:\n    matchLabels:\n      app: backend\n  policyTypes:\n  - Ingress\n  ingress:\n  - from:\n    - podSelector:\n        matchLabels:\n          app: frontend\n    ports:\n    - protocol: TCP\n      port: 6379"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary security benefit of creating a 'private' GKE cluster?", "options": ["It costs less", "The Kubernetes API server (control plane) is not exposed to the public internet, dramatically reducing its attack surface", "It allows all pods to talk to each other", "It uses a different operating system"], "correct": 1, "explanation": "Making the control plane private is one of the most important steps in securing a GKE cluster. It forces all management to happen from within your private network or via a bastion host." },
                        { "id": 2, "question": "The Kubernetes object used to create firewall rules between pods is called a:", "options": ["Service", "Deployment", "Pod Security Policy", "Network Policy"], "correct": 3, "explanation": "Network Policies are the Kubernetes-native way to achieve network micro-segmentation within your cluster, which is essential for Zero Trust networking." },
                        { "id": 3, "question": "Using a hardened, minimal OS like Google's Container-Optimized OS (COS) for your GKE nodes is an example of what security principle?", "options": ["Defense in Depth", "Reducing the Attack Surface", "Principle of Least Privilege", "Separation of Duties"], "correct": 1, "explanation": "A minimal OS has fewer packages, fewer running services, and is therefore less complex and has a smaller attack surface than a general-purpose OS." }
                    ]
                }
            },
            {
                "id": "lesson-22-registry-security",
                "title": "Lesson 22: Container Registry Security",
                "duration": "120 min",
                "objectives": [
                    "Secure Artifact Registry with fine-grained IAM policies for pushing and pulling images",
                    "Automate vulnerability scanning of container images upon upload",
                    "Understand how Binary Authorization integrates with the registry to prevent deployment of unauthorized images"
                ],
                "content": {
                    "overview": "Your container registry is the source of truth for your deployments and a critical part of your software supply chain. This lesson covers the best practices for securing Google Artifact Registry to ensure the integrity and security of your container images.",
                    "sections": [
                        {
                            "title": "Artifact Registry Security",
                            "content": "<p>Artifact Registry is the recommended service for storing and managing container images and other package formats in GCP. It provides a single, centralized service for all your artifacts.</p><ul><li><strong>IAM Control:</strong> Access to repositories is controlled with granular, resource-specific IAM roles like `roles/artifactregistry.reader` (can pull images) and `roles/artifactregistry.writer` (can push and pull images). You should grant these roles to your service accounts (for CI/CD pipelines) and developers with least privilege.</li><li><strong>Vulnerability Scanning:</strong> Artifact Registry can automatically scan your container images for known OS vulnerabilities (CVEs) as soon as they are pushed. The findings are sent to Security Command Center, and you can build automation to act upon them.</li><li><strong>Integration with Binary Authorization:</strong> This is the key security integration. Your CI/CD pipeline pushes a scanned and signed image to Artifact Registry. Binary Authorization then checks for the required attestations on that image in Artifact Registry before allowing it to be deployed to GKE.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1579543183319-a16eee1b1fd3?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Create an Artifact Registry and Grant Permissions (gcloud CLI)",
                        "language": "bash",
                        "code": "# Create a Docker repository in Artifact Registry\ngcloud artifacts repositories create my-app-repo \\\n    --repository-format=docker \\\n    --location=us-central1 \\\n    --description=\"Repository for my web app images\"\n\n# Grant the CI/CD pipeline's service account permission to push images to this repo\ngcloud artifacts repositories add-iam-policy-binding my-app-repo \\\n    --location=us-central1 \\\n    --member=\"serviceAccount:my-cicd-sa@my-project.iam.gserviceaccount.com\" \\\n    --role=\"roles/artifactregistry.writer\""
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "Artifact Registry can automatically scan container images for what?", "options": ["Bad coding practices", "Known OS package vulnerabilities (CVEs)", "The cost of the image", "The image's author"], "correct": 1, "explanation": "Vulnerability scanning is a core feature that provides visibility into the security posture of your container images, helping you shift security left in your development process." }
                    ]
                }
            },
            {
                "id": "lesson-23-workload-identity",
                "title": "Lesson 23: Workload Identity",
                "duration": "120 min",
                "objectives": [
                    "Understand the challenges of service-to-service authentication in Kubernetes",
                    "Configure and use Workload Identity to securely access GCP services from GKE without keys",
                    "Bind Kubernetes Service Accounts (KSAs) to Google Service Accounts (GSAs)"
                ],
                "content": {
                    "overview": "How does a pod running in GKE securely authenticate to a GCP service like Cloud SQL? The old way was to download a JSON key for a service account and store it as a Kubernetes secret, but this is a major security risk. Workload Identity is the modern, secure, and recommended password-less approach. This lesson covers how to set it up.",
                    "sections": [
                        {
                            "title": "The Problem with Keys in Kubernetes",
                            "content": "<p>Storing static Google Service Account (GSA) keys as Kubernetes secrets has several security downsides:</p><ul><li><strong>Rotation Burden:</strong> You are responsible for manually rotating these keys, which is an operational headache and is often neglected.</li><li><strong>Broad Blast Radius:</strong> A compromised secret gives an attacker a long-lived key that they can use from anywhere, even outside the cluster.</li><li><strong>Secret Management:</strong> Managing who has access to view the secrets within Kubernetes can be complex.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1599373922312-5b9340d8a5a5?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Workload Identity: The Password-less Solution",
                            "content": "<p>Workload Identity allows you to map a Kubernetes Service Account (KSA) directly to a Google Cloud Service Account (GSA). This creates a trust relationship that allows the KSA to impersonate the GSA.</p><h3>The Secure Workflow:</h3><ol><li>Your pod starts up and its manifest specifies it should use a particular KSA (`my-ksa`).</li><li>The GKE metadata server on the node sees this. Because of the trust relationship you configured, it can exchange the pod's ephemeral KSA credentials for a short-lived OAuth 2.0 access token for the corresponding GSA (`my-gsa`).</li><li>Your pod's application code (using a Google Cloud client library) transparently gets this token and can now securely access any GCP services that the GSA (`my-gsa`) has been granted IAM permissions to.</li></ol><p>The key benefit is that you no longer have to create, download, manage, or rotate any static JSON keys inside your cluster. It is a completely automated and more secure password-less workflow.</p>",
                            "image": "https://images.unsplash.com/photo-1554224155-83e8b835d07a?w=800&h=400&fit-crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Enable Workload Identity and Bind Accounts (gcloud & kubectl)",
                        "language": "bash",
                        "code": "# Step 1: Create your GSA that the workload will act as.\ngcloud iam service-accounts create my-gsa\n\n# Step 2: Enable Workload Identity on the GKE cluster (if not already enabled).\ngcloud container clusters update my-cluster --workload-pool=your-project-id.svc.id.goog\n\n# Step 3: Create the KSA in your cluster.\nkubectl create serviceaccount my-ksa\n\n# Step 4: Allow the KSA to impersonate the GSA by creating an IAM policy binding.\ngcloud iam service-accounts add-iam-policy-binding my-gsa@your-project-id.iam.gserviceaccount.com \\\n    --role roles/iam.workloadIdentityUser \\\n    --member \"serviceAccount:your-project-id.svc.id.goog[default/my-ksa]\"\n\n# Step 5: Annotate the KSA to complete the link to the GSA.\nkubectl annotate serviceaccount my-ksa \\\n    iam.gke.io/gcp-service-account=my-gsa@your-project-id.iam.gserviceaccount.com"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary security benefit of using Workload Identity in GKE?", "options": ["It makes your pods run faster", "It eliminates the need to manage static, long-lived service account JSON keys inside your cluster", "It provides a firewall for your pods", "It scans your container images"], "correct": 1, "explanation": "Workload Identity provides a seamless, secure, and automated way for your Kubernetes workloads to authenticate to Google Cloud services without the risks and operational overhead associated with managing static credentials." },
                        { "id": 2, "question": "Workload Identity links which two types of accounts together?", "options": ["A User Account and a Group", "A Kubernetes Service Account (KSA) and a Google Service Account (GSA)", "An IAM Role and a Permission", "A Project and a Folder"], "correct": 1, "explanation": "This mapping between the in-cluster identity (KSA) and the cloud identity (GSA) is the core of how Workload Identity works." }
                    ]
                }
            },
            {
                "id": "lesson-24-istio-service-mesh",
                "title": "Lesson 24: Istio Service Mesh Security",
                "duration": "120 min",
                "objectives": [
                    "Understand the concept of a service mesh and its security benefits",
                    "Use Istio to enforce strict mutual TLS (mTLS) for all service-to-service communication",
                    "Create fine-grained authorization policies based on service identity and HTTP methods",
                    "Gain deep security observability into your microservices traffic with telemetry"
                ],
                "content": {
                    "overview": "A service mesh is a dedicated infrastructure layer for making service-to-service communication safe, fast, and reliable in a microservices architecture. This lesson introduces Istio, the most popular open-source service mesh, and its powerful security capabilities within a GKE environment.",
                    "sections": [
                        {
                            "title": "Service-to-Service Security with mTLS",
                            "content": "<p>Istio automatically deploys a lightweight 'sidecar' proxy next to each of your application pods. All traffic to and from the pod is transparently routed through this proxy. The proxies then establish a mutually authenticated and encrypted TLS (mTLS) connection between them.</p><h3>Key Benefits:</h3><ul><li><strong>Automatic Encryption in Transit:</strong> All service-to-service traffic within the mesh is automatically encrypted, with zero changes to your application code. This secures your 'east-west' traffic.</li><li><strong>Strong Cryptographic Identity:</strong> Each service is given a strong, cryptographic identity (a SPIFFE identity), which it uses to authenticate to other services. This prevents service spoofing attacks within the cluster. You know for sure that the service calling you is who it says it is.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1599691888286-93e433f064b8?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Istio Authorization Policies",
                            "content": "<p>Istio provides a powerful, high-level authorization policy language that operates at Layer 7. You can create rules based on the trusted service identities provided by mTLS.</p><p>For example, you can create a rule that says, 'Only allow requests to the `reviews` service (workload identity) from the `product-page` service (workload identity)'. You can get even more granular and say 'Only allow `GET` requests to the `/api/v1/reviews` path from version 2 of the `product-page` service'. This provides another, even richer layer of micro-segmentation on top of Kubernetes Network Policies.</p>",
                            "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit-crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Istio PeerAuthentication Policy to Enforce mTLS (YAML)",
                        "language": "yaml",
                        "code": "# This policy enforces that all workloads in the 'default' namespace must use mTLS for communication.\napiVersion: security.istio.io/v1beta1\nkind: PeerAuthentication\nmetadata:\n  name: default-mtls\n  namespace: default\nspec:\n  mtls:\n    mode: STRICT"
                    },
                    {
                        "title": "Istio AuthorizationPolicy to Restrict Access (YAML)",
                        "language": "yaml",
                        "code": "# This policy allows requests to the 'backend' service ONLY from the 'frontend' service.\napiVersion: security.istio.io/v1beta1\nkind: AuthorizationPolicy\nmetadata:\n  name: backend-policy\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: backend\n  action: ALLOW\n  rules:\n  - from:\n    - source:\n        principals: [\"cluster.local/ns/default/sa/frontend-sa\"]\n    to:\n    - operation:\n        methods: [\"GET\"]"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary security feature provided by a service mesh like Istio?", "options": ["Vulnerability scanning", "Automated, transparent mutual TLS (mTLS) for all service-to-service communication", "Log analysis", "Web application firewalling"], "correct": 1, "explanation": "Automatic mTLS is the foundational security benefit of a service mesh, providing a secure, identity-based network for all your microservices and encrypting east-west traffic." },
                        { "id": 2, "question": "Istio's Authorization Policies provide _____ access control, while Kubernetes Network Policies provide _____ access control.", "options": ["Layer 7 / Layer 3/4", "Layer 3/4 / Layer 7", "Node / Pod", "Pod / Node"], "correct": 0, "explanation": "This is a key distinction. Kubernetes Network Policies work at the IP and port level (Layer 3/4), while Istio can understand service identity, HTTP methods, and paths (Layer 7)." }
                    ]
                }
            },
            {
                "id": "lesson-25-cloud-sql",
                "title": "Lesson 25: Cloud SQL Security",
                "duration": "120 min",
                "objectives": [
                    "Implement a defense-in-depth security model for Cloud SQL instances",
                    "Use the Cloud SQL Auth Proxy for secure, authorized, and encrypted connections",
                    "Configure database authentication using IAM to eliminate passwords",
                    "Implement network security using private IPs and authorized networks"
                ],
                "content": {
                    "overview": "Cloud SQL is a fully managed relational database service for MySQL, PostgreSQL, and SQL Server. Securing your databases, which often contain your most sensitive data, is paramount. This lesson provides a deep dive into the specific best practices for hardening your Cloud SQL instances.",
                    "sections": [
                        {
                            "title": "Network Security",
                            "content": "<p>Network isolation is the first and most important layer of defense for your database.</p><h3>Best Practices:</h3><ul><li><strong>Use Private IP:</strong> A Cloud SQL instance should ALWAYS be configured to only have a private IP address within your VPC. It should never have a public IP address.</li><li><strong>Authorized Networks:</strong> Even with a public IP, you must use the 'Authorized Networks' feature to whitelist specific CIDR ranges that are allowed to connect. This should be used sparingly, and a private IP is always preferred.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1599691888286-93e433f064b8?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Secure Connection with Cloud SQL Auth Proxy",
                            "content": "<p>The Cloud SQL Auth Proxy is a small client-side tool that provides secure, encrypted, and authorized access to your Cloud SQL instances. Using the proxy is the recommended method for connecting.</p><h3>How it Works:</h3><ol><li>Your application connects to the proxy running locally.</li><li>The proxy authenticates to the Cloud SQL API using IAM credentials (from a service account).</li><li>The proxy then wraps your database connection in a secure TLS 1.3 tunnel and sends it to the Cloud SQL instance.</li></ol><p>This is superior to connecting directly because it uses IAM for authorization, handles all the SSL/TLS encryption for you, and doesn't require you to manage whitelisting client IP addresses.</p>",
                            "image": "https://images.unsplash.com/photo-1554224155-83e8b835d07a?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "IAM Database Authentication",
                            "content": "<p>Cloud SQL supports IAM Database Authentication. This allows users or service accounts to log in to the database itself using their IAM identity instead of a traditional password. This is a powerful feature that allows you to manage database access centrally in IAM and implement a completely password-less workflow for your applications.</p>",
                            "image": "https://images.unsplash.com/photo-1599373922312-5b9340d8a5a5?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Create a Private Cloud SQL Instance (gcloud CLI)",
                        "language": "bash",
                        "code": "gcloud sql instances create my-secure-db \\\n    --database-version=POSTGRES_13 \\\n    --region=us-central1 \\\n    --network=projects/my-project-id/global/networks/my-secure-vpc \\\n    --no-assign-ip"
                    },
                    {
                        "title": "Connecting via the Cloud SQL Auth Proxy (command line)",
                        "language": "bash",
                        "code": "# Start the proxy in the background.\n# It will listen on localhost:5432 and forward connections securely to your instance.\n./cloud_sql_proxy -instances=my-project-id:us-central1:my-secure-db=tcp:5432 &\n\n# Now, connect to the database using your standard client, pointing to localhost.\npsql -h 127.0.0.1 -p 5432 -U myuser -d mydb"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the most secure network configuration for a Cloud SQL instance?", "options": ["Assign it a public IP and allow all traffic", "Use a public IP but restrict access with 'Authorized Networks'", "Assign only a private IP and connect to it from within the VPC", "Use an unencrypted connection"], "correct": 2, "explanation": "Configuring the instance with only a private IP is the fundamental step for network isolation, ensuring it is not exposed to the public internet." },
                        { "id": 2, "question": "What is the recommended tool for securely connecting to a Cloud SQL instance, especially from outside the VPC?", "options": ["The `mysql` client directly", "The Cloud SQL Auth Proxy", "A VPN only", "Telnet"], "correct": 1, "explanation": "The Cloud SQL Auth Proxy simplifies secure connectivity by handling IAM authorization and automatic SSL/TLS encryption, removing the need to manage certificates or IP allowlists." },
                        { "id": 3, "question": "What is a major benefit of using IAM Database Authentication?", "options": ["It makes the database slower", "It allows you to manage database login permissions centrally through Cloud IAM, enabling a password-less workflow", "It disables encryption", "It is only available for MySQL"], "correct": 1, "explanation": "IAM authentication is a modern, more secure alternative to traditional password-based authentication, integrating database access into your central cloud identity platform." }
                    ]
                }
            },
            {
                "id": "lesson-26-nosql-security",
                "title": "Lesson 26: Firestore and Bigtable Security",
                "duration": "120 min",
                "objectives": [
                    "Implement the Firestore security model using security rules",
                    "Configure fine-grained IAM and access control for Bigtable",
                    "Enforce data encryption and network controls for NoSQL databases"
                ],
                "content": {
                    "overview": "NoSQL databases like Firestore and Bigtable have unique security models that differ from traditional relational databases. This lesson covers the specific security controls for these powerful, scalable databases, focusing on their respective access control mechanisms.",
                    "sections": [
                        {
                            "title": "Firestore Security Rules",
                            "content": "<p>Cloud Firestore is a flexible, scalable NoSQL document database. Its primary security mechanism is 'Firestore Security Rules'. This is a powerful, declarative language you use to define access control for your database.</p><h3>The Security Rules Model:</h3><p>Security rules live in a file deployed alongside your database. They are not IAM policies. The rules are automatically evaluated for every single read or write request that comes from a client (like a mobile app or web browser).</p><p>You can write rules that are incredibly granular. For example, a rule might state: 'Allow a user to read a document in the `profiles` collection, but only if the document's ID is the same as the user's own authenticated UID'. Or, 'Allow a user to create a new post, but only if the `userId` field in the new document matches their own UID and the `published` field is false'.</p><p>This allows for complex, user-aware authorization logic to be enforced directly by the database, which is essential for serverless and mobile application architectures.</p>",
                            "image": "https://images.unsplash.com/photo-1555099962-4199c345e541?w=800&h=400&fit-crop"
                        },
                        {
                            "title": "Bigtable Security",
                            "content": "<p>Cloud Bigtable is a high-performance, wide-column NoSQL database suitable for very large analytical and operational workloads. Its security is based on standard Cloud IAM.</p><h3>Bigtable IAM Roles:</h3><p>Access control for Bigtable is managed at the project and instance level using predefined IAM roles. Some key roles include:</p><ul><li><strong>`roles/bigtable.reader`:</strong> Can read data from tables.</li><li><strong>`roles/bigtable.user`:</strong> Can read and write data.</li><li><strong>`roles/bigtable.admin`:</strong> Can manage all resources within an instance, including creating tables and garbage collection policies.</li></ul><p>For network isolation, Bigtable can be configured to only be accessible via a private endpoint within your VPC.</p>",
                            "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit-crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Example Firestore Security Rule for User Profiles",
                        "language": "javascript",
                        "code": "// These rules allow a user to read and write their own profile, but not anyone else's.\n// It also ensures a new profile is created with the correct owner ID.\n\nrules_version = '2';\nservice cloud.firestore {\n  match /databases/{database}/documents {\n    match /users/{userId} {\n      allow read, update, delete: if request.auth != null && request.auth.uid == userId;\n      allow create: if request.auth != null && request.resource.data.userId == request.auth.uid;\n    }\n  }\n}"
                    },
                    {
                        "title": "Grant a User Read-Only Access to a Bigtable Instance (gcloud CLI)",
                        "language": "bash",
                        "code": "# Granting a predefined role at the project level.\n# For more fine-grained control, you can apply this to a specific Bigtable instance.\ngcloud bigtable instances add-iam-policy-binding my-bigtable-instance \\\n    --member=\"user:datascientist@example.com\" \\\n    --role=\"roles/bigtable.reader\""
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary mechanism for controlling access to data in Cloud Firestore?", "options": ["IAM Policies", "Firestore Security Rules", "VPC Firewall Rules", "Cloud Armor"], "correct": 1, "explanation": "Firestore Security Rules are a unique, non-IAM access control system that provides the required flexibility and granularity for client-side (mobile/web) applications." },
                        { "id": 2, "question": "The rule `allow read: if request.auth.uid == resource.data.ownerId;` is an example of what?", "options": ["An IAM condition", "A BigQuery policy", "A Firestore Security Rule that enforces ownership-based access", "A firewall rule"], "correct": 2, "explanation": "This is a classic ownership-based rule, which is a very common and powerful pattern in Firestore for user-generated content." },
                        { "id": 3, "question": "Access to a Cloud Bigtable instance is primarily controlled by what?", "options": ["Firestore Security Rules", "Cloud IAM roles", "Access Control Lists (ACLs)", "Cloud KMS"], "correct": 1, "explanation": "Unlike Firestore, Bigtable is an infrastructure-level service whose access is managed through the standard Google Cloud IAM system." }
                    ]
                }
            },
            {
                "id": "lesson-27-bigquery-security",
                "title": "Lesson 27: BigQuery Security",
                "duration": "120 min",
                "objectives": [
                    "Apply the principle of least privilege using predefined and custom IAM roles for BigQuery datasets and tables",
                    "Implement column-level and row-level security policies for fine-grained access control",
                    "Use data masking to de-identify sensitive data in query results"
                ],
                "content": {
                    "overview": "BigQuery is a serverless, petabyte-scale data warehouse. Securing the massive amounts of data it can contain requires a multi-layered, granular approach. This lesson covers the powerful, data-centric security controls available within BigQuery.",
                    "sections": [
                        {
                            "title": "IAM for Datasets and Tables",
                            "content": "<p>Access control starts with IAM. You can grant IAM roles at the project, dataset, or even individual table level. Predefined roles like `roles/bigquery.dataViewer` (can read data), `roles/bigquery.dataEditor` (can read and modify data), and `roles/bigquery.jobUser` (can run queries) are the building blocks of your access model.</p>",
                            "image": "https://images.unsplash.com/photo-1554224155-83e8b835d07a?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Column-Level and Row-Level Security",
                            "content": "<p>These are powerful, fine-grained security controls that go beyond standard IAM.</p><ul><li><strong>Column-Level Security:</strong> Allows you to apply a policy tag to specific columns in a table. You can then grant a user the `Fine-Grained Reader` role on that policy tag. A user can only see the data in a column if they have permission on the tag applied to that column. This lets you protect sensitive columns (like PII) even from users who have access to the rest of the table.</li><li><strong>Row-Level Security:</strong> Allows you to create a policy on a table that filters the rows a user can see based on their identity. For example, a policy can state 'Only allow users to see rows in the sales table where the `region` column matches the user's assigned sales region'.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1522252234503-e356032cafd5?w=800&h=400&fit-crop"
                        },
                        {
                            "title": "Data Masking",
                            "content": "<p>BigQuery provides built-in dynamic data masking. This allows you to apply a masking rule to a column (e.g., show only the last four digits of a credit card number, or hash an email address). The underlying data is not changed, but the data returned in a query result is masked for users who do not have special `Data Masking Unmasker` permission.</p>",
                            "image": "https://images.unsplash.com/photo-1599373922312-5b9340d8a5a5?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Grant a User Read Access to a BigQuery Dataset (gcloud CLI)",
                        "language": "bash",
                        "code": "# To grant a user permission to view tables and their data in a specific dataset:\n# First, get the current IAM policy for the dataset.\nbq show --format=json my_project:my_dataset > policy.json\n\n# Modify the policy.json file to add the new binding, then update it.\nbq update --source policy.json my_project:my_dataset"
                    },
                    {
                        "title": "Create a Row-Level Security Policy (SQL)",
                        "language": "sql",
                        "code": "CREATE ROW ACCESS POLICY region_filter\nON my_project.my_dataset.sales_data\nGRANT TO (\"group:sales-reps@example.com\")\nFILTER USING (region = SESSION_USER());"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "You need to allow an analyst to see most of a customer table, but hide the `social_security_number` column from them. Which security control is best suited for this?", "options": ["An IAM policy", "Column-Level Security", "Row-Level Security", "A firewall rule"], "correct": 1, "explanation": "Column-level security is specifically designed for this use case, allowing you to grant or deny access to specific, sensitive columns within a table." },
                        { "id": 2, "question": "The security control that filters which *rows* a user can see in a table based on a defined condition (like `region = 'North America'`) is called:", "options": ["Column-Level Security", "Dynamic Data Masking", "Row-Level Security", "IAM"], "correct": 2, "explanation": "Row-level security provides this powerful filtering capability, essential for multi-tenant and large enterprise data warehousing scenarios." }
                    ]
                }
            },
            {
                "id": "lesson-28-spanner-security",
                "title": "Lesson 28: Spanner Security",
                "duration": "120 min",
                "objectives": [
                    "Understand the security architecture of Cloud Spanner, a global, strongly consistent database",
                    "Implement fine-grained access control at the table and column level",
                    "Manage encryption with customer-managed keys (CMEK)",
                    "Use audit logging and IAM to meet compliance needs"
                ],
                "content": {
                    "overview": "Cloud Spanner is a unique, globally distributed relational database that provides strong consistency at massive scale. This lesson covers its enterprise-grade security features, focusing on fine-grained access control and compliance.",
                    "sections": [
                        {
                            "title": "Fine-Grained Access Control",
                            "content": "<p>Spanner has its own fine-grained access control system that works in conjunction with Cloud IAM. IAM is used to grant access to the Spanner instance and database itself. Once a user has access to the database, fine-grained access control dictates what they can do *inside* the database.</p><p>You create database roles and grant them specific `SELECT`, `INSERT`, `UPDATE`, or `DELETE` privileges on specific tables, views, or even individual columns. You can then grant these database roles to your IAM principals (users or service accounts). This provides two layers of control for a strong defense-in-depth posture.</p>",
                            "image": "https://images.unsplash.com/photo-1554224155-83e8b835d07a?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Create a Database Role and Grant Privileges (Spanner DDL)",
                        "language": "sql",
                        "code": "CREATE ROLE data_analyst;\n\nGRANT SELECT(col1, col2, col3) ON TABLE my_table TO ROLE data_analyst;"
                    },
                    {
                        "title": "Grant the Database Role to an IAM User (gcloud CLI)",
                        "language": "bash",
                        "code": "# Grant the IAM role that allows the user to assume the 'data_analyst' database role.\ngcloud spanner databases add-iam-policy-binding my-database \\\n    --instance=my-instance \\\n    --member=\"user:analyst@example.com\" \\\n    --role=\"roles/spanner.databaseRoleUser.data_analyst\""
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "Spanner's fine-grained access control allows you to grant privileges (like `SELECT` or `INSERT`) on:", "options": ["The entire project", "The entire instance only", "Specific tables, views, and even individual columns", "Only entire databases"], "correct": 2, "explanation": "This granularity, similar to traditional relational databases, provides precise control over data access within the database itself." }
                    ]
                }
            },
            {
                "id": "lesson-29-app-engine-security",
                "title": "Lesson 29: App Engine Security",
                "duration": "120 min",
                "objectives": [
                    "Configure security controls for App Engine applications",
                    "Use Identity-Aware Proxy (IAP) to protect App Engine apps",
                    "Securely manage traffic splitting and different application versions",
                    "Understand the sandboxed nature of the App Engine environment"
                ],
                "content": {
                    "overview": "App Engine is a fully managed, serverless platform for building and running applications. This lesson covers its unique security model, including its sandboxed runtime, firewall, and tight integration with Identity-Aware Proxy.",
                    "sections": [
                        {
                            "title": "App Engine Firewall",
                            "content": "<p>App Engine has a built-in, dedicated firewall. You can create rules based on IP address CIDR ranges. The default rule allows all traffic. A key best practice is to create a default rule with a `deny` action and a high priority number, and then create lower-numbered `allow` rules for specific trusted IP ranges (like your corporate network or the IP ranges of other cloud services).</p>",
                            "image": "https://images.unsplash.com/photo-1544890225-2fde1e46f71b?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Identity-Aware Proxy (IAP)",
                            "content": "<p>App Engine has the tightest integration with Identity-Aware Proxy. With just a few clicks in the console, you can place your entire App Engine application behind IAP. This forces every single user request to be authenticated and authorized against IAM before it ever touches your application code. This is an incredibly powerful and simple way to secure internal applications, moving from a network-based perimeter to a modern, Zero Trust identity-based perimeter.</p>",
                            "image": "https://images.unsplash.com/photo-1556742044-15b56a42a033?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the simplest and most effective way to secure an internal App Engine application so that it can only be accessed by authenticated employees?", "options": ["Using the App Engine Firewall to allow your corporate IP range", "Enabling Identity-Aware Proxy (IAP)", "Manually coding an authentication system yourself", "Relying on the default settings"], "correct": 1, "explanation": "IAP is specifically designed for this use case, providing a robust, identity-based perimeter for your applications with minimal configuration." }
                    ]
                }
            },
            {
                "id": "lesson-30-cloud-functions-security",
                "title": "Lesson 30: Cloud Functions Security",
                "duration": "120 min",
                "objectives": [
                    "Implement a least-privilege permission model for individual functions",
                    "Use VPC Connectors to allow functions to access resources in a private network",
                    "Securely manage environment variables with Secret Manager",
                    "Configure secure settings for HTTP and event-driven triggers"
                ],
                "content": {
                    "overview": "Cloud Functions are the serverless, event-driven compute service in GCP. Securing them involves a strong focus on identity and permissions, as they are often small, single-purpose pieces of 'glue' code that connect different services together. This lesson covers their security model.",
                    "sections": [
                        {
                            "title": "Identity and Permissions",
                            "content": "<p>The most important security control for a Cloud Function is its identity. You can specify a dedicated service account that the function will run as. This service account should be granted the absolute minimum IAM permissions required for the function to do its job. For example, if a function is triggered by a file upload and its only job is to write a message to a Pub/Sub topic, its service account should only have permission to publish to that one topic, and nothing else.</p>",
                            "image": "https://images.unsplash.com/photo-1555099962-4199c345e541?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "VPC Connector",
                            "content": "<p>By default, Cloud Functions run in a Google-managed environment and cannot access resources in your private VPC network. To allow a function to securely connect to a resource like a Cloud SQL database with a private IP, you must configure a Serverless VPC Access connector. This creates a secure tunnel from the function's environment into your selected VPC subnet.</p>",
                            "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Deploy a Secure Cloud Function (gcloud CLI)",
                        "language": "bash",
                        "code": "# This deploys a function specifying a least-privilege service account,\n# connects it to a VPC, and injects a secret as an environment variable.\ngcloud functions deploy my-secure-function \\\n    --runtime python39 \\\n    --trigger-topic my-input-topic \\\n    --service-account my-function-sa@my-project.iam.gserviceaccount.com \\\n    --vpc-connector projects/my-project/locations/us-central1/connectors/my-vpc-connector \\\n    --set-secrets \"API_KEY=my-api-key:latest\""
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the most critical security control to configure for a Cloud Function?", "options": ["Its name", "Its region", "The dedicated, least-privilege service account it runs as", "Its runtime language"], "correct": 2, "explanation": "The function's service account identity and its associated IAM permissions define the blast radius of what a compromised function could do." },
                        { "id": 2, "question": "To allow a Cloud Function to connect to a Cloud SQL database that only has a private IP address, you must use a:", "options": ["Serverless VPC Access connector", "Firewall rule", "VPN", "Load Balancer"], "correct": 0, "explanation": "A Serverless VPC Access connector is the specific networking component designed to bridge the gap between the Google-managed serverless environment and your private VPC." }
                    ]
                }
            },
            {
                "id": "lesson-31-cloud-run-security",
                "title": "Lesson 31: Cloud Run Security",
                "duration": "120 min",
                "objectives": [
                    "Apply a secure configuration to Cloud Run services",
                    "Implement service-to-service authentication using IAM",
                    "Manage ingress and egress network traffic for services",
                    "Set secure CPU and memory limits to prevent abuse"
                ],
                "content": {
                    "overview": "Cloud Run is a fully managed platform that enables you to run stateless containers that are invocable via web requests or Pub/Sub events. This lesson covers the best practices for securing your Cloud Run services.",
                    "sections": [
                        {
                            "title": "Ingress and Authentication",
                            "content": "<p>You have granular control over who can invoke your Cloud Run service.</p><ul><li><strong>Ingress Controls:</strong> You can configure the ingress setting to allow `all` traffic, `internal` traffic only (from within the same project/VPC), or `internal-and-cloud-load-balancing`. For an internal service, setting ingress to `internal` is a critical network security control.</li><li><strong>Authentication:</strong> By default, public services require no authentication. You can enforce IAM-based authentication so that only specific users or service accounts can invoke your service. Unauthenticated users will receive a 403 Forbidden error.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1579543183319-a16eee1b1fd3?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Deploy a Private, Authenticated Cloud Run Service (gcloud CLI)",
                        "language": "bash",
                        "code": "gcloud run deploy my-internal-service \\\n    --image gcr.io/my-project/my-app:latest \\\n    --platform managed \\\n    --region us-central1 \\\n    --no-allow-unauthenticated \\\n    --ingress internal"
                    },
                    {
                        "title": "Grant an Invoker Role to a Service Account (gcloud CLI)",
                        "language": "bash",
                        "code": "gcloud run services add-iam-policy-binding my-internal-service \\\n    --member=\"serviceAccount:my-caller-sa@my-project.iam.gserviceaccount.com\" \\\n    --role=\"roles/run.invoker\" \\\n    --region us-central1"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "You have a backend microservice deployed on Cloud Run that should only be callable by other services inside your VPC. Which ingress setting should you choose?", "options": ["all", "internal-and-cloud-load-balancing", "internal", "none"], "correct": 2, "explanation": "The 'internal' setting provides a strong network-level boundary, ensuring your service is not exposed to the public internet." }
                    ]
                }
            },
            {
                "id": "lesson-32-api-gateway-security",
                "title": "Lesson 32: API Gateway Security",
                "duration": "120 min",
                "objectives": [
                    "Use API Gateway to provide a secure front-end for your services",
                    "Implement API key-based and JWT-based authentication",
                    "Protect backend services by enforcing quotas and rate limits"
                ],
                "content": {
                    "overview": "API Gateway is a fully managed service that makes it easy to create, secure, and monitor APIs for your serverless backends, including Cloud Functions, Cloud Run, and App Engine. This lesson covers how to use it as a security enforcement point for your APIs.",
                    "sections": [
                        {
                            "title": "API Security with an OpenAPI Specification",
                            "content": "<p>You define your API's configuration, including its security, in an OpenAPI 2.0 or 3.0 specification file (in YAML). This provides a single, version-controllable source of truth for your API's behavior.</p><h3>Security Definitions:</h3><p>Within the YAML file, you can create `securityDefinitions` to specify the authentication methods your API will use. You can then apply these definitions to specific paths.</p><ul><li><strong>API Key:</strong> Require clients to pass a valid API key as a query parameter or in a header. You can manage these keys within GCP.</li><li><strong>JWT Authentication:</strong> Use a security definition to specify the JWT issuer, audience, and public key location (JWKS URI). The gateway will automatically validate the JWT on every request before forwarding it to the backend.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1596003906915-013661138ae2?w=800&h=400&fit-crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "OpenAPI Spec for JWT Authentication",
                        "language": "yaml",
                        "code": "swagger: '2.0'\ninfo:\n  title: My Secure API\n  version: 1.0.0\npaths:\n  /hello:\n    get:\n      summary: \"A secured endpoint\"\n      operationId: hello\n      x-google-backend:\n        address: https://my-backend.cloudfunctions.net/hello\n      security:\n        - jwt_auth: []\nsecurityDefinitions:\n  jwt_auth:\n    authorizationUrl: \"\"\n    flow: \"implicit\"\n    type: \"oauth2\"\n    x-google-issuer: \"https://accounts.google.com\"\n    x-google-jwks_uri: \"https://www.googleapis.com/oauth2/v3/certs\"\n    x-google-audiences: \"my-client-id\""
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "To secure an API deployed on Cloud Functions, the best practice is to place _______ in front of it to handle authentication and rate limiting.", "options": ["Cloud Storage", "API Gateway", "Cloud SQL", "Another Cloud Function"], "correct": 1, "explanation": "API Gateway acts as a dedicated, managed security and policy enforcement point, which is more secure and scalable than implementing these checks in your function code." }
                    ]
                }
            },
            {
                "id": "lesson-33-chronicle-siem",
                "title": "Lesson 33: Chronicle SIEM",
                "duration": "120 min",
                "objectives": [
                    "Understand Chronicle's architecture and petabyte-scale analysis capabilities",
                    "Ingest security telemetry into Chronicle using its forwarder and APIs",
                    "Normalize data using the Unified Data Model (UDM)",
                    "Create detection rules and conduct investigations in Chronicle"
                ],
                "content": {
                    "overview": "Chronicle is Google Cloud's security operations suite, including a powerful cloud-native SIEM. It is built on Google's massive infrastructure and designed for planet-scale data analysis and rapid threat detection. This lesson introduces the core concepts of the Chronicle platform.",
                    "sections": [
                        {
                            "title": "Chronicle Architecture",
                            "content": "<p>Chronicle is different from traditional SIEMs. Its pricing model is based on the number of employees, not the volume of data ingested. This encourages you to send *all* your security telemetry, giving you much deeper visibility. It automatically enriches your data with Google's own threat intelligence, including VirusTotal.</p><h3>Unified Data Model (UDM):</h3><p>As data is ingested, Chronicle normalizes it into a standard, structured schema called the Unified Data Model (UDM). This makes searching and rule writing much simpler, as you can write a query for `udm.principal.ip` and it will work across logs from your firewall, your EDR, and your web proxy without you needing to know the vendor-specific field names.</p>",
                            "image": "https://images.unsplash.com/photo-1542831371-d531d209121f?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "A key architectural feature of Chronicle SIEM is its ability to:", "options": ["Only ingest logs from GCP", "Normalize all ingested data into a standard schema called the Unified Data Model (UDM)", "Limit the amount of data you can send", "Only store data for 30 days"], "correct": 1, "explanation": "The UDM is the core of Chronicle's parsing and analysis engine, enabling powerful, unified searches and detections across diverse log sources." }
                    ]
                }
            },
            {
                "id": "lesson-34-security-analytics",
                "title": "Lesson 34: Security Analytics and Intelligence",
                "duration": "120 min",
                "objectives": [
                    "Build a security data lake on Cloud Storage and BigQuery",
                    "Use BigQuery for advanced, large-scale security analytics and threat hunting",
                    "Integrate threat intelligence feeds into your analytics process"
                ],
                "content": {
                    "overview": "For the most advanced and customized security analysis, many organizations build their own security data lake on top of GCP's powerful data platforms. This lesson covers the architecture and techniques for building this powerful analytics capability.",
                    "sections": [
                        {
                            "title": "Security Data Lake with BigQuery",
                            "content": "<p>You can use the log routing sinks from Cloud Logging to send all your security-relevant logs (Cloud Audit Logs, VPC Flow Logs, firewall logs) into BigQuery datasets. This provides you with a powerful, SQL-based platform for deep analysis.</p><h3>Why BigQuery for Security?:</h3><ul><li><strong>Massive Scalability:</strong> Can query terabytes of data in seconds and petabytes in minutes.</li><li><strong>SQL Interface:</strong> Allows security analysts who know SQL to perform complex threat hunts and analyses without needing to learn a new query language.</li><li><strong>Integration:</strong> BigQuery integrates with data visualization tools like Looker Studio, allowing you to build custom security dashboards.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary benefit of sending security logs to BigQuery?", "options": ["It is the cheapest way to store logs", "It provides a highly scalable, SQL-based platform for advanced security analytics and threat hunting", "It automatically finds all threats", "It encrypts the logs"], "correct": 1, "explanation": "BigQuery's power and familiar SQL interface make it an ideal platform for security data science and deep, customized investigations." }
                    ]
                }
            },
            {
                "id": "lesson-35-virustotal-enterprise",
                "title": "Lesson 35: VirusTotal Enterprise",
                "duration": "120 min",
                "objectives": [
                    "Use VirusTotal's rich dataset for threat intelligence and context",
                    "Analyze files and URLs to understand their behavior and reputation",
                    "Integrate VirusTotal's APIs into your security automation workflows"
                ],
                "content": {
                    "overview": "VirusTotal, part of Google Cloud, is one of the world's richest threat intelligence platforms. It aggregates data from over 70 antivirus scanners and dozens of other tools to provide a comprehensive reputation and behavioral analysis of files and URLs. This lesson covers how to leverage this intelligence in your security operations.",
                    "sections": [
                        {
                            "title": "Analysis and Threat Intelligence",
                            "content": "<p>When investigating an incident, you can take indicators (like a file hash or a suspicious domain) and look them up in VirusTotal. It provides a rich report containing:</p><ul><li><strong>Detection Ratios:</strong> How many antivirus engines detected the file as malicious.</li><li><strong>Behavioral Analysis:</strong> For executable files, a sandbox analysis shows what the file does when it runs (e.g., what network connections it makes, what registry keys it creates).</li><li><strong>Relationships:</strong> The VirusTotal dataset is a massive graph. It can show you what other domains a malicious IP has hosted, or what malware has been downloaded from a specific URL. This is incredibly powerful for pivoting and expanding your investigation.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1563905788977-62b714f520b2?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "VirusTotal is best described as a:", "options": ["SIEM", "Firewall", "Comprehensive threat intelligence and analysis platform", "Key management service"], "correct": 2, "explanation": "Its primary function is to aggregate threat intelligence from a huge number of sources to provide rich context on potential threats." }
                    ]
                }
            },
            {
                "id": "lesson-36-recaptcha-enterprise",
                "title": "Lesson 36: reCAPTCHA Enterprise",
                "duration": "120 min",
                "objectives": [
                    "Implement reCAPTCHA Enterprise to protect your websites from fraud and abuse",
                    "Analyze risk scores to differentiate between humans and bots",
                    "Configure score-based policies for your applications"
                ],
                "content": {
                    "overview": "reCAPTCHA Enterprise is an advanced anti-fraud service that helps you protect your websites from bots and other automated attacks. This lesson covers how to use it to protect your critical user workflows, like logins and payments.",
                    "sections": [
                        {
                            "title": "Risk Score Analysis",
                            "content": "<p>Unlike older versions of CAPTCHA, reCAPTCHA Enterprise is designed to be frictionless for most users. It analyzes a user's interaction and a rich set of browser signals to return a risk score from 0.0 to 1.0. Based on this score, your application can make a decision:</p><ul><li><strong>Low score (e.g., < 0.3):</strong> Likely a bot. You can block the request or require additional verification.</li><li><strong>Medium score (e.g., 0.3 - 0.7):</strong> Could be a suspicious human or a sophisticated bot. You might present a 2FA challenge.</li><li><strong>High score (e.g., > 0.7):</strong> Highly likely to be a human. Allow the action to proceed without any friction.</li></ul><p>This score-based approach provides a much better user experience than always presenting a challenge puzzle.</p>",
                            "image": "https://images.unsplash.com/photo-1614064548237-02f8f17374b2?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "reCAPTCHA Enterprise protects your websites primarily from what?", "options": ["Data exfiltration", "DDoS attacks", "Automated abuse by bots (e.g., credential stuffing, scraping)", "Vulnerable software"], "correct": 2, "explanation": "It is a specialized anti-bot and anti-fraud service." }
                    ]
                }
            },
            {
                "id": "lesson-37-cloud-build-security",
                "title": "Lesson 37: Cloud Build Security",
                "duration": "120 min",
                "objectives": [
                    "Create a secure CI/CD pipeline using Cloud Build",
                    "Protect the build process from tampering",
                    "Integrate automated security scans (SAST, SCA, image scanning) into the pipeline"
                ],
                "content": {
                    "overview": "Cloud Build is a fully managed continuous integration and delivery (CI/CD) platform. This DevSecOps lesson covers the best practices for securing your build pipelines to ensure your software is built and deployed securely.",
                    "sections": [
                        {
                            "title": "Build Pipeline Security",
                            "content": "<p>A secure pipeline integrates security at every step.</p><h3>The Secure Build Workflow:</h3><ol><li><strong>Source:</strong> A developer pushes code to Cloud Source Repositories.</li><li><strong>Build Trigger:</strong> The push triggers a Cloud Build pipeline.</li><li><strong>Security Scans:</strong> The build steps run a series of automated scans:<ul><li>Software Composition Analysis (SCA) to check for vulnerable dependencies.</li><li>Static Application Security Testing (SAST) to check your custom code for vulnerabilities.</li></ul></li><li><strong>Build and Scan Image:</strong> The pipeline builds a container image. It then scans the final image for OS vulnerabilities.</li><li><strong>Attestation:</strong> If all scans pass, an 'attestor' signs the image, creating an attestation for Binary Authorization.</li><li><strong>Push:</strong> The signed, verified image is pushed to Artifact Registry.</li></ol><p>If any security scan fails, the build fails, and the insecure artifact is never created or pushed.</p>",
                            "image": "https://images.unsplash.com/photo-1498050108023-c5249f4df085?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "In a secure Cloud Build pipeline, what should happen if a container vulnerability scan detects a critical CVE?", "options": ["The build should continue, but send a warning email", "The build should fail immediately, preventing the vulnerable image from being created", "The pipeline should automatically fix the vulnerability", "The pipeline should deploy the image anyway"], "correct": 1, "explanation": "Failing the build is the core principle of 'shifting left', ensuring that vulnerabilities are caught and fixed before they can ever reach production." }
                    ]
                }
            },
            {
                "id": "lesson-38-source-repository-security",
                "title": "Lesson 38: Cloud Source Repositories",
                "duration": "120 min",
                "objectives": [
                    "Secure source code using fine-grained IAM roles",
                    "Implement branch protection rules to enforce code reviews",
                    "Prevent secrets from being committed to your repositories"
                ],
                "content": {
                    "overview": "Your source code is your intellectual property. Securing your source code repositories is the first step in a secure software supply chain. This lesson covers the security features of Cloud Source Repositories.",
                    "sections": [
                        {
                            "title": "Access Control and Branch Protection",
                            "content": "<ul><li><strong>IAM Access:</strong> Access is controlled by IAM roles like `roles/source.reader` and `roles/source.writer`.</li><li><strong>Branch Protection Rules:</strong> A critical security control. You can create a rule that protects a branch (like `main` or `production`). This rule can enforce that no one can push directly to that branch. Instead, all changes must be made via a pull request that requires at least one code review from another developer. This 'four-eyes' principle helps catch bugs and security issues.</li><li><strong>Secret Detection:</strong> Cloud Source Repositories can be configured with Secret Manager to automatically detect if a developer accidentally tries to commit a secret (like an API key) to the repository, and can block the push.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1555099962-4199c345e541?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "A branch protection rule that requires all changes to the 'main' branch to go through a peer review is designed to prevent what?", "options": ["Poor code quality and unauthorized changes from being merged into production code", "The repository from being deleted", "Developers from using the correct programming language", "Slow builds"], "correct": 0, "explanation": "Requiring a review is a fundamental control for maintaining code quality and security." }
                    ]
                }
            },
            {
                "id": "lesson-39-container-analysis",
                "title": "Lesson 39: Container Analysis",
                "duration": "120 min",
                "objectives": [
                    "Use the Container Analysis API to get a history of scan results",
                    "Automate vulnerability management and remediation workflows",
                    "Integrate Container Analysis into a broader compliance and audit process"
                ],
                "content": {
                    "overview": "Container Analysis is the underlying service that powers vulnerability scanning in Artifact Registry and Cloud Build. This lesson covers how you can use its API directly to get detailed scan data and build custom security automation.",
                    "sections": [
                        {
                            "title": "API-driven Vulnerability Management",
                            "content": "<p>When Artifact Registry scans an image, it creates a 'vulnerability occurrence' in Container Analysis for each CVE it finds. You can use the Container Analysis API to query these occurrences. For example, when a new major vulnerability is announced (like Log4j), you can write a script to query the API to get a list of every single image in your organization that is affected by that specific CVE. This is incredibly powerful for impact assessment and driving remediation efforts.</p>",
                            "image": "https://images.unsplash.com/photo-1579543183319-a16eee1b1fd3?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What does the Container Analysis API allow you to do?", "options": ["Deploy containers to GKE", "Create container images", "Programmatically query the results of vulnerability scans to build custom automation and reporting", "Delete container images"], "correct": 2, "explanation": "The API provides direct access to the structured vulnerability data, enabling a wide range of custom DevSecOps workflows." }
                    ]
                }
            },
            {
                "id": "lesson-40-supply-chain-security",
                "title": "Lesson 40: Supply Chain Security",
                "duration": "120 min",
                "objectives": [
                    "Understand the risks of the modern software supply chain",
                    "Generate and use a Software Bill of Materials (SBOM)",
                    "Implement a defense-in-depth supply chain security strategy"
                ],
                "content": {
                    "overview": "A modern application is assembled from hundreds of open-source dependencies. Your application's security depends on the security of every one of those dependencies. This lesson covers the broader topic of software supply chain security and the tools GCP provides to help manage this risk.",
                    "sections": [
                        {
                            "title": "Software Bill of Materials (SBOM)",
                            "content": "<p>An SBOM is a list of all the components that make up a piece of software. It's like the list of ingredients on a food package. For a container, this would include the base OS, system libraries, and all the application's packages and dependencies.</p><p>Tools like Container Analysis can help generate an SBOM for your container images. This is becoming a critical component of compliance, as it gives you a complete inventory of what is inside your software so you can track vulnerabilities in your dependencies.</p>",
                            "image": "https://images.unsplash.com/photo-1498050108023-c5249f4df085?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Supply Chain Levels for Software Artifacts (SLSA)",
                            "content": "<p>SLSA (salsa) is a security framework from Google. It's a set of standards and controls to ensure the integrity of your software supply chain, from the source code to the final artifact. Many of the tools we've discussed (like source code review, automated builds, vulnerability scanning, and Binary Authorization) are components that help you achieve a higher SLSA level, which gives you stronger guarantees against tampering and unauthorized modification.</p>",
                            "image": "https://images.unsplash.com/photo-1521791136064-7986c2920216?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is a Software Bill of Materials (SBOM)?", "options": ["A license to use open-source software", "A list of all the open-source and third-party components included in an application", "An invoice for your software", "A firewall for your dependencies"], "correct": 1, "explanation": "An SBOM provides a detailed inventory of your software components, which is essential for managing supply chain vulnerabilities." }
                    ]
                }
            },
            {
                "id": "lesson-41-compliance",
                "title": "Lesson 41: Compliance and Certifications",
                "duration": "120 min",
                "objectives": [
                    "Use Google's compliance reports for your own audits",
                    "Architect environments to meet standards like SOC 2, ISO 27001, HIPAA, and PCI DSS",
                    "Use GCP's native tools for compliance monitoring and evidence gathering"
                ],
                "content": {
                    "overview": "Meeting regulatory and industry compliance is a primary driver for many security programs. This lesson covers how you can leverage GCP's compliant platform and native tools to build and operate environments that meet the requirements of major compliance frameworks.",
                    "sections": [
                        {
                            "title": "Compliance Resources",
                            "content": "<p>Google provides extensive resources to help you with compliance.</p><ul><li><strong>Compliance Reports Manager:</strong> The self-service portal (part of the Trust Center) where you can download Google's own audit reports (like SOC 2, ISO 27001) to demonstrate the compliance of the underlying platform to your auditors.</li><li><strong>Cloud Foundation Toolkit:</strong> A set of pre-built Terraform templates that deploy a secure and compliant landing zone based on Google's best practices.</li><li><strong>Security Command Center (Premium):</strong> Provides continuous compliance monitoring dashboards that map GCP's security checks directly to the controls of standards like PCI DSS, ISO 27001, and CIS Benchmarks.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "To get a copy of Google's own ISO 27001 certification to provide to your company's auditors, you would use:", "options": ["Security Command Center", "The Google Cloud sales team", "The Compliance Reports Manager", "Cloud Logging"], "correct": 2, "explanation": "The Compliance Reports Manager is the official, on-demand portal for accessing Google's audit reports and certifications." }
                    ]
                }
            },
            {
                "id": "lesson-42-data-governance",
                "title": "Lesson 42: Data Governance",
                "duration": "120 min",
                "objectives": [
                    "Use Data Catalog for automated metadata management and data discovery",
                    "Implement data retention policies using Object Lifecycle Management",
                    "Establish a robust data governance framework in the cloud"
                ],
                "content": {
                    "overview": "Data governance is a broad set of processes and policies for managing an organization's data assets. This lesson covers the GCP tools that support a data governance program, helping you understand what data you have, who owns it, and how it should be managed.",
                    "sections": [
                        {
                            "title": "Data Catalog",
                            "content": "<p>Data Catalog is a fully managed, scalable metadata management service. It automatically scans your data sources (like BigQuery and Cloud Storage) and catalogs your data assets. For BigQuery, it can automatically ingest technical metadata like table names and column schemas. You can then enrich this with business metadata by creating a 'data steward' role and having them apply tags that describe the business context, data owner, and data sensitivity. This provides a central, searchable inventory of all your key data assets.</p>",
                            "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Data Retention",
                            "content": "<p>Object Lifecycle Management in Cloud Storage allows you to automate your data retention policies. You can create a rule that says, for example, 'After 365 days, transition objects in this bucket to the Coldline storage class. After 7 years (2555 days), delete the object.' This provides automated, policy-based enforcement of your data retention and deletion requirements.</p>",
                            "image": "https://images.unsplash.com/photo-1542382156942-0268579cf259?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "Which service helps you create a central, searchable inventory of your data assets by managing their technical and business metadata?", "options": ["Data Catalog", "Cloud Functions", "Cloud Armor", "Cloud Build"], "correct": 0, "explanation": "Data Catalog is GCP's dedicated service for data discovery and metadata management, a core component of data governance." }
                    ]
                }
            },
            {
                "id": "lesson-43-risk-management",
                "title": "Lesson 43: Risk Management",
                "duration": "120 min",
                "objectives": [
                    "Integrate cloud security into your corporate risk management framework",
                    "Perform a threat model of a GCP application architecture",
                    "Use a risk matrix to score and prioritize security risks"
                ],
                "content": {
                    "overview": "This lesson focuses on the strategic process of risk management, covering how to identify, assess, and prioritize security risks in your GCP environment so that you can make informed, risk-based decisions about where to invest your security resources.",
                    "sections": [
                        {
                            "title": "Threat Modeling for GCP",
                            "content": "<p>Threat modeling is a structured process to identify threats to your system. A common approach for cloud architectures is:</p><ol><li><strong>Diagram the architecture:</strong> Draw out all the components (load balancer, VMs, database) and the data flows between them.</li><li><strong>Identify trust boundaries:</strong> Where does data cross from a less trusted zone to a more trusted one (e.g., from the public internet to your web server)?</li><li><strong>Brainstorm threats:</strong> For each component and data flow, use a framework like STRIDE to brainstorm potential threats. (e.g., 'What if an attacker could tamper with the data flowing from the web server to the database?').</li><li><strong>Mitigate and prioritize:</strong> Propose mitigation controls for each threat and prioritize them based on risk.</li></ol>",
                            "image": "https://images.unsplash.com/photo-1542626991-cbc4e32524cc?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "Threat modeling is primarily a ________ activity.", "options": ["reactive", "proactive", "manual", "automated"], "correct": 1, "explanation": "The entire point of threat modeling is to proactively find and fix design-level security flaws *before* they are built, which is much cheaper and more effective than finding them after a breach." }
                    ]
                }
            },
            {
                "id": "lesson-44-audit-assessment",
                "title": "Lesson 44: Audit and Assessment",
                "duration": "120 min",
                "objectives": [
                    "Prepare for and manage a third-party audit of your GCP environment",
                    "Understand and follow the rules of engagement for penetration testing",
                    "Automate evidence gathering for audits using GCP's native tools"
                ],
                "content": {
                    "overview": "Regular audits and security assessments are essential for validating the effectiveness of your security controls. This lesson covers how to prepare for an audit in a GCP environment and the specific rules you must follow when performing penetration testing on your own cloud resources.",
                    "sections": [
                        {
                            "title": "Preparing for an Audit",
                            "content": "<p>GCP's native tools make evidence gathering for an audit much simpler than in a traditional on-premises environment.</p><ul><li><strong>Compliance Reports Manager:</strong> Provides Google's own compliance reports.</li><li><strong>Security Command Center / Azure Policy:</strong> Provides the continuous compliance reports for your own environment against specific standards.</li><li><strong>Cloud Audit Logs:</strong> Provides the immutable evidence of who did what, and when.</li><li><strong>Cloud Asset Inventory:</strong> Provides a point-in-time inventory of all your assets and their configurations.</li></ul><p>You can create a custom IAM role with read-only access and grant it to your auditors so they can perform much of their evidence gathering in a self-service manner.</p>",
                            "image": "https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "Before starting a penetration test on your GCP resources, what is the most important first step?", "options": ["Ask Google to disable their security monitoring", "Review and agree to the GCP Penetration Testing Rules of Engagement", "Get your own cyber insurance", "Warn the attackers you are coming"], "correct": 1, "explanation": "You are a tenant in a multi-tenant cloud. You must follow the rules of engagement to ensure your testing does not impact other customers or the platform itself." }
                    ]
                }
            },
            {
                "id": "lesson-45-gcp-ir",
                "title": "Lesson 45: GCP Incident Response",
                "duration": "120 min",
                "objectives": [
                    "Adapt the incident response lifecycle to the GCP cloud",
                    "Use GCP-native tools for evidence preservation and collection",
                    "Know how and when to escalate to Google Cloud Support",
                    "Perform forensic data collection in a cloud-native way"
                ],
                "content": {
                    "overview": "When an incident happens, you need a plan. This lesson adapts the classic incident response framework to the Google Cloud, covering the specific tools and techniques used for detection, containment, eradication, and recovery in a GCP environment.",
                    "sections": [
                        {
                            "title": "Forensic Data Collection in GCP",
                            "content": "<p>In the cloud, you don't have physical access, so evidence collection is done via API calls.</p><h3>The Forensic Workflow:</h3><ol><li><strong>Containment:</strong> The first step is to isolate the compromised VM. The best way is to apply a network tag like 'quarantine' to the VM and have a high-priority firewall rule that denies all traffic to and from any VM with that tag.</li><li><strong>Disk Acquisition:</strong> Take a persistent disk snapshot of the compromised VM's disk. This is a point-in-time, forensically sound copy.</li><li><strong>Analysis:</strong> Create a new disk from that snapshot and attach it as a secondary, non-boot drive to a clean forensic analysis VM in a separate, isolated VPC. You can then mount it read-only and begin your investigation.</li></ol>",
                            "image": "https://images.unsplash.com/photo-1618498263386-339c9a7593c6?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the GCP equivalent of creating a bit-for-bit forensic image of a hard drive?", "options": ["Creating a new IAM user", "Creating a persistent disk snapshot", "Running a vulnerability scan", "Enabling Security Command Center"], "correct": 1, "explanation": "A persistent disk snapshot is the foundational evidence acquisition method for virtual machine disks in GCP." }
                    ]
                }
            },
            {
                "id": "lesson-46-security-automation",
                "title": "Lesson 46: Security Automation",
                "duration": "120 min",
                "objectives": [
                    "Use Cloud Functions for event-driven security automation",
                    "Trigger automation from security findings using Pub/Sub",
                    "Build a basic 'auto-remediation' workflow"
                ],
                "content": {
                    "overview": "This lesson focuses on the hands-on implementation of security automation in GCP. You will learn how to use serverless tools like Cloud Functions and Pub/Sub to create auto-remediation workflows that respond to security events in real time.",
                    "sections": [
                        {
                            "title": "Event-Driven Automation",
                            "content": "<p>The foundation of security automation in GCP is the event-driven model.</p><h3>The Automation Workflow:</h3><ol><li><strong>Source (Finding):</strong> A security service like Security Command Center generates a finding (e.g., 'Public GCS Bucket detected').</li><li><strong>Notification Channel (Pub/Sub):</strong> You configure SCC to send all new findings to a Pub/Sub topic.</li><li><strong>Trigger (Event):</strong> The message arriving on the Pub/Sub topic acts as a trigger.</li><li><strong>Action (Cloud Function):</strong> A Cloud Function is subscribed to this topic. When it receives the message about the public bucket, its code is executed. The code can then use the GCS client library to call the Storage API and disable public access on the bucket.</li></ol>",
                            "image": "https://images.unsplash.com/photo-1542708944-9721d234a413?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What two services are the core components of most event-driven security automation workflows in GCP?", "options": ["Compute Engine and Cloud SQL", "Pub/Sub (for events) and Cloud Functions (for actions)", "VPC and Cloud Storage", "Cloud Armor and Cloud Build"], "correct": 1, "explanation": "This serverless, event-driven pattern (a source sends a message to Pub/Sub, which triggers a Function) is the standard and most scalable way to build automation on GCP." }
                    ]
                }
            },
            {
                "id": "lesson-47-threat-hunting",
                "title": "Lesson 47: Threat Detection and Hunting",
                "duration": "120 min",
                "objectives": [
                    "Use BigQuery and Logs Explorer for advanced threat hunting",
                    "Hunt for specific MITRE ATT&CK techniques in Cloud Audit Logs",
                    "Integrate threat intelligence feeds for enhanced detection"
                ],
                "content": {
                    "overview": "This lesson takes you deep into the proactive side of security operations in GCP. You will learn how to use the powerful query capabilities of BigQuery and the rich data in Cloud Audit Logs to hunt for advanced threats that have evaded your automated detections.",
                    "sections": [
                        {
                            "title": "Hunting with BigQuery",
                            "content": "<p>By sinking your Cloud Audit Logs to BigQuery, you create a powerful platform for threat hunting. You can write complex SQL queries to search for suspicious patterns across months or years of data. For example, you can hunt for a user who has an unusually high number of failed IAM policy checks, or look for a service account that is suddenly being used from a new geographic location.</p>",
                            "image": "https://images.unsplash.com/photo-1542831371-d531d209121f?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "BigQuery Hunt for Service Account Key Creation",
                        "language": "sql",
                        "code": "SELECT\n  protopayload_auditlog.authenticationInfo.principalEmail AS user,\n  protopayload_auditlog.resourceName AS service_account,\n  timestamp\nFROM\n  `my_project.my_dataset.cloudaudit_googleapis_com_activity`\nWHERE\n  protopayload_auditlog.methodName = 'google.iam.admin.v1.CreateServiceAccountKey'"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the key benefit of routing your audit logs to BigQuery?", "options": ["It deletes the logs", "It encrypts the logs", "It provides a powerful, scalable, SQL-based platform for long-term analysis and threat hunting", "It is required for all projects"], "correct": 2, "explanation": "BigQuery turns your logs from a simple record into a rich, queryable dataset for deep security analytics." }
                    ]
                }
            },
            {
                "id": "lesson-48-recovery-lessons-learned",
                "title": "Lesson 48: Recovery and Lessons Learned",
                "duration": "120 min",
                "objectives": [
                    "Implement a secure recovery process following an incident",
                    "Conduct a post-incident 'lessons learned' review",
                    "Use incident findings to drive meaningful security improvements"
                ],
                "content": {
                    "overview": "The final stage of the incident response lifecycle is recovery and learning. This lesson covers the methodical process of restoring services securely and the critical importance of a blameless post-mortem to ensure your organization learns from the incident and improves its defenses.",
                    "sections": [
                        {
                            "title": "The Post-Incident Review",
                            "content": "<p>The post-incident review (or lessons learned meeting) is one of the most important parts of the entire process. The goal is to identify the root cause of the incident and produce actionable recommendations to prevent it from happening again. This must be a 'blameless' process, focused on fixing broken processes and technology, not blaming people.</p>",
                            "image": "https://images.unsplash.com/photo-1542626991-cbc4e32524cc?w=800&h=400&fit-crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "The primary goal of a blameless post-mortem or lessons learned review is to:", "options": ["Determine who to fire", "Identify the root cause of the incident and create actionable plans to improve security, without assigning blame to individuals", "Complete the required paperwork", "Close the incident ticket as quickly as possible"], "correct": 1, "explanation": "A culture of blameless learning is essential for a mature security program. It encourages honesty and focuses on systemic improvements." }
                    ]
                }
            },
            {
                "id": "lesson-49-enterprise-security-architecture",
                "title": "Lesson 49: Enterprise Security Architecture",
                "duration": "120 min",
                "objectives": [
                    "Design a multi-project security architecture using the Google Cloud Foundation Toolkit",
                    "Understand and implement a secure 'landing zone'",
                    "Establish a Security Center of Excellence to scale security practices"
                ],
                "content": {
                    "overview": "This lesson brings together all the concepts of the course to discuss how they apply to designing a holistic security architecture for a large enterprise. We will cover Google's prescriptive guidance for building a secure, multi-project 'landing zone'.",
                    "sections": [
                        {
                            "title": "The Secure Landing Zone",
                            "content": "<p>A landing zone is a pre-configured, secure, multi-project environment that is built based on security best practices. It provides a safe 'landing' place for you to start deploying your workloads.</p><h3>Key Components of a GCP Landing Zone:</h3><ul><li><strong>A well-defined resource hierarchy:</strong> A central organization with folders for different environments.</li><li><strong>A Shared VPC network:</strong> A central hub-and-spoke network managed by a central team.</li><li><strong>Centralized Logging:</strong> An organization-level log sink that sends all logs to a central Log Archive project.</li><li><strong>Preventative Guardrails:</strong> A set of organization policies to enforce security constraints.</li><li><strong>Centralized Identity:</strong> Federation with your corporate IdP.</li></ul><p>Google provides a set of Terraform templates called the 'Cloud Foundation Toolkit' that can deploy a best-practice landing zone automatically.</p>",
                            "image": "https://images.unsplash.com/photo-1521791136064-7986c2920216?w=800&h=400&fit-crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the purpose of a secure landing zone?", "options": ["To provide a single project for all company resources", "To provide a pre-configured, secure, best-practice foundation for deploying workloads in the cloud", "To make all resources public", "To reduce the number of security controls needed"], "correct": 1, "explanation": "A landing zone accelerates secure cloud adoption by providing a pre-built, compliant, and secure environment, saving each application team from having to reinvent the wheel." }
                    ]
                }
            },
            {
                "id": "lesson-50-final-capstone-project",
                "title": "Lesson 50: Final Capstone Project",
                "duration": "240 min",
                "objectives": [
                    "Design and implement a complete, end-to-end secure GCP solution for a complex scenario",
                    "Integrate multiple security services across identity, network, data, and applications",
                    "Produce professional-quality security architecture documentation and Infrastructure as Code"
                ],
                "content": {
                    "overview": "The final capstone project is a comprehensive exercise that requires you to synthesize every skill learned in this program. You will be assigned a detailed business and security requirements document for a fictional enterprise. Your mission is to act as the lead cloud security architect, designing and deploying a secure, compliant, and well-architected GCP environment from the ground up.",
                    "sections": [
                        {
                            "title": "The Capstone Scenario",
                            "content": "<p><strong>The Task:</strong> You are tasked with designing the global GCP environment for a fictional e-commerce company that is moving to the cloud. The solution must be PCI DSS compliant, highly available, and follow Zero Trust principles.</p><h3>Your Deliverables:</h3><ol><li><strong>Security Architecture Document:</strong> A detailed document outlining your proposed architecture, including the resource hierarchy, the hub-and-spoke network design, the IAM and identity federation strategy, data protection controls, and the monitoring/IR plan.</li><li><strong>Infrastructure as Code (IaC):</strong> A set of Terraform or Cloud Deployment Manager templates that will deploy your core landing zone infrastructure.</li><li><strong>Governance and Policy:</strong> A set of custom organization policies and a Binary Authorization policy for the container pipeline.</li><li><strong>Presentation:</strong> A final presentation to a panel of 'executives' where you justify your architectural decisions and how they meet the business and compliance requirements.</li></ol>",
                            "image": "https://images.unsplash.com/photo-1498050108023-c5249f4df085?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 100,
                    "questions": [
                        { "id": 1, "question": "The final capstone project assesses your ability to:", "options": ["Write a single firewall rule", "Answer multiple choice questions", "Synthesize the knowledge from the entire course to design, build, and document a real-world secure cloud solution", "Restart a virtual machine"], "correct": 2, "explanation": "This project is the ultimate test, requiring you to apply your knowledge in a practical and holistic way to solve a complex, enterprise-grade security architecture problem." }
                    ]
                }
            }
        ]
    }
      // =====================================================
      // GLOBAL VARIABLES
      // =====================================================
      let currentUser = null;
      let currentLessonIndex = 0;
      let courseProgress = {};
      let userStats = {};
      let quizState = {
        currentQuestion: 0,
        answers: [],
        score: 0,
        isComplete: false,
      };

      // Enhanced session tracking
      let courseSession = {
        startTime: null,
        totalStudyTime: 0,
        lessonsStarted: 0,
        lessonsCompleted: 0,
        pageLoadTime: new Date(),
        interactionCount: 0,
        lastActivityTime: new Date(),
      };

      // Music Player Variables
      let audioPlayer = new Audio();

      // Achievement notification system
      let notificationQueue = [];
      let isShowingNotification = false;

      // =====================================================
      // INITIALIZATION
      // =====================================================
      document.addEventListener("DOMContentLoaded", async () => {
        try {
          showLoadingScreen();
          await checkAuth();

          if (currentUser) {
            // Initialize session tracking
            startCourseSession();

            // Load course data and progress
            await loadCourseData();
            await loadUserProfile();
            await loadProgress();

            // Initialize UI
            initializeEventListeners();
            renderSidebar();
            loadLesson(currentLessonIndex);

            // Initialize additional features
            initMusicPlayer();
            addMusicIndicator();
            initializeActivityTracking();

            hideLoadingScreen();
          } else {
            openAuthModal();
          }
        } catch (error) {
          console.error("Error initializing course:", error);
          hideLoadingScreen();
          showToast("Failed to initialize course system", "error");
        }
      });

      // =====================================================
      // AUTHENTICATION SYSTEM
      // =====================================================
      async function checkAuth() {
        try {
          const {
            data: { session },
            error,
          } = await supabase.auth.getSession();

          if (error) {
            console.error("Auth error:", error);
            currentUser = null;
            openAuthModal();
            return;
          }

          if (!session) {
            currentUser = null;
            openAuthModal();
            return;
          }

          currentUser = session.user;
          updateUIWithUser();
        } catch (error) {
          console.error("Error checking auth:", error);
          currentUser = null;
          openAuthModal();
        }
      }

      function updateUIWithUser() {
        if (!currentUser) return;

        const name =
          currentUser.user_metadata?.full_name ||
          currentUser.email.split("@")[0];
        const userElements = document.querySelectorAll("[data-user-name]");
        userElements.forEach((el) => (el.textContent = name));
      }

      // =====================================================
      // USER PROFILE & STATS MANAGEMENT
      // =====================================================
      async function loadUserProfile() {
        try {
          //  Step 1: Try to fetch existing profile
          const { data: profile, error } = await supabase
            .from("profiles")
            .select("*")
            .eq("id", currentUser.id)
            .single();

          if (error && error.code !== "PGRST116") {
            throw error;
          }

          if (!profile) {
            //  Step 2: Create new profile if missing
            await createUserProfile();
          } else {
            //  Step 3: Use existing profile
            userStats = profile;
            await updateLastActivity();
          }
        } catch (error) {
          console.error(" Error loading user profile:", error);
          showToast("Failed to load user profile", "error");
        }
      }
      async function createUserProfile() {
        try {
          const newProfile = {
            id: currentUser.id,
            full_name: currentUser.user_metadata?.full_name || "",
            email: currentUser.email,
            level: "Script Kiddie",
            total_points: 0,
            completed_courses: 0,
            current_streak: 0,
            total_certificates: 0,
            total_achievements: 0,
            sections_visited: 0,
            bonus_points: 0,
            in_progress_courses: 0,
            settings_changed: 0,
            midnight_sessions: 0,
            early_sessions: 0,
            weekend_sessions: 0,
            last_activity: new Date().toISOString(),
            created_at: new Date().toISOString(),
          };

          const { error } = await supabase
            .from("profiles")
            .insert([newProfile]);

          if (!error) {
            userStats = newProfile;
            // Award first login achievement
            setTimeout(() => checkAndUnlockAchievement("first_login"), 1000);
          }
        } catch (error) {
          console.error("Error creating user profile:", error);
        }
      }

      async function updateLastActivity() {
        try {
          const now = new Date();

          // Update activity tracking
          courseSession.lastActivityTime = now;

          // Update database
          await supabase
            .from("profiles")
            .update({
              last_activity: now.toISOString(),
            })
            .eq("id", currentUser.id);

          // Check time-based achievements
          await checkTimeBasedAchievements(now);
        } catch (error) {
          console.error("Error updating last activity:", error);
        }
      }

      // =====================================================
      // COURSE SESSION MANAGEMENT
      // =====================================================
      function startCourseSession() {
        courseSession.startTime = new Date();
        courseSession.pageLoadTime = new Date();

        logUserActivity("course_session_start", {
          course_id: COURSE_DATA.id,
          course_title: COURSE_DATA.title,
          user_agent: navigator.userAgent,
          screen_resolution: `${screen.width}x${screen.height}`,
        });

        // Check daily streak
        checkDailyStreak();
      }

      function initializeActivityTracking() {
        // Track page focus/blur for accurate study time
        document.addEventListener("visibilitychange", handleVisibilityChange);

        // Track user interactions
        ["click", "keydown", "scroll", "mousemove"].forEach((event) => {
          document.addEventListener(event, trackUserInteraction, {
            passive: true,
          });
        });

        // Periodic activity updates
        setInterval(updateStudyTime, 60000); // Every minute

        // Save session data before page unload
        window.addEventListener("beforeunload", saveSessionData);
      }

      function handleVisibilityChange() {
        if (document.hidden) {
          courseSession.lastActivityTime = new Date();
        } else {
          // Page became visible again - update activity
          updateLastActivity();
        }
      }

      function trackUserInteraction() {
        courseSession.interactionCount++;
        courseSession.lastActivityTime = new Date();

        // Throttle activity updates
        if (courseSession.interactionCount % 50 === 0) {
          updateLastActivity();
        }
      }

      function updateStudyTime() {
        if (!courseSession.startTime || document.hidden) return;

        const now = new Date();
        const sessionDuration = now - courseSession.startTime;
        courseSession.totalStudyTime = Math.floor(sessionDuration / 1000 / 60); // in minutes

        // Update progress with study time
        saveProgress();
      }

      function saveSessionData() {
        if (!currentUser || !courseSession.startTime) return;

        const sessionData = {
          user_id: currentUser.id,
          course_id: COURSE_DATA.id,
          session_duration: courseSession.totalStudyTime,
          lessons_viewed: courseSession.lessonsStarted,
          lessons_completed: courseSession.lessonsCompleted,
          interactions: courseSession.interactionCount,
          session_date: courseSession.startTime.toISOString().split("T")[0],
        };

        // Store in localStorage as backup
        localStorage.setItem(
          "course_session_backup",
          JSON.stringify(sessionData)
        );

        // Try to save to database
        logUserActivity("course_session_end", sessionData);
      }

      // =====================================================
      // COURSE DATA & PROGRESS MANAGEMENT
      // =====================================================
      async function loadCourseData() {
        try {
          // Update course info in UI
          document.getElementById("courseTitle").textContent =
            COURSE_DATA.title;
          document.getElementById("totalLessons").textContent =
            COURSE_DATA.lessons.length;

          // Log course access
          logUserActivity("course_access", {
            course_id: COURSE_DATA.id,
            course_title: COURSE_DATA.title,
          });
        } catch (error) {
          console.error("Error loading course data:", error);
        }
      }

      async function loadProgress() {
        try {
          // Get existing progress from database
          const { data, error } = await supabase
            .from("course_progress")
            .select("*")
            .eq("user_id", currentUser.id)
            .eq("course_id", COURSE_DATA.id)
            .single();

          if (error && error.code !== "PGRST116") {
            throw error;
          }

          if (data) {
            courseProgress = JSON.parse(data.lesson_progress || "{}");
            currentLessonIndex = data.current_lesson || 0;

            // Update session tracking
            courseSession.lessonsStarted = Object.keys(courseProgress).length;
            courseSession.lessonsCompleted = Object.values(
              courseProgress
            ).filter((p) => p.completed).length;
          } else {
            // Initialize new progress
            courseProgress = {};
            currentLessonIndex = 0;
            await saveProgress();

            // Award first course start achievement
            await checkAndUnlockAchievement("first_course_start");
          }

          updateProgressDisplay();
        } catch (error) {
          console.error("Error loading progress:", error);
          showToast("Failed to load progress", "error");
        }
      }

      async function saveProgress() {
        try {
          if (!currentUser) return;

          const now = new Date();
          const progressData = {
            user_id: currentUser.id,
            course_id: COURSE_DATA.id,
            course_title: COURSE_DATA.title,
            current_lesson: currentLessonIndex,
            lesson_progress: JSON.stringify(courseProgress),
            progress: calculateOverallProgress(),
            lessons_completed: getCompletedLessonsCount(),
            lessons_started: Object.keys(courseProgress).length,
            study_time_minutes: courseSession.totalStudyTime,
            last_accessed: now.toISOString(),
            updated_at: now.toISOString(),
          };

          // Upsert progress
          const { error } = await supabase
            .from("course_progress")
            .upsert([progressData]);

          if (error) throw error;

          // Update user stats
          await updateUserStats();

          updateProgressDisplay();
        } catch (error) {
          console.error("Error saving progress:", error);
          showToast("Failed to save progress", "error");
        }
      }

      async function updateUserStats() {
        try {
          // Get all course progress for this user
          const { data: allProgress, error } = await supabase
            .from("course_progress")
            .select("progress, course_id, study_time_minutes")
            .eq("user_id", currentUser.id);

          if (error) throw error;

          // Calculate stats
          const completedCourses =
            allProgress?.filter((p) => p.progress >= 100).length || 0;
          const inProgressCourses =
            allProgress?.filter((p) => p.progress > 0 && p.progress < 100)
              .length || 0;
          const totalStudyTime =
            allProgress?.reduce(
              (sum, p) => sum + (p.study_time_minutes || 0),
              0
            ) || 0;

          // Calculate points (500 per completed course + achievement points)
          const coursePoints = completedCourses * 500;
          const bonusPoints = userStats.bonus_points || 0;
          const totalPoints = coursePoints + bonusPoints;

          // Update profile
          const updateData = {
            completed_courses: completedCourses,
            in_progress_courses: inProgressCourses,
            total_points: totalPoints,
            total_study_time: totalStudyTime,
            last_activity: new Date().toISOString(),
          };

          const { error: updateError } = await supabase
            .from("profiles")
            .update(updateData)
            .eq("id", currentUser.id);

          if (updateError) throw updateError;

          // Update local stats
          Object.assign(userStats, updateData);
        } catch (error) {
          console.error("Error updating user stats:", error);
        }
      }

      function calculateOverallProgress() {
        const completedLessons = getCompletedLessonsCount();
        return Math.round(
          (completedLessons / COURSE_DATA.lessons.length) * 100
        );
      }

      function getCompletedLessonsCount() {
        return Object.values(courseProgress).filter(
          (lesson) => lesson.completed
        ).length;
      }

      function updateProgressDisplay() {
        const completedCount = getCompletedLessonsCount();
        const progressPercent = calculateOverallProgress();

        // Update UI elements
        const elements = {
          completedLessons: completedCount,
          courseProgressPercent: `${progressPercent}%`,
        };

        Object.entries(elements).forEach(([id, value]) => {
          const element = document.getElementById(id);
          if (element) element.textContent = value;
        });

        // Update progress bar
        const progressBar = document.getElementById("courseProgressFill");
        if (progressBar) progressBar.style.width = `${progressPercent}%`;
      }

      // =====================================================
      // LESSON MANAGEMENT
      // =====================================================
      function loadLesson(index) {
        if (index < 0 || index >= COURSE_DATA.lessons.length) return;

        const lesson = COURSE_DATA.lessons[index];
        currentLessonIndex = index;

        // Mark lesson as started and track activity
        if (!courseProgress[lesson.id]) {
          courseProgress[lesson.id] = {
            started: true,
            completed: false,
            startedAt: new Date().toISOString(),
            timeSpent: 0,
          };

          courseSession.lessonsStarted++;
          saveProgress();

          // Log lesson start
          logUserActivity("lesson_start", {
            lesson_id: lesson.id,
            lesson_title: lesson.title,
            lesson_index: index,
          });
        }

        // Update lesson start time for time tracking
        courseProgress[lesson.id].currentSessionStart = new Date();

        // Update sidebar and navigation
        renderSidebar();
        updateNavigationButtons();

        // Update header info
        updateLessonHeader(lesson, index);

        // Render lesson content
        renderLessonContent(lesson);

        // Smooth scroll and animations
        window.scrollTo({ top: 0, behavior: "smooth" });
        document.getElementById("contentBody").scrollTop = 0;

        const contentBody = document.getElementById("contentBody");
        contentBody.classList.add("fade-in");
        setTimeout(() => contentBody.classList.remove("fade-in"), 500);

        // Check lesson-based achievements
        checkLessonAchievements(index + 1);
      }

      function updateLessonHeader(lesson, index) {
        const elements = {
          currentLessonNumber: index + 1,
          currentLessonTitle: lesson.title,
          navInfo: `Lesson ${index + 1} of ${COURSE_DATA.lessons.length}`,
        };

        Object.entries(elements).forEach(([id, value]) => {
          const element = document.getElementById(id);
          if (element) element.textContent = value;
        });
      }

      function renderSidebar() {
        const lessonNav = document.getElementById("lessonNav");
        if (!lessonNav) return;

        lessonNav.innerHTML = "";

        COURSE_DATA.lessons.forEach((lesson, index) => {
          const lessonItem = document.createElement("div");
          lessonItem.className = "lesson-item";

          // Determine lesson status
          const lessonProgress = courseProgress[lesson.id];
          const isCompleted = lessonProgress?.completed || false;
          const isInProgress = lessonProgress?.started || false;
          const isLocked = !isCompleted && !canAccessLesson(index);
          const isActive = index === currentLessonIndex;

          // Apply status classes
          if (isCompleted) lessonItem.classList.add("completed");
          if (isLocked) lessonItem.classList.add("locked");
          if (isActive) lessonItem.classList.add("active");

          // Determine status display
          let statusClass = "not-started";
          let statusIcon = index + 1;

          if (isCompleted) {
            statusClass = "completed";
            statusIcon = "";
          } else if (isInProgress) {
            statusClass = "in-progress";
            statusIcon = "";
          }

          // Create lesson item HTML
          lessonItem.innerHTML = `
            <div class="lesson-status ${statusClass}">${statusIcon}</div>
            <div class="lesson-info">
                <div class="lesson-title">${lesson.title}</div>
                <div class="lesson-meta">
                    ${
                      isCompleted
                        ? "Completed"
                        : isInProgress
                        ? "In Progress"
                        : isLocked
                        ? "Locked"
                        : "Not Started"
                    }
                </div>
            </div>
            <div class="lesson-duration">${lesson.duration}</div>
        `;

          // Add click handler if not locked
          if (!isLocked) {
            lessonItem.addEventListener("click", () => {
              if (index !== currentLessonIndex) {
                // Track lesson time before switching
                trackLessonTime();

                currentLessonIndex = index;
                loadLesson(index);
                closeSidebar();
              }
            });
          }

          lessonNav.appendChild(lessonItem);
        });
      }

      function canAccessLesson(index) {
        if (index === 0) return true; // First lesson always accessible

        // Can access if previous lesson is completed
        const previousLessonId = COURSE_DATA.lessons[index - 1].id;
        return courseProgress[previousLessonId]?.completed || false;
      }

      function trackLessonTime() {
        const currentLesson = COURSE_DATA.lessons[currentLessonIndex];
        const lessonProgress = courseProgress[currentLesson.id];

        if (lessonProgress?.currentSessionStart) {
          const sessionTime = Math.floor(
            (new Date() - new Date(lessonProgress.currentSessionStart)) /
              1000 /
              60
          );
          lessonProgress.timeSpent =
            (lessonProgress.timeSpent || 0) + sessionTime;
          delete lessonProgress.currentSessionStart;
        }
      }

      // =====================================================
      // LESSON CONTENT RENDERING
      // =====================================================
      function renderLessonContent(lesson) {
        const contentContainer = document.getElementById("lessonContent");
        if (!contentContainer) return;

        let contentHTML = `
        <div class="content-section">
            <h2>Learning Objectives</h2>
            <ul>
                ${lesson.objectives.map((obj) => `<li>${obj}</li>`).join("")}
            </ul>
        </div>
        
        <div class="content-section">
            <h2>Overview</h2>
            <p>${lesson.content.overview}</p>
        </div>
    `;

        // Render content sections
        lesson.content.sections.forEach((section) => {
          contentHTML += `
            <div class="content-section">
                <h2>${section.title}</h2>
                ${section.content}
                ${
                  section.image
                    ? `<img src="${section.image}" alt="${section.title}" class="content-image" loading="lazy">`
                    : ""
                }
            </div>
        `;
        });

        // Render code examples
        if (
          lesson.content.codeExamples &&
          lesson.content.codeExamples.length > 0
        ) {
          contentHTML += `<div class="content-section"><h2>Code Examples</h2></div>`;

          lesson.content.codeExamples.forEach((example, index) => {
            const codeId = `code-${lesson.id}-${index}`;
            contentHTML += `
                <div class="code-section">
                    <div class="code-header">
                        <span class="code-title">${example.title}</span>
                        <button class="copy-btn" onclick="copyCode('${codeId}')">
                            <i class="fas fa-copy"></i> Copy
                        </button>
                    </div>
                    <pre class="code-block"><code id="${codeId}" class="language-${
              example.language
            }">${escapeHtml(example.code)}</code></pre>
                </div>
            `;
          });
        }

        // Render quiz
        contentHTML += renderQuiz(lesson.quiz);

        contentContainer.innerHTML = contentHTML;

        // Highlight code syntax if Prism is available
        setTimeout(() => {
          if (window.Prism) {
            Prism.highlightAll();
          }
        }, 100);
      }

      // =====================================================
      // QUIZ SYSTEM
      // =====================================================
      function renderQuiz(quiz) {
        const currentLessonProgress =
          courseProgress[COURSE_DATA.lessons[currentLessonIndex].id];
        const isCompleted = currentLessonProgress?.completed || false;

        let quizHTML = `
        <div class="quiz-section" id="quizSection">
            <div class="quiz-header">
                <h2 class="quiz-title">
                    <i class="fas fa-clipboard-check"></i>
                    Knowledge Check
                </h2>
                <p class="quiz-info">
                    Complete this quiz with ${quiz.passingScore}% or higher to unlock the next lesson.
                </p>
            </div>
    `;

        if (isCompleted) {
          const savedScore = currentLessonProgress.quizScore || 0;
          quizHTML += `
            <div class="quiz-results show">
                <div class="quiz-score pass">${savedScore}%</div>
                <div class="quiz-message">
                    <strong>Lesson Completed!</strong><br>
                    You've successfully passed this lesson's quiz.
                </div>
            </div>
        `;
        } else {
          // Render quiz questions
          quiz.questions.forEach((question, qIndex) => {
            quizHTML += `
                <div class="quiz-question ${
                  qIndex === 0 ? "active" : ""
                }" data-question="${qIndex}">
                    <div class="question-header">
                        <span class="question-number">Question ${
                          qIndex + 1
                        }</span>
                        <span class="question-progress">${qIndex + 1}/${
              quiz.questions.length
            }</span>
                    </div>
                    <div class="question-text">${question.question}</div>
                    <div class="question-options">
                        ${question.options
                          .map(
                            (option, oIndex) => `
                            <div class="option" data-option="${oIndex}" onclick="selectOption(${qIndex}, ${oIndex})">
                                <span class="option-letter">${String.fromCharCode(
                                  65 + oIndex
                                )}</span>
                                <span class="option-text">${option}</span>
                            </div>
                        `
                          )
                          .join("")}
                    </div>
                </div>
            `;
          });

          quizHTML += `
            <div class="quiz-controls">
                <button class="btn btn-secondary" id="prevQuestionBtn" onclick="previousQuestion()" disabled>
                    <i class="fas fa-chevron-left"></i>
                    Previous
                </button>
                <div>
                    <button class="btn btn-secondary" id="nextQuestionBtn" onclick="nextQuestion()" disabled>
                        Next
                        <i class="fas fa-chevron-right"></i>
                    </button>
                    <button class="btn btn-primary" id="submitQuizBtn" onclick="submitQuiz()" style="display: none;">
                        <i class="fas fa-check"></i>
                        Submit Quiz
                    </button>
                </div>
            </div>

            <div class="quiz-results" id="quizResults">
                <div class="quiz-score" id="quizScore">0%</div>
                <div class="quiz-message" id="quizMessage"></div>
                <div class="quiz-actions">
                    <button class="btn btn-primary" id="continueBtn" onclick="completeLesson()" style="display: none;">
                        <i class="fas fa-arrow-right"></i>
                        Continue to Next Lesson
                    </button>
                    <button class="btn btn-secondary" onclick="retakeQuiz()">
                        <i class="fas fa-redo"></i>
                        Retake Quiz
                    </button>
                </div>
            </div>
        `;
        }

        quizHTML += "</div>";
        return quizHTML;
      }

      // Quiz interaction functions
      function selectOption(questionIndex, optionIndex) {
        // Clear previous selections
        document
          .querySelectorAll(`[data-question="${questionIndex}"] .option`)
          .forEach((opt) => {
            opt.classList.remove("selected");
          });

        // Select current option
        const selectedOption = document.querySelector(
          `[data-question="${questionIndex}"] [data-option="${optionIndex}"]`
        );
        selectedOption.classList.add("selected");

        // Store answer
        quizState.answers[questionIndex] = optionIndex;

        // Update navigation
        const isLastQuestion =
          questionIndex ===
          COURSE_DATA.lessons[currentLessonIndex].quiz.questions.length - 1;
        if (isLastQuestion) {
          document.getElementById("submitQuizBtn").style.display =
            "inline-flex";
          document.getElementById("nextQuestionBtn").style.display = "none";
        } else {
          document.getElementById("nextQuestionBtn").disabled = false;
        }
      }

      function nextQuestion() {
        const currentQuestionEl = document.querySelector(
          ".quiz-question.active"
        );
        const nextQuestionEl = currentQuestionEl.nextElementSibling;

        if (
          nextQuestionEl &&
          nextQuestionEl.classList.contains("quiz-question")
        ) {
          currentQuestionEl.classList.remove("active");
          nextQuestionEl.classList.add("active");
          quizState.currentQuestion++;
          updateQuizNavigation();
        }
      }

      function previousQuestion() {
        const currentQuestionEl = document.querySelector(
          ".quiz-question.active"
        );
        const prevQuestionEl = currentQuestionEl.previousElementSibling;

        if (
          prevQuestionEl &&
          prevQuestionEl.classList.contains("quiz-question")
        ) {
          currentQuestionEl.classList.remove("active");
          prevQuestionEl.classList.add("active");
          quizState.currentQuestion--;
          updateQuizNavigation();
        }
      }

      function updateQuizNavigation() {
        const totalQuestions =
          COURSE_DATA.lessons[currentLessonIndex].quiz.questions.length;
        const prevBtn = document.getElementById("prevQuestionBtn");
        const nextBtn = document.getElementById("nextQuestionBtn");
        const submitBtn = document.getElementById("submitQuizBtn");

        prevBtn.disabled = quizState.currentQuestion === 0;

        const hasAnswer =
          quizState.answers[quizState.currentQuestion] !== undefined;
        const isLastQuestion = quizState.currentQuestion === totalQuestions - 1;

        if (isLastQuestion) {
          nextBtn.style.display = "none";
          submitBtn.style.display = hasAnswer ? "inline-flex" : "none";
        } else {
          nextBtn.style.display = "inline-flex";
          nextBtn.disabled = !hasAnswer;
          submitBtn.style.display = "none";
        }
      }

      async function submitQuiz() {
        const lesson = COURSE_DATA.lessons[currentLessonIndex];
        const quiz = lesson.quiz;
        let correctAnswers = 0;

        // Hide questions and controls
        document
          .querySelectorAll(".quiz-question")
          .forEach((q) => (q.style.display = "none"));
        document.querySelector(".quiz-controls").style.display = "none";

        // Calculate score and highlight answers
        quiz.questions.forEach((question, index) => {
          const userAnswer = quizState.answers[index];
          const correctAnswer = question.correct;
          const isCorrect = userAnswer === correctAnswer;

          if (isCorrect) correctAnswers++;

          // Highlight answers
          const questionEl = document.querySelector(
            `[data-question="${index}"]`
          );
          const options = questionEl.querySelectorAll(".option");

          options[correctAnswer].classList.add("correct");
          if (userAnswer !== correctAnswer && userAnswer !== undefined) {
            options[userAnswer].classList.add("incorrect");
          }
        });

        const score = Math.round(
          (correctAnswers / quiz.questions.length) * 100
        );
        const passed = score >= quiz.passingScore;

        // Update quiz results UI
        const quizScore = document.getElementById("quizScore");
        const quizMessage = document.getElementById("quizMessage");
        const quizActions = document.querySelector(".quiz-actions");

        quizScore.textContent = `${score}%`;
        quizScore.className = `quiz-score ${passed ? "pass" : "fail"}`;

        if (passed) {
          quizMessage.innerHTML = `
            <strong>Congratulations!</strong><br>
            You passed with ${score}%. You can now proceed to the next lesson.
        `;

          quizActions.innerHTML = `
            <button class="btn btn-primary" onclick="completeLesson()">
                <i class="fas fa-arrow-right"></i>
                Continue to Next Lesson
            </button>
        `;

          // Mark lesson as completed
          await markLessonComplete(score);
        } else {
          quizMessage.innerHTML = `
            <strong>Not quite there yet.</strong><br>
            You scored ${score}%. You need ${quiz.passingScore}% to pass. Review the material and try again.
        `;

          quizActions.innerHTML = `
            <button class="btn btn-secondary" onclick="retakeQuiz()">
                <i class="fas fa-redo"></i>
                Retake Quiz
            </button>
        `;
        }

        document.getElementById("quizResults").classList.add("show");

        // Log quiz completion
        logUserActivity("quiz_completed", {
          lesson_id: lesson.id,
          lesson_title: lesson.title,
          score: score,
          passed: passed,
          attempts: (courseProgress[lesson.id]?.quizAttempts || 0) + 1,
        });

        // Scroll to results
        document
          .getElementById("quizResults")
          .scrollIntoView({ behavior: "smooth" });
      }

      function retakeQuiz() {
        // Reset quiz state
        quizState = {
          currentQuestion: 0,
          answers: [],
          score: 0,
          isComplete: false,
        };

        // Track quiz retry
        const lessonId = COURSE_DATA.lessons[currentLessonIndex].id;
        if (!courseProgress[lessonId]) courseProgress[lessonId] = {};
        courseProgress[lessonId].quizAttempts =
          (courseProgress[lessonId].quizAttempts || 0) + 1;

        // Reload lesson content
        loadLesson(currentLessonIndex);

        // Scroll to quiz
        setTimeout(() => {
          document
            .getElementById("quizSection")
            .scrollIntoView({ behavior: "smooth" });
        }, 500);
      }

      async function markLessonComplete(score) {
        const lesson = COURSE_DATA.lessons[currentLessonIndex];
        const lessonId = lesson.id;

        // Track lesson completion time
        trackLessonTime();

        // Update lesson progress
        courseProgress[lessonId] = {
          ...courseProgress[lessonId],
          completed: true,
          quizScore: score,
          completedAt: new Date().toISOString(),
          finalScore: score,
        };

        // Update session tracking
        courseSession.lessonsCompleted++;

        // Save progress to database
        await saveProgress();

        // Update UI
        renderSidebar();
        updateNavigationButtons();

        // Check various achievements
        await checkLessonCompletionAchievements();
        await checkPerfectScoreAchievements(score);
        await checkStudyTimeAchievements();

        // Log lesson completion
        logUserActivity("lesson_completed", {
          lesson_id: lessonId,
          lesson_title: lesson.title,
          final_score: score,
          time_spent: courseProgress[lessonId].timeSpent || 0,
          lesson_number: currentLessonIndex + 1,
        });

        showToast("Lesson completed successfully!", "success");
      }

      async function completeLesson() {
        if (currentLessonIndex < COURSE_DATA.lessons.length - 1) {
          // Move to next lesson
          currentLessonIndex++;
          loadLesson(currentLessonIndex);
        } else {
          // Course completion
          await completeCourse();
        }
      }

      async function completeCourse() {
        try {
          const completionTime = courseSession.totalStudyTime;

          // Update course progress to 100% completed
          await supabase
            .from("course_progress")
            .update({
              progress: 100,
              completed_at: new Date().toISOString(),
              completion_time_minutes: completionTime,
            })
            .eq("user_id", currentUser.id)
            .eq("course_id", COURSE_DATA.id);

          // Award course completion achievements
          await checkAndUnlockAchievement("course_completion_1");
          await checkSpeedCompletionAchievements(completionTime);
          await checkCourseStreakAchievements();

          // Update user stats
          await updateUserStats();

          // Show completion message
          showToast(
            "Congratulations! Course completed successfully!",
            "certificate"
          );

          // Log course completion
          logUserActivity("course_completed", {
            course_id: COURSE_DATA.id,
            course_title: COURSE_DATA.title,
            completion_time_minutes: completionTime,
            total_lessons: COURSE_DATA.lessons.length,
            average_quiz_score: calculateAverageQuizScore(),
          });

          // Redirect to dashboard after delay
          setTimeout(() => {
            window.location.href = "/dashboard";
          }, 3000);
        } catch (error) {
          console.error("Error completing course:", error);
          showToast("Error marking course as complete", "error");
        }
      }

      // =====================================================
      // ACHIEVEMENT INTEGRATION SYSTEM
      // =====================================================
      async function checkAndUnlockAchievement(
        achievementId,
        skipNotification = false
      ) {
        try {
          // Prevent duplicate checks
          const cacheKey = `achievement_${achievementId}_${currentUser.id}`;
          if (sessionStorage.getItem(cacheKey)) return false;

          // Check if already unlocked
          const { data: existing, error } = await supabase
            .from("user_achievements")
            .select("id")
            .eq("user_id", currentUser.id)
            .eq("achievement_id", achievementId)
            .single();

          if (existing) {
            sessionStorage.setItem(cacheKey, "true");
            return false;
          }

          // Award achievement
          const achievementData = {
            user_id: currentUser.id,
            achievement_id: achievementId,
            unlocked_at: new Date().toISOString(),
            points_awarded: getAchievementPoints(achievementId),
            context: "course_system",
          };

          const { data, error: insertError } = await supabase
            .from("user_achievements")
            .insert([achievementData])
            .select()
            .single();

          if (insertError) {
            if (insertError.code === "23505") return false; // Already exists
            throw insertError;
          }

          // Update user points
         await supabase.rpc('increment_user_stats', {
  user_id_param: currentUser.id,
  points_to_add: achievementData.points_awarded,
  achievements_to_add: 1
});

          // Cache and queue notification
          sessionStorage.setItem(cacheKey, "true");

          if (!skipNotification) {
            queueAchievementNotification({
              id: achievementId,
              name: getAchievementName(achievementId),
              description: getAchievementDescription(achievementId),
              points: achievementData.points_awarded,
              rarity: getAchievementRarity(achievementId),
              icon: getAchievementIcon(achievementId),
            });
          }

          return true;
        } catch (error) {
          console.error("Error unlocking achievement:", error);
          return false;
        }
      }

      // Helper functions for achievement data (replace with your actual achievement definitions)
      function getAchievementPoints(id) {
        const pointsMap = {
          first_course_start: 75,
          first_lesson: 100,
          course_completion_1: 500,
          perfect_score: 250,
          speed_demon: 750,
          marathon_learner: 500,
          night_owl: 200,
          early_bird: 200,
          weekend_warrior: 150,
          // Add more as needed
        };
        return pointsMap[id] || 100;
      }

      function getAchievementName(id) {
        const nameMap = {
          first_course_start: "Learning Initiated",
          first_lesson: "First Steps",
          course_completion_1: "Course Conqueror",
          perfect_score: "Perfectionist",
          speed_demon: "Speed Demon",
          // Add more as needed
        };
        return nameMap[id] || "Achievement Unlocked";
      }

      function getAchievementDescription(id) {
        const descMap = {
          first_course_start: "Start your first cybersecurity course",
          first_lesson: "Complete your first lesson",
          course_completion_1: "Complete your first course",
          perfect_score: "Score 100% on any quiz",
          speed_demon: "Complete a course in under 2 hours",
          // Add more as needed
        };
        return descMap[id] || "Achievement description";
      }

      function getAchievementRarity(id) {
        const rarityMap = {
          first_course_start: "common",
          first_lesson: "bronze",
          course_completion_1: "silver",
          perfect_score: "gold",
          speed_demon: "legendary",
          // Add more as needed
        };
        return rarityMap[id] || "common";
      }

      function getAchievementIcon(id) {
        const iconMap = {
          first_course_start: "fas fa-play",
          first_lesson: "fas fa-baby",
          course_completion_1: "fas fa-trophy",
          perfect_score: "fas fa-star",
          speed_demon: "fas fa-rocket",
          // Add more as needed
        };
        return iconMap[id] || "fas fa-award";
      }

      async function checkLessonAchievements(lessonNumber) {
        if (lessonNumber === 1) {
          await checkAndUnlockAchievement("first_lesson");
        }

        // Check if user has completed multiple lessons in one day
        const today = new Date().toISOString().split("T")[0];
        const todayCompletions = Object.values(courseProgress).filter(
          (p) => p.completed && p.completedAt?.startsWith(today)
        ).length;

        if (todayCompletions >= 3) {
          await checkAndUnlockAchievement("lesson_marathon");
        }
      }

      async function checkLessonCompletionAchievements() {
        const completedCount = getCompletedLessonsCount();

        // Lesson-based achievements
        const lessonMilestones = [1, 5, 10, 25, 50, 100];
        for (const milestone of lessonMilestones) {
          if (completedCount >= milestone) {
            await checkAndUnlockAchievement(`lessons_${milestone}`);
          }
        }

        // Course completion achievements
        if (completedCount === COURSE_DATA.lessons.length) {
          await checkAndUnlockAchievement("course_completion_1");

          // Check for additional course completion achievements
          const { data: allCourses } = await supabase
            .from("course_progress")
            .select("course_id")
            .eq("user_id", currentUser.id)
            .eq("progress", 100);

          const totalCompleted = allCourses?.length || 0;

          const courseMilestones = [1, 5, 10, 25];
          for (const milestone of courseMilestones) {
            if (totalCompleted >= milestone) {
              await checkAndUnlockAchievement(`course_completion_${milestone}`);
            }
          }
        }
      }

      async function checkPerfectScoreAchievements(score) {
        if (score === 100) {
          await checkAndUnlockAchievement("perfect_score");

          // Check for consecutive perfect scores
          const recentScores = Object.values(courseProgress)
            .filter((p) => p.completed && p.quizScore)
            .slice(-5) // Last 5 completed
            .map((p) => p.quizScore);

          if (
            recentScores.length >= 3 &&
            recentScores.every((s) => s === 100)
          ) {
            await checkAndUnlockAchievement("perfectionist_streak");
          }
        }
      }

      async function checkSpeedCompletionAchievements(completionTime) {
        // Speed demon: Complete course in under 2 hours (120 minutes)
        if (completionTime <= 120) {
          await checkAndUnlockAchievement("speed_demon");
        }

        // Quick learner: Complete course in under 4 hours (240 minutes)
        if (completionTime <= 240) {
          await checkAndUnlockAchievement("quick_learner");
        }
      }

      async function checkStudyTimeAchievements() {
        const totalTime = courseSession.totalStudyTime;

        // Marathon learner: Study for 8+ hours in a course session
        if (totalTime >= 480) {
          // 8 hours
          await checkAndUnlockAchievement("marathon_learner");
        }

        // Dedicated learner: Study for 4+ hours
        if (totalTime >= 240) {
          // 4 hours
          await checkAndUnlockAchievement("dedicated_learner");
        }
      }

      async function checkCourseStreakAchievements() {
        try {
          // Check for consecutive course completions
          const { data: recentCourses, error } = await supabase
            .from("course_progress")
            .select("completed_at, course_id")
            .eq("user_id", currentUser.id)
            .eq("progress", 100)
            .order("completed_at", { ascending: false })
            .limit(10);

          if (error || !recentCourses) return;

          // Check for courses completed on consecutive days
          let consecutiveDays = 1;
          for (let i = 1; i < recentCourses.length; i++) {
            const prevDate = new Date(
              recentCourses[i - 1].completed_at
            ).toDateString();
            const currentDate = new Date(
              recentCourses[i].completed_at
            ).toDateString();
            const dayDiff =
              Math.abs(new Date(prevDate) - new Date(currentDate)) /
              (1000 * 60 * 60 * 24);

            if (dayDiff <= 1) {
              consecutiveDays++;
            } else {
              break;
            }
          }

          if (consecutiveDays >= 3) {
            await checkAndUnlockAchievement("learning_streak");
          }
        } catch (error) {
          console.error("Error checking course streak achievements:", error);
        }
      }

      // =====================================================
      // TIME-BASED ACHIEVEMENTS
      // =====================================================
      async function checkTimeBasedAchievements(timestamp) {
        const hour = timestamp.getHours();
        const dayOfWeek = timestamp.getDay();

        // Night owl (after midnight, before 6 AM)
        if (hour >= 0 && hour < 6) {
          await incrementTimeBasedCounter("midnight_sessions", "night_owl");
        }

        // Early bird (4 AM to 6 AM)
        if (hour >= 4 && hour < 6) {
          await incrementTimeBasedCounter("early_sessions", "early_bird");
        }

        // Weekend warrior (Saturday = 6, Sunday = 0)
        if (dayOfWeek === 0 || dayOfWeek === 6) {
          await incrementTimeBasedCounter(
            "weekend_sessions",
            "weekend_warrior"
          );
        }
      }

      async function incrementTimeBasedCounter(counterType, achievementId) {
        try {
          const dateStr = new Date().toISOString().split("T")[0];
          const cacheKey = `${counterType}_${currentUser.id}_${dateStr}`;

          // Prevent multiple increments per day
          if (sessionStorage.getItem(cacheKey)) return;

          // Update counter
       await supabase.rpc('increment_profile_counter', {
  user_id_param: currentUser.id,
  counter_field: counterType,
  increment_value: 1
});

          // Cache to prevent double counting
          sessionStorage.setItem(cacheKey, "true");

          // Check related achievement
          if (achievementId) {
            await checkAndUnlockAchievement(achievementId, true);
          }
        } catch (error) {
          console.error(`Error incrementing ${counterType}:`, error);
        }
      }

      async function checkDailyStreak() {
        try {
          const { data: profile, error } = await supabase
            .from("profiles")
            .select("last_activity, current_streak, last_streak_date")
            .eq("id", currentUser.id)
            .single();

          if (error) throw error;

          const now = new Date();
          const today = now.toDateString();
          const lastActivity = profile.last_activity
            ? new Date(profile.last_activity)
            : null;
          const lastStreakDate = profile.last_streak_date
            ? new Date(profile.last_streak_date).toDateString()
            : null;

          let newStreak = profile.current_streak || 0;
          let shouldUpdateStreak = false;

          if (!lastActivity) {
            // First time user
            newStreak = 1;
            shouldUpdateStreak = true;
          } else {
            const daysSinceLastActivity = Math.floor(
              (now - lastActivity) / (1000 * 60 * 60 * 24)
            );

            if (lastStreakDate === today) {
              // Already counted today's streak
              return newStreak;
            } else if (
              daysSinceLastActivity === 1 ||
              (daysSinceLastActivity === 0 && lastStreakDate !== today)
            ) {
              // Consecutive day or same day but not counted yet
              newStreak += 1;
              shouldUpdateStreak = true;
            } else if (daysSinceLastActivity > 1) {
              // Streak broken
              newStreak = 1;
              shouldUpdateStreak = true;
            }
          }

          if (shouldUpdateStreak) {
            await supabase
              .from("profiles")
              .update({
                current_streak: newStreak,
                last_activity: now.toISOString(),
                last_streak_date: now.toISOString(),
              })
              .eq("id", currentUser.id);

            userStats.current_streak = newStreak;

            showToast(`Daily streak: ${newStreak} days!`, "success");
            await checkStreakAchievements(newStreak);
          }

          return newStreak;
        } catch (error) {
          console.error("Error checking daily streak:", error);
          return 0;
        }
      }

      async function checkStreakAchievements(currentStreak) {
        const streakMilestones = [3, 7, 14, 30, 100, 365];

        for (const milestone of streakMilestones) {
          if (currentStreak >= milestone) {
            await checkAndUnlockAchievement(`streak_${milestone}`);
          }
        }
      }

      // =====================================================
      // USER ACTIVITY LOGGING
      // =====================================================
      async function logUserActivity(activityType, metadata = {}) {
        try {
          const now = new Date();

          const activityData = {
            user_id: currentUser.id,
            activity_type: activityType,
            timestamp: now.toISOString(),
            course_id: COURSE_DATA.id,
            lesson_index: currentLessonIndex,
            session_duration: courseSession.totalStudyTime,
            metadata: JSON.stringify(metadata),
            created_at: now.toISOString(),
          };

          // Try to log to activities table
          const { error } = await supabase
            .from("user_activities")
            .insert([activityData]);

          if (error && error.code !== "42P01") {
            console.warn("Activity logging failed:", error.message);
          }

          // Always update last activity in profile
          await supabase
            .from("profiles")
            .update({ last_activity: now.toISOString() })
            .eq("id", currentUser.id);
        } catch (error) {
          console.error("Error logging user activity:", error);
        }
      }

      // =====================================================
      // NAVIGATION SYSTEM
      // =====================================================
      function updateNavigationButtons() {
        const prevBtn = document.getElementById("prevLessonBtn");
        const nextBtn = document.getElementById("nextLessonBtn");

        if (!prevBtn || !nextBtn) return;

        // Previous button
        prevBtn.disabled = currentLessonIndex === 0;

        // Next button logic
        const isLastLesson =
          currentLessonIndex === COURSE_DATA.lessons.length - 1;
        const canGoNext =
          currentLessonIndex < COURSE_DATA.lessons.length - 1 &&
          canAccessLesson(currentLessonIndex + 1);

        if (isLastLesson) {
          const isCurrentCompleted =
            courseProgress[COURSE_DATA.lessons[currentLessonIndex].id]
              ?.completed;
          nextBtn.disabled = !isCurrentCompleted;
          nextBtn.innerHTML = '<i class="fas fa-trophy"></i> Complete Course';
        } else {
          nextBtn.disabled = !canGoNext;
          nextBtn.innerHTML = 'Next <i class="fas fa-chevron-right"></i>';
        }
      }

      // Navigation button event handlers
      function goToPreviousLesson() {
        if (currentLessonIndex > 0) {
          trackLessonTime(); // Track time spent on current lesson
          currentLessonIndex--;
          loadLesson(currentLessonIndex);
        }
      }

      function goToNextLesson() {
        if (currentLessonIndex < COURSE_DATA.lessons.length - 1) {
          const canGoNext = canAccessLesson(currentLessonIndex + 1);
          if (canGoNext) {
            trackLessonTime();
            currentLessonIndex++;
            loadLesson(currentLessonIndex);
          } else {
            showToast("Complete the current lesson quiz to proceed", "warning");
          }
        } else {
          // Complete course
          completeCourse();
        }
      }

      // =====================================================
      // SIDEBAR FUNCTIONS
      // =====================================================
      function toggleSidebar() {
        const sidebar = document.getElementById("sidebar");
        const overlay = document.getElementById("sidebarOverlay");

        if (sidebar) sidebar.classList.toggle("open");
        if (overlay) overlay.classList.toggle("active");
      }

      function closeSidebar() {
        const sidebar = document.getElementById("sidebar");
        const overlay = document.getElementById("sidebarOverlay");

        if (sidebar) sidebar.classList.remove("open");
        if (overlay) overlay.classList.remove("active");
      }

      // =====================================================
      // ACHIEVEMENT NOTIFICATION SYSTEM
      // =====================================================
      function queueAchievementNotification(achievement) {
        notificationQueue.push(achievement);
        processNotificationQueue();
      }

      function processNotificationQueue() {
        if (isShowingNotification || notificationQueue.length === 0) return;

        isShowingNotification = true;
        const achievement = notificationQueue.shift();
        showAchievementNotification(achievement);

        const duration =
          achievement.rarity === "mythic"
            ? 8000
            : achievement.rarity === "legendary"
            ? 7000
            : 6000;

        setTimeout(() => {
          isShowingNotification = false;
          processNotificationQueue();
        }, duration + 500);
      }

      function showAchievementNotification(achievement) {
        const notification = document.getElementById("achievementNotification");
        if (!notification) return;

        const icon = document.getElementById("notificationIcon");
        const title = document.getElementById("notificationTitle");
        const description = document.getElementById("notificationDescription");
        const points = document.getElementById("notificationPoints");

        if (icon) {
          icon.innerHTML = `<i class="${achievement.icon}"></i>`;
          icon.className = `notification-icon ${achievement.rarity}`;
        }
        if (title) title.textContent = achievement.name;
        if (description) description.textContent = achievement.description;
        if (points) points.textContent = `+${achievement.points} Points`;

        notification.className = `achievement-notification ${achievement.rarity}`;
        notification.classList.add("show");

        const duration =
          achievement.rarity === "mythic"
            ? 8000
            : achievement.rarity === "legendary"
            ? 7000
            : 6000;

        setTimeout(() => {
          notification.classList.remove("show");
        }, duration);
      }

      // =====================================================
      // UTILITY FUNCTIONS
      // =====================================================
      function calculateAverageQuizScore() {
        const scores = Object.values(courseProgress)
          .filter((p) => p.completed && p.quizScore)
          .map((p) => p.quizScore);

        if (scores.length === 0) return 0;
        return Math.round(
          scores.reduce((sum, score) => sum + score, 0) / scores.length
        );
      }

      async function resetProgress() {
        if (
          !confirm(
            "Are you sure you want to reset your progress? This action cannot be undone."
          )
        ) {
          return;
        }

        try {
          // Track lesson time before reset
          trackLessonTime();

          // Reset local state
          courseProgress = {};
          currentLessonIndex = 0;
          courseSession = {
            startTime: new Date(),
            totalStudyTime: 0,
            lessonsStarted: 0,
            lessonsCompleted: 0,
            pageLoadTime: new Date(),
            interactionCount: 0,
            lastActivityTime: new Date(),
          };

          // Delete from database
          await supabase
            .from("course_progress")
            .delete()
            .eq("user_id", currentUser.id)
            .eq("course_id", COURSE_DATA.id);

          // Log reset activity
          logUserActivity("progress_reset", {
            course_id: COURSE_DATA.id,
            reset_reason: "manual",
          });

          // Reinitialize
          await saveProgress();
          renderSidebar();
          loadLesson(0);

          showToast("Progress reset successfully", "success");
        } catch (error) {
          console.error("Error resetting progress:", error);
          showToast("Failed to reset progress", "error");
        }
      }

      function copyCode(codeId) {
        const codeElement = document.getElementById(codeId);
        if (!codeElement) return;

        const text = codeElement.textContent;

        navigator.clipboard
          .writeText(text)
          .then(() => {
            showToast("Code copied to clipboard!", "success");

            // Track code copy for achievements
            logUserActivity("code_copied", {
              code_section: codeId,
              lesson_id: COURSE_DATA.lessons[currentLessonIndex].id,
            });
          })
          .catch((err) => {
            console.error("Failed to copy code:", err);
            showToast("Failed to copy code", "error");

            // Fallback for older browsers
            const textArea = document.createElement("textarea");
            textArea.value = text;
            document.body.appendChild(textArea);
            textArea.select();
            try {
              document.execCommand("copy");
              showToast("Code copied to clipboard!", "success");
            } catch (fallbackError) {
              showToast(
                "Copy failed - please select and copy manually",
                "error"
              );
            }
            document.body.removeChild(textArea);
          });
      }

      function escapeHtml(text) {
        const div = document.createElement("div");
        div.textContent = text;
        return div.innerHTML;
      }

      // =====================================================
      // UI FEEDBACK SYSTEMS
      // =====================================================
      function showToast(message, type = "success") {
        const toast = document.getElementById("toast");
        const messageEl = document.getElementById("toastMessage");

        if (!toast || !messageEl) {
          console.log(`Toast: ${message} (${type})`);
          return;
        }

        messageEl.textContent = message;
        toast.className = `toast ${type} show`;

        setTimeout(() => {
          toast.classList.remove("show");
        }, 4000);
      }

      function showLoadingScreen() {
        const loadingScreen = document.getElementById("loadingScreen");
        if (loadingScreen) loadingScreen.classList.remove("hidden");
      }

      function hideLoadingScreen() {
        const loadingScreen = document.getElementById("loadingScreen");
        if (loadingScreen) {
          setTimeout(() => {
            loadingScreen.classList.add("hidden");
          }, 1000);
        }
      }

      // =====================================================
      // MUSIC PLAYER INTEGRATION
      // =====================================================
      function initMusicPlayer() {
        const btnText = document.getElementById("music-button-text");
        const icon = document.getElementById("music-icon");
        const dropdown = document.getElementById("music-dropdown-content");

        if (!btnText || !icon || !dropdown) return;

        function setUI(state) {
          btnText.textContent =
            state === "Playing" ? "PAUSE MUSIC" : "STUDY MUSIC";
          icon.className =
            state === "Playing"
              ? "fa-solid fa-circle-pause"
              : "fa-solid fa-music";
        }

        // Load saved music state
        const savedSrc = localStorage.getItem("cybersec_music_src");
        const savedTime = parseFloat(
          localStorage.getItem("cybersec_music_time") || 0
        );

        if (savedSrc) {
          audioPlayer.src = savedSrc;
          audioPlayer.currentTime = savedTime;
          audioPlayer
            .play()
            .then(() => setUI("Playing"))
            .catch(() => setUI("Stopped"));
        }

        // Music button click handler
        document
          .getElementById("music-dropdown")
          .querySelector("button")
          .addEventListener("click", (e) => {
            e.stopPropagation();
            dropdown.style.display =
              dropdown.style.display === "block" ? "none" : "block";

            if (audioPlayer.src && !audioPlayer.paused) {
              audioPlayer.pause();
              setUI("Stopped");
            } else if (audioPlayer.src) {
              audioPlayer.play().then(() => setUI("Playing"));
            }
          });

        // Music selection handlers
        dropdown.querySelectorAll("a[data-src]").forEach((link) => {
          link.addEventListener("click", (e) => {
            e.preventDefault();
            audioPlayer.src = link.dataset.src;
            audioPlayer.play().then(() => setUI("Playing"));
            localStorage.setItem("cybersec_music_src", link.dataset.src);
            dropdown.style.display = "none";
          });
        });

        // Stop music handler
        const stopLink = document.getElementById("stop-music-link");
        if (stopLink) {
          stopLink.addEventListener("click", (e) => {
            e.preventDefault();
            audioPlayer.pause();
            audioPlayer.currentTime = 0;
            audioPlayer.removeAttribute("src");
            setUI("Stopped");
            localStorage.removeItem("cybersec_music_src");
            localStorage.removeItem("cybersec_music_time");
            dropdown.style.display = "none";
          });
        }

        // Save music state before page unload
        window.addEventListener("beforeunload", () => {
          if (!audioPlayer.paused && audioPlayer.src) {
            localStorage.setItem("cybersec_music_src", audioPlayer.src);
            localStorage.setItem(
              "cybersec_music_time",
              audioPlayer.currentTime
            );
          }
        });

        // Close dropdown when clicking outside
        window.addEventListener("click", (e) => {
          if (!e.target.closest("#music-dropdown")) {
            dropdown.style.display = "none";
          }
        });
      }

      // Show initial music indicator
      function addMusicIndicator() {
        const musicBtn = document.querySelector("#music-dropdown");
        if (musicBtn) {
          const indicator = document.createElement("div");
          indicator.className = "music-indicator";
          indicator.innerHTML = `<i class="fa-solid fa-music"></i> Try Study Music!`;

          musicBtn.style.position = "relative";
          musicBtn.appendChild(indicator);

          setTimeout(() => indicator.remove(), 3000);
        }
      }

      // Initialize Event Listeners
      function initializeEventListeners() {
        // Navigation buttons
        document
          .getElementById("prevLessonBtn")
          ?.addEventListener("click", goToPreviousLesson);
        document
          .getElementById("nextLessonBtn")
          ?.addEventListener("click", goToNextLesson);

        // Reset progress button
        document
          .getElementById("resetProgressBtn")
          ?.addEventListener("click", resetProgress);

        // Mobile menu toggle
        document
          .getElementById("menuToggle")
          ?.addEventListener("click", toggleSidebar);
        document
          .getElementById("sidebarOverlay")
          ?.addEventListener("click", closeSidebar);

        // Keyboard shortcuts
        document.addEventListener("keydown", handleKeyboardShortcuts);

        // Window resize handler
        window.addEventListener("resize", handleWindowResize);

        // Content interaction tracking
        document.getElementById("contentBody")?.addEventListener(
          "scroll",
          debounce(() => {
            trackUserInteraction();
          }, 1000)
        );
      }

      // Keyboard Shortcuts
      function handleKeyboardShortcuts(e) {
        if (document.querySelector(".quiz-question.active")) return;

        if (e.key === "ArrowLeft" && e.ctrlKey) {
          e.preventDefault();
          goToPreviousLesson();
        } else if (e.key === "ArrowRight" && e.ctrlKey) {
          e.preventDefault();
          goToNextLesson();
        }
      }

      // Window Resize Handler
      function handleWindowResize() {
        if (window.innerWidth > 768) {
          closeSidebar();
        }
      }

      // Debounce Helper
      function debounce(func, wait) {
        let timeout;
        return function executedFunction(...args) {
          const later = () => {
            clearTimeout(timeout);
            func(...args);
          };
          clearTimeout(timeout);
          timeout = setTimeout(later, wait);
        };
      }

      // Initialize responsive behavior
      if (window.innerWidth <= 768) {
        document.getElementById("menuToggle").style.display = "inline-flex";
      }

      // Auto-save progress periodically
      setInterval(async () => {
        if (currentUser && Object.keys(courseProgress).length > 0) {
          await saveProgress();
        }
      }, 60000); // Save every minute

      // System initialization logging
      console.log("CyberSec Academy Course System Initialized");
      console.log("Current Course:", COURSE_DATA.title);
      console.log("Total Lessons:", COURSE_DATA.lessons.length);

      // Google OAuth Integration
      const googleBtn = document.querySelector(".btn-google");
      if (googleBtn) {
        googleBtn.addEventListener("click", async () => {
          const { data, error } = await supabase.auth.signInWithOAuth({
            provider: "google",
            options: {
              redirectTo:
                window.location.origin +
                "/courses/gcp-security-essentials",
            },
          });

          if (error) {
            console.error("Google login error:", error.message);
            showToast("Google login failed: " + error.message, "error");
          }
        });
      }

      // Check for existing session
      supabase.auth.getSession().then(({ data }) => {
        if (data.session) {
          console.log("User already logged in:", data.session.user);
          currentUser = data.session.user;
          startCourseSession();
        }
      });

      // Add missing auth modal functions
      function openAuthModal() {
        const modal = document.getElementById("authModal");
        if (modal) {
          modal.style.display = "flex";
        }
      }

      function closeAuthModal() {
        const modal = document.getElementById("authModal");
        if (modal) {
          modal.style.display = "none";
        }
      }

      // Add auth tab switching functionality
      document.getElementById("tabSignIn")?.addEventListener("click", () => {
        document.getElementById("tabSignIn").classList.add("active");
        document.getElementById("tabSignUp").classList.remove("active");
        document.getElementById("signInForm").style.display = "block";
        document.getElementById("signUpForm").style.display = "none";
      });

      document.getElementById("tabSignUp")?.addEventListener("click", () => {
        document.getElementById("tabSignUp").classList.add("active");
        document.getElementById("tabSignIn").classList.remove("active");
        document.getElementById("signUpForm").style.display = "block";
        document.getElementById("signInForm").style.display = "none";
      });

      document
        .getElementById("closeAuthModal")
        ?.addEventListener("click", closeAuthModal);

      // Improved error handling for auth session
      supabase.auth.onAuthStateChange((event, session) => {
        if (event === "SIGNED_IN") {
          currentUser = session.user;
          closeAuthModal();
          startCourseSession();
        } else if (event === "SIGNED_OUT") {
          currentUser = null;
          openAuthModal();
        }
      });

      // Add form submission handlers
      document
        .getElementById("emailSignInForm")
        ?.addEventListener("submit", async (e) => {
          e.preventDefault();
          const email = document.getElementById("signInEmail").value;
          const password = document.getElementById("signInPassword").value;

          try {
            const { data, error } = await supabase.auth.signInWithPassword({
              email,
              password,
            });

            if (error) throw error;

            closeAuthModal();
          } catch (error) {
            showToast(error.message, "error");
          }
        });

      document
        .getElementById("emailSignUpForm")
        ?.addEventListener("submit", async (e) => {
          e.preventDefault();
          const email = document.getElementById("signUpEmail").value;
          const password = document.getElementById("signUpPassword").value;
          const name = document.getElementById("signUpName").value;

          try {
            const { data, error } = await supabase.auth.signUp({
              email,
              password,
              options: {
                data: {
                  full_name: name,
                },
              },
            });

            if (error) throw error;

            showToast(
              "Account created successfully! Please check your email.",
              "success"
            );
          } catch (error) {
            showToast(error.message, "error");
          }
        });
    </script>
  </body>
</html>

