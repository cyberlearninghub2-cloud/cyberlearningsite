


<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    
    <!-- ========== Start: SEO & Schema Enhancement ========== -->
    <title>DevSecOps Principles Course | CipherHall</title>
    <meta name="description" content="Enroll in our expert-led DevSecOps Principles course. Master secure CI/CD pipelines, shift-left security, and automate compliance." />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon.png" />
    <link rel="shortcut icon" href="/favicon.png" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="/favicon.png" />
    <link rel="canonical" href="https://www.cipherhall.com/courses/devsecops-principles-detail.html" />
    <meta name="robots" content="noindex, nofollow" />

    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Course",
      "name": "DevSecOps Principles Course",
      "description": "An in-depth course on integrating security into the entire DevOps lifecycle, from culture and design to tooling and automation.",
      "provider": {
        "@type": "Organization",
        "name": "CipherHall",
        "sameAs": "https://www.cipherhall.com"
      },
      "hasCourseInstance": {
        "@type": "CourseInstance",
        "courseMode": "Online",
        "instructor": {
          "@type": "Person",
          "name": "Dr. Anya Sharma"
        }
      }
    }
    </script>
    <!-- ========== End: SEO & Schema Enhancement ========== -->

    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Roboto+Mono:wght@400;700&family=Exo+2:wght@700;800;900&display=swap"
      rel="stylesheet"
    />
    <script src="https://cdn.jsdelivr.net/npm/@supabase/supabase-js@2.39.7/dist/umd/supabase.min.js"></script>
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-okaidia.min.css"
    />
    <link rel="icon" type="image/x-icon" href="assets/favicon.ico" />

    <link rel="stylesheet" href="assets/css/coursepages.css" />
</head>
  <body>
    <!-- Loading Screen -->
    <div id="loadingScreen" class="loading-screen">
      <div class="loader-icon">
        <i class="fas fa-graduation-cap"></i>
      </div>
      <div class="loader-text">Loading Course Content...</div>
    </div>

    <!-- Sidebar Overlay for Mobile -->
    <div class="sidebar-overlay" id="sidebarOverlay"></div>

    <!-- Music Player (fixed at top right) -->
    <div class="header-controls">
      <div class="music-dropdown" id="music-dropdown">
        <button class="btn btn-secondary">
          <span id="music-button-text">STUDY MUSIC</span>
          <i id="music-icon" class="fa-solid fa-music"></i>
        </button>
        <div class="music-dropdown-content" id="music-dropdown-content">
          <a
            href="#"
            data-src="https://www.learningcontainer.com/wp-content/uploads/2020/02/Kalimba.mp3"
            >1. Coffee Shop Vibes</a
          >
          <a
            href="#"
            data-src="https://www.soundhelix.com/examples/mp3/SoundHelix-Song-16.mp3"
            >2. City Lights Lofi</a
          >
          <a
            href="#"
            data-src="https://www.soundhelix.com/examples/mp3/SoundHelix-Song-15.mp3"
            >3. Mellow Thoughts</a
          >
          <a
            href="#"
            data-src="https://www.soundhelix.com/examples/mp3/SoundHelix-Song-13.mp3"
            >4. Rainy Mood</a
          >
          <a
            href="#"
            data-src="https://www.soundhelix.com/examples/mp3/SoundHelix-Song-10.mp3"
            >5. Time Alone</a
          >
          <a href="#" id="stop-music-link"
            ><i class="fa-solid fa-stop-circle"></i> Stop Music</a
          >
        </div>
      </div>

      <button class="btn btn-secondary" id="resetProgressBtn">
        <i class="fas fa-redo"></i>
        Reset Progress
      </button>
    </div>

    <!-- Auth Modal -->
    <div id="authModal" class="modal" style="display: none">
      <div class="modal-overlay"></div>
      <div class="modal-content">
        <span class="close" id="closeAuthModal">&times;</span>
        <div class="auth-tabs">
          <button id="tabSignIn" class="auth-tab active">Sign In</button>
          <button id="tabSignUp" class="auth-tab">Sign Up</button>
        </div>
        <div
          id="authLoader"
          style="display: none; text-align: center; padding: 2rem"
        >
          <i
            class="fas fa-spinner fa-spin fa-2x"
            style="color: var(--color-green)"
          ></i>
          <p style="margin-top: 0.5rem">Authenticating...</p>
        </div>
        <div id="signInForm" class="auth-form">
          <h2>Sign In to CipherHall</h2>
          <button id="googleSignIn" class="btn btn-google">
            <i class="fab fa-google"></i> Continue with Google
          </button>
          <div class="divider"><span>or</span></div>
          <form id="emailSignInForm">
            <input
              type="email"
              id="signInEmail"
              placeholder="Email Address"
              required
            />
            <input
              type="password"
              id="signInPassword"
              placeholder="Password"
              required
            />
            <button type="submit" class="btn btn-primary">Sign In</button>
          </form>
        </div>
        <div id="signUpForm" class="auth-form" style="display: none">
          <h2>Join CipherHall</h2>
          <button id="googleSignUp" class="btn btn-google">
            <i class="fab fa-google"></i> Continue with Google
          </button>
          <div class="divider"><span>or</span></div>
          <form id="emailSignUpForm">
            <input
              type="text"
              id="signUpName"
              placeholder="Full Name"
              required
            />
            <input
              type="email"
              id="signUpEmail"
              placeholder="Email Address"
              required
            />
            <input
              type="password"
              id="signUpPassword"
              placeholder="Password (min. 8 characters)"
              required
            />
            <button type="submit" class="btn btn-secondary">
              Create Account
            </button>
          </form>
        </div>
        <div id="authMessage"></div>
      </div>
    </div>

    <!-- Sidebar -->
    <aside class="sidebar" id="sidebar">
      <div class="sidebar-header">
        <div class="course-info">
          <h1 class="course-title" id="courseTitle">Loading...</h1>
          <div class="course-progress">
            <div class="progress-header">
              <span class="progress-label">Course Progress</span>
              <span class="progress-percentage" id="courseProgressPercent"
                >0%</span
              >
            </div>
            <div class="progress-bar">
              <div
                class="progress-fill"
                id="courseProgressFill"
                style="width: 0%"
              ></div>
            </div>
            <div class="progress-stats">
              <span id="completedLessons">0</span>
              <span id="totalLessons">0</span>
            </div>
          </div>
          <a href="/dashboard.html" class="back-to-dashboard">
            <i class="fas fa-arrow-left"></i>
            Back to Dashboard
          </a>
        </div>
      </div>

      <nav class="lesson-nav" id="lessonNav">
        <!-- Lessons will be loaded dynamically -->
      </nav>
    </aside>

    <!-- Main Content -->
    <main class="main-content">
      <header class="content-header">
        <div class="lesson-header">
          <div class="lesson-header-left">
            <span class="lesson-number" id="currentLessonNumber">1</span>
            <h1 class="lesson-header-title" id="currentLessonTitle">
              Loading...
            </h1>
          </div>
          <div class="lesson-actions">
            <button class="mbtn btn-primary" id="menuToggle">
              <i class="fas fa-bars"></i>
            </button>
          </div>
        </div>
      </header>

      <div class="content-body" id="contentBody">
        <div class="lesson-content" id="lessonContent">
          <!-- Lesson content will be loaded dynamically -->
        </div>
      </div>

      <footer class="lesson-navigation">
        <div class="nav-info" id="navInfo">Lesson 1 of 10</div>
        <div class="nav-controls">
          <button class="btn btn-secondary" id="prevLessonBtn" disabled>
            <i class="fas fa-chevron-left"></i>
            Previous
          </button>
          <button class="btn btn-primary" id="nextLessonBtn" disabled>
            Next
            <i class="fas fa-chevron-right"></i>
          </button>
        </div>
      </footer>
    </main>

    <!-- Achievement Notification -->
    <div id="achievementNotification" class="achievement-notification">
      <div class="notification-header">
        <div class="notification-icon" id="notificationIcon">
          <i class="fas fa-trophy"></i>
        </div>
        <div class="notification-content">
          <h3 id="notificationTitle">Achievement Unlocked!</h3>
          <p id="notificationDescription">Description here...</p>
        </div>
      </div>
      <div class="notification-reward" id="notificationReward">
        <i class="fas fa-coins"></i>
        <span id="notificationPoints">+100 Points</span>
      </div>
    </div>

    <!-- Toast Notification -->
    <div id="toast" class="toast">
      <span id="toastMessage"></span>
    </div>

    <script>
      // =====================================================
      // SYNCHRONIZED COURSE SYSTEM WITH DASHBOARD INTEGRATION
      // =====================================================

      // Supabase Configuration - Replace with your config
      const supabaseUrl = "https://lzcmzulemfubjaksoqor.supabase.co";
      const supabaseKey =
        "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Imx6Y216dWxlbWZ1Ympha3NvcW9yIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTUzMzM5MDgsImV4cCI6MjA3MDkwOTkwOH0.crhPH4YWtRsr1BJTpAQcmPbWSpwIWRbzoI4sRb2_fPI";
      const supabase = window.supabase.createClient(supabaseUrl, supabaseKey);

      // =====================================================
      // COURSE DATA STRUCTURE - REPLACE WITH YOUR COURSE JSON
      // =====================================================
      const COURSE_DATA =
{
    "id": "devsecops-principles",
    "title": "DevSecOps Principles Course",
    "description": "An in-depth course on integrating security into the entire DevOps lifecycle, from culture and design to tooling and automation.",
    "category": "devsecops",
    "difficulty": "Intermediate",
    "duration": "75 hours",
    "instructor": "Dr. Anya Sharma",
    "lessons": [
        {
            "id": "lesson-1",
            "title": "Introduction to DevSecOps",
            "duration": "90 min",
            "objectives": [
                "Understand the evolution from DevOps to DevSecOps.",
                "Identify the security challenges inherent in traditional SDLC and modern DevOps.",
                "Grasp the core philosophy and cultural mindset required for DevSecOps.",
                "Recognize the business value and ROI of implementing a DevSecOps program."
            ],
            "content": {
                "overview": "This foundational lesson introduces the core concepts of DevSecOps. We will explore why the traditional separation of development, security, and operations is no longer viable in a world of rapid software delivery and how integrating security as a shared responsibility leads to more secure, higher-quality software.",
                "sections": [
                    {
                        "title": "Evolution from DevOps to DevSecOps",
                        "content": "<p>DevOps revolutionized software delivery by breaking down the silo between Development and Operations, focusing on automation, collaboration, and speed. However, this acceleration often left traditional security practices behind, creating a new bottleneck.</p><p>DevSecOps is the natural evolution of this process. It's not about adding a 'Sec' gate, but about integrating security practices and automation into every phase of the DevOps lifecycle. The goal is to make security an intrinsic part of the process, a shared responsibility of everyone involved.</p><h3>The Mantra:</h3><p>Instead of security being a final gate, the DevSecOps mantra is 'Security at speed, not security slowing speed'.</p>",
                        "image": "https://images.unsplash.com/photo-1542626991-a2f5702b3c2b?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "DevSecOps Philosophy and Mindset",
                        "content": "<p>DevSecOps is fundamentally a cultural shift. It's about changing how people think about security.</p><ul><li><strong>Shared Responsibility:</strong> Security is no longer just the security team's job. Developers, operations engineers, and security professionals all share responsibility for building and maintaining secure systems.</li><li><strong>Security as Code:</strong> Security controls, policies, and tests are defined as code. This allows them to be version-controlled, automated, and embedded directly into the CI/CD pipeline.</li><li><strong>Automation over Manual Gates:</strong> Replace slow, manual security reviews with automated security tools that provide fast feedback to developers.</li><li><strong>Continuous Improvement:</strong> The process is a continuous feedback loop. Learn from failures, tune tools, and constantly improve the security posture.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1552664730-d307ca884978?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Business Value and ROI of DevSecOps",
                        "content": "<p>Implementing DevSecOps is not just a technical improvement; it's a business advantage.</p><h3>Key Benefits:</h3><ul><li><strong>Reduced Cost of Remediation:</strong> Finding and fixing a security vulnerability during the design or coding phase is exponentially cheaper than fixing it in production.</li><li><strong>Increased Delivery Speed:</strong> By removing the security bottleneck, teams can release features faster and more confidently.</li><li><strong>Improved Security Posture:</strong> Continuous security testing and automation lead to more secure software and a reduction in breaches.</li><li><strong>Enhanced Compliance:</strong> Automating compliance checks ('Compliance as Code') makes it easier and more reliable to meet regulatory requirements.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1556740738-b6a63e27c4df?w=800&h=400&fit=crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 1: DevSecOps Maturity Assessment Tool",
                        "language": "markdown",
                        "code": "# DevSecOps Maturity Assessment\n\nRate your organization's maturity in each domain (1=Initial, 5=Optimized).\n\n## Culture & Governance\n- **Shared Responsibility:** 2\n- **Security Champions Program:** 1\n- **Blameless Post-Mortems:** 2\n\n## Design & Development (Shift Left)\n- **Threat Modeling:** 2\n- **IDE Security Plugins:** 1\n- **Secure Coding Training:** 3\n\n## CI/CD Pipeline Automation\n- **SAST Integration:** 3\n- **SCA Integration:** 3\n- **DAST Integration:** 1\n- **IaC Scanning:** 2\n\n## Operations & Monitoring\n- **Immutable Infrastructure:** 2\n- **Security Observability:** 2\n- **Automated Incident Response:** 1"
                    },
                    {
                        "title": "Code Example 1: DevSecOps Culture Assessment Dashboard",
                        "language": "json",
                        "code": "{\n  \"assessmentDate\": \"2025-09-01\",\n  \"metrics\": [\n    {\n      \"name\": \"Developer Security Tool Adoption\",\n      \"value\": \"45%\",\n      \"trend\": \"up\",\n      \"target\": \"80%\"\n    },\n    {\n      \"name\": \"Mean Time to Remediate (Critical Vulns)\",\n      \"value\": \"28 days\",\n      \"trend\": \"down\",\n      \"target\": \"7 days\"\n    },\n    {\n      \"name\": \"Security-Initiated Build Breaks\",\n      \"value\": \"15 per week\",\n      \"trend\": \"stable\",\n      \"target\": \"<10 per week\"\n    }\n  ]\n}"
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "What is the core philosophy of DevSecOps?",
                        "options": [
                            "Security is the final gate before production.",
                            "Security is a shared responsibility integrated into the entire DevOps lifecycle.",
                            "Developers should not be concerned with security.",
                            "Security is handled exclusively by automated tools."
                        ],
                        "correct": 1,
                        "explanation": "DevSecOps is fundamentally about breaking down silos and making security a collaborative effort owned by everyone in the software delivery process."
                    },
                    {
                        "id": 2,
                        "question": "The practice of defining security policies and tests in version-controlled files is known as:",
                        "options": [
                            "Security Operations",
                            "Security as Code",
                            "Manual Security Review",
                            "Compliance Auditing"
                        ],
                        "correct": 1,
                        "explanation": "Security as Code is a foundational principle of DevSecOps. It allows security controls to be automated, versioned, and treated like any other application artifact."
                    },
                    {
                        "id": 3,
                        "question": "What is the primary financial benefit of finding a security flaw early in the development cycle?",
                        "options": [
                            "It has no financial impact.",
                            "It is more prestigious to find flaws early.",
                            "It is significantly cheaper to fix a flaw in code than in production.",
                            "It allows the company to buy more security tools."
                        ],
                        "correct": 2,
                        "explanation": "The cost to remediate a vulnerability increases exponentially the later it is found in the SDLC. DevSecOps aims to find flaws early, which provides a massive return on investment (ROI)."
                    },
                    {
                        "id": 4,
                        "question": "DevSecOps evolved from DevOps primarily to address what issue?",
                        "options": [
                            "Slow server deployment times.",
                            "Traditional security practices acting as a bottleneck to rapid release cycles.",
                            "Poor software quality.",
                            "High cloud computing costs."
                        ],
                        "correct": 1,
                        "explanation": "As DevOps accelerated development and deployment, traditional, manual security gates could not keep up. DevSecOps emerged as a way to integrate security into these high-speed pipelines."
                    }
                ]
            }
        },
        {
            "id": "lesson-2",
            "title": "Shift-Left Security Principles",
            "duration": "90 min",
            "objectives": [
                "Understand the 'shift-left' methodology and its benefits.",
                "Learn how to implement pre-commit hooks for early feedback.",
                "Grasp the concept of a Security Champions program.",
                "Explore how to integrate security into Integrated Development Environments (IDEs)."
            ],
            "content": {
                "overview": "Shift-left is the core tactical principle of DevSecOps. It means moving security testing and practices to the earliest possible point in the development lifecycle. This lesson covers the key strategies for shifting security left, empowering developers to find and fix issues before they are ever checked into a code repository.",
                "sections": [
                    {
                        "title": "Understanding Shift-Left Methodology",
                        "content": "<p>In a traditional SDLC, security testing happens on the far right of the timeline, just before release. Shifting left means moving it to the left, into the design and coding phases.</p><h3>Benefits:</h3><ul><li><strong>Faster Feedback:</strong> Developers are notified of potential issues in minutes, while the code is still fresh in their minds, instead of weeks later.</li><li><strong>Cost Reduction:</strong> As discussed, fixing issues early is far cheaper.</li><li><strong>Improved Developer Experience:</strong> Integrating security into the tools developers already use makes it a seamless part of their workflow.</li><li><strong>Secure by Default:</strong> It fosters a culture where developers are empowered to write secure code from the start.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1486312338219-ce68d2c6f44d?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Security Champions Program",
                        "content": "<p>A Security Champions program is a powerful way to scale a security team. It involves identifying developers and engineers on various teams who have an interest in security and empowering them to be the 'security conscience' for their team.</p><h3>Role of a Security Champion:</h3><ul><li>Act as the first point of contact for security questions on their team.</li><li>Help triage and validate findings from security tools.</li><li>Promote secure coding best practices.</li><li>Participate in threat modeling sessions.</li></ul><p>The central security team provides training, resources, and support to the champions, effectively embedding security expertise throughout the engineering organization.</p>",
                        "image": "https://images.unsplash.com/photo-1552664730-d307ca884978?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "IDE Security Plugin Integration",
                        "content": "<p>The earliest possible point to find a bug is as the developer is writing the code. IDE plugins bring the power of SAST and SCA directly into the developer's editor (like VS Code or IntelliJ).</p><p>As a developer types, the plugin can scan the code in real-time and underline a potential vulnerability, providing immediate feedback and remediation advice, much like a spell checker does for grammar.</p>",
                        "image": "https://images.unsplash.com/photo-1587620962725-abab7fe55159?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Pre-Commit Security Hooks",
                        "content": "<p>A pre-commit hook is a script that runs automatically before a developer is allowed to commit their code to version control (Git). This acts as a very early, lightweight quality gate.</p><h3>Common Pre-Commit Checks:</h3><ul><li><strong>Secret Scanning:</strong> Scan the code for hard-coded secrets like API keys or passwords. This is one of the most effective and important pre-commit checks.</li><li><strong>Linting:</strong> Check for basic code quality and style issues.</li><li><strong>Dependency Scanning:</strong> A quick check to see if any new, highly vulnerable libraries are being added.</li></ul><p>If the hook finds an issue, it blocks the commit and instructs the developer to fix it, preventing the flaw from ever entering the central repository.</p>",
                        "image": "https://images.unsplash.com/photo-1515879218367-8466d910aaa4?w=800&h=400&fit=crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 2: Shift-Left Security Pipeline Implementation",
                        "language": "yaml",
                        "code": "# Conceptual Shift-Left CI/CD Pipeline Stages (e.g., GitLab CI)\n\nstages:\n  - pre-build\n  - build\n  - test\n\nsecret-scan:\n  stage: pre-build\n  script:\n    # This fast scan runs on every commit to a feature branch\n    - gitleaks detect --verbose --redact\n\nlint-code:\n  stage: pre-build\n  script:\n    # Check for basic code quality\n    - eslint src/**/*.js\n\nfull-sast-scan:\n  stage: build\n  # This more intensive scan only runs on merge requests to the main branch\n  script:\n    - sonarqube-scanner ...\n  rules:\n    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'"
                    },
                    {
                        "title": "Code Example 2: Pre-Commit Security Hook Framework",
                        "language": "shell",
                        "code": "#!/bin/sh\n# Example pre-commit hook script located in .git/hooks/pre-commit\n\necho \"Running pre-commit security checks...\"\n\n# Use gitleaks to scan for hard-coded secrets\nif gitleaks detect --no-git; then\n    echo \"[FAIL] Hard-coded secrets detected. Commit aborted.\"\n    exit 1\nelse\n    echo \"[PASS] No hard-coded secrets found.\"\nfi\n\n# Add other checks here (e.g., linting)\n\nexit 0"
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "The 'shift-left' methodology in DevSecOps refers to:",
                        "options": [
                            "Moving all security activities to the operations phase.",
                            "Moving security practices to the earliest possible point in the development lifecycle.",
                            "Only using security tools developed on the US West Coast.",
                            "Giving all security responsibilities to the development team."
                        ],
                        "correct": 1,
                        "explanation": "Shifting left is about moving security from the end of the SDLC (the right) to the beginning (the left), during design and development, to provide faster feedback and reduce remediation costs."
                    },
                    {
                        "id": 2,
                        "question": "What is the primary purpose of a pre-commit hook in a secure development workflow?",
                        "options": [
                            "To deploy the application to production.",
                            "To run a full, hour-long security scan.",
                            "To provide a final quality gate before release.",
                            "To run fast, automated checks (like secret scanning) to prevent basic flaws from entering the code repository."
                        ],
                        "correct": 3,
                        "explanation": "Pre-commit hooks are lightweight, client-side checks that provide immediate feedback to the developer before their code is even shared with the team, acting as a very early line of defense."
                    },
                    {
                        "id": 3,
                        "question": "What is a 'Security Champion'?",
                        "options": [
                            "The head of the corporate security team.",
                            "A software tool that automatically fixes bugs.",
                            "An external security consultant.",
                            "A developer or engineer on a team who is trained to be a local security advocate and expert."
                        ],
                        "correct": 3,
                        "explanation": "The Security Champions program is a cultural tool for scaling security. It creates a network of embedded security experts who help their teams build more secure products from the ground up."
                    },
                    {
                        "id": 4,
                        "question": "Integrating a security tool directly into a developer's IDE (like VS Code) provides what major benefit?",
                        "options": [
                            "It makes the IDE run slower.",
                            "It provides the fastest possible feedback, often in real-time as the code is being written.",
                            "It guarantees the code will have zero vulnerabilities.",
                            "It sends all the code to the security team for manual review."
                        ],
                        "correct": 1,
                        "explanation": "IDE plugins are the furthest 'left' you can shift. They provide immediate, actionable feedback to the developer in the tool they use every day, making security a seamless part of the coding process."
                    }
                ]
            }
        },
        {
            "id": "lesson-3",
            "title": "Security by Design",
            "duration": "120 min",
            "objectives": [
                "Understand and apply secure architecture principles like Zero Trust and Defense in Depth.",
                "Learn to use threat modeling methodologies like STRIDE to proactively identify flaws.",
                "Integrate security requirements engineering into the design phase.",
                "Conduct effective secure design reviews."
            ],
            "content": {
                "overview": "Security by Design is the proactive process of building security into a system from its foundation, rather than trying to add it on as an afterthought. This lesson covers the architectural and process-oriented aspects of designing secure systems, focusing on how to think about threats and build resilient defenses before a single line of code is written.",
                "sections": [
                    {
                        "title": "Secure Architecture Principles",
                        "content": "<p>These are the foundational concepts that should guide all design decisions.</p><ul><li><strong>Defense in Depth:</strong> Layering security controls so that the failure of a single control does not lead to a full compromise.</li><li><strong>Least Privilege:</strong> Every user, service, and system should have only the bare minimum permissions necessary to perform its function.</li><li><strong>Zero Trust:</strong> Assume all networks are hostile. Authenticate and authorize every request, and grant access to specific resources, not the entire network.</li><li><strong>Fail Securely:</strong> Applications should fail in a secure state. For example, if an authorization check fails due to an error, it should default to denying access.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Threat Modeling Methodologies",
                        "content": "<p>Threat modeling is a structured exercise performed during the design phase to identify potential threats and design mitigations. It's about thinking like an attacker.</p><h3>Common Methodologies:</h3><ul><li><strong>STRIDE:</strong> A mnemonic developed by Microsoft for categorizing threats: <strong>S</strong>poofing, <strong>T</strong>ampering, <strong>R</strong>epudiation, <strong>I</strong>nformation Disclosure, <strong>D</strong>enial of Service, <strong>E</strong>levation of Privilege. It's great for brainstorming what can go wrong.</li><li><strong>PASTA (Process for Attack Simulation and Threat Analysis):</strong> A seven-step, risk-centric methodology that aligns threat modeling with business objectives and impact.</li></ul><p>The process typically involves diagramming the system, identifying trust boundaries, brainstorming threats, and documenting mitigations.</p>",
                        "image": "https://images.unsplash.com/photo-1543286386-713bdd548da4?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Security Requirements Engineering",
                        "content": "<p>This is the process of translating high-level security goals and threats into specific, testable requirements that developers can build.</p><h3>Types of Requirements:</h3><ul><li><strong>Functional Security Requirements:</strong> Define a security feature the system must have. (e.g., 'The system SHALL enforce MFA for all administrative users.')</li><li><strong>Non-Functional Security Requirements:</strong> Define a quality or characteristic the system must possess. (e.g., 'The system SHALL be resilient to SQL injection attacks.')</li></ul><p>These requirements should be documented in the project's backlog alongside functional requirements.</p>",
                        "image": "https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?w=800&h=400&fit=crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 3: Threat Modeling Workshop Platform",
                        "language": "markdown",
                        "code": "# Threat Model for a User Profile API\n\n**Diagram:** (A data flow diagram showing a user, an API gateway, a profile service, and a user database)\n\n**Threats (STRIDE Analysis):**\n\n1.  **Spoofing:**\n    - **Threat:** Attacker uses stolen JWT to impersonate a legitimate user.\n    - **Mitigation:** Implement short-lived tokens and a token revocation mechanism.\n\n2.  **Tampering:**\n    - **Threat:** Attacker intercepts and modifies the profile update request in transit.\n    - **Mitigation:** Enforce TLS 1.2+ for all communication.\n\n3.  **Information Disclosure:**\n    - **Threat:** A bug in the API (Broken Object Level Authorization) allows a user to request another user's profile by changing the ID.\n    - **Mitigation:** The service must have an authorization check to ensure `requesting_user_id == target_profile_id`.\n\n4.  **Denial of Service:**\n    - **Threat:** Attacker floods the API with requests.\n    - **Mitigation:** Implement rate limiting at the API Gateway."
                    },
                    {
                        "title": "Code Example 3: Automated Threat Model Generator",
                        "language": "yaml",
                        "code": "# A conceptual IaC definition that can be parsed to auto-generate threats\n\n- resource: aws_s3_bucket\n  name: customer-uploads\n  properties:\n    acl: public-read\n\n# --- Generated Threat ---\n# Threat: Information Disclosure (STRIDE)\n# Description: The S3 bucket 'customer-uploads' is configured to be publicly readable,\n# which could expose sensitive customer data.\n# Mitigation: Set the ACL to 'private' and use pre-signed URLs for access."
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "Layering multiple different security controls (e.g., a WAF, an IPS, and endpoint EDR) is an example of which principle?",
                        "options": [
                            "Least Privilege",
                            "Fail Securely",
                            "Defense in Depth",
                            "Zero Trust"
                        ],
                        "correct": 2,
                        "explanation": "Defense in Depth is the core idea that no single control is perfect, so multiple layers should be used to provide redundancy and increase the effort required for an attacker to succeed."
                    },
                    {
                        "id": 2,
                        "question": "What is the primary purpose of threat modeling?",
                        "options": [
                            "To test the application after it has been deployed.",
                            "To write a company's security policy.",
                            "To proactively identify and mitigate potential security flaws during the design phase.",
                            "To respond to active security incidents."
                        ],
                        "correct": 2,
                        "explanation": "Threat modeling is a proactive, 'shift-left' activity. It's about finding and fixing design flaws on the whiteboard, which is much cheaper and more effective than finding them in production."
                    },
                    {
                        "id": 3,
                        "question": "The STRIDE category that deals with an attacker impersonating a legitimate user is:",
                        "options": [
                            "Tampering",
                            "Information Disclosure",
                            "Spoofing",
                            "Elevation of Privilege"
                        ],
                        "correct": 2,
                        "explanation": "Spoofing is the act of faking an identity. This can be user identity (stolen credentials), system identity (DNS spoofing), or any other form of impersonation."
                    },
                    {
                        "id": 4,
                        "question": "The statement 'The system SHALL enforce a minimum password length of 12 characters' is an example of a:",
                        "options": [
                            "Functional Security Requirement",
                            "Non-Functional Security Requirement",
                            "Business Goal",
                            "Threat Model"
                        ],
                        "correct": 0,
                        "explanation": "This is a functional requirement because it describes a specific, testable security function that the system must perform."
                    }
                ]
            }
        },
        {
            "id": "lesson-4",
            "title": "DevSecOps Toolchain Integration",
            "duration": "90 min",
            "objectives": [
                "Understand how to categorize and select the right security tools.",
                "Design a strategy for integrating tools into a cohesive toolchain.",
                "Grasp the importance of API-first security tooling.",
                "Define metrics for measuring security tool effectiveness."
            ],
            "content": {
                "overview": "A collection of individual security tools does not make a DevSecOps program. The key is to integrate these tools into a seamless, automated toolchain that provides a continuous feedback loop. This lesson covers the architectural strategies for selecting, integrating, and orchestrating security tools to create a unified and effective system.",
                "sections": [
                    {
                        "title": "Security Tool Categorization and Selection",
                        "content": "<p>Security tools can be categorized by where they fit in the SDLC.</p><h3>Key Categories:</h3><ul><li><strong>Design:</strong> Threat modeling tools.</li><li><strong>Develop:</strong> IDE plugins, pre-commit hooks.</li><li><strong>Build/Test:</strong> SAST, DAST, IAST, SCA, IaC Scanners, Container Scanners.</li><li><strong>Deploy:</strong> Deployment security gates, policy-as-code engines.</li><li><strong>Operate:</strong> WAF, RASP, EDR, CSPM, SIEM.</li></ul><p>When selecting a tool, the most important criterion is its ability to be automated and integrated via APIs.</p>",
                        "image": "https://images.unsplash.com/photo-1556155092-490a1ba16284?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Tool Integration Strategies",
                        "content": "<p>The goal of integration is to create a seamless flow of data between tools. This is often called orchestration.</p><h3>Key Integration Points:</h3><ul><li><strong>CI/CD Server (e.g., Jenkins, GitLab):</strong> The central orchestrator. The CI/CD server calls the various security scanning tools at the appropriate stages.</li><li><strong>SIEM/Central Log Aggregator:</strong> All tools must send their findings and logs to a central location for correlation and analysis.</li><li><strong>Vulnerability Management System:</strong> Findings from multiple scanners (SAST, DAST, SCA) should be aggregated, de-duplicated, and managed in a central vulnerability management platform.</li><li><strong>SOAR Platform:</strong> Tools must have APIs that allow a SOAR platform to trigger actions for automated response.</li></ul>",
                        "image": "https.images.unsplash.com/photo-1521791136064-7986c2920216?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "API-First Security Tooling",
                        "content": "<p>When evaluating a new security tool, the first question should be: 'Does it have a well-documented, robust API?' An 'API-first' approach means that everything you can do in the tool's user interface, you can also do via an API call.</p><p>This is non-negotiable for DevSecOps. Without a strong API, you cannot automate the tool, integrate it into your pipeline, or pull its data for metrics and reporting. A tool with a poor API will inevitably become a manual silo, creating a bottleneck that undermines the entire DevSecOps philosophy.</p>",
                        "image": "https://images.unsplash.com/photo-1515879218367-8466d910aaa4?w=800&h=400&fit=crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 4: DevSecOps Toolchain Integration Platform",
                        "language": "plaintext",
                        "code": "/* \n  Data Flow in an Integrated DevSecOps Toolchain\n\n  1. Developer commits code.\n  2. CI/CD server triggers a build.\n\n  3. CI/CD calls SAST Scanner (via API).\n     - SAST scanner returns JSON results to CI/CD.\n     - CI/CD sends JSON results to Vulnerability Management Platform (via API).\n\n  4. CI/CD calls SCA Scanner (via API).\n     - SCA scanner returns JSON results to CI/CD.\n     - CI/CD sends JSON results to Vulnerability Management Platform (via API).\n\n  5. Vulnerability Management Platform:\n     - De-duplicates the findings from SAST and SCA.\n     - Prioritizes the vulnerabilities based on risk.\n     - Creates a ticket in Jira for a new, critical finding (via API).\n\n  6. CI/CD checks the results. If a 'build-breaking' vulnerability was found, the pipeline fails and notifies the developer.\n*/"
                    },
                    {
                        "title": "Code Example 4: Security Tool Orchestration Framework",
                        "language": "python",
                        "code": "# Conceptual SOAR playbook for tool orchestration\n\nimport jira\nimport sast_tool_api\nimport sca_tool_api\n\ndef run_security_scan(repo_url):\n    \"\"\"Orchestrates security scans and ticketing.\"\"\"\n    \n    # 1. Run SAST scan via its API\n    sast_results = sast_tool_api.scan(repo_url)\n    \n    # 2. Run SCA scan via its API\n    sca_results = sca_tool_api.scan(repo_url)\n    \n    # 3. Aggregate and process results\n    all_findings = sast_results['findings'] + sca_results['findings']\n    \n    for finding in all_findings:\n        # 4. If a critical finding is new, create a Jira ticket via API\n        if finding['severity'] == 'CRITICAL' and not is_duplicate(finding):\n            jira.create_ticket(\n                summary=f\"New critical vulnerability: {finding['id']}\",\n                description=finding['details']\n            )\n            return \"BUILD_FAILURE\"\n            \n    return \"BUILD_SUCCESS\""
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "What is the most important technical characteristic to look for when selecting a new security tool for a DevSecOps environment?",
                        "options": [
                            "A beautiful user interface.",
                            "A well-documented, comprehensive API.",
                            "The number of features listed on the marketing website.",
                            "The age of the vendor company."
                        ],
                        "correct": 1,
                        "explanation": "Automation is the core of DevSecOps. A tool cannot be automated or integrated into a toolchain without a robust API. This is the single most important technical requirement."
                    },
                    {
                        "id": 2,
                        "question": "The central system that calls other security tools at the appropriate stages of the development lifecycle is the:",
                        "options": [
                            "SIEM",
                            "Firewall",
                            "CI/CD Server (e.g., Jenkins, GitLab)",
                            "IDE"
                        ],
                        "correct": 2,
                        "explanation": "The CI/CD server acts as the primary orchestrator of the DevSecOps toolchain, triggering scans, collecting results, and making decisions like failing a build."
                    },
                    {
                        "id": 3,
                        "question": "Why is it important to send the findings from all security scanners to a central vulnerability management platform?",
                        "options": [
                            "It makes the individual tools run faster.",
                            "To aggregate, de-duplicate, and prioritize findings from all sources in one place.",
                            "It is a legal requirement.",
                            "It is not important; findings should be kept in separate silos."
                        ],
                        "correct": 1,
                        "explanation": "Different tools can find the same vulnerability. A central platform provides a single source of truth for all vulnerabilities, which is essential for efficient tracking, prioritization, and remediation."
                    },
                    {
                        "id": 4,
                        "question": "Which of the following is NOT a category of security tool typically found in a DevSecOps build/test phase?",
                        "options": [
                            "SAST (Static Application Security Testing)",
                            "SCA (Software Composition Analysis)",
                            "EDR (Endpoint Detection and Response)",
                            "DAST (Dynamic Application Security Testing)"
                        ],
                        "correct": 2,
                        "explanation": "SAST, SCA, and DAST are all testing tools used during the pipeline. EDR is a protection and monitoring tool used in the 'Operate' phase on live servers and endpoints."
                    }
                ]
            }
        },
        {
            "id": "lesson-5",
            "title": "Static Application Security Testing (SAST)",
            "duration": "90 min",
            "objectives": [
                "Understand the fundamentals of SAST and how it works.",
                "Learn how to integrate SAST into a CI/CD pipeline effectively.",
                "Develop strategies for managing false positives and tuning SAST tools.",
                "Define meaningful metrics for a SAST program."
            ],
            "content": {
                "overview": "Static Application Security Testing (SAST) is a 'white-box' testing methodology that analyzes an application's source code, byte code, or binary code for security vulnerabilities without executing it. This lesson covers how to effectively implement SAST as a core component of your automated security pipeline.",
                "sections": [
                    {
                        "title": "SAST Fundamentals and Benefits",
                        "content": "<p>SAST works by building a model of the application and analyzing the data flow and control flow through the code to identify patterns that match known vulnerability types.</p><h3>Key Benefits:</h3><ul><li><strong>Early Detection:</strong> SAST can be run very early in the SDLC, as soon as code is written, providing fast feedback to developers.</li><li><strong>Comprehensive Coverage:</strong> Because it analyzes the entire codebase, it can find vulnerabilities in code paths that might be missed by dynamic testing.</li><li><strong>Language Specific:</strong> It can identify specific, language-level vulnerabilities (e.g., insecure use of a particular function in C++).</li></ul><h3>Limitations:</h3><ul><li><strong>False Positives:</strong> SAST tools are prone to false positives, as they lack runtime context and can't always determine if a vulnerability is truly exploitable.</li><li><strong>Can't Find Runtime Flaws:</strong> It cannot find configuration errors or vulnerabilities that only manifest in a running environment.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1517694712202-14dd9538aa97?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Integration with IDEs and CI/CD",
                        "content": "<p>Effective SAST implementation requires a multi-layered approach.</p><h3>Integration Strategy:</h3><ul><li><strong>In the IDE:</strong> Use a lightweight SAST plugin (like SonarLint) to provide real-time feedback to developers as they code. This catches simple bugs immediately.</li><li><strong>On Commit / Pull Request:</strong> Run a fast, incremental scan that only analyzes the code that has changed. This provides quick feedback without slowing down the pipeline.</li><li><strong>Nightly / On Merge to Main:</strong> Run a full, deep scan of the entire application codebase. This is more time-consuming but provides the most comprehensive analysis.</li></ul><p>This tiered approach balances speed of feedback with depth of analysis.</p>",
                        "image": "https://images.unsplash.com/photo-1542382257-80deda0e5d99?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "False Positive Management",
                        "content": "<p>A high number of false positives can cause developers to lose trust in a SAST tool and start ignoring its results. A robust triage and tuning process is essential.</p><h3>The Triage Process:</h3><ol><li><strong>Validate:</strong> A security champion or security engineer reviews a new finding to determine if it is a real vulnerability in the context of the application.</li><li><strong>Prioritize:</strong> If it's a true positive, prioritize it based on its severity and the criticality of the application.</li><li><strong>Remediate:</strong> Assign the finding to the development team for a fix.</li><li><strong>Mark as False Positive:</strong> If it's a false positive, formally mark it as such in the tool so it doesn't appear in future scans.</li></ol><p>Most SAST tools allow you to tune the rulesets, disabling rules that are particularly noisy for your specific codebase.</p>",
                        "image": "https://images.unsplash.com/photo-1555099962-4199c345e546?w=800&h=400&fit=crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 5: SAST Pipeline Integration Workshop",
                        "language": "yaml",
                        "code": "# Example GitLab CI job for SAST\n\nsast-scan:\n  stage: test\n  image: sonarsource/sonar-scanner-cli:latest\n  script:\n    # -Dsonar.qualitygate.wait=true makes the pipeline job wait for the analysis to complete\n    # -Dsonar.qualitygate.timeout=300 sets a 5-minute timeout\n    - sonar-scanner \n        -Dsonar.projectKey=my-awesome-app \n        -Dsonar.sources=. \n        -Dsonar.host.url=$SONAR_HOST_URL \n        -Dsonar.login=$SONAR_TOKEN \n        -Dsonar.qualitygate.wait=true \n        -Dsonar.qualitygate.timeout=300\n  # This job will fail if the SonarQube Quality Gate conditions (e.g., 'No new critical vulnerabilities') are not met."
                    },
                    {
                        "title": "Code Example 5: SAST Results Management and Triage System",
                        "language": "json",
                        "code": "{\n  \"findingId\": \"A1B2-C3D4-E5F6\",\n  \"vulnerability\": \"SQL Injection\",\n  \"severity\": \"CRITICAL\",\n  \"file\": \"src/main/java/com/example/UserRepository.java\",\n  \"line\": 42,\n  \"status\": \"TRIAGE\",\n  \"assignee\": \"security_champion@example.com\",\n  \"history\": [\n    {\n      \"timestamp\": \"2025-09-05T10:00:00Z\",\n      \"action\": \"New finding detected in build #123\"\n    },\n    {\n      \"timestamp\": \"2025-09-05T10:15:00Z\",\n      \"action\": \"Automatically assigned for triage\"\n    }\n  ]\n}"
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "Static Application Security Testing (SAST) analyzes an application's:",
                        "options": [
                            "Running code in a production environment.",
                            "Source code or binary without executing it.",
                            "Network traffic.",
                            "Third-party libraries."
                        ],
                        "correct": 1,
                        "explanation": "SAST is a 'white-box' method that analyzes the application code 'at rest' (statically) to find vulnerabilities."
                    },
                    {
                        "id": 2,
                        "question": "What is a common limitation of SAST tools?",
                        "options": [
                            "They are too slow to run in a CI/CD pipeline.",
                            "They can generate a high number of false positives.",
                            "They can only be run on production code.",
                            "They cannot find any vulnerabilities."
                        ],
                        "correct": 1,
                        "explanation": "Because SAST lacks runtime context, it can sometimes flag issues that are not actually exploitable, leading to false positives. A good triage and tuning process is essential to manage this."
                    },
                    {
                        "id": 3,
                        "question": "What is the best way to provide the fastest SAST feedback to a developer?",
                        "options": [
                            "Send them a PDF report once a month.",
                            "Run a full scan that takes 4 hours on every commit.",
                            "Integrate a SAST plugin directly into their IDE.",
                            "Wait for a penetration test to find the issue."
                        ],
                        "correct": 2,
                        "explanation": "IDE integration provides real-time feedback as the code is being written, which is the earliest and most effective point to notify a developer of a potential issue."
                    },
                    {
                        "id": 4,
                        "question": "A process where a security expert reviews a SAST finding to determine if it is a real, exploitable issue is called:",
                        "options": [
                            "Remediation",
                            "Triage",
                            "Deployment",
                            "Scanning"
                        ],
                        "correct": 1,
                        "explanation": "Triage is the critical step of validating and prioritizing findings to ensure that developers are spending their time fixing real vulnerabilities and not chasing false positives."
                    }
                ]
            }
        },
        {
            "id": "lesson-6",
            "title": "Dynamic Application Security Testing (DAST)",
            "duration": "90 min",
            "objectives": [
                "Understand the principles of DAST and its role in DevSecOps.",
                "Design a strategy for integrating automated DAST into a CI/CD pipeline.",
                "Learn how to manage the test environment for DAST.",
                "Compare DAST with other testing methodologies like SAST and IAST."
            ],
            "content": {
                "overview": "Dynamic Application Security Testing (DAST) is a 'black-box' testing methodology that analyzes a running application for vulnerabilities by simulating external attacks. It has no knowledge of the underlying code. This lesson covers how to integrate DAST into your CI/CD pipeline to find runtime vulnerabilities that static analysis can miss.",
                "sections": [
                    {
                        "title": "DAST Principles and Methodologies",
                        "content": "<p>DAST tools work by acting like a malicious user. They crawl a running web application to discover all its pages, inputs, and APIs. Then, they launch a battery of known attack techniques against it.</p><h3>Key Benefits:</h3><ul><li><strong>Finds Runtime and Configuration Issues:</strong> DAST can find vulnerabilities that only exist in a running environment, such as server misconfigurations, authentication flaws, and issues that depend on the interaction between different components.</li><li><strong>Low False Positive Rate:</strong> Because DAST finds vulnerabilities by actively exploiting them (in a safe way), its findings are almost always true positives.</li><li><strong>Technology Agnostic:</strong> It doesn't matter what language the application is written in; if it's listening on HTTP, a DAST tool can test it.</li></ul><h3>Limitations:</h3><ul><li><strong>No Code Visibility:</strong> It cannot pinpoint the exact line of code that is vulnerable, making remediation harder.</li><li><strong>Requires a Running Application:</strong> It can only be run later in the SDLC, after the application has been deployed to a test environment.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1555949963-aa79dcee981c?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "DAST in CI/CD Pipelines",
                        "content": "<p>Integrating DAST into an automated pipeline requires careful planning.</p><h3>The DAST Stage:</h3><ol><li><strong>Deploy to Test Environment:</strong> The CI/CD pipeline deploys the application to a dedicated, production-like DAST environment.</li><li><strong>Configure the Scan:</strong> The pipeline configures the DAST scanner, providing it with the target URL and credentials to log in as a test user.</li><li><strong>Run the Scan:</strong> The pipeline triggers the DAST scan via an API call. Scans can be full or targeted at just the new or changed parts of the application.</li><li><strong>Ingest Results:</strong> Once the scan is complete, the pipeline retrieves the results and decides whether to pass or fail the build based on the findings.</li></ol>",
                        "image": "https://images.unsplash.com/photo-1542382257-80deda0e5d99?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "API Security Testing Strategies",
                        "content": "<p>Modern DAST tools are not limited to traditional web pages; they are essential for testing the security of APIs (REST, SOAP, GraphQL).</p><p>To test an API, the DAST tool needs to understand its structure. This is typically done by providing the tool with the API's specification document, such as an OpenAPI (Swagger) file. The tool parses the specification to learn all the available endpoints, parameters, and expected data formats, and then uses that knowledge to generate targeted attack tests.</p>",
                        "image": "https://images.unsplash.com/photo-1605995538181-22920bee518f?w=800&h=400&fit=crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 6: Automated DAST Pipeline Implementation",
                        "language": "yaml",
                        "code": "# Example GitLab CI job for DAST\n\ndast-scan:\n  stage: test\n  # This job runs after the 'deploy-to-staging' job\n  script:\n    - echo \"Starting DAST scan against http://staging-app.example.com\"\n    # Trigger a scan using a tool like OWASP ZAP via its API\n    - >\n      curl --request POST 'http://zap-api:8080/JSON/ascan/action/scan/' \\\n      --data-urlencode 'url=http://staging-app.example.com' \\\n      --data-urlencode 'apikey=$ZAP_API_KEY'\n    \n    # The pipeline would then have a loop that polls the scan status\n    # and retrieves the results when complete.\n    - ./check_zap_scan_status.sh\n\n  # Only run on the main branch after a successful deployment to staging\n  rules:\n    - if: $CI_COMMIT_BRANCH == 'main'"
                    },
                   {
  "title": "Code Example 6: DAST Orchestration and Reporting Platform",
  "language": "json",
  "code": "{\n  \"scanId\": \"dast-scan-456\",\n  \"targetUrl\": \"http://staging-app.example.com\",\n  \"startTime\": \"2025-09-06T14:00:00Z\",\n  \"status\": \"COMPLETED\",\n  \"summary\": {\n    \"high\": 1,\n    \"medium\": 3,\n    \"low\": 5\n  },\n  \"findings\": [\n    {\n      \"vulnerability\": \"Cross-Site Scripting (Reflected)\",\n      \"severity\": \"HIGH\",\n      \"url\": \"http://staging-app.example.com/search?q=\\u003cscript\\u003ealert(1)\\u003c/script\\u003e\",\n      \"parameter\": \"q\",\n      \"evidence\": \"...\"\n    }\n  ]\n}"
}

                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "DAST is considered a 'black-box' testing method because:",
                        "options": [
                            "It analyzes the source code of the application.",
                            "It requires a special black-colored server to run.",
                            "It tests the application from the outside, with no knowledge of the internal code.",
                            "It can only find vulnerabilities at night."
                        ],
                        "correct": 2,
                        "explanation": "'Black-box' testing means the tester has no visibility into the internal workings of the system being tested; they are interacting with it just as an external attacker would."
                    },
                    {
                        "id": 2,
                        "question": "What is a key advantage of DAST over SAST?",
                        "options": [
                            "It can be run earlier in the SDLC than SAST.",
                            "It has a very low false positive rate because it finds vulnerabilities by actively exploiting them.",
                            "It can pinpoint the exact line of vulnerable code.",
                            "It does not require a running application."
                        ],
                        "correct": 1,
                        "explanation": "Because DAST is actively testing the running application, a reported vulnerability is almost always a true positive. Its main disadvantage is that it happens later in the lifecycle than SAST."
                    },
                    {
                        "id": 3,
                        "question": "What does a modern DAST tool typically require to effectively test an API?",
                        "options": [
                            "The source code of the API.",
                            "The API's specification file, such as an OpenAPI (Swagger) document.",
                            "Administrator access to the server running the API.",
                            "A list of all the developers who worked on the API."
                        ],
                        "correct": 1,
                        "explanation": "An API specification file acts as a 'map' for the DAST scanner, telling it about all the endpoints, methods, and parameters it needs to test."
                    },
                    {
                        "id": 4,
                        "question": "A significant architectural requirement for running DAST in an automated CI/CD pipeline is:",
                        "options": [
                            "Having a dedicated, running test environment to scan.",
                            "Access to the source code repository.",
                            "A threat model of the application.",
                            "A list of all open-source libraries used."
                        ],
                        "correct": 0,
                        "explanation": "DAST can only test a running application. Therefore, a critical prerequisite in the pipeline is a stage that deploys the application to a stable, production-like environment where the DAST scanner can then be pointed."
                    }
                ]
            }
        },
        {
            "id": "lesson-7",
            "title": "Interactive Application Security Testing (IAST)",
            "duration": "90 min",
            "objectives": [
                "Understand the technology behind IAST and how it works.",
                "Compare the pros and cons of IAST vs. SAST and DAST.",
                "Learn how to integrate IAST into a testing workflow.",
                "Grasp the concept of application instrumentation."
            ],
            "content": {
                "overview": "Interactive Application Security Testing (IAST) is a 'gray-box' testing methodology that combines elements of both SAST and DAST. It works from inside a running application to identify vulnerabilities in real-time. This lesson explores this powerful emerging technology and its place in a modern DevSecOps toolchain.",
                "sections": [
                    {
                        "title": "IAST Technology Overview",
                        "content": "<p>IAST works by using 'instrumentation'. An IAST agent is deployed within the application server's runtime environment (e.g., as a Java agent for a JVM, or a library for a .NET application).</p><p>This agent has deep visibility into the application as it runs. It can observe data flow, function calls, and interactions with backend systems like databases. When a user or a DAST scanner interacts with the application, the IAST agent watches from the inside to see if any of the inputs trigger insecure behavior in the code.</p>",
                        "image": "https://images.unsplash.com/photo-1573497175235-d3648a07b388?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "IAST vs. SAST vs. DAST Comparison",
                        "content": "<p>IAST is designed to combine the best of both worlds.</p><h3>Key Advantages of IAST:</h3><ul><li><strong>High Accuracy:</strong> Like DAST, it confirms vulnerabilities with real requests, leading to very low false positive rates.</li><li><strong>Code-Level Visibility:</strong> Like SAST, it can pinpoint the exact line of code and the data flow that led to the vulnerability, making remediation much faster for developers.</li><li><strong>Real-time Feedback:</strong> It can provide immediate feedback during any kind of testing (automated or manual), not just a dedicated security scan.</li></ul><h3>Limitations:</h3><ul><li><strong>Language Dependent:</strong> Requires a specific agent for each language/framework (Java, .NET, Python, etc.).</li><li><strong>Performance Overhead:</strong> The instrumentation agent adds some performance overhead to the application, so it is typically used only in test/QA environments.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1555099962-4199c345e546?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "IAST Tool Integration Strategies",
                        "content": "<p>IAST is not typically a separate, standalone stage in a CI/CD pipeline. Instead, it is integrated into the existing functional and QA testing phases.</p><h3>Integration Workflow:</h3><ol><li><strong>Deploy:</strong> The CI/CD pipeline deploys the application to a QA or staging environment. The IAST agent is enabled as part of this deployment.</li><li><strong>Test:</strong> The QA team runs their normal suite of automated functional tests, regression tests, and manual exploratory tests.</li><li><strong>Detect:</strong> As the QA tests run, the IAST agent works silently in the background. If any of the tests happen to trigger a security vulnerability (even accidentally), the IAST agent detects it and reports it to a central dashboard in real-time.</li></ol><p>This approach leverages existing testing efforts to find security flaws without requiring a dedicated security scan.</p>",
                        "image": "https://images.unsplash.com/photo-1542382257-80deda0e5d99?w=800&h=400&fit=crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 7: IAST Implementation and Integration",
                        "language": "shell",
                        "code": "# Example of starting a Java application with an IAST agent enabled\n\n# The CI/CD deploy script would include the '-javaagent' flag\n# to attach the IAST agent to the Java Virtual Machine (JVM) at startup.\n\njava -javaagent:/path/to/iast-agent.jar -jar my-web-app.jar\n\n# Once the application is running, all subsequent testing (e.g., Selenium tests,\n# manual QA, DAST scans) will be monitored by the IAST agent."
                    },
                    {
                        "title": "Code Example 7: IAST Data Collection and Analysis Framework",
                        "language": "json",
                        "code": "{\n  \"findingId\": \"iast-finding-789\",\n  \"vulnerability\": \"SQL Injection\",\n  \"severity\": \"HIGH\",\n  \"url\": \"/api/products?id=101' OR '1'='1'\",\n  \"details\": {\n    \"sink\": {\n      \"file\": \"ProductRepository.java\",\n      \"method\": \"executeQuery\",\n      \"lineNumber\": 88\n    },\n    \"source\": {\n      \"parameter\": \"id\",\n      \"value\": \"101' OR '1'='1'\"\n    },\n    \"fullStackTrace\": \"...\"\n  },\n  \"http_request\": \"GET /api/products?id=101' OR '1'='1' ...\"\n}"
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "IAST works by using an 'agent' that runs where?",
                        "options": [
                            "On the developer's workstation.",
                            "On the network firewall.",
                            "Inside the running application's runtime environment.",
                            "In the source code repository."
                        ],
                        "correct": 2,
                        "explanation": "IAST uses instrumentation, which means an agent is attached to the running application (e.g., inside the JVM or .NET CLR) to get an internal view of its execution."
                    },
                    {
                        "id": 2,
                        "question": "What is the key advantage of IAST's 'gray-box' approach?",
                        "options": [
                            "It is the fastest type of scan.",
                            "It has zero performance overhead.",
                            "It combines the code-level visibility of SAST with the runtime context of DAST, providing accurate, actionable findings.",
                            "It works for any programming language without needing a specific agent."
                        ],
                        "correct": 2,
                        "explanation": "By working from inside the running application, IAST can see both the HTTP request that triggered an issue (like DAST) and the exact line of code that was vulnerable (like SAST), giving developers all the context they need to fix it."
                    },
                    {
                        "id": 3,
                        "question": "How is IAST typically integrated into a DevSecOps workflow?",
                        "options": [
                            "As a separate, long-running scan stage in the CI/CD pipeline.",
                            "It is enabled in the background during the regular QA functional testing phase.",
                            "It is only used by the security team for manual penetration tests.",
                            "It is run as a pre-commit hook."
                        ],
                        "correct": 1,
                        "explanation": "IAST's power is that it can find vulnerabilities during any kind of testing. The most efficient way to use it is to simply enable it in the QA environment and let it find security issues while the QA team does their normal job."
                    },
                    {
                        "id": 4,
                        "question": "The process of modifying an application's code at runtime to add monitoring and security capabilities is called:",
                        "options": [
                            "Instrumentation",
                            "Compilation",
                            "Encryption",
                            "Penetration Testing"
                        ],
                        "correct": 0,
                        "explanation": "Instrumentation is the core technology behind IAST and Application Performance Monitoring (APM) tools. It allows an external agent to hook into a running application to observe its behavior."
                    }
                ]
            }
        },
        {
            "id": "lesson-8",
            "title": "Software Composition Analysis (SCA)",
            "duration": "90 min",
            "objectives": [
                "Understand the security risks associated with open-source software.",
                "Learn how SCA tools identify vulnerable dependencies and license issues.",
                "Design a remediation workflow for managing vulnerable components.",
                "Grasp the concept of a Software Bill of Materials (SBOM)."
            ],
            "content": {
                "overview": "Modern applications are not built, they are assembled. A typical application is composed of 80-90% open-source components. Software Composition Analysis (SCA) is the automated process of identifying the open-source libraries in a codebase and flagging them for known security vulnerabilities or license compliance issues. This lesson covers how to secure your software supply chain with SCA.",
                "sections": [
                    {
                        "title": "Open Source Security Risks",
                        "content": "<p>While open-source software (OSS) is a powerful accelerator, it also introduces risks.</p><h3>Key Risks:</h3><ul><li><strong>Known Vulnerabilities:</strong> A library may have a publicly disclosed vulnerability (a CVE). If you are using that version of the library, your application is also vulnerable. This is the primary risk SCA tools address.</li><li><strong>License Compliance:</strong> Some OSS licenses have requirements (e.g., the GPL license) that can be incompatible with proprietary commercial software. SCA tools can identify these license risks.</li><li><strong>Supply Chain Attacks:</strong> Attackers may intentionally publish malicious packages to public repositories (e.g., typosquatting popular package names) or compromise a legitimate package to inject malicious code.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1556075798-4825dfaaf498?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Dependency Vulnerability Management",
                        "content": "<p>SCA tools work by parsing an application's package manager files (e.g., `package-lock.json` for Node.js, `pom.xml` for Maven) to create a list of all dependencies and their specific versions. This list is often called a Software Bill of Materials (SBOM).</p><p>The tool then compares this list against a database of known vulnerabilities. If a dependency in your project matches a version with a known CVE, the tool raises an alert.</p>",
                        "image": "https://images.unsplash.com/photo-1542382257-80deda0e5d99?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Remediation Workflows",
                        "content": "<p>Finding a vulnerable dependency is only the first step. The architecture must support an efficient remediation workflow.</p><h3>Automated Remediation:</h3><p>Many modern SCA tools can automate the fix. For example, if your project uses `vulnerable-library-1.2.3` and the tool knows that `vulnerable-library-1.2.4` contains the fix, it can automatically create a pull request in your source code repository to update the package version. The development team then just needs to test and approve the pull request.</p><h3>Prioritization:</h3><p>SCA tools can find hundreds of vulnerabilities. It's important to prioritize. A good tool will not only show the CVE score (e.g., CVSS) but also provide context, such as whether the vulnerable function is actually being called by your code.</p>",
                        "image": "https://images.unsplash.com/photo-1521791136064-7986c2920216?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Software Bill of Materials (SBOM)",
                        "content": "<p>An SBOM is a formal, machine-readable inventory of all the software components, libraries, and modules that are included in a piece of software. It's like a list of ingredients for a software product.</p><p>Generating an SBOM is a key output of an SCA tool. SBOMs are becoming increasingly important for regulatory compliance and for supply chain security. If a new vulnerability like Log4Shell is discovered, an organization with a complete and up-to-date set of SBOMs can immediately query them to find every single application that uses the vulnerable library.</p>",
                        "image": "https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?w=800&h=400&fit=crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 8: Comprehensive SCA Pipeline Setup",
                        "language": "yaml",
                        "code": "# Example GitHub Action workflow for SCA using Snyk\n\nname: Snyk Security Scan\n\non: [push]\n\njobs:\n  snyk:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Run Snyk to check for vulnerabilities\n        uses: snyk/actions/node@master\n        env:\n          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}\n        with:\n          # Fail the build if any high severity vulnerabilities are found\n          args: --severity-threshold=high"
                    },
                    {
                        "title": "Code Example 8: Automated Dependency Security Management System",
                        "language": "json",
                        "code": "{\n  \"sbomFormat\": \"CycloneDX\",\n  \"specVersion\": \"1.4\",\n  \"serialNumber\": \"urn:uuid:3e671687-395b-41f5-a30f-a58921a69b79\",\n  \"version\": 1,\n  \"metadata\": { ... },\n  \"components\": [\n    {\n      \"type\": \"library\",\n      \"name\": \"log4j-core\",\n      \"version\": \"2.14.1\",\n      \"purl\": \"pkg:maven/org.apache.logging.log4j/log4j-core@2.14.1\",\n      \"vulnerabilities\": [\n        {\n          \"id\": \"CVE-2021-44228\",\n          \"source\": \"NVD\",\n          \"severity\": \"CRITICAL\",\n          \"recommendation\": \"Upgrade to version 2.17.1 or later.\"\n        }\n      ]\n    }\n  ]\n}"
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "What is the primary function of a Software Composition Analysis (SCA) tool?",
                        "options": [
                            "To analyze the custom source code of an application.",
                            "To test the running application from the outside.",
                            "To identify the open-source libraries in a codebase and check them for known vulnerabilities.",
                            "To monitor the application for threats in production."
                        ],
                        "correct": 2,
                        "explanation": "SCA focuses on the security of the third-party and open-source components that are 'composed' to build a modern application."
                    },
                    {
                        "id": 2,
                        "question": "A formal, machine-readable inventory of all the software components in an application is known as a:",
                        "options": [
                            "Threat Model",
                            "Software Bill of Materials (SBOM)",
                            "Penetration Test Report",
                            "Firewall Ruleset"
                        ],
                        "correct": 1,
                        "explanation": "An SBOM is like a list of ingredients for software. It is a critical artifact for managing supply chain security and responding to new vulnerabilities."
                    },
                    {
                        "id": 3,
                        "question": "A feature in an SCA tool that automatically creates a pull request to upgrade a vulnerable library to a patched version is an example of:",
                        "options": [
                            "Automated Remediation",
                            "Vulnerability Discovery",
                            "License Compliance",
                            "Threat Modeling"
                        ],
                        "correct": 0,
                        "explanation": "Automated remediation makes it easy for developers to fix vulnerable dependencies, significantly speeding up the patching process."
                    },
                    {
                        "id": 4,
                        "question": "Besides security vulnerabilities, what other major risk do SCA tools help manage?",
                        "options": [
                            "Poor application performance.",
                            "Server misconfigurations.",
                            "Open-source software license compliance.",
                            "Phishing attacks."
                        ],
                        "correct": 2,
                        "explanation": "SCA tools can read the license of each open-source library (e.g., MIT, Apache, GPL) and alert developers if a license is incompatible with the company's policies, preventing legal issues."
                    }
                ]
            }
        },
        {
            "id": "lesson-9",
            "title": "Container Security",
            "duration": "120 min",
            "objectives": [
                "Understand the container security lifecycle.",
                "Learn to scan container images for vulnerabilities in the CI/CD pipeline.",
                "Design for runtime container protection and threat detection.",
                "Grasp key security best practices for Kubernetes orchestration."
            ],
            "content": {
                "overview": "Containers have become the standard for deploying modern applications, but they introduce a new and complex attack surface. This lesson covers a holistic approach to container security, addressing the entire lifecycle from the build pipeline to the runtime environment and the orchestration platform that manages it all.",
                "sections": [
                    {
                        "title": "Image Vulnerability Scanning",
                        "content": "<p>Container security starts in the build pipeline. A container image is composed of multiple layers, including a base operating system and various software packages. Any of these can contain vulnerabilities.</p><h3>The Process:</h3><ol><li><strong>Build:</strong> The CI/CD pipeline builds the container image using a Dockerfile.</li><li><strong>Scan:</strong> The pipeline uses a container scanner (e.g., Trivy, Clair, or a commercial tool) to inspect every layer of the newly built image. The scanner compares the list of installed OS packages and software libraries against a database of known vulnerabilities (CVEs).</li><li><strong>Gate:</strong> The pipeline is configured to fail the build if the scan discovers any critical or high-severity vulnerabilities for which a patch is available.</li></ol><p>This prevents vulnerable images from ever being pushed to the container registry.</p>",
                        "image": "https://images.unsplash.com/photo-1614064548237-02f0d1a2c39c?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Runtime Container Protection",
                        "content": "<p>A clean image scan is not enough; threats can still emerge at runtime. Runtime protection focuses on detecting and preventing malicious activity inside a running container.</p><h3>Key Capabilities (provided by CWPP tools):</h3><ul><li><strong>Behavioral Monitoring:</strong> The tool learns the normal behavior of a container (e.g., 'this container only ever runs the `nginx` process and listens on port 80'). It then alerts on any deviation, such as a shell being executed (`/bin/sh`) or an outbound connection to a strange IP address.</li><li><strong>File Integrity Monitoring:</strong> Alerts if critical files inside the container are modified unexpectedly.</li><li><strong>Vulnerability Shielding:</strong> Some tools can virtually patch a running container against a known vulnerability, even before the image itself has been rebuilt.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1573497175235-d3648a07b388?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Kubernetes Security Best Practices",
                        "content": "<p>The container orchestrator (almost always Kubernetes) is a powerful and complex system that must be secured.</p><h3>Architectural Controls:</h3><ul><li><strong>Network Policies:</strong> Implement default-deny network policies to create a Zero Trust network within the cluster, preventing pods from communicating unless explicitly allowed.</li><li><strong>Pod Security Standards:</strong> Enforce policies that prevent containers from running as root, using host networking, or mounting sensitive host directories.</li><li><strong>RBAC:</strong> Use Kubernetes Role-Based Access Control to enforce least privilege for users and service accounts interacting with the Kubernetes API.</li><li><strong>Secrets Management:</strong> Use the built-in Kubernetes Secrets object or, preferably, integrate with an external secrets manager like HashiCorp Vault.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1593441139884-faf2c88c7c97?w=800&h=400&fit=crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 9: Container Security Pipeline Implementation",
                        "language": "yaml",
                        "code": "# Example GitLab CI job for container image scanning with Trivy\n\nimage-scan:\n  stage: test\n  image: docker:20.10.16\n  services:\n    - docker:20.10.16-dind\n  script:\n    - export IMAGE=my-app:$CI_COMMIT_SHA\n    - docker build -t $IMAGE .\n    # Install Trivy scanner\n    - wget https://github.com/aquasecurity/trivy/releases/download/v0.30.4/trivy_0.30.4_Linux-64bit.tar.gz\n    - tar zxvf trivy_0.30.4_Linux-64bit.tar.gz\n    # Scan the image and fail the pipeline if any HIGH or CRITICAL vulnerabilities are found\n    - ./trivy image --exit-code 1 --severity HIGH,CRITICAL $IMAGE"
                    },
                    {
                        "title": "Code Example 9: Container Security Automation Platform",
                        "language": "json",
                        "code": "{\n  \"alertId\": \"runtime-alert-1122\",\n  \"timestamp\": \"2025-09-09T18:30:00Z\",\n  \"ruleName\": \"Terminal Shell in Container\",\n  \"severity\": \"HIGH\",\n  \"container\": {\n    \"name\": \"prod-webapp-7f8c9d...\",\n    \"image\": \"my-webapp:v1.2\",\n    \"namespace\": \"production\"\n  },\n  \"details\": {\n    \"process\": \"/bin/sh\",\n    \"command\": \"/bin/sh -c 'whoami'\",\n    \"description\": \"A shell was executed in a container that does not normally run shells. This is a strong indicator of compromise.\"\n  },\n  \"actionTaken\": \"CONTAINER_PAUSED\"\n}"
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "What is the primary goal of scanning a container image in a CI/CD pipeline?",
                        "options": [
                            "To make the image smaller.",
                            "To test the application's functionality.",
                            "To prevent container images with known vulnerabilities in their OS packages or libraries from being deployed.",
                            "To assign a name to the image."
                        ],
                        "correct": 2,
                        "explanation": "Image scanning is a critical 'shift-left' control for container security. It acts as a quality gate to ensure that only images free of known high-severity vulnerabilities are promoted to the container registry."
                    },
                    {
                        "id": 2,
                        "question": "A runtime security tool that alerts when a shell process (`/bin/sh`) is unexpectedly executed inside a running container is an example of:",
                        "options": [
                            "Image scanning",
                            "Behavioral monitoring",
                            "License compliance scanning",
                            "Static analysis"
                        ],
                        "correct": 1,
                        "explanation": "Runtime protection focuses on the behavior of the running container. It establishes a baseline of normal activity and alerts on any deviations, which are often indicators of compromise."
                    },
                    {
                        "id": 3,
                        "question": "In Kubernetes, what is the function of a Network Policy?",
                        "options": [
                            "To check a container image for vulnerabilities.",
                            "To act as a firewall for pods, controlling which pods can communicate with each other.",
                            "To manage user access to the Kubernetes API.",
                            "To store sensitive data like passwords."
                        ],
                        "correct": 1,
                        "explanation": "Network Policies are essential for implementing micro-segmentation and Zero Trust within a Kubernetes cluster. They allow you to define explicit rules about traffic flow between pods."
                    },
                    {
                        "id": 4,
                        "question": "Preventing a container from running as the 'root' user is a best practice enforced by what Kubernetes control?",
                        "options": [
                            "Network Policies",
                            "RBAC",
                            "Secrets",
                            "Pod Security Standards"
                        ],
                        "correct": 3,
                        "explanation": "Pod Security Standards (and the older Pod Security Policies) are cluster-wide rules that enforce security contexts for pods, such as preventing privileged execution, which significantly reduces the container's attack surface."
                    }
                ]
            }
        },
        {
            "id": "lesson-10",
            "title": "Infrastructure as Code (IaC) Security",
            "duration": "90 min",
            "objectives": [
                "Understand how to apply security principles to IaC.",
                "Learn to use tools to scan IaC templates for misconfigurations.",
                "Implement preventative guardrails using Policy as Code.",
                "Design a process for detecting and remediating configuration drift."
            ],
            "content": {
                "overview": "Infrastructure as Code (IaC) allows teams to manage and provision infrastructure through machine-readable definition files (like Terraform or CloudFormation) rather than manual processes. This brings great power and speed, but also the risk of deploying a misconfiguration at massive scale. This lesson covers how to secure your IaC pipelines to prevent cloud misconfigurations before they happen.",
                "sections": [
                    {
                        "title": "Infrastructure Security Scanning",
                        "content": "<p>This is the 'SAST for infrastructure'. IaC security scanners are tools that parse IaC templates (e.g., `.tf` files for Terraform) and check them for security best practice violations.</p><h3>Common Issues Found:</h3><ul><li>An S3 bucket configured to be public.</li><li>A cloud firewall (security group) rule that allows unrestricted inbound access (0.0.0.0/0) on a sensitive port like SSH or RDP.</li><li>A database that does not have encryption enabled.</li><li>An IAM policy that grants excessive permissions.</li></ul><p>These scanners (e.g., `tfsec`, `Checkov`) are integrated into the CI/CD pipeline to provide fast feedback to developers.</p>",
                        "image": "https://images.unsplash.com/photo-1510915228340-29c85a43dcfe?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Policy as Code Implementation",
                        "content": "<p>Policy as Code (PaC) takes IaC security a step further by providing preventative guardrails. It allows you to write policies in a high-level language (like Rego with Open Policy Agent - OPA) that define what is and is not allowed in your environment.</p><h3>The Workflow:</h3><ol><li>A developer runs `terraform plan` to see the changes they are about to make.</li><li>The CI/CD pipeline takes the plan file (which is in a machine-readable JSON format).</li><li>The pipeline checks the plan against the PaC engine (OPA).</li><li>OPA evaluates the plan against its loaded policies (e.g., 'A security group rule cannot have a CIDR block of 0.0.0.0/0').</li><li>If the plan violates a policy, OPA returns a 'deny' decision, and the pipeline fails, blocking the insecure change from ever being applied.</li></ol>",
                        "image": "https://images.unsplash.com/photo-1521791136064-7986c2920216?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Configuration Drift Detection",
                        "content": "<p>IaC provides a 'single source of truth' for your infrastructure's desired state. 'Drift' occurs when someone makes a manual change to the live environment (e.g., through the cloud console) that is not reflected in the IaC code.</p><p>This is a security risk because these manual changes bypass the pipeline's security checks. The architecture must include tools (like a CSPM or specialized IaC tools) that continuously scan the live environment and compare its actual state to the state defined in the code. If drift is detected, an alert should be generated, and the team should either update the code to reflect the change or revert the manual change.</p>",
                        "image": "https://images.unsplash.com/photo-1573497175235-d3648a07b388?w=800&h=400&fit-crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 10: IaC Security Pipeline Workshop",
                        "language": "yaml",
                        "code": "# Example GitLab CI job for scanning Terraform code with tfsec\n\niac-scan:\n  stage: test\n  image: \n    name: aquasecurity/tfsec-ci:latest\n    entrypoint: [\"\"]\n  script:\n    # tfsec will scan the current directory for Terraform files\n    # and will exit with a non-zero code if it finds issues,\n    # which will cause the pipeline job to fail.\n    - /usr/bin/tfsec ."
                    },
                    {
                        "title": "Code Example 10: Infrastructure Security Policy Engine",
                        "language": "hcl",
                        "code": "# Example Terraform code with a security vulnerability\n\nresource \"aws_security_group\" \"insecure_ssh\" {\n  name        = \"insecure-ssh-access\"\n  description = \"Allow SSH from anywhere\"\n\n  ingress {\n    from_port   = 22\n    to_port     = 22\n    protocol    = \"tcp\"\n    # This is a major security risk!\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n}\n\n# --- IaC Scanner (like tfsec) Output ---\n# Result: CRITICAL\n# Description: Security group rule allows ingress from all IPs on port 22.\n# Impact: The SSH port of an instance is exposed to the entire internet.\n# Resolution: Set a more restrictive CIDR block."
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "A tool that analyzes Terraform or CloudFormation files for security issues like public S3 buckets is known as an:",
                        "options": [
                            "DAST scanner",
                            "SCA scanner",
                            "IaC scanner",
                            "Antivirus"
                        ],
                        "correct": 2,
                        "explanation": "IaC scanners are the 'SAST for infrastructure', analyzing the code that defines infrastructure to find security flaws before it is deployed."
                    },
                    {
                        "id": 2,
                        "question": "The primary goal of integrating IaC scanning into a CI/CD pipeline is to:",
                        "options": [
                            "Make the infrastructure deployment process slower.",
                            "Proactively prevent cloud misconfigurations from being deployed.",
                            "Scan the running application for vulnerabilities.",
                            "Check for open-source license issues."
                        ],
                        "correct": 1,
                        "explanation": "This is a key 'shift-left' practice for cloud security. By finding and blocking misconfigurations in the pipeline, you prevent them from ever becoming a risk in the production environment."
                    },
                    {
                        "id": 3,
                        "question": "A situation where a manual change is made in the cloud console that is not reflected in the source Terraform code is called:",
                        "options": [
                            "Policy as Code",
                            "Configuration Drift",
                            "A successful deployment",
                            "Continuous Integration"
                        ],
                        "correct": 1,
                        "explanation": "Drift undermines the 'single source of truth' benefit of IaC. It creates an unmanaged, untracked configuration that has not been through the pipeline's security checks."
                    },
                    {
                        "id": 4,
                        "question": "A system that uses a tool like Open Policy Agent to programmatically block a `terraform apply` if the plan contains a non-compliant change is an example of:",
                        "options": [
                            "Policy as Code (PaC)",
                            "Configuration Drift",
                            "Manual Review",
                            "Incident Response"
                        ],
                        "correct": 0,
                        "explanation": "Policy as Code provides preventative guardrails. It allows you to define and automatically enforce architectural standards, making it a very powerful governance tool."
                    }
                ]
            }
        },
        {
            "id": "lesson-11",
            "title": "Secrets Management",
            "duration": "90 min",
            "objectives": [
                "Understand the risks of 'secret sprawl'.",
                "Learn the architecture of modern vault technologies.",
                "Design a strategy for dynamic and short-lived secrets.",
                "Integrate secrets management securely into CI/CD pipelines."
            ],
            "content": {
                "overview": "'Secret sprawl'the dangerous practice of hard-coding passwords, API keys, and certificates in source code, config files, and environment variablesis a leading cause of major breaches. This lesson covers the architecture of a robust secrets management program, designed to centralize, secure, and tightly control access to all secrets.",
                "sections": [
                    {
                        "title": "Secrets Management Principles",
                        "content": "<p>A secret is any piece of information that grants privileged access, such as a password, API key, TLS certificate, or encryption key. The goal of a secrets management program is to eliminate secret sprawl.</p><h3>Core Principles:</h3><ul><li><strong>Centralize:</strong> All secrets must be stored in a single, secure, centralized location (a 'vault').</li><li><strong>Encrypt:</strong> Secrets must be encrypted at rest in the vault and in transit when being accessed.</li><li><strong>Authenticate:</strong> Every human and machine that wants to access a secret must first strongly authenticate itself to the vault.</li><li><strong>Authorize:</strong> The vault must enforce least-privilege policies, ensuring clients can only access the specific secrets they need.</li><li><strong>Audit:</strong> All access to secrets (who accessed what, when) must be recorded in a non-repudiable audit log.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1584929788015-230a14589d31?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Vault Technologies and Solutions",
                        "content": "<p>A secrets management vault is a purpose-built, highly secure system for storing and controlling access to secrets. Leading solutions include HashiCorp Vault and cloud provider services like AWS Secrets Manager or Azure Key Vault.</p><h3>Key Architectural Features:</h3><ul><li><strong>Secure Storage:</strong> An encrypted backend for storing the secrets.</li><li><strong>Authentication Methods:</strong> Multiple methods for clients to authenticate (e.g., username/password, tokens, cloud IAM roles, Kubernetes service accounts).</li><li><strong>Secrets Engines:</strong> Different backends for different types of secrets (e.g., a key/value store, a database engine that can generate credentials).</li><li><strong>Policy Engine:</strong> A fine-grained authorization system to control access.</li><li><strong>Audit Log:</strong> A detailed, tamper-resistant log of all activities.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Dynamic Secrets Generation",
                        "content": "<p>The most advanced secrets management architecture moves beyond just storing static, long-lived secrets. Instead, it generates secrets dynamically, on-demand.</p><h3>How it Works (Database Example):</h3><ol><li>An application needs to connect to a database. It authenticates to the vault.</li><li>Instead of asking for the database password, it asks the vault's 'database secrets engine' for a credential.</li><li>The vault, which has a privileged connection to the database, uses its own credentials to create a brand new, unique database username/password for the application.</li><li>The vault returns this new, temporary credential to the application and also sets a Time-to-Live (TTL) for it (e.g., 1 hour).</li><li>The application uses the temporary credential to connect to the database.</li><li>After 1 hour, the vault automatically revokes the credential in the database.</li></ol><p>This means the secret only exists for a short period of time, dramatically reducing the risk if it is compromised.</p>",
                        "image": "https://images.unsplash.com/photo-1555949963-aa79dcee981c?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Integration with CI/CD Pipelines",
                        "content": "<p>A common challenge is providing secrets to a CI/CD pipeline (e.g., a cloud provider API key to run a deployment) without exposing it.</p><h3>Secure Integration Patterns:</h3><ul><li><strong>Don't store secrets in the pipeline's configuration file.</strong> Use the CI/CD platform's built-in secrets management feature (e.g., GitLab CI/CD Variables, GitHub Actions Secrets).</li><li><strong>Use short-lived, dynamic tokens.</strong> The best approach is to use a protocol like OIDC to allow the pipeline to securely fetch a short-lived access token from the cloud provider without needing a long-lived secret at all.</li><li><strong>Retrieve secrets at runtime.</strong> The pipeline job authenticates to the vault and retrieves the secrets it needs just before it uses them. The secrets are never stored on disk.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1542382257-80deda0e5d99?w=800&h=400&fit=crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 11: Enterprise Secrets Management Implementation",
                        "language": "shell",
                        "code": "# Example of a CI/CD job retrieving a secret from HashiCorp Vault at runtime\n\n- name: Deploy to Cloud\n  script: |\n    # 1. Authenticate to Vault using the CI/CD job's JWT token\n    export VAULT_TOKEN=$(vault write -field=token auth/jwt/login role=\"my-ci-role\" jwt=\"$CI_JOB_JWT\")\n    \n    # 2. Read the cloud API key from the Vault\n    export CLOUD_API_KEY=$(vault read -field=api_key secret/data/cloud/deployment_key)\n    \n    # 3. Use the secret to run the deployment\n    # The secret is only held in memory in the ephemeral job runner.\n    ./deploy.sh --api-key \"$CLOUD_API_KEY\""
                    },
                    {
                        "title": "Code Example 11: Automated Secrets Lifecycle Management System",
                        "language": "hcl",
                        "code": "# Example HashiCorp Vault configuration for dynamic database secrets\n\n# 1. Enable the database secrets engine\nvault secrets enable database\n\n# 2. Configure the connection to the database (Vault uses this to manage credentials)\nvault write database/config/my-postgres \\\n    plugin_name=\"postgresql-database-plugin\" \\\n    allowed_roles=\"readonly-role\" \\\n    connection_url=\"postgresql://{{username}}:{{password}}@postgres.example.com:5432/mydb\"\n    username=\"vault-admin\" \\\n    password=\"super-secret-password\"\n\n# 3. Create a role that defines the permissions for the dynamic credentials\nvault write database/roles/readonly-role \\\n    db_name=\"my-postgres\" \\\n    creation_statements=\"CREATE ROLE \\\"{{name}}\\\" WITH LOGIN PASSWORD '{{password}}' VALID UNTIL '{{expiration}}'; GRANT SELECT ON ALL TABLES IN SCHEMA public TO \\\"{{name}}\\\";\" \\\n    default_ttl=\"1h\" \\\n    max_ttl=\"24h\"\n\n# Now, an application can request a credential from the 'readonly-role' and get a unique,\n# short-lived user with only SELECT permissions."
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "The widespread problem of hard-coding credentials in source code and configuration files is known as:",
                        "options": [
                            "Secret Sprawl",
                            "Dynamic Secrets",
                            "A Vault",
                            "Authentication"
                        ],
                        "correct": 0,
                        "explanation": "Secret sprawl is a major security risk because it makes secrets difficult to track, rotate, and revoke. Centralizing them in a vault is the solution."
                    },
                    {
                        "id": 2,
                        "question": "What is the primary function of a secrets management vault like HashiCorp Vault?",
                        "options": [
                            "To scan source code for vulnerabilities.",
                            "To act as a firewall.",
                            "To provide a centralized, secure, and auditable system for storing and controlling access to secrets.",
                            "To deploy applications to production."
                        ],
                        "correct": 2,
                        "explanation": "A vault is a purpose-built tool designed to solve the problem of secret sprawl by providing a secure and programmatic way to manage the entire lifecycle of secrets."
                    },
                    {
                        "id": 3,
                        "question": "A system where a vault creates a unique, temporary database password for an application on-demand is known as:",
                        "options": [
                            "Static Secrets",
                            "Password Rotation",
                            "Dynamic Secrets",
                            "Secret Sprawl"
                        ],
                        "correct": 2,
                        "explanation": "Dynamic secrets are a powerful, modern approach. By creating credentials that are short-lived and unique, they dramatically reduce the window of opportunity for an attacker if a secret is compromised."
                    },
                    {
                        "id": 4,
                        "question": "What is the most secure way for a CI/CD pipeline to get credentials for deploying to a cloud environment?",
                        "options": [
                            "Store the master cloud API key as plain text in the `.gitlab-ci.yml` file.",
                            "Use a protocol like OIDC to allow the pipeline job to securely request a short-lived token from the cloud provider.",
                            "Email the API key to all the developers on the team.",
                            "Write the API key on a sticky note on the server."
                        ],
                        "correct": 1,
                        "explanation": "Using a passwordless, token-based authentication mechanism like OIDC is the most secure pattern. It eliminates the need to store any long-lived, static secrets in the CI/CD system, which is a prime target for attackers."
                    }
                ]
            }
        },
        {
            "id": "lesson-12",
            "title": "CI/CD Pipeline Security",
            "duration": "120 min",
            "objectives": [
                "Understand the CI/CD pipeline as a critical asset and attack vector.",
                "Design secure access controls for the pipeline.",
                "Architect for the integrity and signing of build artifacts.",
                "Implement effective security gates and pipeline monitoring."
            ],
            "content": {
                "overview": "The CI/CD pipeline is the automated factory that builds and delivers your software. A compromise of the pipeline can be catastrophic, allowing an attacker to inject malicious code into your applications. This lesson focuses on securing the pipeline itself, treating it as a critical piece of production infrastructure.",
                "sections": [
                    {
                        "title": "Secure Pipeline Design Principles",
                        "content": "<p>The CI/CD pipeline has powerful privileges, often with the ability to deploy code to production. It must be secured accordingly.</p><h3>Key Principles:</h3><ul><li><strong>Least Privilege:</strong> The pipeline's service account or runner should have the absolute minimum permissions needed to perform its job. It should not have global admin rights.</li><li><strong>Segregation:</strong> Use separate pipelines or runners for development and production environments. A build for a feature branch should not be able to use the credentials to deploy to production.</li><li><strong>Ephemeral Build Environments:</strong> Each pipeline job should run in a clean, ephemeral environment (like a fresh container) that is destroyed after the job completes. This prevents secrets or artifacts from one build from leaking into another.</li><li><strong>Pipeline as Code:</strong> The pipeline's definition (e.g., the `Jenkinsfile` or `.gitlab-ci.yml`) should be stored in version control. Changes to the pipeline should go through a mandatory peer review process, just like application code.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1542382257-80deda0e5d99?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Build Environment Security",
                        "content": "<p>The environment where the code is built and tested is a key part of the supply chain and must be secure.</p><h3>Controls:</h3><ul><li><strong>Hardened Runners:</strong> The servers or containers that execute the pipeline jobs (the 'runners' or 'agents') must be hardened, patched, and monitored just like production servers.</li><li><strong>Dependency Management:</strong> The build environment itself has dependencies (e.g., the version of Docker, Node.js, or Maven used). These should be explicitly managed and scanned for vulnerabilities.</li><li><strong>Log all Commands:</strong> The pipeline should be configured to log every single command that is executed during a build. These logs should be sent to a central SIEM for monitoring.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1510915228340-29c85a43dcfe?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Artifact Integrity and Signing",
                        "content": "<p>A critical goal is to ensure that the build artifact (e.g., the container image or JAR file) that is deployed to production is the exact same one that was built and scanned in the pipeline.</p><h3>Architectural Solution:</h3><ol><li><strong>Build and Scan:</strong> The pipeline builds the artifact.</li><li><strong>Sign:</strong> After all security scans have passed, a final step in the pipeline digitally signs the artifact using a private key stored in a secure location (like an HSM or vault). This signature acts as a tamper-proof seal.</li><li><strong>Store:</strong> The signed artifact is pushed to a secure artifact repository (e.g., Artifactory, Nexus, or a container registry).</li><li><strong>Verify:</strong> Before deploying to production, the deployment tool (e.g., Kubernetes) must have a policy that verifies the signature on the artifact. If the signature is invalid or missing, the deployment is blocked.</li></ol><p>This creates a secure chain of custody from the build to production.</p>",
                        "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Deployment Security Gates",
                        "content": "<p>A security gate is a mandatory checkpoint in the pipeline that must pass before an artifact can be promoted to the next environment.</p><h3>Example Gates before Production Deployment:</h3><ul><li>Has the SAST scan completed with zero new critical vulnerabilities?</li><li>Has the SCA scan completed with zero new critical vulnerabilities?</li><li>Has the container image been scanned and signed?</li><li>Does the IaC plan pass the Policy as Code checks?</li><li>Has the change received a manual approval from the QA lead?</li></ul><p>These gates are the primary mechanism for enforcing security policy automatically within the software delivery lifecycle.</p>",
                        "image": "https://images.unsplash.com/photo-1521791136064-7986c2920216?w=800&h=400&fit-crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 12: Secure CI/CD Pipeline Construction",
                        "language": "yaml",
                        "code": "# Conceptual secure pipeline with separated prod deployment\n\n# Main pipeline for feature branches\nbuild-and-test:\n  script:\n    - mvn install\n    - ./run_sast.sh\n    - ./run_sca.sh\n  # This job uses a general-purpose runner with no prod access\n  tags: [dev-runner]\n\n# This separate job only runs on the 'main' branch\ndeploy-to-production:\n  script:\n    # 1. Verify the signature of the artifact from the 'build' job\n    - ./verify_artifact_signature.sh\n    # 2. Run the deployment script\n    - ./deploy_to_prod.sh\n  # This job ONLY runs on a specific, locked-down runner\n  # that has the credentials to access production.\n  tags: [prod-runner]\n  rules:\n    - if: $CI_COMMIT_BRANCH == 'main'"
                    },
                    {
                        "title": "Code Example 12: Pipeline Security Orchestration Framework",
                        "language": "json",
                        "code": "{\n  \"buildId\": \"build-789\",\n  \"artifact\": \"my-app:v1.3.0\",\n  \"securityGates\": [\n    {\n      \"gateName\": \"SAST Quality Gate\",\n      \"status\": \"PASSED\",\n      \"details\": \"0 new critical vulnerabilities found.\"\n    },\n    {\n      \"gateName\": \"SCA Quality Gate\",\n      \"status\": \"PASSED\",\n      \"details\": \"0 new critical CVEs in dependencies.\"\n    },\n    {\n      \"gateName\": \"Artifact Signature Verification\",\n      \"status\": \"PASSED\",\n      \"details\": \"Signature verified with production signing key.\"\n    },\n    {\n      \"gateName\": \"Manual QA Approval\",\n      \"status\": \"PASSED\",\n      \"approver\": \"qa_lead@example.com\"\n    }\n  ],\n  \"finalDecision\": \"APPROVED_FOR_PRODUCTION\"\n}"
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "The practice of defining your CI/CD pipeline in a version-controlled file like `Jenkinsfile` is known as:",
                        "options": [
                            "Pipeline as Code",
                            "Infrastructure as Code",
                            "Security as Code",
                            "Manual Configuration"
                        ],
                        "correct": 0,
                        "explanation": "Pipeline as Code is a core DevOps practice that allows changes to the build and deployment process to be versioned, reviewed, and tested, which is essential for securing the pipeline itself."
                    },
                    {
                        "id": 2,
                        "question": "What is the primary security benefit of using ephemeral build environments?",
                        "options": [
                            "They are cheaper to run.",
                            "They prevent secrets or artifacts from one build from leaking into a subsequent build.",
                            "They make builds run faster.",
                            "They do not require any security."
                        ],
                        "correct": 1,
                        "explanation": "Using a clean, fresh environment for every single pipeline job ensures consistency and prevents state-related issues or data leakage between builds, which is a major security and reliability concern."
                    },
                    {
                        "id": 3,
                        "question": "The process of digitally signing a build artifact and then verifying that signature before deployment provides what security guarantee?",
                        "options": [
                            "Confidentiality",
                            "Availability",
                            "Integrity",
                            "Performance"
                        ],
                        "correct": 2,
                        "explanation": "Digital signatures provide integrity. It creates a tamper-proof seal that guarantees that the artifact being deployed is the exact same one that was built and passed all the security checks in the pipeline."
                    },
                    {
                        "id": 4,
                        "question": "A mandatory checkpoint in a pipeline, such as 'fail the build if the SAST scan finds new critical vulnerabilities', is called a:",
                        "options": [
                            "Build Step",
                            "Security Gate",
                            "Code Comment",
                            "Pipeline Trigger"
                        ],
                        "correct": 1,
                        "explanation": "A security gate is an automated enforcement point for a security policy. It's a key mechanism for ensuring that only code that meets a minimum security bar can be promoted to production."
                    }
                ]
            }
        },
        {
            "id": "lesson-13",
            "title": "API Security in DevSecOps",
            "duration": "90 min",
            "objectives": [
                "Understand the OWASP API Security Top 10 risks.",
                "Design secure API authentication using OAuth 2.0 and OpenID Connect.",
                "Integrate API security testing strategies into the CI/CD pipeline.",
                "Architect for API threat protection using an API gateway."
            ],
            "content": {
                "overview": "APIs are the backbone of modern applications, but they are also a primary target for attackers. In a DevSecOps context, securing APIs requires automating security testing in the pipeline and architecting for robust protection at runtime. This lesson covers the key patterns for building and deploying secure APIs.",
                "sections": [
                    {
                        "title": "API Security Fundamentals",
                        "content": "<p>The OWASP API Security Top 10 project highlights the most critical risks facing APIs. The DevSecOps pipeline and runtime architecture must be designed to address these.</p><h3>Key Risks to Address:</h3><ul><li><strong>Broken Object Level Authorization (BOLA):</strong> An attacker can access data belonging to other users by manipulating object IDs in API calls.</li><li><strong>Broken Authentication:</strong> Weak or improperly implemented authentication.</li><li><strong>Excessive Data Exposure:</strong> The API returns more data than the client needs, potentially exposing sensitive information.</li><li><strong>Lack of Resources & Rate Limiting:</strong> Vulnerability to denial-of-service and brute-force attacks.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1605995538181-22920bee518f?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "API Gateway Security Patterns",
                        "content": "<p>An API Gateway is a critical architectural control point that acts as a single entry point for all API traffic. It is the ideal place to enforce security policies centrally.</p><h3>Key Security Functions:</h3><ul><li><strong>Authentication:</strong> The gateway should be responsible for validating the credentials of the API client, typically by validating an OAuth 2.0 access token (JWT).</li><li><strong>Coarse-Grained Authorization:</strong> The gateway can check if the client has the required 'scope' to call a particular API endpoint.</li><li><strong>Rate Limiting and Throttling:</strong> Protects backend services from abuse and DoS attacks.</li><li><strong>WAF Integration:</strong> Can inspect the API traffic for common attack patterns like SQL injection.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1544890225-2fde0e66f255?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "API Security Testing Strategies",
                        "content": "<p>API security testing must be automated in the CI/CD pipeline.</p><h3>The Process:</h3><ol><li><strong>Deploy:</strong> The pipeline deploys the application and its API to a staging environment.</li><li><strong>Scan:</strong> The pipeline triggers a specialized DAST tool configured for API testing.</li><li><strong>Provide Schema:</strong> The DAST tool is given the API's specification file (e.g., OpenAPI/Swagger). This allows the tool to understand all the endpoints and parameters and generate intelligent tests.</li><li><strong>Test for Flaws:</strong> The scanner specifically tests for common API flaws like BOLA, injection attacks, and authentication issues.</li><li><strong>Report:</strong> The results are fed back into the pipeline, which can be configured to fail if critical vulnerabilities are found.</li></ol>",
                        "image": "https://images.unsplash.com/photo-1542382257-80deda0e5d99?w=800&h=400&fit=crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 13: API Security Testing Pipeline",
                        "language": "yaml",
                        "code": "# Example GitLab CI job for API security testing using OWASP ZAP\n\napi-scan:\n  stage: test\n  # Assumes the API has been deployed to a staging environment\n  script:\n    - docker run -v $(pwd):/zap/wrk/:rw -t owasp/zap2docker-stable zap-api-scan.py \\\n        -t http://staging-api.example.com/v3/api-docs \\\n        -f openapi \\\n        -r zap-report.html\n    # The -r flag generates a report. A script would then parse this report\n    # and fail the job if certain conditions are met.\n  artifacts:\n    paths: [zap-report.html]"
                    },
                    {
                        "title": "Code Example 13: Automated API Security Validation Framework",
                        "language": "json",
                        "code": "{\n  \"scanType\": \"API-DAST\",\n  \"specification\": \"openapi.json\",\n  \"findings\": [\n    {\n      \"vulnerability\": \"Broken Object Level Authorization (BOLA)\",\n      \"severity\": \"CRITICAL\",\n      \"endpoint\": \"/api/v1/users/{userId}\",\n      \"details\": \"Was able to access /api/v1/users/userB with authentication token for userA.\",\n      \"recommendation\": \"Ensure the backend service validates that the authenticated user's ID matches the requested userId.\"\n    },\n    {\n      \"vulnerability\": \"Missing Rate Limiting\",\n      \"severity\": \"HIGH\",\n      \"endpoint\": \"/api/v1/login\",\n      \"details\": \"The login endpoint did not block requests after 100 failed attempts.\"\n    }\n  ]\n}"
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "The most common and critical API vulnerability, where a user can access another user's data by changing an ID in the request, is known as:",
                        "options": [
                            "Lack of Rate Limiting",
                            "Broken Object Level Authorization (BOLA)",
                            "Excessive Data Exposure",
                            "Broken Authentication"
                        ],
                        "correct": 1,
                        "explanation": "BOLA (also known as Insecure Direct Object Reference - IDOR) is a pervasive and severe API flaw. The fix requires a server-side authorization check on every request that accesses a specific object."
                    },
                    {
                        "id": 2,
                        "question": "What is the primary role of an API Gateway in a secure architecture?",
                        "options": [
                            "To store the application's data.",
                            "To act as a centralized enforcement point for policies like authentication, authorization, and rate limiting.",
                            "To host the API's source code.",
                            "To write the business logic for the API."
                        ],
                        "correct": 1,
                        "explanation": "An API Gateway is a reverse proxy that provides a single, managed entry point for all APIs. This allows security policies to be applied consistently without having to code them into every individual backend microservice."
                    },
                    {
                        "id": 3,
                        "question": "What does an API security scanner need to effectively test a modern API?",
                        "options": [
                            "The name of the lead developer.",
                            "The API's specification or schema file (e.g., OpenAPI).",
                            "The physical location of the server.",
                            "The number of users the API has."
                        ],
                        "correct": 1,
                        "explanation": "The API specification acts as a roadmap for the scanner, telling it what endpoints are available, what methods they support, and what parameters they expect. This enables much more intelligent and comprehensive testing than blind crawling."
                    },
                    {
                        "id": 4,
                        "question": "The standard protocol framework for delegated authorization, commonly used to get access tokens for APIs, is:",
                        "options": [
                            "SAML",
                            "LDAP",
                            "OAuth 2.0",
                            "Kerberos"
                        ],
                        "correct": 2,
                        "explanation": "OAuth 2.0 is the industry standard for API authorization. OpenID Connect (OIDC) is then built on top of it to provide identity information."
                    }
                ]
            }
        },
        {
            "id": "lesson-14",
            "title": "Cloud-Native Security",
            "duration": "120 min",
            "objectives": [
                "Apply DevSecOps principles to serverless and microservices architectures.",
                "Understand the role of a Service Mesh in providing Zero Trust.",
                "Integrate Cloud Security Posture Management (CSPM) into the DevSecOps loop.",
                "Design for consistent security across multi-cloud environments."
            ],
            "content": {
                "overview": "Cloud-native architectures, built on microservices, containers, and serverless functions, require a cloud-native approach to security. This lesson focuses on how to apply DevSecOps principles to these modern, distributed systems, leveraging automation and specialized tools to manage security at scale.",
                "sections": [
                    {
                        "title": "Serverless Security Considerations",
                        "content": "<p>In serverless (e.g., AWS Lambda), the security focus shifts from the server to the function and its configuration.</p><h3>Key DevSecOps Controls:</h3><ul><li><strong>Least Privilege IAM Roles:</strong> Each function must have its own unique, tightly scoped IAM role defined in the IaC template. This is the most critical serverless security control.</li><li><strong>SCA for Functions:</strong> The CI/CD pipeline must use SCA to scan the function's dependencies for vulnerabilities.</li><li><strong>SAST for Function Code:</strong> The pipeline should use SAST to scan the function's code for bugs.</li><li><strong>IaC Scanning for Configuration:</strong> The IaC template that defines the function and its triggers (e.g., an API Gateway) must be scanned for misconfigurations.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1555949963-ff9808202534?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Microservices and Service Mesh Security",
                        "content": "<p>In a microservices architecture, a major challenge is securing the 'east-west' traffic (communication between services). A service mesh is the modern architectural pattern for solving this.</p><p>A service mesh (e.g., Istio) provides a dedicated, transparent infrastructure layer that can enforce security policies without requiring any changes to the application code.</p><h3>Security as Code with a Service Mesh:</h3><ul><li><strong>mTLS Policy:</strong> A simple YAML file can enforce that all traffic between services must be mutually authenticated and encrypted.</li><li><strong>Authorization Policy:</strong> Another YAML file can define fine-grained rules, like 'the `orders-service` can only call the `GET` method on the `inventory-service`.'</li></ul><p>These policy files can be version-controlled and managed through a GitOps workflow.</p>",
                        "image": "https://images.unsplash.com/photo-1593441139884-faf2c88c7c97?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Cloud Security Posture Management (CSPM)",
                        "content": "<p>CSPM tools continuously monitor the configuration of your cloud environment and are a critical part of the DevSecOps feedback loop for cloud security.</p><h3>Integration with DevSecOps:</h3><ul><li><strong>Detective Control:</strong> The CSPM tool acts as a safety net, detecting any misconfigurations that might have slipped through the CI/CD pipeline or were made manually.</li><li><strong>Feedback to Developers:</strong> When a CSPM tool finds a misconfiguration (e.g., a public S3 bucket), it can be configured to automatically create a ticket and assign it to the team that owns that resource. This provides a direct feedback loop to fix the underlying IaC code.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1573497175235-d3648a07b388?w=800&h=400&fit-crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 14: Cloud-Native Security Implementation",
                        "language": "yaml",
                        "code": "# Example Istio AuthorizationPolicy (Policy as Code for a Service Mesh)\n\napiVersion: security.istio.io/v1beta1\nkind: AuthorizationPolicy\nmetadata:\n  name: inventory-viewer\n  namespace: backend\nspec:\n  # Apply this policy to the 'inventory-service'\n  selector:\n    matchLabels:\n      app: inventory-service\n  # The default action is to deny all requests\n  action: ALLOW\n  rules:\n    # Allow requests if...\n    - from:\n        # ...the source is a principal from the 'frontend' service account\n        - source:\n            principals: [\"cluster.local/ns/frontend/sa/frontend-sa\"]\n      to:\n        # ...to an operation with the HTTP GET method\n        - operation:\n            methods: [\"GET\"]"
                    },
                    {
                        "title": "Code Example 14: Multi-Cloud Security Orchestration Platform",
                        "language": "plaintext",
                        "code": "/* \n  Conceptual Workflow: CSPM Feedback Loop\n\n  1.  **Detection:** A CSPM tool scans the AWS environment and detects a Security Group\n      that allows unrestricted SSH access (0.0.0.0/0 port 22).\n      - The CSPM identifies the resource owner via cloud tags: 'owner-team: backend-platform'.\n\n  2.  **Alerting:** The CSPM sends a high-severity alert via webhook.\n\n  3.  **Orchestration (SOAR/Automation Platform):**\n      - The webhook triggers a workflow.\n      - The workflow parses the alert and extracts the resource ID and owner tag.\n      - [API Call] The workflow creates a new ticket in the 'backend-platform' team's Jira board.\n        - The ticket is pre-populated with the finding, the resource ID, and a link to the\n          company's secure configuration standard.\n      - [API Call] The workflow posts a notification to the team's Slack channel.\n\n  Result: The development team receives immediate, actionable feedback about a security\n  misconfiguration in their environment, enabling them to fix the root cause in their IaC code.\n*/"
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "What is the most critical security control for a serverless function?",
                        "options": [
                            "Scanning its source code for vulnerabilities.",
                            "Assigning it a unique, least-privilege IAM role.",
                            "Ensuring it has a long timeout.",
                            "Placing it in a public VPC."
                        ],
                        "correct": 1,
                        "explanation": "The IAM execution role defines the function's permissions and its potential 'blast radius' if compromised. A tightly scoped, least-privilege role is the single most important security control."
                    },
                    {
                        "id": 2,
                        "question": "A service mesh provides Zero Trust security for microservices primarily by:",
                        "options": [
                            "Scanning container images for vulnerabilities.",
                            "Hardening the underlying Kubernetes nodes.",
                            "Using a sidecar proxy to transparently enforce mTLS and authorization policies for all service-to-service traffic.",
                            "Running antivirus software in each microservice."
                        ],
                        "correct": 2,
                        "explanation": "A service mesh secures the 'east-west' traffic between services, which is a major challenge in a microservices architecture. It achieves this by creating a secure, policy-driven communication layer."
                    },
                    {
                        "id": 3,
                        "question": "How does a CSPM tool fit into the DevSecOps feedback loop?",
                        "options": [
                            "It scans source code for bugs.",
                            "It acts as a detective control that finds misconfigurations in the live cloud environment and provides feedback to developers.",
                            "It is a tool for developers to write code faster.",
                            "It replaces the need for a CI/CD pipeline."
                        ],
                        "correct": 1,
                        "explanation": "While the pipeline provides preventative controls, the CSPM acts as a continuous validation and feedback mechanism for the security of the deployed cloud infrastructure itself."
                    },
                    {
                        "id": 4,
                        "question": "The concept of defining network security rules for a service mesh in version-controlled YAML files is an example of:",
                        "options": [
                            "Manual configuration",
                            "Security as Code / Policy as Code",
                            "Incident Response",
                            "Vulnerability Scanning"
                        ],
                        "correct": 1,
                        "explanation": "Modern cloud-native security relies heavily on Security as Code. Defining security policies declaratively in code allows them to be versioned, reviewed, and managed through automated GitOps workflows."
                    }
                ]
            }
        },
        {
            "id": "lesson-15",
            "title": "Security Testing Automation",
            "duration": "90 min",
            "objectives": [
                "Understand the principles of Test-Driven Security (TDS).",
                "Learn how to automate the generation of security test cases.",
                "Explore the role of automated penetration testing and regression testing.",
                "Design a framework for continuous security validation."
            ],
            "content": {
                "overview": "This lesson focuses on the pinnacle of 'shift-left' security: writing automated security tests that run alongside functional unit and integration tests. By treating security as a testable attribute of the software, teams can build a comprehensive and continuous safety net that validates defenses and prevents regressions.",
                "sections": [
                    {
                        "title": "Test-Driven Security Development",
                        "content": "<p>Test-Driven Security is an extension of Test-Driven Development (TDD). The core idea is to write a failing security test *before* writing the functional code.</p><h3>The Workflow:</h3><ol><li><strong>Write a Failing Test:</strong> An engineer writes a small, automated test that proves a security control is missing or a vulnerability exists. For example, a test that tries to access another user's data and asserts that it should receive a '403 Forbidden' error. Initially, this test will fail.</li><li><strong>Write the Code:</strong> The engineer writes the minimum amount of code required to make the failing security test pass (e.g., they add the correct authorization logic).</li><li><strong>Refactor:</strong> The engineer refactors the code to clean it up, ensuring all tests (both functional and security) still pass.</li></ol><p>This process ensures that security considerations are an integral part of the development process from the very beginning.</p>",
                        "image": "https://images.unsplash.com/photo-1515879218367-8466d910aaa4?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Security Regression Testing",
                        "content": "<p>A security regression is when a change to the code accidentally breaks or removes an existing security control. A comprehensive suite of automated security tests is the best defense against this.</p><p>Every time a new security control is added or a vulnerability is fixed, a corresponding automated test case should be added to the security test suite. This suite is then run on every single build. If a future code change inadvertently re-introduces the old vulnerability, the automated test will fail, breaking the build and immediately notifying the team of the regression.</p>",
                        "image": "https://images.unsplash.com/photo-1542382257-80deda0e5d99?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Continuous Security Validation",
                        "content": "<p>The goal is to move beyond point-in-time testing to a state of continuous validation. The architecture should support a constant stream of automated security tests running against deployed environments.</p><h3>Tools and Techniques:</h3><ul><li><strong>DAST in the Pipeline:</strong> As discussed previously, running automated DAST scans on every build.</li><li><strong>Breach and Attack Simulation (BAS):</strong> Using a BAS platform to continuously run safe, simulated attacks against the production environment to validate that security controls (like EDR, WAF, and firewalls) are working correctly.</li><li><strong>Security-Focused Chaos Engineering:</strong> Intentionally injecting security-related failures into an environment (e.g., revoking a service's credentials) to test the system's resilience and the monitoring team's ability to respond.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1556155092-490a1ba16284?w=800&h=400&fit=crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 15: Automated Security Testing Framework",
                        "language": "python",
                        "code": "# Example of a security integration test using Python's 'pytest' framework\n\nimport requests\n\n# Test case for Broken Object Level Authorization (BOLA)\ndef test_user_cannot_access_other_users_data():\n    # 1. Get an authentication token for 'user_a'\n    user_a_token = get_auth_token('user_a', 'password123')\n    headers_a = {'Authorization': f'Bearer {user_a_token}'}\n\n    # 2. As 'user_a', try to request the data for 'user_b'\n    response = requests.get('http://test-api/users/user_b/profile', headers=headers_a)\n\n    # 3. Assert that the request was forbidden.\n    # This test will fail until the proper authorization logic is implemented.\n    assert response.status_code == 403"
                    },
                    {
  "title": "Code Example 15: Comprehensive Security Test Automation Suite",
  "language": "java",
  "code": "// Example of a security unit test using Java's JUnit framework\n// This test checks that the input validator correctly rejects malicious input.\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.*;\n\nclass InputValidatorTest {\n\n    @Test\n    void testValidateUsername_rejectsXssPayload() {\n        InputValidator validator = new InputValidator();\n        String maliciousInput = \"\\u003cscript\\u003ealert('xss')\\u003c/script\\u003e\";\n        \n        // Assert that the validation function throws an InvalidInputException\n        // when it receives the malicious payload.\n        assertThrows(InvalidInputException.class, () -> {\n            validator.validateUsername(maliciousInput);\n        });\n    }\n}"
}

                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "The practice of writing a failing security test before writing the functional code is known as:",
                        "options": [
                            "Security Regression Testing",
                            "Test-Driven Security (TDS)",
                            "Penetration Testing",
                            "Vulnerability Scanning"
                        ],
                        "correct": 1,
                        "explanation": "Test-Driven Security, modeled after TDD, is a powerful 'shift-left' practice that forces security to be considered as a primary requirement during code implementation."
                    },
                    {
                        "id": 2,
                        "question": "What is a security regression?",
                        "options": [
                            "A new security feature.",
                            "When a code change accidentally re-introduces a previously fixed vulnerability.",
                            "A type of security report.",
                            "An upgrade to a security tool."
                        ],
                        "correct": 1,
                        "explanation": "Regressions are a common problem in complex software. An automated suite of security regression tests acts as a safety net to catch these mistakes automatically."
                    },
                    {
                        "id": 3,
                        "question": "A security testing method that involves intentionally and safely injecting failures into a production environment to test resilience is called:",
                        "options": [
                            "SAST",
                            "DAST",
                        "Chaos Engineering",
                            "Unit Testing"
                        ],
                        "correct": 2,
                        "explanation": "Chaos Engineering (and its security-focused variant) is an advanced practice for testing how a complex system behaves under turbulent conditions, which helps to build more resilient and fault-tolerant architectures."
                    },
                    {
                        "id": 4,
                        "question": "What is the primary benefit of having a large suite of automated security tests?",
                        "options": [
                            "It allows the team to get rid of all other security tools.",
                            "It provides continuous assurance and a fast feedback loop, automatically preventing security regressions on every build.",
                            "It makes the build process take less time.",
                            "It replaces the need for security architects."
                        ],
                        "correct": 1,
                        "explanation": "Automation is key. A comprehensive suite of security tests running in the CI/CD pipeline acts as a powerful, continuous safety net that scales with the speed of development."
                    }
                ]
            }
        },
        
        {
            "id": "lesson-16",
            "title": "Vulnerability Management",
            "duration": "90 min",
            "objectives": [
                "Understand the modern vulnerability management lifecycle in a DevSecOps context.",
                "Learn to implement risk-based prioritization for vulnerabilities.",
                "Design automated remediation and patch management workflows.",
                "Develop a strategy for responding to zero-day vulnerabilities."
            ],
            "content": {
                "overview": "Vulnerability management in a DevSecOps world is not a slow, periodic scanning process. It is a continuous, automated, and integrated part of the software lifecycle. This lesson covers how to build a high-velocity vulnerability management program that prioritizes risk and leverages automation to reduce the window of exposure.",
                "sections": [
                    {
                        "title": "DevSecOps Vulnerability Lifecycle",
                        "content": "<p>The traditional lifecycle (scan, report, patch) is too slow. The DevSecOps lifecycle is a continuous loop integrated into the pipeline.</p><ol><li><strong>Discover:</strong> Vulnerabilities are continuously discovered by multiple automated tools (SAST, SCA, DAST, IaC scanners) within the CI/CD pipeline.</li><li><strong>Prioritize:</strong> Findings are automatically aggregated and prioritized based on risk, not just severity.</li><li><strong>Remediate:</strong> Actionable tickets are automatically created, and for many issues (especially dependencies), automated pull requests are generated.</li><li><strong>Verify:</strong> The next run of the pipeline automatically verifies that the fix is effective.</li></ol>",
                        "image": "https://images.unsplash.com/photo-1542382257-80deda0e5d99?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Risk-Based Vulnerability Prioritization",
                        "content": "<p>Not all 'critical' vulnerabilities are created equal. Prioritization must be based on real-world risk, which is a function of more than just the CVSS score.</p><h3>Key Prioritization Factors:</h3><ul><li><strong>Severity (CVSS):</strong> The base score of the vulnerability.</li><li><strong>Exploitability:</strong> Is there a known public exploit for this vulnerability? (Provided by threat intelligence).</li><li><strong>Business Criticality:</strong> Is the vulnerability in a mission-critical, external-facing application or an internal, non-critical tool?</li><li><strong>Reachability:</strong> For code vulnerabilities (SAST/SCA), is the vulnerable function actually reachable and called by the application code?</li></ul><p>An intelligent prioritization engine automatically combines these factors to surface the vulnerabilities that represent the most immediate and significant risk.</p>",
                        "image": "https://images.unsplash.com/photo-1600880292210-859bb1fed5b1?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Zero-Day Vulnerability Response",
                        "content": "<p>When a major zero-day vulnerability (like Log4Shell) is announced, a mature DevSecOps program can respond in hours, not weeks.</p><h3>The Architectural Enablers:</h3><ul><li><strong>Software Bill of Materials (SBOM):</strong> A complete, up-to-date inventory of all software components (from SCA tools) allows the team to immediately identify every single application that uses the vulnerable library.</li><li><strong>Automated Patching:</strong> The SCA tool can create pull requests across hundreds of repositories simultaneously to update the vulnerable dependency.</li><li><strong>Centralized Monitoring:</strong> The SOC can quickly deploy new detection rules to the SIEM and EDR to hunt for any signs of exploitation.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1542744173-8e7e53415bb0?w=800&h=400&fit=crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 16: Enterprise Vulnerability Management Platform",
                        "language": "plaintext",
                        "code": "/* \n  Conceptual Workflow for an Automated Remediation Playbook (SCA)\n\n  1.  **Detection:** SCA tool, running in the CI/CD pipeline, detects that `library-x:1.2.3`\n      has a critical vulnerability (CVE-2025-1234).\n\n  2.  **Enrichment:** The vulnerability management platform ingests the finding.\n      - It checks threat intelligence: 'Is there a public exploit for CVE-2025-1234?' -> Yes.\n      - It checks the asset inventory: 'Is this application internet-facing?' -> Yes.\n\n  3.  **Prioritization:** The platform calculates a risk score of 9.8/10 (Critical) and marks it\n      for immediate remediation.\n\n  4.  **Automated Remediation:**\n      - [API Call] The platform instructs the SCA tool to create a pull request in the application's\n        Git repository to upgrade `library-x` to the patched version `1.2.4`.\n\n  5.  **Verification:**\n      - The pull request automatically triggers a new CI/CD pipeline run.\n      - The pipeline builds and tests the application with the new library version.\n      - The SCA scan runs again and confirms the vulnerability is no longer present.\n\n  6.  **Closure:** The developer reviews the successful pipeline run and merges the pull request.\n      The vulnerability ticket is automatically closed.\n*/"
                    },
                    {
                        "title": "Code Example 16: Intelligent Vulnerability Prioritization Engine",
                        "language": "python",
                        "code": "def calculate_risk_score(vulnerability, asset):\n    score = vulnerability.cvss_score\n    \n    if vulnerability.has_public_exploit:\n        score *= 1.2  # Increase score if easily exploitable\n        \n    if asset.is_internet_facing:\n        score *= 1.5  # Increase score for external assets\n\n    if not vulnerability.is_reachable:\n        score *= 0.5 # Decrease score if code is not called\n        \n    return min(10.0, score)"
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "What is the primary goal of the DevSecOps vulnerability management lifecycle?",
                        "options": [
                            "To create detailed monthly reports.",
                            "To continuously discover, prioritize, and remediate vulnerabilities as an integrated part of the development pipeline.",
                            "To manually scan production servers once a year.",
                            "To purchase as many scanning tools as possible."
                        ],
                        "correct": 1,
                        "explanation": "The DevSecOps approach transforms vulnerability management from a slow, periodic process into a continuous, automated feedback loop."
                    },
                    {
                        "id": 2,
                        "question": "Risk-based prioritization goes beyond just the CVSS score by considering factors like:",
                        "options": [
                            "The name of the developer who wrote the code.",
                            "The color of the application's logo.",
                            "Business criticality and active exploitability.",
                            "The age of the server."
                        ],
                        "correct": 2,
                        "explanation": "Context is key. A 'critical' vulnerability on an internal test server is far less risky than a 'high' vulnerability with a public exploit on your main e-commerce website. Risk-based prioritization focuses on what matters most."
                    },
                    {
                        "id": 3,
                        "question": "What artifact is most critical for a rapid response to a zero-day vulnerability in an open-source library?",
                        "options": [
                            "A network diagram.",
                            "A comprehensive and up-to-date Software Bill of Materials (SBOM).",
                            "The company's security policy.",
                            "A list of all employee laptops."
                        ],
                        "correct": 1,
                        "explanation": "When a new vulnerability is announced, the first question is always 'Where are we using this?' An SBOM, generated by SCA tools, provides an immediate and definitive answer, allowing the response to be targeted and swift."
                    },
                    {
                        "id": 4,
                        "question": "A feature of an SCA tool that automatically creates a pull request to upgrade a vulnerable dependency is an example of:",
                        "options": [
                            "Automated Discovery",
                            "Automated Prioritization",
                            "Automated Remediation",
                            "Automated Reporting"
                        ],
                        "correct": 2,
                        "explanation": "Automated remediation is a key goal of a mature DevSecOps program. By automatically proposing the fix, it dramatically reduces the manual effort and time required for developers to patch vulnerable components."
                    }
                ]
            }
        },
        {
            "id": "lesson-17",
            "title": "Security Monitoring and Observability",
            "duration": "120 min",
            "objectives": [
                "Understand the principles of security observability.",
                "Design a strategy for application security monitoring and real-time threat detection.",
                "Architect for the integration of security data into a central SIEM.",
                "Leverage security analytics and machine learning for advanced detection."
            ],
            "content": {
                "overview": "In a dynamic DevSecOps environment, security monitoring needs to go beyond traditional log analysis. Security Observability is the practice of building systems that can be debugged from the outside, providing deep insights into their behavior. This lesson covers the architecture for building a real-time monitoring and detection capability that can keep pace with modern applications.",
                "sections": [
                    {
                        "title": "Security Observability Principles",
                        "content": "<p>Observability is often described by its three pillars:</p><ul><li><strong>Logs:</strong> Structured, event-based records of what happened.</li><li><strong>Metrics:</strong> Aggregated, numerical data about the performance and health of a system over time.</li><li><strong>Traces:</strong> Show the end-to-end journey of a single request as it travels through a distributed (microservices) system.</li></ul><p>Security observability means instrumenting applications to produce rich logs, metrics, and traces that are useful for security analysis. For example, a trace could show not just the path of a request, but also the user identity and authorization decisions made at each step.</p>",
                        "image": "https://images.unsplash.com/photo-1526628953301-3e589a6a8b74?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Application Security Monitoring",
                        "content": "<p>This involves detecting threats at the application layer, not just the network or host layer.</p><h3>Key Technologies:</h3><ul><li><strong>Runtime Application Self-Protection (RASP):</strong> An evolution of IAST. A RASP agent is integrated into the application runtime and can not only detect attacks in real-time but also block them. For example, if it detects a SQL injection payload, it can terminate the malicious request before it reaches the database.</li><li><strong>Structured Logging:</strong> Applications should be architected to produce structured logs (e.g., in JSON format) that include rich security context (like user ID, source IP, and session ID) with every event. This makes the logs much easier to parse and analyze in a SIEM.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1581291518857-4e27b48ff24e?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "SIEM Integration Strategies",
                        "content": "<p>The CI/CD pipeline and other DevSecOps tools are a rich source of security data that should be sent to the SIEM.</p><h3>Key Data Sources:</h3><ul><li><strong>Scanner Results:</strong> High-severity findings from SAST, DAST, and SCA scans.</li><li><strong>Pipeline Events:</strong> A log of every build, test, and deployment, including who initiated it.</li><li><strong>IaC Scan Alerts:</strong> Alerts about insecure infrastructure code.</li><li><strong>Source Code Commits:</strong> Metadata about who is committing code to which repositories.</li></ul><p>Correlating this data can uncover threats. For example, a sudden spike in high-severity SAST findings from a new developer could indicate an insider threat or a need for more training.</p>",
                        "image": "https://images.unsplash.com/photo-1551288049-bebda4e38f71?w=800&h=400&fit=crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 17: Security Observability Platform Setup",
                        "language": "json",
                        "code": "// Example of a structured application security log event\n\n{\n  \"timestamp\": \"2025-09-17T11:30:05Z\",\n  \"event_type\": \"AUTHENTICATION_FAILURE\",\n  \"severity\": \"MEDIUM\",\n  \"application\": \"billing-api\",\n  \"source_ip\": \"203.0.113.55\",\n  \"user_agent\": \"Mozilla/5.0 ...\",\n  \"user\": {\n    \"username\": \"testuser\",\n    \"id\": \"user-8877\"\n  },\n  \"trace_id\": \"a1b2c3d4-e5f6-7890\",\n  \"details\": {\n    \"reason\": \"Invalid password provided.\"\n  }\n}"
                    },
                    {
                        "title": "Code Example 17: Real-Time Security Event Processing System",
                        "language": "sql",
                        "code": "-- Conceptual SIEM rule to detect suspicious developer activity\n\nSELECT developer_name\nFROM pipeline_events\nWHERE\n  -- Look for events where a security scanner was disabled\n  event_type = 'SECURITY_SCAN_DISABLED'\n  AND\n  -- And the commit message contains keywords indicating a rush\n  commit_message LIKE '%hotfix%' OR commit_message LIKE '%urgent%'\nGROUP BY developer_name\nHAVING \n  -- Alert if this happens more than once in an hour\n  COUNT(*) > 1\nTIMESPAN 1 hour"
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "The three pillars of observability are:",
                        "options": [
                            "SAST, DAST, and SCA",
                            "Firewalls, Routers, and Switches",
                            "Logs, Metrics, and Traces",
                            "Confidentiality, Integrity, and Availability"
                        ],
                        "correct": 2,
                        "explanation": "Logs, metrics, and traces are the three primary types of telemetry that provide deep insight into a system's behavior, which is the foundation of observability."
                    },
                    {
                        "id": 2,
                        "question": "A security technology that works from inside a running application to both detect and block attacks in real-time is known as:",
                        "options": [
                            "SAST",
                            "DAST",
                            "WAF",
                            "RASP (Runtime Application Self-Protection)"
                        ],
                        "correct": 3,
                        "explanation": "RASP is a more advanced form of IAST. Its key differentiator is the ability to take protective action, such as terminating a malicious request, providing a last line of defense within the application itself."
                    },
                    {
                        "id": 3,
                        "question": "What is the primary benefit of using structured logging (e.g., JSON format) for security events?",
                        "options": [
                            "It makes the logs smaller.",
                            "It makes the logs human-readable only.",
                            "It is a legal requirement.",
                            "It makes the logs machine-readable, which allows for much easier and more reliable parsing, searching, and alerting in a SIEM."
                        ],
                        "correct": 3,
                        "explanation": "Unstructured logs require complex and brittle regular expressions to parse. Structured logs have a clear key-value format that can be ingested and analyzed automatically with high fidelity."
                    },
                    {
                        "id": 4,
                        "question": "An end-to-end view of a single request as it flows through multiple microservices is called a:",
                        "options": [
                            "Log",
                            "Metric",
                            "Trace",
                            "Alert"
                        ],
                        "correct": 2,
                        "explanation": "Distributed tracing is essential for understanding performance and security in a microservices architecture. A security-aware trace can help pinpoint exactly which service in a long chain is causing a security issue."
                    }
                ]
            }
        },
        {
            "id": "lesson-18",
            "title": "Incident Response in DevSecOps",
            "duration": "90 min",
            "objectives": [
                "Understand how DevSecOps principles accelerate incident response.",
                "Design automated workflows for incident detection and containment.",
                "Integrate the 'lessons learned' from incidents back into the CI/CD pipeline.",
                "Foster a culture of blameless post-mortems."
            ],
            "content": {
                "overview": "Incident Response in a DevSecOps environment leverages the same principles of automation and collaboration that are used in development. The goal is to create a rapid, automated, and data-driven response process that minimizes the impact of an incident and uses every failure as an opportunity to improve.",
                "sections": [
                    {
                        "title": "Automated Incident Detection",
                        "content": "<p>In a DevSecOps model, detection is not just the SOC's job. The pipeline itself is a source of detection.</p><h3>Detection Sources:</h3><ul><li><strong>Pipeline Alerts:</strong> A sudden spike in critical SAST findings could indicate a developer checking in malicious code.</li><li><strong>IaC Scanner Alerts:</strong> An attempt to commit code that makes an S3 bucket public should trigger an immediate alert.</li><li><strong>Observability Platform:</strong> Rich telemetry from applications provides the data for automated behavioral detection rules (UEBA).</li></ul>",
                        "image": "https://images.unsplash.com/photo-1542382257-80deda0e5d99?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Response Workflow Automation",
                        "content": "<p>The speed of response is critical. A SOAR platform is the key architectural component for automating response workflows.</p><h3>Example: Malicious Code Commit</h3><ol><li><strong>Detection:</strong> SAST scanner in the pipeline detects a high-confidence remote code execution vulnerability in a new commit. The build fails.</li><li><strong>SOAR Trigger:</strong> The failed build sends an alert to the SOAR platform.</li><li><strong>Automated Response:</strong> The SOAR playbook executes:<ul><li>Creates a P1 incident ticket.</li><li>Notifies the security team and the developer's manager.</li><li>[API Call] Temporarily locks the developer's ability to commit to the repository.</li><li>[API Call] Reverts the malicious commit.</li></ul></li></ol><p>This automated containment happens in seconds, preventing the malicious code from ever being merged or deployed.</p>",
                        "image": "https://images.unsplash.com/photo-1521791136064-7986c2920216?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Blameless Post-Mortems",
                        "content": "<p>A blameless post-mortem is a cultural cornerstone of both DevOps and DevSecOps. After an incident is resolved, the team comes together to analyze the root cause.</p><p>The focus is on failures in the *system* and *process*, not on blaming individuals. The goal is to understand the sequence of events that allowed the failure to occur and to create concrete action items to improve the system's resilience. This fosters a culture of psychological safety, where engineers feel safe to report issues and suggest improvements without fear of punishment.</p>",
                        "image": "https://images.unsplash.com/photo-1552664730-d307ca884978?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Lessons Learned Integration",
                        "content": "<p>The action items from the post-mortem are the most valuable output. They must be fed back into the DevSecOps loop.</p><h3>The Feedback Loop:</h3><ul><li><strong>Root Cause:</strong> A vulnerability was missed because the SAST scanner's rules were not updated. -> **Action Item:** Add a step to the pipeline to automatically update scanner rules daily.</li><li><strong>Root Cause:</strong> The on-call engineer didn't have the right permissions to isolate a host. -> **Action Item:** Create a 'break-glass' automated process for granting temporary emergency permissions.</li><li><strong>Root Cause:</strong> The vulnerability was a specific type of injection flaw. -> **Action Item:** Write a new, failing security regression test for that specific flaw and add it to the test suite.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1542744173-8e7e53415bb0?w=800&h=400&fit-crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 18: Automated Incident Response Platform",
                        "language": "python",
                        "code": "# Conceptual SOAR playbook for responding to a leaked credential on GitHub\n\nimport github_api\nimport identity_provider_api\nimport ticketing_system\n\ndef respond_to_leaked_key(alert):\n    \"\"\"Automates the initial response to a leaked key alert.\"\"\"\n    \n    key_id = alert['details']['key_id']\n    user_email = alert['details']['user_email']\n    repo_url = alert['details']['repo_url']\n\n    # 1. Containment: Revoke the key\n    identity_provider_api.revoke_api_key(key_id)\n\n    # 2. Containment: Disable the user's account temporarily\n    identity_provider_api.disable_user(user_email)\n\n    # 3. Create a high-priority incident ticket\n    ticketing_system.create_incident(\n        summary=f\"Leaked API Key {key_id} found in {repo_url}\",\n        assignee=\"soc_team\"\n    )\n    \n    print(\"Response playbook completed.\")"
                    },
                    {
                        "title": "Code Example 18: Intelligent Incident Response Orchestration System",
                        "language": "markdown",
                        "code": "# Post-Mortem Action Item Template\n\n- **Incident:** `INC-2025-098` (Production API Outage)\n- **Timeline:** ...\n- **Root Cause:** A new microservice was deployed with an incorrect timeout configuration, causing a cascading failure. The security group was also misconfigured, preventing engineers from SSH'ing to the box to debug.\n- **What went well:** The monitoring system detected the failure within 60 seconds.\n- **What could be improved:** The deployment process lacked automated configuration validation. Emergency access procedures were too slow.\n\n### Action Items:\n1.  **[TESTING]** Add a new integration test to the pipeline that specifically checks for this timeout configuration error. (`Owner: AppTeamA`)\n2.  **[IaC]** Update the Terraform module for security groups to include a rule allowing SSH access from the designated bastion host. (`Owner: PlatformTeam`)\n3.  **[IR]** Create an automated SOAR playbook for granting temporary 'break-glass' SSH access. (`Owner: SecurityTeam`)"
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "What is the primary goal of a blameless post-mortem?",
                        "options": [
                            "To identify the individual responsible for an incident and assign blame.",
                            "To focus on failures in the system and process in order to generate actionable improvements.",
                            "To write a report for legal counsel.",
                            "To decide how to punish the on-call engineer."
                        ],
                        "correct": 1,
                        "explanation": "A blameless culture is essential for learning. By focusing on systemic issues rather than individual errors, teams are encouraged to be transparent about failures, which is the first step to preventing them in the future."
                    },
                    {
                        "id": 2,
                        "question": "How does DevSecOps improve the 'lessons learned' phase of incident response?",
                        "options": [
                            "By ensuring lessons are discussed once and then forgotten.",
                            "By providing a framework to feed action items directly back into the automated CI/CD pipeline as new tests, policies, and controls.",
                            "By making the process manual and slow.",
                            "By blaming developers for all incidents."
                        ],
                        "correct": 1,
                        "explanation": "The DevSecOps feedback loop is key. The 'lessons learned' are not just documented; they are turned into codea new security test, a new policy-as-code rule, a new automation playbookwhich continuously hardens the system."
                    },
                    {
                        "id": 3,
                        "question": "A SOAR playbook that automatically disables a user's account after a high-confidence alert is an example of:",
                        "options": [
                            "Automated Detection",
                            "Automated Containment",
                            "Automated Reporting",
                            "Automated Triage"
                        ],
                        "correct": 1,
                        "explanation": "Containment is the phase of IR focused on stopping the attack from spreading. Automating this step via a SOAR platform dramatically reduces the time an attacker has to do damage."
                    },
                    {
                        "id": 4,
                        "question": "A root cause analysis determines that a security incident was caused by a specific type of vulnerability. What is the most effective DevSecOps-aligned action item?",
                        "options": [
                            "Tell the developers to 'be more careful'.",
                            "Write a new, automated security regression test that specifically checks for that vulnerability.",
                            "Fire the developer who wrote the code.",
                            "Manually scan for the vulnerability once a year."
                        ],
                        "correct": 1,
                        "explanation": "Adding an automated test to the regression suite ensures that this specific mistake can never happen again anywhere in the codebase without being automatically detected, providing a permanent fix."
                    }
                ]
            }
        },
        {
            "id": "lesson-19",
            "title": "Compliance as Code",
            "duration": "90 min",
            "objectives": [
                "Understand the principles of automating compliance.",
                "Learn to map regulatory requirements to technical controls and automated tests.",
                "Design a system for automated evidence collection and audit trail generation.",
                "Integrate compliance checks directly into the CI/CD pipeline."
            ],
            "content": {
                "overview": "Traditional compliance is a manual, time-consuming, and point-in-time process involving spreadsheets and screenshots. Compliance as Code applies the DevSecOps principles of automation and 'as-code' definitions to the challenges of regulatory compliance. This lesson covers how to build an architecture where compliance is a continuous, automated, and verifiable state.",
                "sections": [
                    {
                        "title": "Compliance Automation Principles",
                        "content": "<p>Compliance as Code treats compliance requirements as a set of policies that can be defined in code and validated automatically.</p><h3>Key Principles:</h3><ul><li><strong>Codified Policies:</strong> Translate human-readable compliance requirements (e.g., 'Passwords must be rotated every 90 days') into machine-readable policy code.</li><li><strong>Preventative Guardrails:</strong> Use Policy as Code in the CI/CD pipeline to prevent non-compliant infrastructure from being deployed.</li><li><strong>Continuous Validation:</strong> Continuously scan the production environment to detect any drift from the compliant state.</li><li><strong>Automated Evidence:</strong> Automatically generate the evidence an auditor needs, rather than manually collecting it.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1590102426319-c72115b5a832?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Policy Enforcement Automation",
                        "content": "<p>This is about building compliance directly into the infrastructure and deployment process.</p><h3>Architectural Patterns:</h3><ul><li><strong>Policy as Code (e.g., OPA):</strong> As covered in the IaC lesson, using a policy engine to validate IaC plans is a core preventative control. The policies can be directly mapped to compliance requirements. (e.g., A policy that says 'all databases must have encryption enabled' helps satisfy PCI DSS).</li><li><strong>Cloud-Native Guardrails (e.g., AWS SCPs):</strong> Use the cloud provider's own governance tools to enforce compliance at the organization level (e.g., using an SCP to restrict deployments to only approved regions to meet data residency requirements).</li></ul>",
                        "image": "https://images.unsplash.com/photo-1510915228340-29c85a43dcfe?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Audit Trail and Evidence Automation",
                        "content": "<p>Auditors need evidence. An automated architecture can provide this on demand.</p><h3>The Process:</h3><p>Instead of an auditor asking for a screenshot of a server's configuration, you can provide them with:</p><ul><li>A link to the version-controlled IaC code that defines the server's configuration.</li><li>The results of the pipeline run that tested and deployed that code.</li><li>A report from the CSPM tool showing that the server has remained in its compliant state since deployment.</li><li>A dashboard showing the complete, immutable audit trail from a centralized logging system.</li></ul><p>This provides a much higher level of assurance than manual evidence collection and dramatically reduces the effort of an audit.</p>",
                        "image": "https://images.unsplash.com/photo-1581291518857-4e27b48ff24e?w=800&h=400&fit=crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 19: Compliance as Code Implementation",
                        "language": "ruby",
                        "code": "# Example of an InSpec test (Compliance as Code)\n# This code can be run against a server to automatically test its compliance.\n\n# Control mapped to PCI DSS Requirement 2.2.4\ncontrol 'sshd-config-secure' do\n  impact 1.0\n  title 'SSH Protocol and Root Login'\n  desc 'Ensure SSH protocol is 2 and root login is disabled.'\n\n  # Test the SSH configuration file\n  describe sshd_config do\n    # Assert that the 'Protocol' setting is '2'\n    its('Protocol') { should eq '2' }\n    \n    # Assert that 'PermitRootLogin' is set to 'no'\n    its('PermitRootLogin') { should eq 'no' }\n  end\nend"
                    },
                    {
                        "title": "Code Example 19: Automated Compliance Validation Framework",
                        "language": "json",
                        "code": "{\n  \"controlId\": \"PCI-DSS-Req-8.2.3\",\n  \"description\": \"Passwords must be a minimum of 7 characters.\",\n  \"automatedTest\": {\n    \"testId\": \"iam-policy-test-001\",\n    \"source\": \"CSPM-Tool\",\n    \"lastRun\": \"2025-09-19T10:00:00Z\",\n    \"status\": \"PASSED\",\n    \"evidenceLink\": \"https://cspm.example.com/results/iam-policy-test-001\"\n  },\n  \"compliantResources\": 150,\n  \"nonCompliantResources\": 0\n}"
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "The primary goal of Compliance as Code is to:",
                        "options": [
                            "Make compliance more difficult and slower.",
                            "Replace security engineers with auditors.",
                            "Transform compliance from a manual, point-in-time activity into a continuous and automated process.",
                            "Create longer compliance reports."
                        ],
                        "correct": 2,
                        "explanation": "Compliance as Code applies DevOps principles to compliance, making it an automated, repeatable, and continuous part of the software lifecycle, rather than a painful annual exercise."
                    },
                    {
                        "id": 2,
                        "question": "Translating a requirement like 'All S3 buckets must be private' into a machine-readable OPA policy that is checked in the CI/CD pipeline is an example of a:",
                        "options": [
                            "Manual Audit",
                            "Detective Control",
                            "Preventative Guardrail",
                            "Incident Response Playbook"
                        ],
                        "correct": 2,
                        "explanation": "This is a preventative control because it stops the non-compliant configuration from ever being deployed. Detective controls (like a CSPM) find the issue after it has been deployed."
                    },
                    {
                        "id": 3,
                        "question": "A tool like Chef InSpec is used to:",
                        "options": [
                            "Scan source code for vulnerabilities.",
                            "Write automated tests that can be run against a running server to validate its compliance state.",
                            "Manage user passwords.",
                            "Deploy applications."
                        ],
                        "correct": 1,
                        "explanation": "InSpec is a popular open-source framework for writing compliance tests as code, allowing you to automatically verify that your systems meet the required security baselines."
                    },
                    {
                        "id": 4,
                        "question": "How does an automated, code-driven approach to compliance change the audit process?",
                        "options": [
                            "It makes the audit process much longer and more painful.",
                            "It replaces auditors with developers.",
                            "It allows for the automatic generation of high-fidelity evidence, reducing manual effort and providing stronger assurance to auditors.",
                            "It has no effect on the audit process."
                        ],
                        "correct": 2,
                        "explanation": "When compliance is defined and tested in code, the code itself, along with the automated test results and immutable logs, becomes the evidence. This is far more trustworthy and efficient than manually collecting screenshots."
                    }
                ]
            }
        },
        {
            "id": "lesson-20",
            "title": "Security Metrics and KPIs",
            "duration": "90 min",
            "objectives": [
                "Understand how to create a framework for DevSecOps metrics.",
                "Define meaningful Key Performance Indicators (KPIs) that measure effectiveness.",
                "Learn to measure the business impact and ROI of security initiatives.",
                "Design effective executive dashboards for reporting on risk and performance."
            ],
            "content": {
                "overview": "'What gets measured gets managed.' A successful DevSecOps program must be data-driven. This lesson focuses on how to define and track meaningful metrics that go beyond simple activity counting to measure the true effectiveness, efficiency, and business value of your security program.",
                "sections": [
                    {
                        "title": "DevSecOps Metrics Framework",
                        "content": "<p>Good metrics should be SMART: Specific, Measurable, Achievable, Relevant, and Time-bound. In DevSecOps, we can group metrics into several key areas.</p><h3>Metric Categories:</h3><ul><li><strong>Speed (Velocity):</strong> How fast can we fix things? (e.g., Mean Time to Remediate).</li><li><strong>Quality:</strong> Are we building more secure code? (e.g., Vulnerability Density).</li><li><strong>Efficiency:</strong> How effective are our automated processes? (e.g., False Positive Rate).</li><li><strong>Coverage:</strong> How much of our environment is covered by our controls? (e.g., % of repos with SAST).</li><li><strong>Risk:</strong> What is our overall risk posture? (e.g., Number of overdue critical vulnerabilities).</li></ul>",
                        "image": "https://images.unsplash.com/photo-1551288049-bebda4e38f71?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Security Performance Indicators",
                        "content": "<h3>Key KPIs to Track:</h3><ul><li><strong>Mean Time to Remediate (MTTR):</strong> The average time from when a vulnerability is discovered to when it is fixed. This is one of the most important measures of a program's efficiency.</li><li><strong>Vulnerability Density:</strong> The number of vulnerabilities found per lines of code or per application. A downward trend indicates that developers are writing more secure code.</li><li><strong>Security Control Coverage:</strong> The percentage of assets covered by a key control (e.g., '% of repositories with SCA scans enabled'). This measures the breadth of the program.</li><li><strong>Automated Fix Rate:</strong> The percentage of vulnerabilities that are fixed by automated pull requests (e.g., from an SCA tool). This measures the efficiency of your automation.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1543286386-713bdd548da4?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Executive Dashboard Design",
                        "content": "<p>Metrics must be presented in a way that is meaningful to the audience. An executive dashboard should be high-level, visual, and focused on business risk.</p><h3>Dashboard Best Practices:</h3><ul><li><strong>Focus on Trends:</strong> A single number is meaningless without context. Show trends over time. Is the MTTR getting better or worse?</li><li><strong>Use Risk-Based Language:</strong> Instead of just 'Number of Vulnerabilities', show 'Number of Critical Vulnerabilities on Internet-Facing Systems'.</li><li><strong>Show Business Alignment:</strong> Connect the metrics to business goals. 'Our improved MTTR has reduced our risk exposure, helping us achieve SOC 2 compliance.'</li><li><strong>Keep it Simple:</strong> A CISO should be able to understand the organization's security posture in 60 seconds by looking at the dashboard.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1600880292210-859bb1fed5b1?w=800&h=400&fit-crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 20: Security Metrics Dashboard Creation",
                        "language": "json",
                        "code": "{\n  \"dashboardName\": \"CISO Monthly Security Posture\",\n  \"kpis\": [\n    {\n      \"name\": \"Mean Time to Remediate (Critical)\",\n      \"currentValue\": \"12 Days\",\n      \"previousValue\": \"18 Days\",\n      \"trend\": \"improving\",\n      \"target\": \"< 7 Days\"\n    },\n    {\n      \"name\": \"SAST Coverage (by Repositories)\",\n      \"currentValue\": \"85%\",\n      \"previousValue\": \"80%\",\n      \"trend\": \"improving\",\n      \"target\": \"95%\"\n    },\n    {\n      \"name\": \"Open Critical Vulns (External Assets)\",\n      \"currentValue\": \"7\",\n      \"previousValue\": \"15\",\n      \"trend\": \"improving\",\n      \"target\": \"0\"\n    }\n  ]\n}"
                    },
                    {
                        "title": "Code Example 20: Comprehensive Security Analytics Platform",
                        "language": "sql",
                        "code": "-- Conceptual SQL query to calculate MTTR from a vulnerability database\n\nSELECT\n    -- Calculate the average difference between the closed and opened dates\n    AVG(DATEDIFF(day, date_opened, date_closed)) AS mean_time_to_remediate_days\nFROM\n    vulnerability_findings\nWHERE\n    severity = 'CRITICAL'\n    AND\n    status = 'CLOSED'\n    AND\n    -- Limit the calculation to the last 90 days\n    date_opened >= NOW() - INTERVAL '90 days';"
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "What is the most important Key Performance Indicator (KPI) for measuring the speed and efficiency of a vulnerability management program?",
                        "options": [
                            "The number of tools in use.",
                            "The number of vulnerabilities found.",
                            "The Mean Time to Remediate (MTTR).",
                            "The number of security engineers on the team."
                        ],
                        "correct": 2,
                        "explanation": "MTTR is a crucial metric because it measures the outcome of the entire processhow quickly the organization is actually fixing security issues and reducing risk."
                    },
                    {
                        "id": 2,
                        "question": "A metric that tracks 'Vulnerabilities per 1,000 lines of code' is known as:",
                        "options": [
                            "Control Coverage",
                            "Vulnerability Density",
                            "False Positive Rate",
                            "Mean Time to Detect"
                        ],
                        "correct": 1,
                        "explanation": "Vulnerability density helps to normalize the number of vulnerabilities found against the size of the codebase. A downward trend in this metric is a strong indicator that the quality of code being written is improving from a security perspective."
                    },
                    {
                        "id": 3,
                        "question": "When presenting security metrics to an executive audience, what is the most important principle?",
                        "options": [
                            "Use as much technical jargon as possible.",
                            "Show data in large, complex spreadsheets.",
                            "Focus on trends and connect the metrics to business risk and value.",
                            "Only show metrics that are positive."
                        ],
                        "correct": 2,
                        "explanation": "Executives need to understand the business implications of the data. Effective communication involves translating technical metrics into a clear story about risk posture, program performance, and business alignment."
                    },
                    {
                        "id": 4,
                        "question": "A metric that tracks the 'Percentage of repositories with SCA scanning enabled' is a measure of:",
                        "options": [
                            "Speed",
                            "Quality",
                            "Efficiency",
                            "Coverage"
                        ],
                        "correct": 3,
                        "explanation": "Coverage metrics are essential for understanding how widely your security controls have been deployed. 100% coverage is the ultimate goal for foundational controls."
                    }
                ]
            }
        },
        {
            "id": "lesson-21",
            "title": "Team Structure and Roles",
            "duration": "90 min",
            "objectives": [
                "Explore different organizational models for DevSecOps.",
                "Understand the role and importance of a Security Champions network.",
                "Define the key responsibilities for different roles in a DevSecOps culture.",
                "Develop strategies for fostering cross-functional collaboration."
            ],
            "content": {
                "overview": "DevSecOps is not just about tools; it's about people and how they work together. A successful DevSecOps transformation requires a deliberate approach to team structure, role definition, and fostering a culture of collaboration. This lesson explores how to build the human element of a high-performing DevSecOps program.",
                "sections": [
                    {
                        "title": "DevSecOps Organizational Models",
                        "content": "<p>There is no one-size-fits-all model. The right structure depends on the organization's size and maturity.</p><h3>Common Models:</h3><ul><li><strong>Centralized Security Team (as Consultants):</strong> The central security team acts as an internal center of excellence. They don't act as a gate, but rather as expert consultants who provide the tools, platforms, and training to empower development teams.</li><li><strong>Embedded Security Engineers:</strong> A security engineer is directly embedded within a product or development team. This provides a very tight feedback loop but can be difficult to scale.</li><li><strong>Hybrid Model (most common):</strong> A central platform security team builds and maintains the secure CI/CD pipeline and other tools. They support a network of Security Champions who are embedded in the development teams.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1552664730-d307ca884978?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Security Champions Network",
                        "content": "<p>A Security Champions program is one of the most effective ways to scale security expertise and foster a security-conscious culture. A champion is a member of a development team with a passion for security who volunteers to be a security advocate for their team.</p><h3>Responsibilities:</h3><ul><li>Be the first point of contact for security questions.</li><li>Help triage and validate automated security findings.</li><li>Lead threat modeling sessions for new features.</li><li>Share security knowledge and best practices with their teammates.</li></ul><p>The central security team's job is to train, mentor, and empower the champions.</p>",
                        "image": "https://images.unsplash.com/photo-1542744173-8e7e53415bb0?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Role Definitions and Responsibilities",
                        "content": "<p>In a DevSecOps culture, security responsibilities are distributed.</p><ul><li><strong>Developers:</strong> Responsible for writing secure code, fixing vulnerabilities found by scanners, and participating in threat modeling.</li><li><strong>Operations/SRE:</strong> Responsible for building and maintaining secure infrastructure (IaC), configuring monitoring, and responding to incidents.</li><li><strong>Security Engineers:</strong> Responsible for building and maintaining the security toolchain, training champions, performing advanced testing, and leading incident response.</li><li><strong>Product Managers:</strong> Responsible for prioritizing security features and bug fixes in the product backlog.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1556155092-490a1ba16284?w=800&h=400&fit=crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 21: DevSecOps Team Assessment Workshop",
                        "language": "markdown",
                        "code": "# RASCI Chart for Vulnerability Management\n\n| Activity | Developer | Security Champion | Security Engineer | Product Manager |\n|---|---|---|---|---|\n| **Write Secure Code** | R | A | C | I |\n| **Run Scans in Pipeline** | A | I | R | I |\n| **Triage Findings** | A | R | S | C |\n| **Fix Vulnerability** | R | A | C | I |\n| **Prioritize Fix in Backlog**| I | I | C | R |\n| **Tune Scanner Rules** | I | C | R | I |\n\n**Legend:**\n- **R:** Responsible (Does the work)\n- **A:** Accountable (Owns the outcome)\n- **S:** Supports (Provides assistance)\n- **C:** Consulted (Provides input)\n- **I:** Informed (Is kept up-to-date)"
                    },
                    {
                        "title": "Code Example 21: Team Collaboration and Communication Platform",
                        "language": "plaintext",
                        "code": "/* \n  Example of a well-defined security ticket in Jira\n\n  Project: WEB-APP\n  Ticket ID: WEB-1234\n  Type: Bug\n  Component: Authentication\n  Security: [x] Yes\n  Severity: Critical\n\n  Summary: [SCA] Critical Remote Code Execution vulnerability in library `apache-utils:2.1.4`\n\n  Description:\n  The SCA scanner has detected a critical vulnerability (CVE-2025-9876) in the `apache-utils` library, version 2.1.4.\n\n  - Link to finding in Scanner: [link]\n  - Link to CVE details: [link]\n\n  Remediation:\n  Please upgrade the library to version `2.1.5` or later.\n\n  Assigned To: @developer_a\n  Security Champion: @champion_b (for assistance if needed)\n*/"
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "What is the primary role of a Security Champion?",
                        "options": [
                            "To manually approve every line of code.",
                            "To act as a security advocate and first point of contact within their own development team.",
                            "To replace the need for a central security team.",
                            "To run the company's annual security audit."
                        ],
                        "correct": 1,
                        "explanation": "Security Champions are a force multiplier. They are embedded members of the development team who help to scale security knowledge and practices throughout the organization."
                    },
                    {
                        "id": 2,
                        "question": "In a mature DevSecOps model, the central security team typically acts as:",
                        "options": [
                            "A strict gatekeeper that manually reviews all changes.",
                            "A team that only responds to incidents.",
                            "A center of excellence that provides tools, platforms, and consulting to empower development teams.",
                            "A team that is completely separate from development and operations."
                        ],
                        "correct": 2,
                        "explanation": "The modern security team's role is to enable, not to block. They build the 'secure paved road' (the secure pipeline and platforms) that makes it easy for developers to deliver software securely and at speed."
                    },
                    {
                        "id": 3,
                        "question": "A RASCI chart is a tool used for what purpose?",
                        "options": [
                            "To draw network diagrams.",
                            "To clearly define the roles and responsibilities for activities in a process.",
                            "To scan for vulnerabilities.",
                            "To write code."
                        ],
                        "correct": 1,
                        "explanation": "A RASCI chart is a valuable governance tool for clarifying who does what in a cross-functional process, which is essential in a shared responsibility model like DevSecOps."
                    },
                    {
                        "id": 4,
                        "question": "In a DevSecOps culture, who is responsible for fixing a security vulnerability found in the code?",
                        "options": [
                            "The security team.",
                            "The operations team.",
                            "An external consultant.",
                            "The developer or team who wrote the code."
                        ],
                        "correct": 3,
                        "explanation": "A core principle of DevSecOps is that the team that builds the code also owns its quality and security. The security team provides the tools and expertise, but the development team is responsible for the actual remediation."
                    }
                ]
            }
        },
        {
            "id": "lesson-22",
            "title": "Training and Culture Change",
            "duration": "90 min",
            "objectives": [
                "Understand that DevSecOps is primarily a cultural transformation.",
                "Develop strategies for effective developer security education.",
                "Explore gamification and other techniques to drive engagement.",
                "Learn how to measure the success of a culture change initiative."
            ],
            "content": {
                "overview": "You can have the best tools and processes in the world, but if the culture doesn't support them, a DevSecOps transformation will fail. Culture change is the most difficult but also the most important part of the journey. This lesson focuses on the strategies for fostering a security-first mindset, educating developers, and making security an engaging and rewarding part of everyone's job.",
                "sections": [
                    {
                        "title": "Developer Security Education",
                        "content": "<p>Effective training must be relevant, timely, and engaging.</p><h3>Modern Training Strategies:</h3><ul><li><strong>Contextual Micro-Learning:</strong> Instead of long, generic annual training, provide short, specific training modules directly in the developer's workflow. For example, if a SAST tool finds a SQL injection flaw, it can provide a link to a 5-minute video and interactive lab on how to fix that specific vulnerability.</li><li><strong>Interactive and Hands-On:</strong> Use platforms that allow developers to learn by doing, such as 'capture the flag' (CTF) events or platforms that let them exploit and then fix a real vulnerability in a safe environment.</li><li><strong>Role-Based:</strong> Provide training that is specific to the developer's role and technology stack. A front-end JavaScript developer needs different training than a backend Go developer.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1516321497487-e288fb19713f?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Gamification Strategies",
                        "content": "<p>Gamification uses game mechanics to make security training and practices more engaging and fun.</p><h3>Examples:</h3><ul><li><strong>Bug Bounties:</strong> Reward developers (with points, swag, or cash) for finding and fixing security vulnerabilities.</li><li><strong>Tournaments:</strong> Hold regular 'capture the flag' competitions where teams compete to solve security challenges.</li><li><strong>Leaderboards:</strong> Create leaderboards that show which teams or individuals are fixing the most vulnerabilities or completing the most training modules.</li><li><strong>Badges and Achievements:</strong> Award digital badges for completing security training or for achieving certain goals, like having zero critical vulnerabilities in a project for a full quarter.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1588665387928-a8d2a13f8373?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Cultural Transformation Techniques",
                        "content": "<h3>Key Techniques:</h3><ul><li><strong>Start Small and Show Value:</strong> Don't try to boil the ocean. Start with a single, motivated pilot team. Help them succeed and then use their success story to evangelize the benefits to other teams.</li><li><strong>Blameless Culture:</strong> As discussed in the IR lesson, a blameless culture is essential. Failures should be treated as learning opportunities for the system, not as reasons to punish individuals.</li><li><strong>Celebrate Wins:</strong> Publicly recognize and reward teams and individuals who demonstrate great security citizenship. This reinforces the desired behavior.</li><li><strong>Leadership Buy-in:</strong> Culture change must be supported from the top down. Engineering and security leadership must consistently communicate the importance of DevSecOps.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1552664730-d307ca884978?w=800&h=400&fit=crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 22: Security Training Platform Development",
                        "language": "markdown",
                        "code": "# Plan for a Developer Security Dojo\n\n**Concept:** A recurring, monthly, 2-hour optional workshop for developers.\n\n**Format:**\n1.  **(30 mins) Threat of the Month:** A security engineer presents a real-world, anonymized incident that happened at the company or in the industry.\n2.  **(60 mins) Hands-On Lab:** Developers break into teams and compete in a short 'Capture the Flag' exercise related to the threat of the month. (e.g., if the threat was BOLA, the CTF involves finding and exploiting a BOLA flaw in a test API).\n3.  **(30 mins) Open Discussion & Q&A:** An open forum for developers to ask the security team any questions.\n\n**Gamification:**\n- The winning team of the CTF gets a prize and a mention in the engineering newsletter.\n- Attendees get a special badge on their internal profile."
                    },
                    {
                        "title": "Code Example 22: Gamified Security Learning Management System",
                        "language": "json",
                        "code": "{\n  \"userId\": \"dev-123\",\n  \"userName\": \"Alex\",\n  \"xp_points\": 1550,\n  \"level\": \"Security Adept\",\n  \"badges\": [\n    {\n      \"badgeName\": \"SQLi Slayer\",\n      \"dateEarned\": \"2025-09-10\",\n      \"description\": \"Completed the advanced SQL Injection training module.\"\n    },\n    {\n      \"badgeName\": \"Bug Finder\",\n      \"dateEarned\": \"2025-08-20\",\n      \"description\": \"Submitted a valid medium-severity vulnerability.\"\n    }\n  ]\n}"
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "The most difficult and most important aspect of a successful DevSecOps transformation is:",
                        "options": [
                            "Buying the right tools.",
                            "Changing the organizational culture.",
                            "Writing a security policy.",
                            "Getting a compliance certification."
                        ],
                        "correct": 1,
                        "explanation": "DevSecOps is fundamentally a cultural shift. Without buy-in from people and a change in mindset, even the best tools and processes will fail to be adopted."
                    },
                    {
                        "id": 2,
                        "question": "Using leaderboards and competitions to make security practices more engaging is an example of:",
                        "options": [
                            "Gamification",
                            "Incident Response",
                            "Vulnerability Scanning",
                            "Compliance Auditing"
                        ],
                        "correct": 0,
                        "explanation": "Gamification applies game-design thinking to non-game contexts to increase user engagement and motivation, which can be a very effective technique for security training and awareness."
                    },
                    {
                        "id": 3,
                        "question": "What is 'contextual micro-learning' in developer security education?",
                        "options": [
                            "A mandatory 8-hour annual training video.",
                            "Sending developers to a week-long conference.",
                            "Providing short, targeted training modules at the moment a developer needs it (e.g., when a scanner finds a specific flaw).",
                            "Giving every developer a large security textbook."
                        ],
                        "correct": 2,
                        "explanation": "Just-in-time, contextual training is far more effective than generic, out-of-band training. It helps the developer solve their immediate problem and reinforces the learning with practical application."
                    },
                    {
                        "id": 4,
                        "question": "A key technique for driving cultural change across a large organization is to:",
                        "options": [
                            "Try to change every team at the same time.",
                            "Start with a motivated pilot team, make them successful, and then use that success story to evangelize.",
                            "Keep the initiative a secret from everyone.",
                            "Mandate the change without explaining the benefits."
                        ],
                        "correct": 1,
                        "explanation": "The 'start small and evangelize' model is a proven change management technique. A real-world success story from a peer team is the most powerful tool for convincing other teams to adopt a new way of working."
                    }
                ]
            }
        },
        {
            "id": "lesson-23",
            "title": "Enterprise DevSecOps Scaling",
            "duration": "90 min",
            "objectives": [
                "Develop a strategy for scaling DevSecOps across a large enterprise.",
                "Design a governance model that provides consistency without stifling autonomy.",
                "Implement a 'paved road' approach for tools and processes.",
                "Measure and report on the ROI of the DevSecOps program."
            ],
            "content": {
                "overview": "Scaling DevSecOps from a single pilot team to an entire enterprise of hundreds or thousands of developers presents a new set of challenges. This lesson focuses on the governance, architectural, and strategic patterns needed to achieve consistency, quality, and risk reduction at scale.",
                "sections": [
                    {
                        "title": "Governance and Oversight Models",
                        "content": "<p>As you scale, you need a way to ensure consistency and manage risk without creating a centralized bottleneck.</p><h3>The Center of Excellence (CoE) Model:</h3><p>A DevSecOps CoE is a central team that is responsible for:</p><ul><li><strong>Defining Standards and Policies:</strong> Setting the baseline security requirements and quality gates for all pipelines.</li><li><strong>Building the 'Paved Road':</strong> Creating and maintaining the core, shared security toolchain and infrastructure.</li><li><strong>Providing Expertise:</strong> Acting as internal consultants and supporting the Security Champions network.</li><li><strong>Governance and Reporting:</strong> Monitoring the health and performance of the overall program and reporting on risk to leadership.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1552664730-d307ca884978?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Standardization and the 'Paved Road'",
                        "content": "<p>The 'paved road' is a key concept for scaling. It means the central team provides a well-supported, secure, and easy-to-use set of tools and pipelines for development teams.</p><p>Teams are free to go 'off-road' and use their own tools, but they then become responsible for their own security, compliance, and operational support. Most teams will choose the easy, well-lit paved road.</p><h3>Benefits:</h3><ul><li><strong>Consistency:</strong> Ensures all teams are using a consistent, vetted set of security tools.</li><li><strong>Efficiency:</strong> Frees development teams from having to build and maintain their own security infrastructure.</li><li><strong>Scalability:</strong> Allows the central team to roll out updates and new security controls to hundreds of teams at once.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1510915228340-29c85a43dcfe?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Quality Gates and Approvals",
                        "content": "<p>At scale, you need automated quality gates to enforce a minimum security bar.</p><h3>Tiered Gates Model:</h3><ul><li><strong>Tier 1 (Fully Automated):</strong> For low-risk applications, the pipeline can run and deploy to production automatically as long as all automated security gates (SAST, SCA, etc.) pass.</li><li><strong>Tier 2 (Automated + Champion Approval):</strong> For medium-risk applications, the pipeline requires an approval from the team's Security Champion before deploying to production.</li><li><strong>Tier 3 (Manual Review):</strong> For the most critical, high-risk applications, the pipeline may require a formal review and approval from the central security team before a major release.</li></ul><p>This risk-based approach allows most teams to move fast while providing extra oversight where it is needed most.</p>",
                        "image": "https://images.unsplash.com/photo-1521791136064-7986c2920216?w=800&h=400&fit-crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 23: Enterprise DevSecOps Architecture Design",
                        "language": "plaintext",
                        "code": "/* \n  Enterprise 'Paved Road' CI/CD Architecture\n\n  1.  **Central Platform Team (DevSecOps CoE):**\n      - Manages a central instance of GitLab CI.\n      - Develops and maintains a library of version-controlled, reusable CI/CD templates.\n      - Example template: `include: 'templates/secure-node-app.yml'`\n\n  2.  **Reusable CI/CD Template (`secure-node-app.yml`):**\n      - Defines the standard stages: test, scan, build, deploy.\n      - Includes pre-configured jobs for SAST, SCA, and container scanning.\n      - These jobs use the centrally managed and licensed security tools.\n      - Defines the organization's standard quality gates (e.g., fail if critical vulns are found).\n\n  3.  **Application Team:**\n      - The development team for 'App A' creates their own `.gitlab-ci.yml` file.\n      - Their file is very simple:\n\n        ```yaml\n        include:\n          - project: 'devsecops-coe/cicd-templates'\n            ref: 'v2.1'\n            file: '/templates/secure-node-app.yml'\n        ```\n\n  Result: App A's team automatically inherits the entire, centrally managed security pipeline.\n  When the CoE updates the central template (e.g., to add a new scanner), App A's team\n  gets the new control automatically by updating the 'ref' version.\n*/"
                    },
                    {
                        "title": "Code Example 23: Enterprise Security Governance Platform",
                        "language": "json",
                        "code": "{\n  \"organization\": \"MyCorp\",\n  \"globalPolicy\": {\n    \"name\": \"Global CI/CD Security Requirements\",\n    \"rules\": [\n      {\n        \"control\": \"SCA\",\n        \"description\": \"All builds must pass an SCA scan.\",\n        \"enforcement\": \"BLOCK_ON_CRITICAL\"\n      },\n      {\n        \"control\": \"SAST\",\n        \"description\": \"All builds must pass a SAST scan.\",\n        \"enforcement\": \"BLOCK_ON_CRITICAL\"\n      }\n    ]\n  },\n  \"teamOverrides\": [\n    {\n      \"teamName\": \"experimental-labs\",\n      \"justification\": \"Non-production R&D projects.\",\n      \"overrides\": {\n        \"SAST\": {\n          \"enforcement\": \"ALERT_ONLY\"\n        }\n      }\n    }\n  ]\n}"
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "The concept of a central team providing a set of easy-to-use, secure, and supported tools and pipelines for development teams is known as:",
                        "options": [
                            "A manual review gate",
                            "The 'Paved Road'",
                            "Shadow IT",
                            "A siloed approach"
                        ],
                        "correct": 1,
                        "explanation": "The 'Paved Road' (or 'Golden Path') is a key scaling strategy. It makes the secure and compliant way the easiest way, encouraging adoption without forcing a rigid mandate on all teams."
                    },
                    {
                        "id": 2,
                        "question": "In a large enterprise, a DevSecOps Center of Excellence (CoE) is primarily responsible for:",
                        "options": [
                            "Manually approving every pull request from every team.",
                            "Defining standards, building the shared toolchain, and enabling development teams.",
                            "Writing all the application code for the company.",
                            "Responding to every security alert."
                        ],
                        "correct": 1,
                        "explanation": "The CoE is a strategic function focused on enabling and scaling DevSecOps. It provides the platform and governance that allows hundreds of individual teams to operate securely and autonomously."
                    },
                    {
                        "id": 3,
                        "question": "A risk-based governance model where low-risk applications can be deployed automatically but high-risk applications require manual approval is an example of:",
                        "options": [
                            "A 'one-size-fits-all' approach",
                            "A tiered quality gate model",
                            "A manual review process",
                            "A development bottleneck"
                        ],
                        "correct": 1,
                        "explanation": "A tiered, risk-based approach to governance provides the right balance between speed and control. It allows low-risk changes to move fast while applying more friction and oversight to high-risk changes."
                    },
                    {
                        "id": 4,
                        "question": "How does using reusable CI/CD templates help to scale DevSecOps?",
                        "options": [
                            "It makes every team build their own pipeline from scratch.",
                            "It allows a central team to define security controls once and have them easily inherited by hundreds of application teams.",
                            "It makes the CI/CD pipeline configuration more complex.",
                            "It has no effect on scalability."
                        ],
                        "correct": 1,
                        "explanation": "Reusable templates are the technical implementation of the 'Paved Road'. They are a highly efficient way to distribute and enforce security standards at enterprise scale."
                    }
                ]
            }
        },
        {
            "id": "lesson-24",
            "title": "Advanced DevSecOps Patterns",
            "duration": "90 min",
            "objectives": [
                "Explore the use of event-driven architecture for security automation.",
                "Understand how AI/ML can be used to enhance DevSecOps workflows.",
                "Learn the principles of Chaos Engineering for security.",
                "Integrate proactive threat hunting into the DevSecOps lifecycle."
            ],
            "content": {
                "overview": "As a DevSecOps program matures, it can move beyond foundational security checks to more advanced, proactive, and intelligent patterns. This lesson explores the cutting edge of DevSecOps, including how to leverage event-driven architecture, AI, and chaos engineering to build a truly predictive and resilient security program.",
                "sections": [
                    {
                        "title": "Event-Driven Security Architecture",
                        "content": "<p>This is an architectural pattern where security actions are triggered by events. Instead of a linear pipeline, the system is a collection of small, independent functions that react to events from a central message bus (e.g., Kafka).</p><h3>Example Workflow:</h3><ol><li>A CSPM tool detects a public S3 bucket and publishes a `s3_bucket_public` event to the message bus.</li><li>A `remediation` function is subscribed to this event. It triggers, calls the AWS API to make the bucket private, and publishes a `s3_bucket_remediated` event.</li><li>A `notification` function is subscribed to both events. It sees the original event and the remediation event and sends a message to Slack: 'Detected and automatically remediated public S3 bucket X.'</li></ol><p>This is a highly scalable and decoupled way to build security automation.</p>",
                        "image": "https://images.unsplash.com/photo-1534972195531-0e108fc312f0?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "AI/ML in DevSecOps Workflows",
                        "content": "<p>Artificial intelligence and machine learning can be used to make DevSecOps tools and processes smarter.</p><h3>Use Cases:</h3><ul><li><strong>Intelligent Triage:</strong> An AI model can be trained on past vulnerability data to predict whether a new SAST finding is likely to be a true or false positive, helping to automate the triage process.</li><li><strong>Predictive Security Analytics:</strong> An ML model can analyze metrics from source code repositories and CI/CD pipelines to predict which components are most likely to have security defects in the future. This allows teams to focus their testing efforts proactively.</li><li><strong>UEBA in the Pipeline:</strong> An ML model can baseline the normal behavior of a CI/CD pipeline (e.g., 'this pipeline normally takes 10 minutes and uses these specific build tools') and alert on anomalous activity that could indicate a compromised build agent.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1620712943543-285f231f7927?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Chaos Engineering for Security",
                        "content": "<p>Chaos Engineering is the practice of intentionally experimenting on a system to build confidence in its ability to withstand turbulent conditions in production. Security Chaos Engineering applies this to security controls.</p><h3>The Goal:</h3><p>The goal is to proactively find failures in your security controls before an attacker does. It answers questions like:</p><ul><li>'If our EDR agent crashes on a server, do our other monitoring systems still detect a simulated attack on that server?'</li><li>'If we revoke a microservice's network credentials, does it fail gracefully and alert correctly?'</li><li>'If our WAF goes offline, how does it affect our application's security posture?'</li></ul><p>These experiments are conducted in a controlled way in production to test the real-world resilience of the security architecture.</p>",
                        "image": "https://images.unsplash.com/photo-1588665387928-a8d2a13f8373?w=800&h=400&fit=crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 24: Advanced Security Pattern Implementation",
                        "language": "python",
                        "code": "# Conceptual Security Chaos Engineering Experiment\n\nimport chaos_toolkit_api\n\ndef test_edr_failure_detection():\n    \"\"\"Verify that we can still detect an attack if the EDR agent fails.\"\"\"\n    \n    # 1. Hypothesis: Our SIEM correlation rules, based on network and authentication logs,\n    #    are sufficient to detect lateral movement even without an EDR alert.\n    \n    # 2. Select a target production host (in a safe, non-critical pool)\n    target_host = \"prod-web-canary-01\"\n    \n    # 3. Experiment: Inject the failure\n    # Use the chaos engineering tool to remotely and temporarily stop the EDR service on the target host.\n    chaos_toolkit_api.stop_service(host=target_host, service=\"edr-agent\")\n    \n    # 4. Experiment: Simulate the attack\n    # Use a Breach and Attack Simulation tool to run a safe lateral movement simulation\n    # originating from the target host.\n    attack_result = bas_tool_api.run_simulation(source_host=target_host, type=\"lateral_movement\")\n\n    # 5. Verify the outcome\n    # Check the SIEM for the expected correlation alert within 5 minutes.\n    siem_alert_found = siem_api.check_for_alert(source_host=target_host, rule=\"Lateral Movement Detected\")\n    \n    # 6. Rollback\n    # Ensure the EDR agent is restarted regardless of the outcome.\n    chaos_toolkit_api.start_service(host=target_host, service=\"edr-agent\")\n    \n    # 7. Assert the result\n    assert siem_alert_found, \"Detection failed when EDR agent was offline!\""
                    },
                    {
                        "title": "Code Example 24: AI-Powered DevSecOps Automation Platform",
                        "language": "json",
                        "code": "{\n  \"sastFindingId\": \"SAST-5566\",\n  \"vulnerability\": \"Cross-Site Scripting\",\n  \"confidence\": \"MEDIUM\",\n  \"triagePrediction\": {\n    \"modelId\": \"triage-model-v3\",\n    \"prediction\": \"Likely False Positive\",\n    \"confidence\": \"92%\",\n    \"explanation\": [\n      \"Data source is a trusted internal system.\",\n      \"Output is written to a content-type of 'application/json', not 'text/html'.\"\n    ]\n  },\n  \"recommendedAction\": \"ROUTE_TO_CHAMPION_FOR_REVIEW\"\n}"
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "An architectural pattern where security tools react to notifications from a central message bus is known as:",
                        "options": [
                            "Chaos Engineering",
                            "Event-Driven Security",
                            "Threat Hunting",
                            "A monolithic architecture"
                        ],
                        "correct": 1,
                        "explanation": "Event-driven architecture is a highly scalable and decoupled pattern for building automation. Security actions (like remediation or notification) are implemented as small, independent functions that are triggered by events."
                    },
                    {
                        "id": 2,
                        "question": "What is the primary goal of Security Chaos Engineering?",
                        "options": [
                            "To cause production outages.",
                            "To find as many software bugs as possible.",
                            "To proactively identify weaknesses in the resilience of security controls by injecting controlled failures.",
                            "To test the usability of an application."
                        ],
                        "correct": 2,
                        "explanation": "Security Chaos Engineering is a sophisticated practice that moves from 'Is the control present?' to 'What happens when the control fails?' It's about testing the resilience and redundancy of your entire security ecosystem."
                    },
                    {
                        "id": 3,
                        "question": "Using a machine learning model to predict if a new SAST finding is a true or false positive is an example of what advanced pattern?",
                        "options": [
                            "Event-Driven Security",
                            "AI/ML in DevSecOps",
                            "Chaos Engineering",
                            "Threat Hunting"
                        ],
                        "correct": 1,
                        "explanation": "This is a prime use case for AI/ML in DevSecOps. By automating or augmenting the triage process, it can significantly reduce the manual workload on security teams and champions."
                    },
                    {
                        "id": 4,
                        "question": "An event-driven remediation script that is triggered by a CSPM alert is an example of what?",
                        "options": [
                            "A manual process",
                            "A proactive control",
                            "A detective and reactive control",
                            "A preventative control"
                        ],
                        "correct": 2,
                        "explanation": "The CSPM alert is the 'detective' part (it found a problem). The automated script that is triggered to fix the problem is the 'reactive' or 'response' part of the automated workflow."
                    }
                ]
            }
        },
        {
            "id": "lesson-25",
            "title": "DevSecOps in Regulated Industries",
            "duration": "90 min",
            "objectives": [
                "Understand the specific challenges of implementing DevSecOps in regulated environments (e.g., finance, healthcare).",
                "Map compliance requirements (e.g., PCI DSS, HIPAA) to DevSecOps controls.",
                "Architect for immutable audit trails and automated evidence collection.",
                "Balance the need for speed with the requirements for governance and change control."
            ],
            "content": {
                "overview": "Implementing DevSecOps in highly regulated industries like finance, healthcare, and government requires a deliberate architectural approach that bakes compliance and governance into the automated pipelines. This lesson explores the patterns for achieving both speed and compliance, proving to auditors that a high-velocity DevOps model can be more secure and auditable than a traditional, manual one.",
                "sections": [
                    {
                        "title": "Healthcare DevSecOps (HIPAA)",
                        "content": "<p>The Health Insurance Portability and Accountability Act (HIPAA) requires strict controls to protect patient data (PHI).</p><h3>Mapping HIPAA to DevSecOps Controls:</h3><ul><li><strong>Access Control:</strong> Mapped to strong IAM policies defined in IaC, and enforced by Kubernetes RBAC and network policies.</li><li><strong>Audit Controls:</strong> Mapped to a comprehensive, immutable audit trail captured in a centralized logging system (e.g., CloudTrail).</li><li><strong>Integrity:</strong> Mapped to artifact signing and verification in the CI/CD pipeline.</li><li><strong>Transmission Security:</strong> Mapped to policies (enforced by a service mesh or IaC linter) that mandate TLS encryption for all data in transit.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1533285809283-0a7c6177ac43?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Financial Services Requirements",
                        "content": "<p>Regulations like the Payment Card Industry Data Security Standard (PCI DSS) have very prescriptive requirements.</p><h3>Mapping PCI DSS to DevSecOps Controls:</h3><ul><li><strong>Req 6 (Secure Development):</strong> Mapped directly to the integration of SAST, DAST, and SCA into the CI/CD pipeline, along with developer training.</li><li><strong>Req 11 (Regular Testing):</strong> Mapped to automated vulnerability scanning, penetration testing, and file integrity monitoring (FIM) provided by a CWPP.</li><li><strong>Req 3 (Protect Stored Cardholder Data):</strong> Mapped to IaC policies that enforce encryption at rest for databases and storage.</li><li><strong>Req 1 (Firewall Configuration):</strong> Mapped to version-controlled firewall rules and security group definitions managed via IaC.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1567427018141-0584cfcbf1b8?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Cross-Industry Best Practices",
                        "content": "<p>Regardless of the specific industry, the architectural patterns for auditable DevSecOps are consistent.</p><ul><li><strong>Everything as Code:</strong> Policies, infrastructure, pipeline definitions, and compliance tests should all be defined as code in version control. This provides a perfect, time-stamped audit trail of every change.</li><li><strong>Immutable Evidence:</strong> The CI/CD pipeline should generate a set of immutable 'compliance artifacts' for every build (e.g., scan results, test reports). These artifacts can be stored in a dedicated, access-controlled location for auditors.</li><li><strong>Separation of Duties:</strong> Even in a collaborative culture, separation of duties is a key control. For example, a developer can write code and create a pull request, but the pipeline requires a peer review and has a separate, privileged service account to deploy to production.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1590102426319-c72115b5a832?w=800&h=400&fit=crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 25: Regulated Industry DevSecOps Workshop",
                        "language": "markdown",
                        "code": "# Mapping PCI DSS Requirement 6.5.1 (SQL Injection) to DevSecOps Controls\n\n- **Requirement:** Address common coding vulnerabilities, including SQL injection.\n\n- **Control 1 (Preventative - Design):**\n  - **Implementation:** Security Champions are trained to identify SQLi risks during threat modeling.\n  - **Evidence:** Threat model document showing SQLi was considered and mitigated.\n\n- **Control 2 (Preventative - Code):**\n  - **Implementation:** The official corporate coding standard mandates the use of parameterized queries.\n  - **Evidence:** Link to the coding standard wiki page.\n\n- **Control 3 (Automated - Build/Test):**\n  - **Implementation:** The CI/CD pipeline includes a SAST scanner that has rules to detect SQLi flaws.\n  - **Evidence:** SAST scan results from the build pipeline.\n\n- **Control 4 (Automated - Runtime):**\n  - **Implementation:** Production web applications are protected by a WAF with SQLi detection rules.\n  - **Evidence:** WAF logs sent to the SIEM."
                    },
                    {
                        "title": "Code Example 25: Industry-Specific Compliance Automation Framework",
                        "language": "hcl",
                        "code": "# Example of a Terraform Checkov policy for HIPAA compliance\n\n# This custom policy checks if an AWS RDS database has deletion protection enabled,\n# which is a control for ensuring data integrity and availability.\n\nmetadata:\n  name: \"RDS Deletion Protection Enabled (HIPAA)\"\n  id: \"CKV_AWS_999\"\n  category: \"BACKUP_AND_RECOVERY\"\n  guideline: \"HIPAA Security Rule 164.308(a)(7)(ii)(B)\"\ndefine:\n  # This policy will trigger if...\n  resource.type == \"aws_db_instance\" and\n  # ...the 'deletion_protection' attribute is either missing or set to false.\n  (not resource.deletion_protection or resource.deletion_protection != true)"
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "How does a DevSecOps approach help with compliance audits?",
                        "options": [
                            "It makes them more difficult because everything is automated.",
                            "It replaces auditors with software.",
                            "By defining everything as code and generating automated evidence, it creates a high-fidelity, continuous audit trail.",
                            "It eliminates the need for compliance altogether."
                        ],
                        "correct": 2,
                        "explanation": "DevSecOps can transform audits from a painful, manual process into a simple reporting exercise. The version-controlled code, pipeline logs, and automated test results provide strong, continuous evidence that controls are in place and effective."
                    },
                    {
                        "id": 2,
                        "question": "A CI/CD pipeline that integrates a SAST scanner to find SQL injection flaws is directly helping to satisfy which PCI DSS requirement?",
                        "options": [
                            "Requirement 1 (Firewall Configuration)",
                            "Requirement 3 (Protect Stored Data)",
                            "Requirement 6 (Develop and Maintain Secure Systems and Applications)",
                            "Requirement 9 (Restrict Physical Access)"
                        ],
                        "correct": 2,
                        "explanation": "PCI DSS Requirement 6 is focused on secure software development. Integrating automated security testing tools like SAST and DAST into the CI/CD pipeline is a primary way to meet these requirements."
                    },
                    {
                        "id": 3,
                        "question": "The concept of 'Everything as Code' is critical for regulated environments because:",
                        "options": [
                            "It allows developers to make any changes they want without oversight.",
                            "It creates a version-controlled, auditable history of every change made to infrastructure, policy, and pipelines.",
                            "It is slower than making manual changes.",
                            "It only works for non-critical systems."
                        ],
                        "correct": 1,
                        "explanation": "When every change is a code commit that is peer-reviewed and logged, it provides a perfect audit trail that auditors can use to see the 'who, what, when, and why' of every change."
                    },
                    {
                        "id": 4,
                        "question": "A developer can commit code, but a separate, privileged service account is used by the pipeline to deploy to production. This is an example of what security principle?",
                        "options": [
                            "Separation of Duties",
                            "Vulnerability Scanning",
                            "Blameless Post-Mortems",
                            "Threat Modeling"
                        ],
                        "correct": 0,
                        "explanation": "Even in a highly automated and collaborative environment, enforcing separation of duties is a key compliance control. This ensures that no single individual has the end-to-end ability to write and deploy code without any oversight, which is what this pipeline architecture achieves."
                    }
                ]
            }
        },
        {
            "id": "lesson-26",
            "title": "Supply Chain Security",
            "duration": "90 min",
            "objectives": [
                "Understand the modern software supply chain and its primary threats.",
                "Learn the importance and structure of a Software Bill of Materials (SBOM).",
                "Design a secure build system to prevent tampering.",
                "Implement artifact signing and verification to ensure integrity."
            ],
            "content": {
                "overview": "The software supply chain is the entire lifecycle of a piece of software, from development and dependencies to deployment. Attacks against the supply chain, where an attacker injects malicious code into a trusted component, have become a major threat. This lesson covers the architectural patterns for securing the end-to-end software supply chain.",
                "sections": [
                    {
                        "title": "Software Supply Chain Threats",
                        "content": "<p>An attacker can target multiple points in the supply chain.</p><h3>Common Attack Vectors:</h3><ul><li><strong>Dependency Confusion/Typosquatting:</strong> An attacker publishes a malicious package to a public repository with the same name as an internal package, or a name that is a common typo of a popular package.</li><li><strong>Compromised Developer Account:</strong> An attacker compromises a developer's credentials and injects malicious code into the source code repository.</li><li><strong>Compromised Build System:</strong> An attacker compromises the CI/CD server itself and modifies the application's code or artifacts during the build process.</li><li><strong>Vulnerable Open-Source Components:</strong> Using a third-party library that contains a known vulnerability (as covered in the SCA lesson).</li></ul>",
                        "image": "https://images.unsplash.com/photo-1556075798-4825dfaaf498?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "SBOM (Software Bill of Materials)",
                        "content": "<p>An SBOM is a nested inventory, a list of ingredients that make up software components. It is a foundational element of supply chain security.</p><h3>Why it's Critical:</h3><ul><li><strong>Visibility:</strong> Provides a complete and accurate inventory of every component in your software.</li><li><strong>Vulnerability Management:</strong> When a new zero-day is announced, the SBOM allows you to instantly identify all affected applications.</li><li><strong>License Compliance:</strong> Tracks the licenses of all components.</li></ul><p>The architecture should mandate that every build in the CI/CD pipeline must generate and publish an SBOM for the resulting artifact. Common formats include CycloneDX and SPDX.</p>",
                        "image": "https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Build System Security",
                        "content": "<p>The CI/CD build system is a high-value target and must be architected as a piece of critical, production infrastructure.</p><h3>Key Controls:</h3><ul><li><strong>Hardened and Isolated Runners:</strong> Build jobs should run on hardened, ephemeral runners with no direct access to production networks.</li><li><strong>Least Privilege:</strong> The build system's credentials must be tightly scoped and short-lived.</li><li><strong>Pipeline as Code:</strong> Changes to the build process itself must be reviewed and approved via a pull request.</li><li><strong>Dependency Pinning:</strong> The build should use a lock file (e.g., `package-lock.json`) to ensure that the exact, vetted versions of all dependencies are used, preventing a malicious update from being pulled in automatically.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1542382257-80deda0e5d99?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Artifact Signing and Verification",
                        "content": "<p>This provides a strong guarantee of integrity throughout the supply chain.</p><h3>The SLSA Framework:</h3><p>The Supply-chain Levels for Software Artifacts (SLSA, pronounced 'salsa') is a security framework that provides a checklist of standards and controls to prevent tampering and improve integrity.</p><ul><li><strong>Provenance:</strong> The build system generates a signed, non-forgeable metadata document called 'provenance'. This document attests to how the artifact was built, including the source code commit, the build script used, and the dependencies included.</li><li><strong>Signing:</strong> The artifact itself and its provenance are digitally signed.</li><li><strong>Verification:</strong> The deployment environment is configured with a policy that requires it to verify this signature and provenance before allowing the artifact to be deployed.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit-crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 26: Supply Chain Security Implementation",
                        "language": "shell",
                        "code": "# Example of using Cosign (part of the Sigstore project) to sign a container image\n\n# 1. The CI/CD pipeline builds the image\ndocker build -t myregistry/myapp:v1.4.0 .\n\n# 2. The pipeline authenticates to the signing service (e.g., using its OIDC token)\n\n# 3. The pipeline signs the image. This creates a signed attestation and pushes it\n#    to the container registry alongside the image.\ncosign sign myregistry/myapp:v1.4.0\n\n# --- In the Kubernetes Cluster ---\n\n# 4. An admission controller (like Kyverno) has a policy that requires all images\n#    deployed to the 'production' namespace to be signed by the trusted CI/CD key.\n#    An attempt to deploy an unsigned or tampered image will be blocked."
                    },
                    {
                        "title": "Code Example 26: Software Supply Chain Risk Management Platform",
                        "language": "json",
                        "code": "{\n  \"artifactName\": \"my-app:v1.4.0\",\n  \"slsaLevel\": \"2\",\n  \"sbom\": {\n    \"format\": \"CycloneDX\",\n    \"location\": \"s3://artifacts/my-app/v1.4.0/sbom.json\"\n  },\n  \"provenance\": {\n    \"builderId\": \"gitlab-ci-runner-prod-123\",\n    \"sourceCommit\": \"a1b2c3d4e5f6...\",\n    \"buildScript\": \"build.sh\"\n  },\n  \"signature\": {\n    \"keyId\": \"ci-prod-signer@example.com\",\n    \"value\": \"...\"\n  },\n  \"vulnerabilityScan\": {\n    \"status\": \"PASSED\",\n    \"criticalCount\": 0,\n    \"highCount\": 0\n  }\n}"
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "An attack where a malicious package is published to a public repository with a name similar to a legitimate internal package is known as:",
                        "options": [
                            "Dependency Confusion",
                            "A Man-in-the-Middle Attack",
                            "A Denial of Service Attack",
                            "A Physical Attack"
                        ],
                        "correct": 0,
                        "explanation": "Dependency confusion is a sophisticated supply chain attack that tricks a package manager into downloading a malicious public package instead of the intended internal one."
                    },
                    {
                        "id": 2,
                        "question": "What is the primary purpose of a Software Bill of Materials (SBOM)?",
                        "options": [
                            "To list the developers on a team.",
                            "To provide a detailed, machine-readable inventory of all software components and dependencies in an application.",
                            "To document the API endpoints of an application.",
                            "To track the financial cost of a project."
                        ],
                        "correct": 1,
                        "explanation": "An SBOM provides the foundational visibility needed for supply chain security. Without a list of ingredients, it's impossible to know if you are affected by a vulnerability in a specific component."
                    },
                    {
                        "id": 3,
                        "question": "Using a file like `package-lock.json` or `yarn.lock` to ensure that a build always uses the exact same versions of dependencies is a defense against what risk?",
                        "options": [
                            "A malicious or vulnerable update to a dependency being pulled into the build unexpectedly.",
                            "A denial of service attack.",
                            "A phishing attack.",
                            "A misconfigured firewall."
                        ],
                        "correct": 0,
                        "explanation": "Lock files provide deterministic builds. They 'pin' the exact version of every direct and transitive dependency, preventing the package manager from automatically downloading a newer (and potentially malicious) version."
                    },
                    {
                        "id": 4,
                        "question": "The SLSA framework is primarily focused on what aspect of supply chain security?",
                        "options": [
                            "Developer training.",
                            "Protecting against tampering by generating verifiable provenance and using digital signatures.",
                            "Network segmentation.",
                            "Password management."
                        ],
                        "correct": 1,
                        "explanation": "SLSA (Supply-chain Levels for Software Artifacts) is a framework designed to ensure the integrity of the build process. It provides a way to prove that the artifact you are deploying came from a trusted source and has not been tampered with."
                    }
                ]
            }
        },
        {
            "id": "lesson-27",
            "title": "Zero Trust DevSecOps",
            "duration": "90 min",
            "objectives": [
                "Apply Zero Trust principles to the DevSecOps lifecycle.",
                "Architect for strong identity for both developers and workloads.",
                "Implement least-privilege access for all CI/CD pipeline components.",
                "Design for continuous verification throughout the development process."
            ],
            "content": {
                "overview": "Zero Trust is a security model that eliminates the idea of a trusted internal network and requires every access request to be strictly verified. Applying these principles to the DevSecOps lifecycle means treating the pipeline and the development environment as untrusted. This lesson covers how to architect a Zero Trust model for the entire software supply chain.",
                "sections": [
                    {
                        "title": "Zero Trust Principles in DevSecOps",
                        "content": "<p>The core principle is 'Never trust, always verify'. In a DevSecOps context, this means:</p><ul><li><strong>Assume Breach:</strong> Assume a developer's machine could be compromised, or a build agent could be malicious.</li><li><strong>Verify Explicitly:</strong> Every entitydeveloper, service account, pipeline job, workloadmust have a strong, verifiable identity and must authenticate before being granted access.</li><li><strong>Least Privilege Access:</strong> Access to resources (source code, build secrets, deployment environments) must be narrowly scoped, temporary, and just enough to perform the required task.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Identity and Access Management",
                        "content": "<p>Identity becomes the new perimeter. Every action in the DevSecOps lifecycle must be tied back to a strong, authenticated identity.</p><h3>Key Controls:</h3><ul><li><strong>Developer Identity:</strong> Developers must use strong authentication (MFA) to access source code repositories. Git commits should be cryptographically signed to prove their origin.</li><li><strong>Workload Identity:</strong> CI/CD jobs and running applications need a strong, verifiable identity. Modern platforms use protocols like OIDC and SPIFFE to automatically issue short-lived, cryptographic identities to workloads, eliminating the need for long-lived secrets like API keys.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1550751827-4133d1a65c19?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Least Privilege Implementation",
                        "content": "<p>Least privilege must be enforced at every stage.</p><h3>Examples:</h3><ul><li><strong>Source Code:</strong> A developer on Team A should not have write access to the code repository for Team B's application.</li><li><strong>Pipeline:</strong> A CI/CD job that builds a feature branch should not have the credentials to deploy to production. A separate, more privileged job should handle production deployments, and it should only be triggerable from the main branch.</li><li><strong>Infrastructure:</strong> An application's service account should only have the IAM permissions needed to access the specific resources it uses (e.g., a single S3 bucket or DynamoDB table).</li></ul>",
                        "image": "https://images.unsplash.com/photo-1584929788015-230a14589d31?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Continuous Verification",
                        "content": "<p>Zero Trust is not a one-time check; it's a continuous process.</p><h3>Architectural Patterns:</h3><ul><li><strong>Device Trust:</strong> Access to developer tools and source code should be conditional, based on the security posture of the developer's device. (e.g., 'Allow access only from a corporate-managed device that is patched and has EDR running').</li><li><strong>Policy as Code:</strong> Every step of the pipeline is a verification point. Policy as Code engines continuously verify that the code, dependencies, infrastructure, and artifacts meet the defined security policies.</li><li><strong>Attestation:</strong> The build system should produce a signed attestation (provenance) that can be verified at deployment time, proving that the workload passed all the required security checks.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1556155092-490a1ba16284?w=800&h=400&fit-crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 27: Zero Trust DevSecOps Architecture",
                        "language": "plaintext",
                        "code": "/* \n  Zero Trust CI/CD Workflow with Workload Identity (e.g., GitHub Actions + AWS IAM)\n\n  1.  **Configuration:**\n      - In AWS IAM, an OIDC identity provider is configured to trust GitHub Actions.\n      - An IAM Role is created with a trust policy that allows principals from a specific\n        GitHub repository (`my-org/my-app`) and branch (`main`) to assume it.\n      - The IAM Role has a least-privilege policy attached (e.g., only allowing it to\n        write to a specific S3 bucket).\n\n  2.  **Pipeline Execution:**\n      - A developer pushes code to the `main` branch of the `my-org/my-app` repo.\n      - The GitHub Actions workflow starts.\n      - The workflow requests a signed OIDC JWT from GitHub's OIDC provider. This JWT contains\n        claims about the repository, branch, and commit SHA.\n\n  3.  **Authentication:**\n      - The workflow calls the AWS `AssumeRoleWithWebIdentity` API, presenting the JWT.\n      - AWS IAM validates the JWT's signature and its claims against the trust policy.\n\n  4.  **Authorization:**\n      - If valid, AWS STS issues short-lived, temporary AWS credentials to the workflow runner.\n\n  5.  **Action:**\n      - The workflow runner uses these temporary credentials to upload a file to the S3 bucket.\n\n  Result: The pipeline gains access without any long-lived secrets (API keys) being stored in GitHub. \n  Access is strongly authenticated, narrowly scoped, and temporary.\n*/"
                    },
                    {
                        "title": "Code Example 27: Zero Trust Security Enforcement Engine",
                        "language": "yaml",
                        "code": "# Example Kyverno (Kubernetes Policy Engine) Policy for Zero Trust\n# This policy requires that all container images deployed have a signed attestation.\n\napiVersion: kyverno.io/v1\nkind: ClusterPolicy\nmetadata:\n  name: check-image-signature\nspec:\n  validationFailureAction: Enforce\n  rules:\n    - name: verify-image-is-signed\n      match:\n        any:\n        - resources:\n            kinds:\n              - Pod\n      verifyImages:\n      - imageReferences:\n          - \"myregistry/my-app:*\"\n        attestations:\n          - type: \"https://slsa.dev/provenance/v0.2\"\n            conditions:\n              - all:\n                - key: \"{{ subject }}\"\n                  operator: \"Equals\"\n                  value: \"{{ images.cosign.subject }}\"\n"
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "What is the core principle of a Zero Trust security model?",
                        "options": [
                            "Trust all internal network traffic.",
                            "Never trust, always verify every access request.",
                            "Authenticate once at the perimeter.",
                            "Grant broad network access to all users."
                        ],
                        "correct": 1,
                        "explanation": "Zero Trust completely discards the old 'castle-and-moat' model. It assumes there is no trusted internal network and requires every user, device, and workload to be strictly authenticated and authorized for every request."
                    },
                    {
                        "id": 2,
                        "question": "Using a protocol like OIDC to allow a CI/CD job to get temporary cloud credentials without using a long-lived API key is an example of:",
                        "options": [
                            "Static Secret Management",
                            "Workload Identity",
                            "A legacy approach",
                            "Manual configuration"
                        ],
                        "correct": 1,
                        "explanation": "Workload identity is a foundational Zero Trust pattern for automation. It provides a strong, cryptographic identity for non-human entities like CI/CD jobs, allowing them to authenticate securely without static secrets."
                    },
                    {
                        "id": 3,
                        "question": "A policy that requires a developer to use MFA and commit their code with a cryptographic signature is applying Zero Trust to what?",
                        "options": [
                            "Developer Identity",
                            "The Production Environment",
                            "The Network Firewall",
                            "The Application Database"
                        ],
                        "correct": 0,
                        "explanation": "In a Zero Trust DevSecOps model, the trust starts with the developer. Ensuring the developer's identity is strong and that their code commits are non-repudiable is a critical first step in securing the supply chain."
                    },
                    {
                        "id": 4,
                        "question": "In a Zero Trust DevSecOps pipeline, security checks performed by Policy as Code engines act as a form of:",
                        "options": [
                            "Manual Review",
                            "Continuous Verification",
                            "Incident Response",
                            "Threat Hunting"
                        ],
                        "correct": 1,
                        "explanation": "Zero Trust is not a one-time gate. Continuous verification means that policies are checked automatically at every stage of the lifecycle, from code commit to deployment, ensuring that security and compliance are constantly being validated."
                    }
                ]
            }
        },
        {
            "id": "lesson-28",
            "title": "DevSecOps for Legacy Systems",
            "duration": "90 min",
            "objectives": [
                "Identify the unique security challenges of legacy monolithic systems.",
                "Develop risk assessment and mitigation strategies for unpatchable systems.",
                "Design a 'wrapper-based' security architecture to protect legacy applications.",
                "Integrate legacy systems into modern DevSecOps pipelines and monitoring."
            ],
            "content": {
                "overview": "Not every application is a modern, cloud-native microservice. Most enterprises have a significant portfolio of legacy, monolithic applications that are critical to the business but difficult to change. This lesson covers pragmatic strategies for applying DevSecOps principles to these systems to reduce their risk without requiring a full rewrite.",
                "sections": [
                    {
                        "title": "Legacy System Security Challenges",
                        "content": "<p>Legacy systems often have significant security challenges.</p><h3>Common Problems:</h3><ul><li><strong>Unpatchable OS/Frameworks:</strong> The application may depend on an operating system or application framework that is no longer supported by the vendor, meaning no new security patches are available.</li><li><strong>Lack of Automated Testing:</strong> The system was likely built before automated testing was common, making it risky to change.</li><li><strong>No CI/CD Pipeline:</strong> Deployments are often manual, slow, and error-prone.</li><li><strong>Monolithic Architecture:</strong> The application is a single, large block of code, making it difficult to update or secure individual components.</li><li><strong>Missing Source Code:</strong> In some extreme cases, the original source code may have been lost.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1555099962-4199c345e546?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Wrapper-Based Security Approaches",
                        "content": "<p>Since you can't easily change the application itself, the strategy is to surround it with modern security controls. This is called 'wrapping' the application.</p><h3>The Wrapper Architecture:</h3><ul><li><strong>Reverse Proxy / API Gateway:</strong> Place a modern reverse proxy (like NGINX) or an API Gateway in front of the legacy application. This gateway can provide modern security features like TLS termination, strong authentication (by integrating with a modern IdP), WAF capabilities, and rate limiting.</li><li><strong>Containerization:</strong> Package the legacy application and its dependencies into a container. While this doesn't fix the code, it makes the application portable, easier to deploy, and allows you to apply container runtime security and monitoring tools.</li><li><strong>Micro-segmentation:</strong> Place the application in a highly isolated network segment and use a firewall to strictly control all inbound and outbound connections.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1517694712202-14dd9538aa97?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Integration with Modern Pipelines",
                        "content": "<p>Even without source code, you can still bring legacy systems into a modern pipeline.</p><h3>Strategies:</h3><ul><li><strong>Infrastructure as Code (IaC):</strong> Define the entire legacy environment (the container, the network rules, the gateway configuration) as code. This allows you to manage and deploy it in a repeatable, automated way.</li><li><strong>DAST and IAST:</strong> Since you have a running application, you can use 'black-box' (DAST) and 'gray-box' (IAST) scanning tools in the pipeline to find vulnerabilities, even without access to the source code.</li><li><strong>Automated Testing:</strong> Build a suite of high-level automated tests that validate the application's core functionality. This provides a safety net, giving you confidence to make small changes or apply OS patches.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1542382257-80deda0e5d99?w=800&h=400&fit=crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 28: Legacy System Security Integration",
                        "language": "yaml",
                        "code": "# Conceptual CI/CD Pipeline for a Containerized Legacy Application\n\nstages:\n  - build\n  - test\n  - deploy\n\nbuild-container:\n  stage: build\n  script:\n    # Use a Dockerfile to package the legacy application binary and its dependencies\n    - docker build -t legacy-app:latest .\n    - docker push myregistry/legacy-app:latest\n\ndeploy-to-staging:\n  stage: test\n  script:\n    # Use IaC (e.g., Terraform) to deploy the container to a staging environment\n    # along with its wrapper components (API Gateway, locked-down Security Group).\n    - terraform apply ./terraform/staging/\n\nrun-dast-scan:\n  stage: test\n  script:\n    # Run a DAST scan against the API Gateway endpoint in the staging environment\n    - ./run_zap_scan.sh http://staging.legacy-app.example.com\n\ndeploy-to-prod:\n  stage: deploy\n  script:\n    - terraform apply ./terraform/prod/\n  rules:\n    - if: $CI_COMMIT_BRANCH == 'main'"
                    },
                    {
                        "title": "Code Example 28: Legacy System Security Wrapper Framework",
                        "language": "nginx",
                        "code": "# Example NGINX configuration acting as a security wrapper\n\nserver {\n    listen 443 ssl;\n    \n    # 1. Provide modern TLS\n    ssl_certificate /etc/nginx/certs/legacy-app.crt;\n    ssl_certificate_key /etc/nginx/certs/legacy-app.key;\n    ssl_protocols TLSv1.2 TLSv1.3;\n\n    # 2. Integrate with modern authentication (e.g., using an auth proxy)\n    location / {\n        auth_request /_oauth2_proxy;\n        proxy_pass http://legacy-app-backend:8080;\n    }\n\n    # 3. Add security headers\n    add_header Strict-Transport-Security \"max-age=31536000\";\n\n    # 4. (Optional) Integrate a WAF module like ModSecurity\n}"
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "What is the primary challenge with securing legacy systems?",
                        "options": [
                            "They are too fast and modern.",
                            "They are often unpatchable, have no automated tests, and are difficult to change.",
                            "They have too many security features built-in.",
                            "They are always well-documented."
                        ],
                        "correct": 1,
                        "explanation": "Legacy systems are often brittle and run on unsupported software, making direct security improvements risky. This necessitates a strategy of external controls."
                    },
                    {
                        "id": 2,
                        "question": "The strategy of placing a modern reverse proxy or API Gateway in front of a legacy application to provide modern security features is called:",
                        "options": [
                            "Rewriting",
                            "Decommissioning",
                            "Wrapping",
                            "Ignoring"
                        ],
                        "correct": 2,
                        "explanation": "Wrapping is a pragmatic approach that improves the security of a legacy application from the outside, without requiring risky and expensive changes to the application's code itself."
                    },
                    {
                        "id": 3,
                        "question": "Which type of security testing is most suitable for a legacy application where you do not have the source code?",
                        "options": [
                            "SAST (Static Application Security Testing)",
                            "DAST (Dynamic Application Security Testing)",
                            "A manual code review",
                            "Unit testing"
                        ],
                        "correct": 1,
                        "explanation": "DAST is a 'black-box' technique that tests the running application from the outside. Since it doesn't need source code, it is an ideal way to find vulnerabilities in legacy systems."
                    },
                    {
                        "id": 4,
                        "question": "How can containerization help improve the security of a legacy application?",
                        "options": [
                            "It magically fixes all the bugs in the application's code.",
                            "It makes the application run slower.",
                            "It makes the application portable and allows you to apply modern runtime security monitoring and micro-segmentation controls.",
                            "It has no security benefits."
                        ],
                        "correct": 2,
                        "explanation": "Containerizing a legacy application provides a consistent package for deployment and allows you to 'wrap' it with modern cloud-native security controls, even if the application itself cannot be changed."
                    }
                ]
            }
        },
        {
            "id": "lesson-29",
            "title": "Performance and Security Balance",
            "duration": "90 min",
            "objectives": [
                "Understand the performance impact of various security tools.",
                "Design a CI/CD pipeline that is both secure and fast.",
                "Learn strategies for parallelizing security tests to optimize speed.",
                "Develop a framework for making risk-based trade-off decisions."
            ],
            "content": {
                "overview": "Security controls can sometimes add latency and consume resources. In a performance-critical DevOps environment, it's essential to implement security without creating unacceptable delays. This lesson covers the architectural strategies for balancing strong security with the need for speed, ensuring the pipeline remains both secure and efficient.",
                "sections": [
                    {
                        "title": "Security Performance Optimization",
                        "content": "<p>Not all security scans are created equal. The key is to run the right scan at the right time.</p><h3>Tiered Scanning Strategy:</h3><ul><li><strong>On Every Commit (in feature branches):</strong> Run only the fastest checks that provide immediate feedback. This includes pre-commit hooks for secret scanning, linting, and very fast, incremental SAST scans.</li><li><strong>On Pull/Merge Request (to main):</strong> Run more comprehensive scans that take a few minutes. This is where you would run a full SAST scan and an SCA scan.</li><li><strong>Nightly or on a Schedule:</strong> Run the longest, most intensive scans. This is the ideal time for a full DAST scan of the staging environment or a deep container image scan.</li></ul><p>This tiered approach ensures developers get fast feedback for most changes, while still having deep scanning as a safety net.</p>",
                        "image": "https://images.unsplash.com/photo-1542382257-80deda0e5d99?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Parallel Security Testing Approaches",
                        "content": "<p>A CI/CD pipeline executes its stages in order. If you have multiple long-running scans in the same stage, they will run sequentially, adding up their total time. Most modern CI/CD platforms allow you to run jobs within a stage in parallel.</p><h3>Architectural Design:</h3><p>Design the 'scan' stage of your pipeline to run different security checks as parallel jobs. For example, the SAST scan, SCA scan, and IaC scan can all be run at the same time. The pipeline will only proceed once all the parallel jobs in the stage have successfully completed. This significantly reduces the total wall-clock time of the pipeline.</p>",
                        "image": "https://images.unsplash.com/photo-1521791136064-7986c2920216?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Resource Allocation Strategies",
                        "content": "<p>Security tools, especially scanners, can be resource-intensive. The architecture for the CI/CD runners must account for this.</p><h3>Strategies:</h3><ul><li><strong>Dedicated Runners for Scans:</strong> Use a separate pool of CI/CD runners (agents) with more CPU and memory that are dedicated to running security scans. This prevents security jobs from starving regular build and test jobs of resources.</li><li><strong>Autoscaling Runners:</strong> In a cloud environment, configure the runner fleet to autoscale. This allows the system to spin up more runner instances when there is a high demand (e.g., many developers committing code) and scale down to save costs during off-hours.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1510915228340-29c85a43dcfe?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Trade-off Decision Frameworks",
                        "content": "<p>Sometimes, a security control and a performance requirement will be in direct conflict. The architect must provide a framework for making a risk-based decision.</p><h3>Example:</h3><p>A RASP agent provides excellent runtime protection but adds 5% latency to API calls. The business has a strict performance SLA that this violates.</p><ol><li><strong>Quantify the Risk:</strong> What is the specific risk the RASP agent is mitigating? How likely is it?</li><li><strong>Explore Alternatives:</strong> Can we achieve a similar level of protection with a combination of a WAF and better DAST testing, which have less performance impact?</li><li><strong>Risk Acceptance:</strong> If no alternative is viable, the architect must present the trade-off to the business and risk owners. 'We can meet the performance SLA, but it requires us to accept the risk of X. Or, we can mitigate risk X, but we will miss the SLA.' The business owner must then make the final decision and formally accept the risk.</li></ol>",
                        "image": "https://images.unsplash.com/photo-1556155092-490a1ba16284?w=800&h=400&fit-crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 29: Performance-Optimized Security Pipeline",
                        "language": "yaml",
                        "code": "# Example of a parallelized scan stage in GitLab CI\n\nstages:\n  - build\n  - scan\n  - deploy\n\nbuild-app:\n  stage: build\n  script: mvn install\n\n# All jobs in the 'scan' stage will run in parallel\nsast-scan:\n  stage: scan\n  script: ./run_sast.sh\n\nsca-scan:\n  stage: scan\n  script: ./run_sca.sh\n\niac-scan:\n  stage: scan\n  script: ./run_iac_scan.sh\n\n# The 'deploy' stage will not start until ALL jobs in the 'scan' stage have passed.\ndeploy-to-staging:\n  stage: deploy\n  script: ./deploy.sh"
                    },
                    {
                        "title": "Code Example 29: Intelligent Security Tool Orchestration System",
                        "language": "python",
                        "code": "import git_api\n\ndef should_run_deep_scan(pull_request):\n    \"\"\"Intelligently decide whether to run a long, intensive scan.\"\"\"\n    \n    # Get the files changed in this pull request\n    changed_files = git_api.get_changed_files(pull_request)\n    \n    # Define high-risk files or directories\n    high_risk_paths = ['src/auth/', 'src/payment/', 'pom.xml']\n    \n    for file_path in changed_files:\n        for risk_path in high_risk_paths:\n            if file_path.startswith(risk_path):\n                # If a high-risk file was changed, run the deep scan\n                return True\n    \n    # Otherwise, skip the deep scan to keep the pipeline fast\n    return False"
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "A strategy where fast, incremental scans are run on every commit, while longer, full-depth scans are run nightly, is an example of a:",
                        "options": [
                            "Tiered Scanning Strategy",
                            "Manual Scanning Strategy",
                            "A single-layer strategy",
                            "A slow pipeline"
                        ],
                        "correct": 0,
                        "explanation": "A tiered scanning strategy is a key architectural pattern for balancing speed and thoroughness. It provides fast feedback for most changes while ensuring deep analysis is still performed regularly."
                    },
                    {
                        "id": 2,
                        "question": "How can you reduce the total wall-clock time of the security scanning stage in a CI/CD pipeline?",
                        "options": [
                            "Run all scans sequentially on a single machine.",
                            "Remove all security scanning.",
                            "Configure the SAST, SCA, and IaC scan jobs to run in parallel.",
                            "Add more security scans to the same stage."
                        ],
                        "correct": 2,
                        "explanation": "Parallelization is a standard technique for optimizing pipeline performance. By running independent jobs concurrently, the total time for the stage is determined by the longest-running job, not the sum of all job times."
                    },
                    {
                        "id": 3,
                        "question": "Using a separate pool of high-CPU CI/CD runners specifically for security scans is a strategy for:",
                        "options": [
                            "Making the scans run slower.",
                            "Saving money on licensing.",
                            "Resource Allocation and Isolation.",
                            "Manual testing."
                        ],
                        "correct": 2,
                        "explanation": "This ensures that resource-intensive security scans do not slow down the normal build and test jobs for other teams, preventing the security toolchain from becoming a bottleneck."
                    },
                    {
                        "id": 4,
                        "question": "If a security control and a business performance requirement are in direct conflict, what is the architect's role?",
                        "options": [
                            "To always insist on the security control, regardless of business impact.",
                            "To always remove the security control to meet the performance goal.",
                            "To quantify the risk, explore alternatives, and present a clear, risk-based trade-off to the business owner for a final decision.",
                            "To ignore the conflict."
                        ],
                        "correct": 2,
                        "explanation": "The architect's role is to be a risk advisor. They must provide the data and options so that the business can make an informed decision and formally accept any residual risk."
                    }
                ]
            }
        },
        {
            "id": "lesson-30",
            "title": "Future of DevSecOps",
            "duration": "90 min",
            "objectives": [
                "Analyze emerging technology trends and their impact on DevSecOps.",
                "Explore the future role of AI and ML in security automation.",
                "Understand the potential implications of quantum computing for security.",
                "Identify key areas for future research and career development."
            ],
            "content": {
                "overview": "The field of DevSecOps is constantly evolving. New technologies, new attack techniques, and new development paradigms require a continuous process of learning and adaptation. This final lesson looks to the future, exploring the emerging trends that will shape the next generation of DevSecOps architecture and practice.",
                "sections": [
                    {
                        "title": "AI/ML Security Automation",
                        "content": "<p>The future of DevSecOps will be increasingly driven by artificial intelligence. While we've discussed some current uses, the future potential is vast.</p><h3>Future Use Cases:</h3><ul><li><strong>Automated Code Remediation:</strong> AI models (like ChatGPT-4) are becoming capable of not just finding a vulnerability in code, but automatically writing and proposing the correct, secure code to fix it.</li><li><strong>Predictive Threat Modeling:</strong> An AI could analyze a proposed architectural change and predict the likely threats and vulnerabilities it would introduce.</li><li><strong>Autonomous Response:</strong> Incident response playbooks could become fully autonomous, with an AI agent analyzing an alert, investigating the cause, and taking containment actions without human intervention for common incidents.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1620712943543-285f231f7927?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Quantum Computing Implications",
                        "content": "<p>As covered in the Quantum-Resistant Architecture lesson, the eventual arrival of quantum computers will break most of the public-key cryptography that secures the internet and our software supply chains.</p><h3>Future of DevSecOps:</h3><p>DevSecOps pipelines will need to be the primary mechanism for driving the migration to Post-Quantum Cryptography (PQC). This will involve:</p><ul><li>Using SCA tools to find all instances of legacy cryptographic libraries.</li><li>Updating CI/CD templates to use new PQC-enabled compilers and libraries.</li><li>Building automated tests to ensure that the new cryptography is implemented correctly.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1510915228340-29c85a43dcfe?w=800&h=400&fit=crop"
                    },
                    {
                        "title": "Edge and Blockchain Security",
                        "content": "<p>As applications become more distributed, the DevSecOps model will need to adapt.</p><h3>Edge Computing:</h3><p>DevSecOps pipelines will need to manage the secure build and deployment of software to thousands or millions of distributed edge devices. This will require a robust architecture for secure remote updates and monitoring.</p><h3>Blockchain/Web3:</h3><p>The immutable nature of smart contracts makes 'shifting left' absolutely critical. A vulnerability deployed to a blockchain can be impossible to patch. The future of DevSecOps for Web3 will involve highly specialized static analysis tools and formal verification techniques to prove the correctness of smart contract code before deployment.</p>",
                        "image": "https://images.unsplash.com/photo-1642104793574-e395f87f5471?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Career Development Pathways",
                        "content": "<p>The skills learned in this course are in high demand and form the foundation for several career paths.</p><h3>Potential Roles:</h3><ul><li><strong>DevSecOps Engineer:</strong> A hands-on practitioner who builds and maintains the secure CI/CD pipeline.</li><li><strong>Security Architect:</strong> A strategic thinker who designs the overall security program and governance framework.</li><li><strong>Application Security Engineer:</strong> A specialist who works closely with development teams, performing threat modeling, code reviews, and penetration testing.</li><li><strong>Cloud Security Engineer:</strong> A specialist focused on securing the cloud platform and services that the DevSecOps pipeline runs on.</li></ul><p>The future belongs to security professionals who can combine deep technical knowledge with strong software development and automation skills.</p>",
                        "image": "https://images.unsplash.com/photo-1556155092-490a1ba16284?w=800&h=400&fit=crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Lab 30: Future DevSecOps Architecture Design",
                        "language": "python",
                        "code": "# Conceptual code for an AI-powered code remediation service\n\nimport large_language_model_api\n\ndef fix_vulnerable_code(code_snippet, vulnerability_type):\n    \"\"\"Uses a Large Language Model to propose a fix for a vulnerability.\"\"\"\n    \n    prompt = f\"\"\"\nThe following Python code has a '{vulnerability_type}' vulnerability.\nRewrite the code to fix the vulnerability, explaining your changes.\n\nCode:\n---\n{code_snippet}\n---\n\"\"\"\n\n    # Call the LLM API with the prompt\n    response = large_language_model_api.generate(prompt)\n    \n    # The response would contain the proposed secure code and an explanation\n    return response['fixed_code'], response['explanation']\n\n# This service could be integrated into a CI/CD pipeline to automatically\n# create a pull request with the AI-generated fix."
                    },
                    {
                        "title": "Code Example 30: Next-Generation DevSecOps Platform",
                        "language": "json",
                        "code": "{\n  \"pipelineEvent\": \"PULL_REQUEST_CREATED\",\n  \"analysis\": {\n    \"riskScore\": 8.5,\n    \"predictionEngine\": \"v2.1-beta\",\n    \"contributors\": [\n      {\n        \"type\": \"SAST\",\n        \"details\": \"New SQL Injection vulnerability detected.\"\n      },\n      {\n        \"type\": \"BEHAVIORAL\",\n        \"details\": \"Commit includes unusually large number of changes to authentication logic.\"\n      },\n      {\n        \"type\": \"REPUTATION\",\n        \"details\": \"Code author has a history of introducing security bugs.\"\n      }\n    ]\n  },\n  \"action\": \"REQUIRE_MANUAL_APPROVAL_FROM_SENIOR_ARCHITECT\"\n}"
                    }
                ]
            },
            "quiz": {
                "passingScore": 75,
                "questions": [
                    {
                        "id": 1,
                        "question": "Using an AI model to automatically rewrite vulnerable code with a secure alternative is an example of what future trend?",
                        "options": [
                            "Manual Penetration Testing",
                            "Automated Code Remediation",
                            "Legacy System Modernization",
                            "Compliance Auditing"
                        ],
                        "correct": 1,
                        "explanation": "Generative AI and Large Language Models are showing great promise in their ability to understand and write code, which will likely lead to powerful tools that can not only find but also fix security vulnerabilities automatically."
                    },
                    {
                        "id": 2,
                        "question": "Why is the 'shift-left' principle especially critical for smart contract development in a Web3/blockchain context?",
                        "options": [
                            "Because smart contracts run very slowly.",
                            "Because once deployed to a blockchain, a vulnerable smart contract is often immutable and cannot be easily patched.",
                            "Because blockchain is not affected by security vulnerabilities.",
                            "Because there are no security tools for smart contracts."
                        ],
                        "correct": 1,
                        "explanation": "The immutable nature of most blockchains means that security must be perfected before deployment. A vulnerability in a deployed smart contract can lead to an irreversible loss of funds, making pre-deployment testing and verification paramount."
                    },
                    {
                        "id": 3,
                        "question": "Which of the following describes a hands-on practitioner who primarily focuses on building and maintaining the secure CI/CD toolchain?",
                        "options": [
                            "Security Architect",
                            "DevSecOps Engineer",
                            "Chief Information Security Officer (CISO)",
                            "Project Manager"
                        ],
                        "correct": 1,
                        "explanation": "The DevSecOps Engineer is typically the hands-on role responsible for the technical implementation and operation of the automated security pipeline and its integrated tools."
                    },
                    {
                        "id": 4,
                        "question": "The primary impact of quantum computing on DevSecOps will be:",
                        "options": [
                            "It will make CI/CD pipelines run faster.",
                            "It will have no impact.",
                            "It will require a massive, pipeline-driven effort to migrate all applications and systems to post-quantum cryptography.",
                            "It will eliminate the need for security scanning."
                        ],
                        "correct": 2,
                        "explanation": "The threat of quantum computing breaking modern public-key cryptography will necessitate one of the largest and most complex technology migrations in history, and automated DevSecOps pipelines will be the essential tool for carrying out that migration securely and efficiently."
                    }
                ]
            }
        }
    ]
}

      // =====================================================
      // GLOBAL VARIABLES
      // =====================================================
      let currentUser = null;
      let currentLessonIndex = 0;
      let courseProgress = {};
      let userStats = {};
      let quizState = {
        currentQuestion: 0,
        answers: [],
        score: 0,
        isComplete: false,
      };

      // Enhanced session tracking
      let courseSession = {
        startTime: null,
        totalStudyTime: 0,
        lessonsStarted: 0,
        lessonsCompleted: 0,
        pageLoadTime: new Date(),
        interactionCount: 0,
        lastActivityTime: new Date(),
      };

      // Music Player Variables
      let audioPlayer = new Audio();

      // Achievement notification system
      let notificationQueue = [];
      let isShowingNotification = false;

      // =====================================================
      // INITIALIZATION
      // =====================================================
      document.addEventListener("DOMContentLoaded", async () => {
        try {
          showLoadingScreen();
          await checkAuth();

          if (currentUser) {
            // Initialize session tracking
            startCourseSession();

            // Load course data and progress
            await loadCourseData();
            await loadUserProfile();
            await loadProgress();

            // Initialize UI
            initializeEventListeners();
            renderSidebar();
            loadLesson(currentLessonIndex);

            // Initialize additional features
            initMusicPlayer();
            addMusicIndicator();
            initializeActivityTracking();

            hideLoadingScreen();
          } else {
            openAuthModal();
          }
        } catch (error) {
          console.error("Error initializing course:", error);
          hideLoadingScreen();
          showToast("Failed to initialize course system", "error");
        }
      });

      // =====================================================
      // AUTHENTICATION SYSTEM
      // =====================================================
      async function checkAuth() {
        try {
          const {
            data: { session },
            error,
          } = await supabase.auth.getSession();

          if (error) {
            console.error("Auth error:", error);
            currentUser = null;
            openAuthModal();
            return;
          }

          if (!session) {
            currentUser = null;
            openAuthModal();
            return;
          }

          currentUser = session.user;
          updateUIWithUser();
        } catch (error) {
          console.error("Error checking auth:", error);
          currentUser = null;
          openAuthModal();
        }
      }

      function updateUIWithUser() {
        if (!currentUser) return;

        const name =
          currentUser.user_metadata?.full_name ||
          currentUser.email.split("@")[0];
        const userElements = document.querySelectorAll("[data-user-name]");
        userElements.forEach((el) => (el.textContent = name));
      }

      // =====================================================
      // USER PROFILE & STATS MANAGEMENT
      // =====================================================
      async function loadUserProfile() {
        try {
          //  Step 1: Try to fetch existing profile
          const { data: profile, error } = await supabase
            .from("profiles")
            .select("*")
            .eq("id", currentUser.id)
            .single();

          if (error && error.code !== "PGRST116") {
            throw error;
          }

          if (!profile) {
            //  Step 2: Create new profile if missing
            await createUserProfile();
          } else {
            //  Step 3: Use existing profile
            userStats = profile;
            await updateLastActivity();
          }
        } catch (error) {
          console.error(" Error loading user profile:", error);
          showToast("Failed to load user profile", "error");
        }
      }
      async function createUserProfile() {
        try {
          const newProfile = {
            id: currentUser.id,
            full_name: currentUser.user_metadata?.full_name || "",
            email: currentUser.email,
            level: "Script Kiddie",
            total_points: 0,
            completed_courses: 0,
            current_streak: 0,
            total_certificates: 0,
            total_achievements: 0,
            sections_visited: 0,
            bonus_points: 0,
            in_progress_courses: 0,
            settings_changed: 0,
            midnight_sessions: 0,
            early_sessions: 0,
            weekend_sessions: 0,
            last_activity: new Date().toISOString(),
            created_at: new Date().toISOString(),
          };

          const { error } = await supabase
            .from("profiles")
            .insert([newProfile]);

          if (!error) {
            userStats = newProfile;
            // Award first login achievement
            setTimeout(() => checkAndUnlockAchievement("first_login"), 1000);
          }
        } catch (error) {
          console.error("Error creating user profile:", error);
        }
      }

      async function updateLastActivity() {
        try {
          const now = new Date();

          // Update activity tracking
          courseSession.lastActivityTime = now;

          // Update database
          await supabase
            .from("profiles")
            .update({
              last_activity: now.toISOString(),
            })
            .eq("id", currentUser.id);

          // Check time-based achievements
          await checkTimeBasedAchievements(now);
        } catch (error) {
          console.error("Error updating last activity:", error);
        }
      }

      // =====================================================
      // COURSE SESSION MANAGEMENT
      // =====================================================
      function startCourseSession() {
        courseSession.startTime = new Date();
        courseSession.pageLoadTime = new Date();

        logUserActivity("course_session_start", {
          course_id: COURSE_DATA.id,
          course_title: COURSE_DATA.title,
          user_agent: navigator.userAgent,
          screen_resolution: `${screen.width}x${screen.height}`,
        });

        // Check daily streak
        checkDailyStreak();
      }

      function initializeActivityTracking() {
        // Track page focus/blur for accurate study time
        document.addEventListener("visibilitychange", handleVisibilityChange);

        // Track user interactions
        ["click", "keydown", "scroll", "mousemove"].forEach((event) => {
          document.addEventListener(event, trackUserInteraction, {
            passive: true,
          });
        });

        // Periodic activity updates
        setInterval(updateStudyTime, 60000); // Every minute

        // Save session data before page unload
        window.addEventListener("beforeunload", saveSessionData);
      }

      function handleVisibilityChange() {
        if (document.hidden) {
          courseSession.lastActivityTime = new Date();
        } else {
          // Page became visible again - update activity
          updateLastActivity();
        }
      }

      function trackUserInteraction() {
        courseSession.interactionCount++;
        courseSession.lastActivityTime = new Date();

        // Throttle activity updates
        if (courseSession.interactionCount % 50 === 0) {
          updateLastActivity();
        }
      }

      function updateStudyTime() {
        if (!courseSession.startTime || document.hidden) return;

        const now = new Date();
        const sessionDuration = now - courseSession.startTime;
        courseSession.totalStudyTime = Math.floor(sessionDuration / 1000 / 60); // in minutes

        // Update progress with study time
        saveProgress();
      }

      function saveSessionData() {
        if (!currentUser || !courseSession.startTime) return;

        const sessionData = {
          user_id: currentUser.id,
          course_id: COURSE_DATA.id,
          session_duration: courseSession.totalStudyTime,
          lessons_viewed: courseSession.lessonsStarted,
          lessons_completed: courseSession.lessonsCompleted,
          interactions: courseSession.interactionCount,
          session_date: courseSession.startTime.toISOString().split("T")[0],
        };

        // Store in localStorage as backup
        localStorage.setItem(
          "course_session_backup",
          JSON.stringify(sessionData)
        );

        // Try to save to database
        logUserActivity("course_session_end", sessionData);
      }

      // =====================================================
      // COURSE DATA & PROGRESS MANAGEMENT
      // =====================================================
      async function loadCourseData() {
        try {
          // Update course info in UI
          document.getElementById("courseTitle").textContent =
            COURSE_DATA.title;
          document.getElementById("totalLessons").textContent =
            COURSE_DATA.lessons.length;

          // Log course access
          logUserActivity("course_access", {
            course_id: COURSE_DATA.id,
            course_title: COURSE_DATA.title,
          });
        } catch (error) {
          console.error("Error loading course data:", error);
        }
      }

      async function loadProgress() {
        try {
          // Get existing progress from database
          const { data, error } = await supabase
            .from("course_progress")
            .select("*")
            .eq("user_id", currentUser.id)
            .eq("course_id", COURSE_DATA.id)
            .single();

          if (error && error.code !== "PGRST116") {
            throw error;
          }

          if (data) {
            courseProgress = JSON.parse(data.lesson_progress || "{}");
            currentLessonIndex = data.current_lesson || 0;

            // Update session tracking
            courseSession.lessonsStarted = Object.keys(courseProgress).length;
            courseSession.lessonsCompleted = Object.values(
              courseProgress
            ).filter((p) => p.completed).length;
          } else {
            // Initialize new progress
            courseProgress = {};
            currentLessonIndex = 0;
            await saveProgress();

            // Award first course start achievement
            await checkAndUnlockAchievement("first_course_start");
          }

          updateProgressDisplay();
        } catch (error) {
          console.error("Error loading progress:", error);
          showToast("Failed to load progress", "error");
        }
      }

      async function saveProgress() {
        try {
          if (!currentUser) return;

          const now = new Date();
          const progressData = {
            user_id: currentUser.id,
            course_id: COURSE_DATA.id,
            course_title: COURSE_DATA.title,
            current_lesson: currentLessonIndex,
            lesson_progress: JSON.stringify(courseProgress),
            progress: calculateOverallProgress(),
            lessons_completed: getCompletedLessonsCount(),
            lessons_started: Object.keys(courseProgress).length,
            study_time_minutes: courseSession.totalStudyTime,
            last_accessed: now.toISOString(),
            updated_at: now.toISOString(),
          };

          // Upsert progress
          const { error } = await supabase
            .from("course_progress")
            .upsert([progressData]);

          if (error) throw error;

          // Update user stats
          await updateUserStats();

          updateProgressDisplay();
        } catch (error) {
          console.error("Error saving progress:", error);
          showToast("Failed to save progress", "error");
        }
      }

      async function updateUserStats() {
        try {
          // Get all course progress for this user
          const { data: allProgress, error } = await supabase
            .from("course_progress")
            .select("progress, course_id, study_time_minutes")
            .eq("user_id", currentUser.id);

          if (error) throw error;

          // Calculate stats
          const completedCourses =
            allProgress?.filter((p) => p.progress >= 100).length || 0;
          const inProgressCourses =
            allProgress?.filter((p) => p.progress > 0 && p.progress < 100)
              .length || 0;
          const totalStudyTime =
            allProgress?.reduce(
              (sum, p) => sum + (p.study_time_minutes || 0),
              0
            ) || 0;

          // Calculate points (500 per completed course + achievement points)
          const coursePoints = completedCourses * 500;
          const bonusPoints = userStats.bonus_points || 0;
          const totalPoints = coursePoints + bonusPoints;

          // Update profile
          const updateData = {
            completed_courses: completedCourses,
            in_progress_courses: inProgressCourses,
            total_points: totalPoints,
            total_study_time: totalStudyTime,
            last_activity: new Date().toISOString(),
          };

          const { error: updateError } = await supabase
            .from("profiles")
            .update(updateData)
            .eq("id", currentUser.id);

          if (updateError) throw updateError;

          // Update local stats
          Object.assign(userStats, updateData);
        } catch (error) {
          console.error("Error updating user stats:", error);
        }
      }

      function calculateOverallProgress() {
        const completedLessons = getCompletedLessonsCount();
        return Math.round(
          (completedLessons / COURSE_DATA.lessons.length) * 100
        );
      }

      function getCompletedLessonsCount() {
        return Object.values(courseProgress).filter(
          (lesson) => lesson.completed
        ).length;
      }

      function updateProgressDisplay() {
        const completedCount = getCompletedLessonsCount();
        const progressPercent = calculateOverallProgress();

        // Update UI elements
        const elements = {
          completedLessons: completedCount,
          courseProgressPercent: `${progressPercent}%`,
        };

        Object.entries(elements).forEach(([id, value]) => {
          const element = document.getElementById(id);
          if (element) element.textContent = value;
        });

        // Update progress bar
        const progressBar = document.getElementById("courseProgressFill");
        if (progressBar) progressBar.style.width = `${progressPercent}%`;
      }

      // =====================================================
      // LESSON MANAGEMENT
      // =====================================================
      function loadLesson(index) {
        if (index < 0 || index >= COURSE_DATA.lessons.length) return;

        const lesson = COURSE_DATA.lessons[index];
        currentLessonIndex = index;

        // Mark lesson as started and track activity
        if (!courseProgress[lesson.id]) {
          courseProgress[lesson.id] = {
            started: true,
            completed: false,
            startedAt: new Date().toISOString(),
            timeSpent: 0,
          };

          courseSession.lessonsStarted++;
          saveProgress();

          // Log lesson start
          logUserActivity("lesson_start", {
            lesson_id: lesson.id,
            lesson_title: lesson.title,
            lesson_index: index,
          });
        }

        // Update lesson start time for time tracking
        courseProgress[lesson.id].currentSessionStart = new Date();

        // Update sidebar and navigation
        renderSidebar();
        updateNavigationButtons();

        // Update header info
        updateLessonHeader(lesson, index);

        // Render lesson content
        renderLessonContent(lesson);

        // Smooth scroll and animations
        window.scrollTo({ top: 0, behavior: "smooth" });
        document.getElementById("contentBody").scrollTop = 0;

        const contentBody = document.getElementById("contentBody");
        contentBody.classList.add("fade-in");
        setTimeout(() => contentBody.classList.remove("fade-in"), 500);

        // Check lesson-based achievements
        checkLessonAchievements(index + 1);
      }

      function updateLessonHeader(lesson, index) {
        const elements = {
          currentLessonNumber: index + 1,
          currentLessonTitle: lesson.title,
          navInfo: `Lesson ${index + 1} of ${COURSE_DATA.lessons.length}`,
        };

        Object.entries(elements).forEach(([id, value]) => {
          const element = document.getElementById(id);
          if (element) element.textContent = value;
        });
      }

      function renderSidebar() {
        const lessonNav = document.getElementById("lessonNav");
        if (!lessonNav) return;

        lessonNav.innerHTML = "";

        COURSE_DATA.lessons.forEach((lesson, index) => {
          const lessonItem = document.createElement("div");
          lessonItem.className = "lesson-item";

          // Determine lesson status
          const lessonProgress = courseProgress[lesson.id];
          const isCompleted = lessonProgress?.completed || false;
          const isInProgress = lessonProgress?.started || false;
          const isLocked = !isCompleted && !canAccessLesson(index);
          const isActive = index === currentLessonIndex;

          // Apply status classes
          if (isCompleted) lessonItem.classList.add("completed");
          if (isLocked) lessonItem.classList.add("locked");
          if (isActive) lessonItem.classList.add("active");

          // Determine status display
          let statusClass = "not-started";
          let statusIcon = index + 1;

          if (isCompleted) {
            statusClass = "completed";
            statusIcon = "";
          } else if (isInProgress) {
            statusClass = "in-progress";
            statusIcon = "";
          }

          // Create lesson item HTML
          lessonItem.innerHTML = `
            <div class="lesson-status ${statusClass}">${statusIcon}</div>
            <div class="lesson-info">
                <div class="lesson-title">${lesson.title}</div>
                <div class="lesson-meta">
                    ${
                      isCompleted
                        ? "Completed"
                        : isInProgress
                        ? "In Progress"
                        : isLocked
                        ? "Locked"
                        : "Not Started"
                    }
                </div>
            </div>
            <div class="lesson-duration">${lesson.duration}</div>
        `;

          // Add click handler if not locked
          if (!isLocked) {
            lessonItem.addEventListener("click", () => {
              if (index !== currentLessonIndex) {
                // Track lesson time before switching
                trackLessonTime();

                currentLessonIndex = index;
                loadLesson(index);
                closeSidebar();
              }
            });
          }

          lessonNav.appendChild(lessonItem);
        });
      }

      function canAccessLesson(index) {
        if (index === 0) return true; // First lesson always accessible

        // Can access if previous lesson is completed
        const previousLessonId = COURSE_DATA.lessons[index - 1].id;
        return courseProgress[previousLessonId]?.completed || false;
      }

      function trackLessonTime() {
        const currentLesson = COURSE_DATA.lessons[currentLessonIndex];
        const lessonProgress = courseProgress[currentLesson.id];

        if (lessonProgress?.currentSessionStart) {
          const sessionTime = Math.floor(
            (new Date() - new Date(lessonProgress.currentSessionStart)) /
              1000 /
              60
          );
          lessonProgress.timeSpent =
            (lessonProgress.timeSpent || 0) + sessionTime;
          delete lessonProgress.currentSessionStart;
        }
      }

      // =====================================================
      // LESSON CONTENT RENDERING
      // =====================================================
      function renderLessonContent(lesson) {
        const contentContainer = document.getElementById("lessonContent");
        if (!contentContainer) return;

        let contentHTML = `
        <div class="content-section">
            <h2>Learning Objectives</h2>
            <ul>
                ${lesson.objectives.map((obj) => `<li>${obj}</li>`).join("")}
            </ul>
        </div>
        
        <div class="content-section">
            <h2>Overview</h2>
            <p>${lesson.content.overview}</p>
        </div>
    `;

        // Render content sections
        lesson.content.sections.forEach((section) => {
          contentHTML += `
            <div class="content-section">
                <h2>${section.title}</h2>
                ${section.content}
                ${
                  section.image
                    ? `<img src="${section.image}" alt="${section.title}" class="content-image" loading="lazy">`
                    : ""
                }
            </div>
        `;
        });

        // Render code examples
        if (
          lesson.content.codeExamples &&
          lesson.content.codeExamples.length > 0
        ) {
          contentHTML += `<div class="content-section"><h2>Code Examples</h2></div>`;

          lesson.content.codeExamples.forEach((example, index) => {
            const codeId = `code-${lesson.id}-${index}`;
            contentHTML += `
                <div class="code-section">
                    <div class="code-header">
                        <span class="code-title">${example.title}</span>
                        <button class="copy-btn" onclick="copyCode('${codeId}')">
                            <i class="fas fa-copy"></i> Copy
                        </button>
                    </div>
                    <pre class="code-block"><code id="${codeId}" class="language-${
              example.language
            }">${escapeHtml(example.code)}</code></pre>
                </div>
            `;
          });
        }

        // Render quiz
        contentHTML += renderQuiz(lesson.quiz);

        contentContainer.innerHTML = contentHTML;

        // Highlight code syntax if Prism is available
        setTimeout(() => {
          if (window.Prism) {
            Prism.highlightAll();
          }
        }, 100);
      }

      // =====================================================
      // QUIZ SYSTEM
      // =====================================================
      function renderQuiz(quiz) {
        const currentLessonProgress =
          courseProgress[COURSE_DATA.lessons[currentLessonIndex].id];
        const isCompleted = currentLessonProgress?.completed || false;

        let quizHTML = `
        <div class="quiz-section" id="quizSection">
            <div class="quiz-header">
                <h2 class="quiz-title">
                    <i class="fas fa-clipboard-check"></i>
                    Knowledge Check
                </h2>
                <p class="quiz-info">
                    Complete this quiz with ${quiz.passingScore}% or higher to unlock the next lesson.
                </p>
            </div>
    `;

        if (isCompleted) {
          const savedScore = currentLessonProgress.quizScore || 0;
          quizHTML += `
            <div class="quiz-results show">
                <div class="quiz-score pass">${savedScore}%</div>
                <div class="quiz-message">
                    <strong>Lesson Completed!</strong><br>
                    You've successfully passed this lesson's quiz.
                </div>
            </div>
        `;
        } else {
          // Render quiz questions
          quiz.questions.forEach((question, qIndex) => {
            quizHTML += `
                <div class="quiz-question ${
                  qIndex === 0 ? "active" : ""
                }" data-question="${qIndex}">
                    <div class="question-header">
                        <span class="question-number">Question ${
                          qIndex + 1
                        }</span>
                        <span class="question-progress">${qIndex + 1}/${
              quiz.questions.length
            }</span>
                    </div>
                    <div class="question-text">${question.question}</div>
                    <div class="question-options">
                        ${question.options
                          .map(
                            (option, oIndex) => `
                            <div class="option" data-option="${oIndex}" onclick="selectOption(${qIndex}, ${oIndex})">
                                <span class="option-letter">${String.fromCharCode(
                                  65 + oIndex
                                )}</span>
                                <span class="option-text">${option}</span>
                            </div>
                        `
                          )
                          .join("")}
                    </div>
                </div>
            `;
          });

          quizHTML += `
            <div class="quiz-controls">
                <button class="btn btn-secondary" id="prevQuestionBtn" onclick="previousQuestion()" disabled>
                    <i class="fas fa-chevron-left"></i>
                    Previous
                </button>
                <div>
                    <button class="btn btn-secondary" id="nextQuestionBtn" onclick="nextQuestion()" disabled>
                        Next
                        <i class="fas fa-chevron-right"></i>
                    </button>
                    <button class="btn btn-primary" id="submitQuizBtn" onclick="submitQuiz()" style="display: none;">
                        <i class="fas fa-check"></i>
                        Submit Quiz
                    </button>
                </div>
            </div>

            <div class="quiz-results" id="quizResults">
                <div class="quiz-score" id="quizScore">0%</div>
                <div class="quiz-message" id="quizMessage"></div>
                <div class="quiz-actions">
                    <button class="btn btn-primary" id="continueBtn" onclick="completeLesson()" style="display: none;">
                        <i class="fas fa-arrow-right"></i>
                        Continue to Next Lesson
                    </button>
                    <button class="btn btn-secondary" onclick="retakeQuiz()">
                        <i class="fas fa-redo"></i>
                        Retake Quiz
                    </button>
                </div>
            </div>
        `;
        }

        quizHTML += "</div>";
        return quizHTML;
      }

      // Quiz interaction functions
      function selectOption(questionIndex, optionIndex) {
        // Clear previous selections
        document
          .querySelectorAll(`[data-question="${questionIndex}"] .option`)
          .forEach((opt) => {
            opt.classList.remove("selected");
          });

        // Select current option
        const selectedOption = document.querySelector(
          `[data-question="${questionIndex}"] [data-option="${optionIndex}"]`
        );
        selectedOption.classList.add("selected");

        // Store answer
        quizState.answers[questionIndex] = optionIndex;

        // Update navigation
        const isLastQuestion =
          questionIndex ===
          COURSE_DATA.lessons[currentLessonIndex].quiz.questions.length - 1;
        if (isLastQuestion) {
          document.getElementById("submitQuizBtn").style.display =
            "inline-flex";
          document.getElementById("nextQuestionBtn").style.display = "none";
        } else {
          document.getElementById("nextQuestionBtn").disabled = false;
        }
      }

      function nextQuestion() {
        const currentQuestionEl = document.querySelector(
          ".quiz-question.active"
        );
        const nextQuestionEl = currentQuestionEl.nextElementSibling;

        if (
          nextQuestionEl &&
          nextQuestionEl.classList.contains("quiz-question")
        ) {
          currentQuestionEl.classList.remove("active");
          nextQuestionEl.classList.add("active");
          quizState.currentQuestion++;
          updateQuizNavigation();
        }
      }

      function previousQuestion() {
        const currentQuestionEl = document.querySelector(
          ".quiz-question.active"
        );
        const prevQuestionEl = currentQuestionEl.previousElementSibling;

        if (
          prevQuestionEl &&
          prevQuestionEl.classList.contains("quiz-question")
        ) {
          currentQuestionEl.classList.remove("active");
          prevQuestionEl.classList.add("active");
          quizState.currentQuestion--;
          updateQuizNavigation();
        }
      }

      function updateQuizNavigation() {
        const totalQuestions =
          COURSE_DATA.lessons[currentLessonIndex].quiz.questions.length;
        const prevBtn = document.getElementById("prevQuestionBtn");
        const nextBtn = document.getElementById("nextQuestionBtn");
        const submitBtn = document.getElementById("submitQuizBtn");

        prevBtn.disabled = quizState.currentQuestion === 0;

        const hasAnswer =
          quizState.answers[quizState.currentQuestion] !== undefined;
        const isLastQuestion = quizState.currentQuestion === totalQuestions - 1;

        if (isLastQuestion) {
          nextBtn.style.display = "none";
          submitBtn.style.display = hasAnswer ? "inline-flex" : "none";
        } else {
          nextBtn.style.display = "inline-flex";
          nextBtn.disabled = !hasAnswer;
          submitBtn.style.display = "none";
        }
      }

      async function submitQuiz() {
        const lesson = COURSE_DATA.lessons[currentLessonIndex];
        const quiz = lesson.quiz;
        let correctAnswers = 0;

        // Hide questions and controls
        document
          .querySelectorAll(".quiz-question")
          .forEach((q) => (q.style.display = "none"));
        document.querySelector(".quiz-controls").style.display = "none";

        // Calculate score and highlight answers
        quiz.questions.forEach((question, index) => {
          const userAnswer = quizState.answers[index];
          const correctAnswer = question.correct;
          const isCorrect = userAnswer === correctAnswer;

          if (isCorrect) correctAnswers++;

          // Highlight answers
          const questionEl = document.querySelector(
            `[data-question="${index}"]`
          );
          const options = questionEl.querySelectorAll(".option");

          options[correctAnswer].classList.add("correct");
          if (userAnswer !== correctAnswer && userAnswer !== undefined) {
            options[userAnswer].classList.add("incorrect");
          }
        });

        const score = Math.round(
          (correctAnswers / quiz.questions.length) * 100
        );
        const passed = score >= quiz.passingScore;

        // Update quiz results UI
        const quizScore = document.getElementById("quizScore");
        const quizMessage = document.getElementById("quizMessage");
        const quizActions = document.querySelector(".quiz-actions");

        quizScore.textContent = `${score}%`;
        quizScore.className = `quiz-score ${passed ? "pass" : "fail"}`;

        if (passed) {
          quizMessage.innerHTML = `
            <strong>Congratulations!</strong><br>
            You passed with ${score}%. You can now proceed to the next lesson.
        `;

          quizActions.innerHTML = `
            <button class="btn btn-primary" onclick="completeLesson()">
                <i class="fas fa-arrow-right"></i>
                Continue to Next Lesson
            </button>
        `;

          // Mark lesson as completed
          await markLessonComplete(score);
        } else {
          quizMessage.innerHTML = `
            <strong>Not quite there yet.</strong><br>
            You scored ${score}%. You need ${quiz.passingScore}% to pass. Review the material and try again.
        `;

          quizActions.innerHTML = `
            <button class="btn btn-secondary" onclick="retakeQuiz()">
                <i class="fas fa-redo"></i>
                Retake Quiz
            </button>
        `;
        }

        document.getElementById("quizResults").classList.add("show");

        // Log quiz completion
        logUserActivity("quiz_completed", {
          lesson_id: lesson.id,
          lesson_title: lesson.title,
          score: score,
          passed: passed,
          attempts: (courseProgress[lesson.id]?.quizAttempts || 0) + 1,
        });

        // Scroll to results
        document
          .getElementById("quizResults")
          .scrollIntoView({ behavior: "smooth" });
      }

      function retakeQuiz() {
        // Reset quiz state
        quizState = {
          currentQuestion: 0,
          answers: [],
          score: 0,
          isComplete: false,
        };

        // Track quiz retry
        const lessonId = COURSE_DATA.lessons[currentLessonIndex].id;
        if (!courseProgress[lessonId]) courseProgress[lessonId] = {};
        courseProgress[lessonId].quizAttempts =
          (courseProgress[lessonId].quizAttempts || 0) + 1;

        // Reload lesson content
        loadLesson(currentLessonIndex);

        // Scroll to quiz
        setTimeout(() => {
          document
            .getElementById("quizSection")
            .scrollIntoView({ behavior: "smooth" });
        }, 500);
      }

      async function markLessonComplete(score) {
        const lesson = COURSE_DATA.lessons[currentLessonIndex];
        const lessonId = lesson.id;

        // Track lesson completion time
        trackLessonTime();

        // Update lesson progress
        courseProgress[lessonId] = {
          ...courseProgress[lessonId],
          completed: true,
          quizScore: score,
          completedAt: new Date().toISOString(),
          finalScore: score,
        };

        // Update session tracking
        courseSession.lessonsCompleted++;

        // Save progress to database
        await saveProgress();

        // Update UI
        renderSidebar();
        updateNavigationButtons();

        // Check various achievements
        await checkLessonCompletionAchievements();
        await checkPerfectScoreAchievements(score);
        await checkStudyTimeAchievements();

        // Log lesson completion
        logUserActivity("lesson_completed", {
          lesson_id: lessonId,
          lesson_title: lesson.title,
          final_score: score,
          time_spent: courseProgress[lessonId].timeSpent || 0,
          lesson_number: currentLessonIndex + 1,
        });

        showToast("Lesson completed successfully!", "success");
      }

      async function completeLesson() {
        if (currentLessonIndex < COURSE_DATA.lessons.length - 1) {
          // Move to next lesson
          currentLessonIndex++;
          loadLesson(currentLessonIndex);
        } else {
          // Course completion
          await completeCourse();
        }
      }

      async function completeCourse() {
        try {
          const completionTime = courseSession.totalStudyTime;

          // Update course progress to 100% completed
          await supabase
            .from("course_progress")
            .update({
              progress: 100,
              completed_at: new Date().toISOString(),
              completion_time_minutes: completionTime,
            })
            .eq("user_id", currentUser.id)
            .eq("course_id", COURSE_DATA.id);

          // Award course completion achievements
          await checkAndUnlockAchievement("course_completion_1");
          await checkSpeedCompletionAchievements(completionTime);
          await checkCourseStreakAchievements();

          // Update user stats
          await updateUserStats();

          // Show completion message
          showToast(
            "Congratulations! Course completed successfully!",
            "certificate"
          );

          // Log course completion
          logUserActivity("course_completed", {
            course_id: COURSE_DATA.id,
            course_title: COURSE_DATA.title,
            completion_time_minutes: completionTime,
            total_lessons: COURSE_DATA.lessons.length,
            average_quiz_score: calculateAverageQuizScore(),
          });

          // Redirect to dashboard after delay
          setTimeout(() => {
            window.location.href = "/dashboard.html";
          }, 3000);
        } catch (error) {
          console.error("Error completing course:", error);
          showToast("Error marking course as complete", "error");
        }
      }

      // =====================================================
      // ACHIEVEMENT INTEGRATION SYSTEM
      // =====================================================
      async function checkAndUnlockAchievement(
        achievementId,
        skipNotification = false
      ) {
        try {
          // Prevent duplicate checks
          const cacheKey = `achievement_${achievementId}_${currentUser.id}`;
          if (sessionStorage.getItem(cacheKey)) return false;

          // Check if already unlocked
          const { data: existing, error } = await supabase
            .from("user_achievements")
            .select("id")
            .eq("user_id", currentUser.id)
            .eq("achievement_id", achievementId)
            .single();

          if (existing) {
            sessionStorage.setItem(cacheKey, "true");
            return false;
          }

          // Award achievement
          const achievementData = {
            user_id: currentUser.id,
            achievement_id: achievementId,
            unlocked_at: new Date().toISOString(),
            points_awarded: getAchievementPoints(achievementId),
            context: "course_system",
          };

          const { data, error: insertError } = await supabase
            .from("user_achievements")
            .insert([achievementData])
            .select()
            .single();

          if (insertError) {
            if (insertError.code === "23505") return false; // Already exists
            throw insertError;
          }

          // Update user points
         await supabase.rpc('increment_user_stats', {
  user_id_param: currentUser.id,
  points_to_add: achievementData.points_awarded,
  achievements_to_add: 1
});

          // Cache and queue notification
          sessionStorage.setItem(cacheKey, "true");

          if (!skipNotification) {
            queueAchievementNotification({
              id: achievementId,
              name: getAchievementName(achievementId),
              description: getAchievementDescription(achievementId),
              points: achievementData.points_awarded,
              rarity: getAchievementRarity(achievementId),
              icon: getAchievementIcon(achievementId),
            });
          }

          return true;
        } catch (error) {
          console.error("Error unlocking achievement:", error);
          return false;
        }
      }

      // Helper functions for achievement data (replace with your actual achievement definitions)
      function getAchievementPoints(id) {
        const pointsMap = {
          first_course_start: 75,
          first_lesson: 100,
          course_completion_1: 500,
          perfect_score: 250,
          speed_demon: 750,
          marathon_learner: 500,
          night_owl: 200,
          early_bird: 200,
          weekend_warrior: 150,
          // Add more as needed
        };
        return pointsMap[id] || 100;
      }

      function getAchievementName(id) {
        const nameMap = {
          first_course_start: "Learning Initiated",
          first_lesson: "First Steps",
          course_completion_1: "Course Conqueror",
          perfect_score: "Perfectionist",
          speed_demon: "Speed Demon",
          // Add more as needed
        };
        return nameMap[id] || "Achievement Unlocked";
      }

      function getAchievementDescription(id) {
        const descMap = {
          first_course_start: "Start your first cybersecurity course",
          first_lesson: "Complete your first lesson",
          course_completion_1: "Complete your first course",
          perfect_score: "Score 100% on any quiz",
          speed_demon: "Complete a course in under 2 hours",
          // Add more as needed
        };
        return descMap[id] || "Achievement description";
      }

      function getAchievementRarity(id) {
        const rarityMap = {
          first_course_start: "common",
          first_lesson: "bronze",
          course_completion_1: "silver",
          perfect_score: "gold",
          speed_demon: "legendary",
          // Add more as needed
        };
        return rarityMap[id] || "common";
      }

      function getAchievementIcon(id) {
        const iconMap = {
          first_course_start: "fas fa-play",
          first_lesson: "fas fa-baby",
          course_completion_1: "fas fa-trophy",
          perfect_score: "fas fa-star",
          speed_demon: "fas fa-rocket",
          // Add more as needed
        };
        return iconMap[id] || "fas fa-award";
      }

      async function checkLessonAchievements(lessonNumber) {
        if (lessonNumber === 1) {
          await checkAndUnlockAchievement("first_lesson");
        }

        // Check if user has completed multiple lessons in one day
        const today = new Date().toISOString().split("T")[0];
        const todayCompletions = Object.values(courseProgress).filter(
          (p) => p.completed && p.completedAt?.startsWith(today)
        ).length;

        if (todayCompletions >= 3) {
          await checkAndUnlockAchievement("lesson_marathon");
        }
      }

      async function checkLessonCompletionAchievements() {
        const completedCount = getCompletedLessonsCount();

        // Lesson-based achievements
        const lessonMilestones = [1, 5, 10, 25, 50, 100];
        for (const milestone of lessonMilestones) {
          if (completedCount >= milestone) {
            await checkAndUnlockAchievement(`lessons_${milestone}`);
          }
        }

        // Course completion achievements
        if (completedCount === COURSE_DATA.lessons.length) {
          await checkAndUnlockAchievement("course_completion_1");

          // Check for additional course completion achievements
          const { data: allCourses } = await supabase
            .from("course_progress")
            .select("course_id")
            .eq("user_id", currentUser.id)
            .eq("progress", 100);

          const totalCompleted = allCourses?.length || 0;

          const courseMilestones = [1, 5, 10, 25];
          for (const milestone of courseMilestones) {
            if (totalCompleted >= milestone) {
              await checkAndUnlockAchievement(`course_completion_${milestone}`);
            }
          }
        }
      }

      async function checkPerfectScoreAchievements(score) {
        if (score === 100) {
          await checkAndUnlockAchievement("perfect_score");

          // Check for consecutive perfect scores
          const recentScores = Object.values(courseProgress)
            .filter((p) => p.completed && p.quizScore)
            .slice(-5) // Last 5 completed
            .map((p) => p.quizScore);

          if (
            recentScores.length >= 3 &&
            recentScores.every((s) => s === 100)
          ) {
            await checkAndUnlockAchievement("perfectionist_streak");
          }
        }
      }

      async function checkSpeedCompletionAchievements(completionTime) {
        // Speed demon: Complete course in under 2 hours (120 minutes)
        if (completionTime <= 120) {
          await checkAndUnlockAchievement("speed_demon");
        }

        // Quick learner: Complete course in under 4 hours (240 minutes)
        if (completionTime <= 240) {
          await checkAndUnlockAchievement("quick_learner");
        }
      }

      async function checkStudyTimeAchievements() {
        const totalTime = courseSession.totalStudyTime;

        // Marathon learner: Study for 8+ hours in a course session
        if (totalTime >= 480) {
          // 8 hours
          await checkAndUnlockAchievement("marathon_learner");
        }

        // Dedicated learner: Study for 4+ hours
        if (totalTime >= 240) {
          // 4 hours
          await checkAndUnlockAchievement("dedicated_learner");
        }
      }

      async function checkCourseStreakAchievements() {
        try {
          // Check for consecutive course completions
          const { data: recentCourses, error } = await supabase
            .from("course_progress")
            .select("completed_at, course_id")
            .eq("user_id", currentUser.id)
            .eq("progress", 100)
            .order("completed_at", { ascending: false })
            .limit(10);

          if (error || !recentCourses) return;

          // Check for courses completed on consecutive days
          let consecutiveDays = 1;
          for (let i = 1; i < recentCourses.length; i++) {
            const prevDate = new Date(
              recentCourses[i - 1].completed_at
            ).toDateString();
            const currentDate = new Date(
              recentCourses[i].completed_at
            ).toDateString();
            const dayDiff =
              Math.abs(new Date(prevDate) - new Date(currentDate)) /
              (1000 * 60 * 60 * 24);

            if (dayDiff <= 1) {
              consecutiveDays++;
            } else {
              break;
            }
          }

          if (consecutiveDays >= 3) {
            await checkAndUnlockAchievement("learning_streak");
          }
        } catch (error) {
          console.error("Error checking course streak achievements:", error);
        }
      }

      // =====================================================
      // TIME-BASED ACHIEVEMENTS
      // =====================================================
      async function checkTimeBasedAchievements(timestamp) {
        const hour = timestamp.getHours();
        const dayOfWeek = timestamp.getDay();

        // Night owl (after midnight, before 6 AM)
        if (hour >= 0 && hour < 6) {
          await incrementTimeBasedCounter("midnight_sessions", "night_owl");
        }

        // Early bird (4 AM to 6 AM)
        if (hour >= 4 && hour < 6) {
          await incrementTimeBasedCounter("early_sessions", "early_bird");
        }

        // Weekend warrior (Saturday = 6, Sunday = 0)
        if (dayOfWeek === 0 || dayOfWeek === 6) {
          await incrementTimeBasedCounter(
            "weekend_sessions",
            "weekend_warrior"
          );
        }
      }

      async function incrementTimeBasedCounter(counterType, achievementId) {
        try {
          const dateStr = new Date().toISOString().split("T")[0];
          const cacheKey = `${counterType}_${currentUser.id}_${dateStr}`;

          // Prevent multiple increments per day
          if (sessionStorage.getItem(cacheKey)) return;

          // Update counter
          await supabase
            .from("profiles")
            .update({
              [counterType]: supabase.sql`${counterType} + 1`,
            })
            .eq("id", currentUser.id);

          // Cache to prevent double counting
          sessionStorage.setItem(cacheKey, "true");

          // Check related achievement
          if (achievementId) {
            await checkAndUnlockAchievement(achievementId, true);
          }
        } catch (error) {
          console.error(`Error incrementing ${counterType}:`, error);
        }
      }

      async function checkDailyStreak() {
        try {
          const { data: profile, error } = await supabase
            .from("profiles")
            .select("last_activity, current_streak, last_streak_date")
            .eq("id", currentUser.id)
            .single();

          if (error) throw error;

          const now = new Date();
          const today = now.toDateString();
          const lastActivity = profile.last_activity
            ? new Date(profile.last_activity)
            : null;
          const lastStreakDate = profile.last_streak_date
            ? new Date(profile.last_streak_date).toDateString()
            : null;

          let newStreak = profile.current_streak || 0;
          let shouldUpdateStreak = false;

          if (!lastActivity) {
            // First time user
            newStreak = 1;
            shouldUpdateStreak = true;
          } else {
            const daysSinceLastActivity = Math.floor(
              (now - lastActivity) / (1000 * 60 * 60 * 24)
            );

            if (lastStreakDate === today) {
              // Already counted today's streak
              return newStreak;
            } else if (
              daysSinceLastActivity === 1 ||
              (daysSinceLastActivity === 0 && lastStreakDate !== today)
            ) {
              // Consecutive day or same day but not counted yet
              newStreak += 1;
              shouldUpdateStreak = true;
            } else if (daysSinceLastActivity > 1) {
              // Streak broken
              newStreak = 1;
              shouldUpdateStreak = true;
            }
          }

          if (shouldUpdateStreak) {
            await supabase
              .from("profiles")
              .update({
                current_streak: newStreak,
                last_activity: now.toISOString(),
                last_streak_date: now.toISOString(),
              })
              .eq("id", currentUser.id);

            userStats.current_streak = newStreak;

            showToast(`Daily streak: ${newStreak} days!`, "success");
            await checkStreakAchievements(newStreak);
          }

          return newStreak;
        } catch (error) {
          console.error("Error checking daily streak:", error);
          return 0;
        }
      }

      async function checkStreakAchievements(currentStreak) {
        const streakMilestones = [3, 7, 14, 30, 100, 365];

        for (const milestone of streakMilestones) {
          if (currentStreak >= milestone) {
            await checkAndUnlockAchievement(`streak_${milestone}`);
          }
        }
      }

      // =====================================================
      // USER ACTIVITY LOGGING
      // =====================================================
      async function logUserActivity(activityType, metadata = {}) {
        try {
          const now = new Date();

          const activityData = {
            user_id: currentUser.id,
            activity_type: activityType,
            timestamp: now.toISOString(),
            course_id: COURSE_DATA.id,
            lesson_index: currentLessonIndex,
            session_duration: courseSession.totalStudyTime,
            metadata: JSON.stringify(metadata),
            created_at: now.toISOString(),
          };

          // Try to log to activities table
          const { error } = await supabase
            .from("user_activities")
            .insert([activityData]);

          if (error && error.code !== "42P01") {
            console.warn("Activity logging failed:", error.message);
          }

          // Always update last activity in profile
          await supabase
            .from("profiles")
            .update({ last_activity: now.toISOString() })
            .eq("id", currentUser.id);
        } catch (error) {
          console.error("Error logging user activity:", error);
        }
      }

      // =====================================================
      // NAVIGATION SYSTEM
      // =====================================================
      function updateNavigationButtons() {
        const prevBtn = document.getElementById("prevLessonBtn");
        const nextBtn = document.getElementById("nextLessonBtn");

        if (!prevBtn || !nextBtn) return;

        // Previous button
        prevBtn.disabled = currentLessonIndex === 0;

        // Next button logic
        const isLastLesson =
          currentLessonIndex === COURSE_DATA.lessons.length - 1;
        const canGoNext =
          currentLessonIndex < COURSE_DATA.lessons.length - 1 &&
          canAccessLesson(currentLessonIndex + 1);

        if (isLastLesson) {
          const isCurrentCompleted =
            courseProgress[COURSE_DATA.lessons[currentLessonIndex].id]
              ?.completed;
          nextBtn.disabled = !isCurrentCompleted;
          nextBtn.innerHTML = '<i class="fas fa-trophy"></i> Complete Course';
        } else {
          nextBtn.disabled = !canGoNext;
          nextBtn.innerHTML = 'Next <i class="fas fa-chevron-right"></i>';
        }
      }

      // Navigation button event handlers
      function goToPreviousLesson() {
        if (currentLessonIndex > 0) {
          trackLessonTime(); // Track time spent on current lesson
          currentLessonIndex--;
          loadLesson(currentLessonIndex);
        }
      }

      function goToNextLesson() {
        if (currentLessonIndex < COURSE_DATA.lessons.length - 1) {
          const canGoNext = canAccessLesson(currentLessonIndex + 1);
          if (canGoNext) {
            trackLessonTime();
            currentLessonIndex++;
            loadLesson(currentLessonIndex);
          } else {
            showToast("Complete the current lesson quiz to proceed", "warning");
          }
        } else {
          // Complete course
          completeCourse();
        }
      }

      // =====================================================
      // SIDEBAR FUNCTIONS
      // =====================================================
      function toggleSidebar() {
        const sidebar = document.getElementById("sidebar");
        const overlay = document.getElementById("sidebarOverlay");

        if (sidebar) sidebar.classList.toggle("open");
        if (overlay) overlay.classList.toggle("active");
      }

      function closeSidebar() {
        const sidebar = document.getElementById("sidebar");
        const overlay = document.getElementById("sidebarOverlay");

        if (sidebar) sidebar.classList.remove("open");
        if (overlay) overlay.classList.remove("active");
      }

      // =====================================================
      // ACHIEVEMENT NOTIFICATION SYSTEM
      // =====================================================
      function queueAchievementNotification(achievement) {
        notificationQueue.push(achievement);
        processNotificationQueue();
      }

      function processNotificationQueue() {
        if (isShowingNotification || notificationQueue.length === 0) return;

        isShowingNotification = true;
        const achievement = notificationQueue.shift();
        showAchievementNotification(achievement);

        const duration =
          achievement.rarity === "mythic"
            ? 8000
            : achievement.rarity === "legendary"
            ? 7000
            : 6000;

        setTimeout(() => {
          isShowingNotification = false;
          processNotificationQueue();
        }, duration + 500);
      }

      function showAchievementNotification(achievement) {
        const notification = document.getElementById("achievementNotification");
        if (!notification) return;

        const icon = document.getElementById("notificationIcon");
        const title = document.getElementById("notificationTitle");
        const description = document.getElementById("notificationDescription");
        const points = document.getElementById("notificationPoints");

        if (icon) {
          icon.innerHTML = `<i class="${achievement.icon}"></i>`;
          icon.className = `notification-icon ${achievement.rarity}`;
        }
        if (title) title.textContent = achievement.name;
        if (description) description.textContent = achievement.description;
        if (points) points.textContent = `+${achievement.points} Points`;

        notification.className = `achievement-notification ${achievement.rarity}`;
        notification.classList.add("show");

        const duration =
          achievement.rarity === "mythic"
            ? 8000
            : achievement.rarity === "legendary"
            ? 7000
            : 6000;

        setTimeout(() => {
          notification.classList.remove("show");
        }, duration);
      }

      // =====================================================
      // UTILITY FUNCTIONS
      // =====================================================
      function calculateAverageQuizScore() {
        const scores = Object.values(courseProgress)
          .filter((p) => p.completed && p.quizScore)
          .map((p) => p.quizScore);

        if (scores.length === 0) return 0;
        return Math.round(
          scores.reduce((sum, score) => sum + score, 0) / scores.length
        );
      }

      async function resetProgress() {
        if (
          !confirm(
            "Are you sure you want to reset your progress? This action cannot be undone."
          )
        ) {
          return;
        }

        try {
          // Track lesson time before reset
          trackLessonTime();

          // Reset local state
          courseProgress = {};
          currentLessonIndex = 0;
          courseSession = {
            startTime: new Date(),
            totalStudyTime: 0,
            lessonsStarted: 0,
            lessonsCompleted: 0,
            pageLoadTime: new Date(),
            interactionCount: 0,
            lastActivityTime: new Date(),
          };

          // Delete from database
          await supabase
            .from("course_progress")
            .delete()
            .eq("user_id", currentUser.id)
            .eq("course_id", COURSE_DATA.id);

          // Log reset activity
          logUserActivity("progress_reset", {
            course_id: COURSE_DATA.id,
            reset_reason: "manual",
          });

          // Reinitialize
          await saveProgress();
          renderSidebar();
          loadLesson(0);

          showToast("Progress reset successfully", "success");
        } catch (error) {
          console.error("Error resetting progress:", error);
          showToast("Failed to reset progress", "error");
        }
      }

      function copyCode(codeId) {
        const codeElement = document.getElementById(codeId);
        if (!codeElement) return;

        const text = codeElement.textContent;

        navigator.clipboard
          .writeText(text)
          .then(() => {
            showToast("Code copied to clipboard!", "success");

            // Track code copy for achievements
            logUserActivity("code_copied", {
              code_section: codeId,
              lesson_id: COURSE_DATA.lessons[currentLessonIndex].id,
            });
          })
          .catch((err) => {
            console.error("Failed to copy code:", err);
            showToast("Failed to copy code", "error");

            // Fallback for older browsers
            const textArea = document.createElement("textarea");
            textArea.value = text;
            document.body.appendChild(textArea);
            textArea.select();
            try {
              document.execCommand("copy");
              showToast("Code copied to clipboard!", "success");
            } catch (fallbackError) {
              showToast(
                "Copy failed - please select and copy manually",
                "error"
              );
            }
            document.body.removeChild(textArea);
          });
      }

      function escapeHtml(text) {
        const div = document.createElement("div");
        div.textContent = text;
        return div.innerHTML;
      }

      // =====================================================
      // UI FEEDBACK SYSTEMS
      // =====================================================
      function showToast(message, type = "success") {
        const toast = document.getElementById("toast");
        const messageEl = document.getElementById("toastMessage");

        if (!toast || !messageEl) {
          console.log(`Toast: ${message} (${type})`);
          return;
        }

        messageEl.textContent = message;
        toast.className = `toast ${type} show`;

        setTimeout(() => {
          toast.classList.remove("show");
        }, 4000);
      }

      function showLoadingScreen() {
        const loadingScreen = document.getElementById("loadingScreen");
        if (loadingScreen) loadingScreen.classList.remove("hidden");
      }

      function hideLoadingScreen() {
        const loadingScreen = document.getElementById("loadingScreen");
        if (loadingScreen) {
          setTimeout(() => {
            loadingScreen.classList.add("hidden");
          }, 1000);
        }
      }

      // =====================================================
      // MUSIC PLAYER INTEGRATION
      // =====================================================
      function initMusicPlayer() {
        const btnText = document.getElementById("music-button-text");
        const icon = document.getElementById("music-icon");
        const dropdown = document.getElementById("music-dropdown-content");

        if (!btnText || !icon || !dropdown) return;

        function setUI(state) {
          btnText.textContent =
            state === "Playing" ? "PAUSE MUSIC" : "STUDY MUSIC";
          icon.className =
            state === "Playing"
              ? "fa-solid fa-circle-pause"
              : "fa-solid fa-music";
        }

        // Load saved music state
        const savedSrc = localStorage.getItem("cybersec_music_src");
        const savedTime = parseFloat(
          localStorage.getItem("cybersec_music_time") || 0
        );

        if (savedSrc) {
          audioPlayer.src = savedSrc;
          audioPlayer.currentTime = savedTime;
          audioPlayer
            .play()
            .then(() => setUI("Playing"))
            .catch(() => setUI("Stopped"));
        }

        // Music button click handler
        document
          .getElementById("music-dropdown")
          .querySelector("button")
          .addEventListener("click", (e) => {
            e.stopPropagation();
            dropdown.style.display =
              dropdown.style.display === "block" ? "none" : "block";

            if (audioPlayer.src && !audioPlayer.paused) {
              audioPlayer.pause();
              setUI("Stopped");
            } else if (audioPlayer.src) {
              audioPlayer.play().then(() => setUI("Playing"));
            }
          });

        // Music selection handlers
        dropdown.querySelectorAll("a[data-src]").forEach((link) => {
          link.addEventListener("click", (e) => {
            e.preventDefault();
            audioPlayer.src = link.dataset.src;
            audioPlayer.play().then(() => setUI("Playing"));
            localStorage.setItem("cybersec_music_src", link.dataset.src);
            dropdown.style.display = "none";
          });
        });

        // Stop music handler
        const stopLink = document.getElementById("stop-music-link");
        if (stopLink) {
          stopLink.addEventListener("click", (e) => {
            e.preventDefault();
            audioPlayer.pause();
            audioPlayer.currentTime = 0;
            audioPlayer.removeAttribute("src");
            setUI("Stopped");
            localStorage.removeItem("cybersec_music_src");
            localStorage.removeItem("cybersec_music_time");
            dropdown.style.display = "none";
          });
        }

        // Save music state before page unload
        window.addEventListener("beforeunload", () => {
          if (!audioPlayer.paused && audioPlayer.src) {
            localStorage.setItem("cybersec_music_src", audioPlayer.src);
            localStorage.setItem(
              "cybersec_music_time",
              audioPlayer.currentTime
            );
          }
        });

        // Close dropdown when clicking outside
        window.addEventListener("click", (e) => {
          if (!e.target.closest("#music-dropdown")) {
            dropdown.style.display = "none";
          }
        });
      }

      // Show initial music indicator
      function addMusicIndicator() {
        const musicBtn = document.querySelector("#music-dropdown");
        if (musicBtn) {
          const indicator = document.createElement("div");
          indicator.className = "music-indicator";
          indicator.innerHTML = `<i class="fa-solid fa-music"></i> Try Study Music!`;

          musicBtn.style.position = "relative";
          musicBtn.appendChild(indicator);

          setTimeout(() => indicator.remove(), 3000);
        }
      }

      // Initialize Event Listeners
      function initializeEventListeners() {
        // Navigation buttons
        document
          .getElementById("prevLessonBtn")
          ?.addEventListener("click", goToPreviousLesson);
        document
          .getElementById("nextLessonBtn")
          ?.addEventListener("click", goToNextLesson);

        // Reset progress button
        document
          .getElementById("resetProgressBtn")
          ?.addEventListener("click", resetProgress);

        // Mobile menu toggle
        document
          .getElementById("menuToggle")
          ?.addEventListener("click", toggleSidebar);
        document
          .getElementById("sidebarOverlay")
          ?.addEventListener("click", closeSidebar);

        // Keyboard shortcuts
        document.addEventListener("keydown", handleKeyboardShortcuts);

        // Window resize handler
        window.addEventListener("resize", handleWindowResize);

        // Content interaction tracking
        document.getElementById("contentBody")?.addEventListener(
          "scroll",
          debounce(() => {
            trackUserInteraction();
          }, 1000)
        );
      }

      // Keyboard Shortcuts
      function handleKeyboardShortcuts(e) {
        if (document.querySelector(".quiz-question.active")) return;

        if (e.key === "ArrowLeft" && e.ctrlKey) {
          e.preventDefault();
          goToPreviousLesson();
        } else if (e.key === "ArrowRight" && e.ctrlKey) {
          e.preventDefault();
          goToNextLesson();
        }
      }

      // Window Resize Handler
      function handleWindowResize() {
        if (window.innerWidth > 768) {
          closeSidebar();
        }
      }

      // Debounce Helper
      function debounce(func, wait) {
        let timeout;
        return function executedFunction(...args) {
          const later = () => {
            clearTimeout(timeout);
            func(...args);
          };
          clearTimeout(timeout);
          timeout = setTimeout(later, wait);
        };
      }

      // Initialize responsive behavior
      if (window.innerWidth <= 768) {
        document.getElementById("menuToggle").style.display = "inline-flex";
      }

      // Auto-save progress periodically
      setInterval(async () => {
        if (currentUser && Object.keys(courseProgress).length > 0) {
          await saveProgress();
        }
      }, 60000); // Save every minute

      // System initialization logging
      console.log("CyberSec Academy Course System Initialized");
      console.log("Current Course:", COURSE_DATA.title);
      console.log("Total Lessons:", COURSE_DATA.lessons.length);

      // Google OAuth Integration
      const googleBtn = document.querySelector(".btn-google");
      if (googleBtn) {
        googleBtn.addEventListener("click", async () => {
          const { data, error } = await supabase.auth.signInWithOAuth({
            provider: "google",
            options: {
              redirectTo:
                window.location.origin +
                "/courses/complete-devsecops-principles.html",
            },
          });

          if (error) {
            console.error("Google login error:", error.message);
            showToast("Google login failed: " + error.message, "error");
          }
        });
      }

      // Check for existing session
      supabase.auth.getSession().then(({ data }) => {
        if (data.session) {
          console.log("User already logged in:", data.session.user);
          currentUser = data.session.user;
          startCourseSession();
        }
      });

      // Add missing auth modal functions
      function openAuthModal() {
        const modal = document.getElementById("authModal");
        if (modal) {
          modal.style.display = "flex";
        }
      }

      function closeAuthModal() {
        const modal = document.getElementById("authModal");
        if (modal) {
          modal.style.display = "none";
        }
      }

      // Add auth tab switching functionality
      document.getElementById("tabSignIn")?.addEventListener("click", () => {
        document.getElementById("tabSignIn").classList.add("active");
        document.getElementById("tabSignUp").classList.remove("active");
        document.getElementById("signInForm").style.display = "block";
        document.getElementById("signUpForm").style.display = "none";
      });

      document.getElementById("tabSignUp")?.addEventListener("click", () => {
        document.getElementById("tabSignUp").classList.add("active");
        document.getElementById("tabSignIn").classList.remove("active");
        document.getElementById("signUpForm").style.display = "block";
        document.getElementById("signInForm").style.display = "none";
      });

      document
        .getElementById("closeAuthModal")
        ?.addEventListener("click", closeAuthModal);

      // Improved error handling for auth session
      supabase.auth.onAuthStateChange((event, session) => {
        if (event === "SIGNED_IN") {
          currentUser = session.user;
          closeAuthModal();
          startCourseSession();
        } else if (event === "SIGNED_OUT") {
          currentUser = null;
          openAuthModal();
        }
      });

      // Add form submission handlers
      document
        .getElementById("emailSignInForm")
        ?.addEventListener("submit", async (e) => {
          e.preventDefault();
          const email = document.getElementById("signInEmail").value;
          const password = document.getElementById("signInPassword").value;

          try {
            const { data, error } = await supabase.auth.signInWithPassword({
              email,
              password,
            });

            if (error) throw error;

            closeAuthModal();
          } catch (error) {
            showToast(error.message, "error");
          }
        });

      document
        .getElementById("emailSignUpForm")
        ?.addEventListener("submit", async (e) => {
          e.preventDefault();
          const email = document.getElementById("signUpEmail").value;
          const password = document.getElementById("signUpPassword").value;
          const name = document.getElementById("signUpName").value;

          try {
            const { data, error } = await supabase.auth.signUp({
              email,
              password,
              options: {
                data: {
                  full_name: name,
                },
              },
            });

            if (error) throw error;

            showToast(
              "Account created successfully! Please check your email.",
              "success"
            );
          } catch (error) {
            showToast(error.message, "error");
          }
        });
    </script>
  </body>
</html>
