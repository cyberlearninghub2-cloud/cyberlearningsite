




<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <title>Disk Forensics Course Curriculum | CipherHall</title>
    <meta name="description" content="Begin your free Disk Forensics course. This curriculum covers evidence acquisition, file system analysis, data carving, Windows artifacts, and forensic reporting." />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon.png" />
    <link rel="shortcut icon" href="/favicon.png" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="/favicon.png" />
    <link rel="canonical" href="https://www.cipherhall.com/courses/disk-forensics-complete-course.html" />

    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Course",
      "name": "Disk Forensics: A Complete Course",
      "description": "A comprehensive 20-lesson course on the principles and practices of digital disk forensics, from evidence acquisition to advanced file system and artifact analysis.",
      "provider": {
        "@type": "Organization",
        "name": "CipherHall",
        "sameAs": "https://www.cipherhall.com"
      },
      "hasCourseInstance": {
        "@type": "CourseInstance",
        "courseMode": "Online",
        "instructor": {
          "@type": "Person",
          "name": "Dr. Kenji Tanaka"
        }
      }
    }
    </script>
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:wght@400;700&family=Exo+2:wght@700;800;900&display=swap" rel="stylesheet" />
    <script src="https://cdn.jsdelivr.net/npm/@supabase/supabase-js@2.39.7/dist/umd/supabase.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-okaidia.min.css" />
    <link rel="stylesheet" href="assets/css/coursepages.css">
</head>
  <body>
    <!-- Loading Screen -->
    <div id="loadingScreen" class="loading-screen">
      <div class="loader-icon">
        <i class="fas fa-graduation-cap"></i>
      </div>
      <div class="loader-text">Loading Course Content...</div>
    </div>

    <!-- Sidebar Overlay for Mobile -->
    <div class="sidebar-overlay" id="sidebarOverlay"></div>

    <!-- Music Player (fixed at top right) -->
    <div class="header-controls">
      <div class="music-dropdown" id="music-dropdown">
        <button class="btn btn-secondary">
          <span id="music-button-text">STUDY MUSIC</span>
          <i id="music-icon" class="fa-solid fa-music"></i>
        </button>
        <div class="music-dropdown-content" id="music-dropdown-content">
          <a
            href="#"
            data-src="https://www.learningcontainer.com/wp-content/uploads/2020/02/Kalimba.mp3"
            >1. Coffee Shop Vibes</a
          >
          <a
            href="#"
            data-src="https://www.soundhelix.com/examples/mp3/SoundHelix-Song-16.mp3"
            >2. City Lights Lofi</a
          >
          <a
            href="#"
            data-src="https://www.soundhelix.com/examples/mp3/SoundHelix-Song-15.mp3"
            >3. Mellow Thoughts</a
          >
          <a
            href="#"
            data-src="https://www.soundhelix.com/examples/mp3/SoundHelix-Song-13.mp3"
            >4. Rainy Mood</a
          >
          <a
            href="#"
            data-src="https://www.soundhelix.com/examples/mp3/SoundHelix-Song-10.mp3"
            >5. Time Alone</a
          >
          <a href="#" id="stop-music-link"
            ><i class="fa-solid fa-stop-circle"></i> Stop Music</a
          >
        </div>
      </div>

      <button class="btn btn-secondary" id="resetProgressBtn">
        <i class="fas fa-redo"></i>
        Reset Progress
      </button>
    </div>

    <!-- Auth Modal -->
    <div id="authModal" class="modal" style="display: none">
      <div class="modal-overlay"></div>
      <div class="modal-content">
        <span class="close" id="closeAuthModal">&times;</span>
        <div class="auth-tabs">
          <button id="tabSignIn" class="auth-tab active">Sign In</button>
          <button id="tabSignUp" class="auth-tab">Sign Up</button>
        </div>
        <div
          id="authLoader"
          style="display: none; text-align: center; padding: 2rem"
        >
          <i
            class="fas fa-spinner fa-spin fa-2x"
            style="color: var(--color-green)"
          ></i>
          <p style="margin-top: 0.5rem">Authenticating...</p>
        </div>
        <div id="signInForm" class="auth-form">
          <h2>Sign In to CipherHall</h2>
          <button id="googleSignIn" class="btn btn-google">
            <i class="fab fa-google"></i> Continue with Google
          </button>
          <div class="divider"><span>or</span></div>
          <form id="emailSignInForm">
            <input
              type="email"
              id="signInEmail"
              placeholder="Email Address"
              required
            />
            <input
              type="password"
              id="signInPassword"
              placeholder="Password"
              required
            />
            <button type="submit" class="btn btn-primary">Sign In</button>
          </form>
        </div>
        <div id="signUpForm" class="auth-form" style="display: none">
          <h2>Join CipherHall</h2>
          <button id="googleSignUp" class="btn btn-google">
            <i class="fab fa-google"></i> Continue with Google
          </button>
          <div class="divider"><span>or</span></div>
          <form id="emailSignUpForm">
            <input
              type="text"
              id="signUpName"
              placeholder="Full Name"
              required
            />
            <input
              type="email"
              id="signUpEmail"
              placeholder="Email Address"
              required
            />
            <input
              type="password"
              id="signUpPassword"
              placeholder="Password (min. 8 characters)"
              required
            />
            <button type="submit" class="btn btn-secondary">
              Create Account
            </button>
          </form>
        </div>
        <div id="authMessage"></div>
      </div>
    </div>

    <!-- Sidebar -->
    <aside class="sidebar" id="sidebar">
      <div class="sidebar-header">
        <div class="course-info">
          <h1 class="course-title" id="courseTitle">Loading...</h1>
          <div class="course-progress">
            <div class="progress-header">
              <span class="progress-label">Course Progress</span>
              <span class="progress-percentage" id="courseProgressPercent"
                >0%</span
              >
            </div>
            <div class="progress-bar">
              <div
                class="progress-fill"
                id="courseProgressFill"
                style="width: 0%"
              ></div>
            </div>
            <div class="progress-stats">
              <span id="completedLessons">0</span>
              <span id="totalLessons">0</span>
            </div>
          </div>
          <a href="/dashboard.html" class="back-to-dashboard">
            <i class="fas fa-arrow-left"></i>
            Back to Dashboard
          </a>
        </div>
      </div>

      <nav class="lesson-nav" id="lessonNav">
        <!-- Lessons will be loaded dynamically -->
      </nav>
    </aside>

    <!-- Main Content -->
    <main class="main-content">
      <header class="content-header">
        <div class="lesson-header">
          <div class="lesson-header-left">
            <span class="lesson-number" id="currentLessonNumber">1</span>
            <h1 class="lesson-header-title" id="currentLessonTitle">
              Loading...
            </h1>
          </div>
          <div class="lesson-actions">
            <button class="mbtn btn-primary" id="menuToggle">
              <i class="fas fa-bars"></i>
            </button>
          </div>
        </div>
      </header>

      <div class="content-body" id="contentBody">
        <div class="lesson-content" id="lessonContent">
          <!-- Lesson content will be loaded dynamically -->
        </div>
      </div>

      <footer class="lesson-navigation">
        <div class="nav-info" id="navInfo">Lesson 1 of 10</div>
        <div class="nav-controls">
          <button class="btn btn-secondary" id="prevLessonBtn" disabled>
            <i class="fas fa-chevron-left"></i>
            Previous
          </button>
          <button class="btn btn-primary" id="nextLessonBtn" disabled>
            Next
            <i class="fas fa-chevron-right"></i>
          </button>
        </div>
      </footer>
    </main>

    <!-- Achievement Notification -->
    <div id="achievementNotification" class="achievement-notification">
      <div class="notification-header">
        <div class="notification-icon" id="notificationIcon">
          <i class="fas fa-trophy"></i>
        </div>
        <div class="notification-content">
          <h3 id="notificationTitle">Achievement Unlocked!</h3>
          <p id="notificationDescription">Description here...</p>
        </div>
      </div>
      <div class="notification-reward" id="notificationReward">
        <i class="fas fa-coins"></i>
        <span id="notificationPoints">+100 Points</span>
      </div>
    </div>

    <!-- Toast Notification -->
    <div id="toast" class="toast">
      <span id="toastMessage"></span>
    </div>

    <script>
      // =====================================================
      // SYNCHRONIZED COURSE SYSTEM WITH DASHBOARD INTEGRATION
      // =====================================================

      // Supabase Configuration - Replace with your config
      const supabaseUrl = "https://lzcmzulemfubjaksoqor.supabase.co";
      const supabaseKey =
        "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Imx6Y216dWxlbWZ1Ympha3NvcW9yIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTUzMzM5MDgsImV4cCI6MjA3MDkwOTkwOH0.crhPH4YWtRsr1BJTpAQcmPbWSpwIWRbzoI4sRb2_fPI";
      const supabase = window.supabase.createClient(supabaseUrl, supabaseKey);

      // =====================================================
      // COURSE DATA STRUCTURE - REPLACE WITH YOUR COURSE JSON
      // =====================================================

      const COURSE_DATA =   {
        "id": "disk-forensics",
        "title": "Disk Forensics - Complete Course Curriculum",
        "description": "An in-depth, hands-on journey into the world of disk forensics. Learn to recover, analyze, and report on digital evidence from a wide array of storage media and file systems to solve real-world cases.",
        "category": "digital-forensics",
        "difficulty": "Intermediate to Expert",
        "duration": "80 hours",
        "instructor": "Dr. Anya Sharma",
        "lessons": [
            {
                "id": "lesson-1",
                "title": "Fundamentals of Digital Forensics and Disk Analysis",
                "duration": "120 min",
                "objectives": [
                    "Understand the core principles and methodologies of digital forensics.",
                    "Explain the importance of legal admissibility, evidence handling, and the chain of custody.",
                    "Define forensic soundness and its role in an investigation.",
                    "Describe the fundamental structures of a disk, including MBR, GPT, sectors, and clusters.",
                    "Differentiate between hardware and software forensic approaches.",
                    "Compare forensic imaging with live analysis and understand when to use each.",
                    "Learn the standards for proper documentation and reporting."
                ],
                "content": {
                    "overview": "This foundational lesson introduces the world of digital forensics. We will establish the scientific and legal principles that govern every action an investigator takes, from the initial seizure of a device to the final report. You will learn the 'rules of the road' for handling digital evidence and gain a fundamental understanding of how data is physically and logically stored on a disk.",
                    "sections": [
                        {
                            "title": "Digital Forensics Principles and Methodology",
                            "content": "<p>Digital forensics is the science of identifying, preserving, analyzing, and presenting digital evidence in a legally admissible manner. The process is guided by a strict methodology to ensure findings are repeatable and defensible.</p><h3>The Forensic Process:</h3><ol><li><strong>Identification:</strong> Recognizing and identifying potential sources of digital evidence.</li><li><strong>Preservation:</strong> Collecting and protecting the integrity of the evidence. This is where forensic imaging and chain of custody are critical.</li><li><strong>Analysis:</strong> Conducting a deep-dive examination of the evidence to uncover artifacts and reconstruct events.</li><li><strong>Presentation:</strong> Documenting the findings in a clear, concise, and objective report that can be understood by a non-technical audience, such as a jury.</li></ol>",
                            "image": "https://images.unsplash.com/photo-1526628953301-3e589a6a8b74?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Legal Admissibility and Chain of Custody",
                            "content": "<p>The primary goal of a forensic investigation is to produce evidence that can be used in a legal proceeding. This requires an unbroken and well-documented chain of custody.</p><p><strong>Real-World Example:</strong> In a criminal case, a laptop is seized. The chain of custody form is a log that tracks every person who handles that laptop, from the officer who seized it, to the forensic analyst who imaged it, to the clerk who stores it in the evidence locker. Any gap in this log could allow a defense attorney to argue that the evidence was tampered with, potentially making it inadmissible in court.</p><div class=\"info-box warning\"><div class=\"info-box-header\"><i class=\"fas fa-exclamation-triangle\"></i><strong>Forensic Soundness</strong></div><p>This is the principle that evidence must be altered as little as possible by the examination process. This is why analysts *never* work on the original evidence. They work on a perfect, bit-for-bit copy (a forensic image) to preserve the original in its pristine state.</p></div>",
                            "image": "https://images.unsplash.com/photo-1588196749597-9ff075ee6b5b?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Disk Structure Fundamentals: MBR, GPT, Sectors, Clusters",
                            "content": "<p>To analyze a disk, you must first understand how it's organized at a low level.</p><ul><li><strong>Sectors:</strong> The smallest physical storage unit on a drive, typically 512 bytes or 4096 bytes.</li><li><strong>Clusters:</strong> The smallest logical unit that the file system can address. A cluster is a group of one or more contiguous sectors.</li><li><strong>Master Boot Record (MBR):</strong> The old standard for partitioning a disk. It resides in the very first sector and contains the partition table and the initial boot code. It has limitations, such as supporting a maximum of four primary partitions and disks up to 2TB.</li><li><strong>GUID Partition Table (GPT):</strong> The modern standard that replaces MBR. It supports much larger disks (up to a zettabyte) and up to 128 partitions. It also includes redundancy and error-checking features not present in MBR.</li></ul><p>Understanding these structures is critical for recovering deleted partitions or identifying hidden data.</p>",
                            "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop"
                        }
                    ],
                    "codeExamples": [
                        {
                            "title": "Basic Forensic Workstation Setup (Conceptual)",
                            "language": "bash",
                            "code": "# This script outlines the conceptual setup for a Linux-based forensic workstation.\n\n# 1. Update the system\nsudo apt update && sudo apt upgrade -y\n\n# 2. Install core forensic toolkits\nsudo apt install -y sleuthkit autopsy\n\n# 3. Install disk imaging tools\nsudo apt install -y dcfldd\n\n# 4. Install essential analysis tools\nsudo apt install -y hexedit foremost bless\n\n# 5. Create dedicated directories for cases and evidence\nmkdir ~/forensics\nmkdir ~/forensics/cases\nmkdir ~/forensics/evidence_locker\n\n# 6. Configure the system to be forensically sound\n# (e.g., disable automounting of new drives to prevent accidental writes)\necho \"Disabling automount in a real setup is a critical step.\"\n\n# Real-time Problem: Corrupted evidence drive recovery\n# If a drive is unreadable, a first step is to use a tool like 'ddrescue'.\n# ddrescue works like 'dd' but is designed to handle read errors, skipping bad\n# sectors and trying to recover as much data as possible from a failing drive.\n# Example: sudo ddrescue -f -n /dev/sdb /evidence_locker/image.dd /evidence_locker/mapfile.log"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        {
                            "id": 1,
                            "question": "What is the primary reason forensic analysts work on an image of a drive instead of the original evidence?",
                            "options": [
                                "It is faster.",
                                "To follow the principle of forensic soundness and preserve the original evidence in an unaltered state.",
                                "The original evidence is usually encrypted.",
                                "Forensic tools do not work on original drives."
                            ],
                            "correct": 1,
                            "explanation": "Forensic soundness is a core principle. To ensure the investigation is repeatable and the evidence is defensible, the original evidence must be preserved. All analysis is performed on a bit-for-bit copy."
                        },
                        {
                            "id": 2,
                            "question": "A log that tracks every person who has handled a piece of evidence is called what?",
                            "options": [
                                "An incident report",
                                "A chain of custody",
                                "A system log",
                                "A master file table"
                            ],
                            "correct": 1,
                            "explanation": "The chain of custody is a legal document that provides an unbroken audit trail of evidence handling, which is crucial for the evidence to be admissible in court."
                        },
                        {
                            "id": 3,
                            "question": "What is the modern standard for disk partitioning that has largely replaced MBR?",
                            "options": [
                                "FAT32",
                                "NTFS",
                                "GUID Partition Table (GPT)",
                                "ext4"
                            ],
                            "correct": 2,
                            "explanation": "GPT is the modern standard used by most current operating systems. It overcomes the size and partition limitations of the older MBR standard and includes better error-checking."
                        }
                    ]
                }
            },
            {
                "id": "lesson-2",
                "title": "Disk Storage Technologies and Architecture",
                "duration": "100 min",
                "objectives": [
                    "Explain the internal components and operation of a Hard Disk Drive (HDD).",
                    "Describe the architecture of a Solid-State Drive (SSD) and its forensic challenges.",
                    "Analyze the forensic implications of different RAID configurations.",
                    "Discuss the unique challenges of acquiring and analyzing data from NAS and SAN systems.",
                    "Understand the impact of wear-leveling and garbage collection on SSD data recovery.",
                    "Address the challenges posed by encrypted storage."
                ],
                "content": {
                    "overview": "Before you can analyze the data, you must understand the media on which it is stored. This lesson explores the internal architecture of different storage technologies, from traditional spinning hard drives to modern solid-state drives and complex RAID arrays. We will focus on how the physical design of each technology impacts the forensic process.",
                    "sections": [
                        {
                            "title": "Hard Disk Drive (HDD) Internals",
                            "content": "<p>A traditional HDD is a mechanical device that stores data on spinning magnetic platters.</p><h3>Key Components:</h3><ul><li><strong>Platters:</strong> Circular disks coated with a magnetic material where data is stored.</li><li><strong>Read/Write Heads:</strong> An electromagnet on an actuator arm that reads and writes data to the platters. The heads float on a microscopic cushion of air and never touch the surface.</li><li><strong>Spindle Motor:</strong> Rotates the platters at a high speed (e.g., 7200 RPM).</li></ul><p><strong>Forensic Implication:</strong> Because data is written magnetically, it can sometimes be recovered even after deletion, as faint magnetic traces (remanence) may be left behind. This is much less of a factor on modern drives but is a classic forensic concept.</p>",
                            "image": "https://images.unsplash.com/photo-1588196749597-9ff075ee6b5b?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Solid-State Drive (SSD) Architecture and Challenges",
                            "content": "<p>SSDs have no moving parts. They store data on NAND flash memory chips.</p><h3>Forensic Challenges of SSDs:</h3><ul><li><strong>Wear Leveling:</strong> SSDs distribute writes evenly across all memory cells to prevent any one cell from wearing out. This means the physical location of a file can constantly change, making it difficult to find specific data blocks.</li><li><strong>Garbage Collection & TRIM:</strong> To maintain performance, an SSD's controller actively seeks out blocks of data that have been marked as 'deleted' by the operating system and erases them *before* new data is written there. This is like a constant, automated wiping process.</li></ul><p><strong>Real-World Example:</strong> On an HDD, when you delete a file, the data often remains in unallocated space until it is overwritten. On an SSD, the TRIM command tells the drive that the data is no longer in use. The drive's garbage collection process will likely erase that data permanently within minutes or hours, making recovery of deleted files from an SSD extremely difficult, if not impossible.</p>",
                            "image": "https://images.unsplash.com/photo-1544197150-b99a580bb7a8?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "RAID Configurations and Forensic Implications",
                            "content": "<p>RAID (Redundant Array of Independent Disks) combines multiple physical drives into a single logical unit. Analyzing a RAID array requires understanding how the data is distributed.</p><h3>Common RAID Levels:</h3><ul><li><strong>RAID 0 (Striping):</strong> Data is split across multiple drives. Offers high performance but no redundancy. If one drive fails, all data is lost.</li><li><strong>RAID 1 (Mirroring):</strong> Data is duplicated across two or more drives. Offers high redundancy but no performance gain.</li><li><strong>RAID 5 (Striping with Parity):</strong> Data is striped across multiple drives, with parity (error-checking) information also striped. Allows one drive to fail without data loss.</li></ul><p><strong>Real-time Problem: RAID 5 array reconstruction.</strong> If a server is seized but one drive from a 4-drive RAID 5 array is missing or failed, the forensic analyst must use software to virtually rebuild the array from the remaining 3 drives. This requires knowing the stripe size, disk order, and parity rotation to reconstruct the logical volume before the file system can be analyzed.</p>",
                            "image": "https://images.unsplash.com/photo-1521791136064-7986c2920216?w=800&h=400&fit=crop"
                        }
                    ],
                    "codeExamples": [
                        {
                            "title": "RAID 5 Array Reconstruction (Conceptual)",
                            "language": "bash",
                            "code": "# This example shows the concept of using a tool like 'mdadm' on Linux\n# to reassemble a degraded RAID 5 array for forensic analysis.\n\n# Assume we have forensic images of three out of four drives from a RAID 5 array.\n# image1.dd, image2.dd, image4.dd (drive 3 is missing).\n\n# 1. Map the images to loopback devices to treat them as block devices\nsudo losetup /dev/loop1 image1.dd\nsudo losetup /dev/loop2 image2.dd\nsudo losetup /dev/loop4 image4.dd\n\n# 2. Use mdadm to assemble the array in a degraded state\n# The tool needs to be told one of the drives is missing.\n# The --assume-clean tells it not to try and sync the drives, which would alter evidence.\nsudo mdadm --assemble --run --assume-clean /dev/md0 /dev/loop1 /dev/loop2 missing /dev/loop4\n\n# 3. Check the status of the newly created array\ncat /proc/mdstat\n\n# 4. The logical volume /dev/md0 can now be mounted read-only or imaged for analysis.\n# This allows the analyst to access the complete file system even with one drive missing."
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        {
                            "id": 1,
                            "question": "Which SSD feature makes the recovery of deleted files particularly difficult by proactively erasing data marked for deletion?",
                            "options": [
                                "DRAM Cache",
                                "The SATA interface",
                                "Garbage Collection (in conjunction with TRIM)",
                                "The power connector"
                            ],
                            "correct": 2,
                            "explanation": "The TRIM command from the OS tells the SSD which blocks are no longer in use. The SSD's internal garbage collection process then erases these blocks to prepare them for new data, making recovery of the old data nearly impossible."
                        },
                        {
                            "id": 2,
                            "question": "In a RAID 1 configuration (Mirroring), how is the data stored?",
                            "options": [
                                "The data is split across all drives.",
                                "An identical copy of the data is written to each drive in the array.",
                                "The data is stored on one drive, and parity information is stored on another.",
                                "The data is compressed and stored on a single drive."
                            ],
                            "correct": 1,
                            "explanation": "RAID 1 is all about redundancy. Every write operation is duplicated on all drives in the mirror, so if one drive fails, a perfect copy of the data exists on the other drive(s)."
                        },
                        {
                            "id": 3,
                            "question": "Why is analyzing a RAID 0 array a major problem if one of the member drives has failed?",
                            "options": [
                                "It is not a problem; the data is mirrored.",
                                "Because RAID 0 (Striping) splits files across all drives without any redundancy, losing one drive results in the loss of all data.",
                                "The parity information can be used to rebuild the missing data.",
                                "RAID 0 is too slow to be used in modern systems."
                            ],
                            "correct": 1,
                            "explanation": "RAID 0 is purely for performance. It has no fault tolerance. Since every file is broken up and striped across the drives, the failure of a single drive makes it impossible to reassemble any of the files."
                        }
                    ]
                }
            },
            {
                "id": "lesson-3",
                "title": "File Systems Deep Dive",
                "duration": "120 min",
                "objectives": [
                    "Analyze the structure and key metadata of the NTFS file system.",
                    "Conduct a forensic examination of FAT16/FAT32 and exFAT.",
                    "Understand the journaling and metadata features of Linux file systems (ext4).",
                    "Examine the structures of macOS file systems (HFS+ and APFS).",
                    "Perform a deep-dive analysis of the Master File Table (MFT) in NTFS.",
                    "Extract and interpret file system timestamps and metadata for timeline reconstruction.",
                    "Analyze file system journals to recover evidence of past activity."
                ],
                "content": {
                    "overview": "A file system is the roadmap that an operating system uses to store and retrieve data on a disk. To a forensic investigator, it's a treasure map. This lesson provides a deep dive into the internal structures of the most common file systems—Windows NTFS, Linux ext4, and macOS APFS—focusing on the rich metadata that can be used to reconstruct a user's activity.",
                    "sections": [
                        {
                            "title": "Windows NTFS: The Master File Table (MFT)",
                            "content": "<p>NTFS (New Technology File System) is the standard file system for modern Windows. Its core is a special file called the Master File Table (MFT).</p><p>The MFT is a database that contains at least one record for every file and directory on the volume. Each MFT record stores a file's metadata, or 'attributes'.</p><h3>Key NTFS Attributes:</h3><ul><li><strong>$STANDARD_INFORMATION:</strong> Contains the file's primary timestamps (Created, Modified, Accessed, MFT Entry Changed - MACB times), permissions, and other standard attributes.</li><li><strong>$FILE_NAME:</strong> Contains the file's name, parent directory, and a *second* set of timestamps. These timestamps are often not updated as frequently as the ones in $STANDARD_INFORMATION, which can be forensically significant.</li><li><strong>$DATA:</strong> For small files, the entire file content is stored directly within the MFT record. For larger files, this attribute contains pointers to the clusters on the disk where the file's data is stored.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1611162617474-5b21e879e113?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Linux ext4: The Power of Journaling",
                            "content": "<p>ext4 (Fourth Extended Filesystem) is the default for most Linux distributions. It is a robust, journaling file system.</p><h3>The Journal:</h3><p>A journaling file system keeps a special log, the 'journal', of all the changes it is about to make *before* it makes them. This provides crash resistance.</p><p><strong>Real-World Example: Corrupted MFT reconstruction.</strong> The MFT is so critical that a copy of its first few records is stored in the middle of the disk in a file called `$MFTMirr`. If the primary MFT becomes corrupted, a forensic tool can use this mirror to help rebuild the beginning of the file system. Analyzing the NTFS transaction log (`$LogFile`) can also help recover recent changes to reconstruct a damaged MFT.</p><p>For a forensic investigator, the journal can be a goldmine. Even after a file is deleted and its metadata is gone, traces of its existence and the operations performed on it may still exist in the journal, allowing an analyst to prove a file existed at a certain time.</p>",
                            "image": "https://images.unsplash.com/photo-1629654297299-c8506221ca97?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "macOS: HFS+ and APFS",
                            "content": "<p>Apple has its own proprietary file systems.</p><h3>HFS+:</h3><p>The older file system used for many years. It is similar in concept to other file systems but has its own unique structures like the 'Catalog File' (similar to the MFT).</p><h3>APFS (Apple File System):</h3><p>The modern file system designed for SSDs and used across all Apple devices (macOS, iOS, watchOS). It has several features that create forensic challenges:</p><ul><li><strong>Snapshots:</strong> APFS can create point-in-time snapshots of the file system. An investigator might find that a file appears deleted on the live system, but a copy of it still exists in an older snapshot.</li><li><strong>Space Sharing:</strong> Multiple logical 'volumes' can share the same underlying free space, which can complicate analysis of disk usage.</li><li><strong>Built-in Encryption:</strong> APFS is designed with strong, native, full-volume encryption as a default.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1518432031352-d6fc5c10da5a?w=800&h=400&fit=crop"
                        }
                    ],
                    "codeExamples": [
                        {
                            "title": "Multi-Platform File System Comparison (Conceptual)",
                            "language": "markdown",
                            "code": "# Comparing Key Forensic Artifacts Across File Systems\n\n| Artifact/Feature       | Windows (NTFS)                                  | Linux (ext4)                                      | macOS (APFS)                                  |\n|------------------------|-------------------------------------------------|---------------------------------------------------|-----------------------------------------------|\n| **Core Metadata File** | `$MFT` (Master File Table)                      | Inodes and Superblock                             | Catalog File (B-Tree)                         |\n| **Journaling File**    | `$LogFile`                                      | `.journal` file                                   | Integrated into core metadata operations      |\n| **Timestamps**         | 4 per file ($STD_INFO + $FILE_NAME)             | 4 per file (Access, Modify, Change, Birth)        | Multiple timestamps, including Added Date     |\n| **Key Feature**        | Alternate Data Streams (ADS) - hidden content   | Extents for efficient large file storage          | Snapshots for point-in-time volume views      |\n| **Forensic Challenge** | Parsing the complex MFT structure.              | Finding data in the journal before it's gone.     | Analyzing multiple snapshots and encryption.  |"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        {
                            "id": 1,
                            "question": "In the NTFS file system, what is the name of the master database that contains a record for every file and directory?",
                            "options": [
                                "The File Allocation Table (FAT)",
                                "The Master File Table (MFT)",
                                "The Superblock",
                                "The Catalog File"
                            ],
                            "correct": 1,
                            "explanation": "The MFT is the heart of an NTFS volume. Every file and folder is represented by at least one record in this critical metadata file."
                        },
                        {
                            "id": 2,
                            "question": "What is a primary benefit of a journaling file system like Linux ext4 from a forensic perspective?",
                            "options": [
                                "It prevents files from ever being deleted.",
                                "The journal may contain traces of file operations (like creation or deletion) even after the file's primary metadata has been removed.",
                                "It does not store timestamps.",
                                "It makes the disk drive faster."
                            ],
                            "correct": 1,
                            "explanation": "The journal acts as a short-term log of metadata changes. This log can be a valuable source of evidence, potentially allowing an investigator to prove a file existed, even if it was quickly deleted."
                        },
                        {
                            "id": 3,
                            "question": "Which of the following is a key feature and forensic challenge of the modern APFS file system?",
                            "options": [
                                "Its use of a Master Boot Record (MBR).",
                                "Its lack of support for large files.",
                                "Its use of point-in-time snapshots, which can preserve older versions of files.",
                                "Its complete lack of metadata."
                            ],
                            "correct": 2,
                            "explanation": "APFS's ability to create snapshots means that an analyst must examine not just the live file system, but all available snapshots, as a deleted file might still exist in an older version of the volume."
                        }
                    ]
                }
            },
            {
                "id": "lesson-4",
                "title": "Forensic Imaging and Acquisition",
                "duration": "120 min",
                "objectives": [
                    "Differentiate between physical and logical imaging and understand their use cases.",
                    "Master the technique of bit-for-bit copying.",
                    "Properly use both hardware and software write-blockers to protect evidence.",
                    "Verify image integrity using cryptographic hashing (MD5, SHA-256).",
                    "Compare and use common imaging tools like dd, dcfldd, FTK Imager, and EnCase.",
                    "Understand the challenges and procedures for live and remote imaging.",
                    "Manage different image formats, including compressed and split images."
                ],
                "content": {
                    "overview": "Forensic acquisition is the process of creating a forensically sound copy of digital evidence. This is the single most important practical skill for a forensic analyst. An improper acquisition can destroy evidence and render an entire investigation invalid. This lesson provides a hands-on guide to the tools and procedures for creating verifiable, bit-for-bit copies of storage media.",
                    "sections": [
                        {
                            "title": "Physical vs. Logical Acquisition",
                            "content": "<p>There are two primary ways to acquire data from a source drive (the 'evidence').</p><h3>Physical Acquisition:</h3><ul><li>A bit-for-bit copy of the entire physical drive, from the first sector to the last.</li><li>This is the gold standard. It captures everything: active files, deleted files, unallocated space, slack space, and partition information.</li><li>This is the most complete and desirable form of acquisition.</li></ul><h3>Logical Acquisition:</h3><ul><li>A copy of the logical file system structure. It only copies the active files and directories that the operating system can see.</li><li>It does NOT capture unallocated space or deleted files.</li><li><strong>When to use it:</strong> When a physical image is not practical due to time constraints, storage size (e.g., acquiring only the `/users` directory from a 10TB server), or encryption.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1544197150-b99a580bb7a8?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Write Blocking: The First Commandment",
                            "content": "<p>The cardinal rule of forensic acquisition is 'Thou shalt not alter the original evidence.' A write-blocker is a device or software that ensures no data can be written *to* the evidence drive during the acquisition process.</p><h3>Types of Write-Blockers:</h3><ul><li><strong>Hardware Write-Blocker:</strong> A physical device that sits between the evidence drive and the forensic workstation. It has firmware that physically intercepts and blocks any write commands. This is the most reliable and legally defensible method.</li><li><strong>Software Write-Blocker:</strong> A piece of software that runs on the forensic workstation to prevent writes to a connected drive. This is less reliable as a software bug could cause it to fail.</li></ul><p><strong>Real-World Example:</strong> When you plug a standard USB drive into a Windows computer, the OS immediately writes information to it (e.g., updating the 'Last Accessed' timestamp). Without a write-blocker, this simple act of connecting the evidence drive would alter it, violating the principle of forensic soundness.</p>",
                            "image": "https://images.unsplash.com/photo-1521791136064-7986c2920216?w=800&h=400&fit-crop"
                        },
                        {
                            "title": "Image Integrity and Hashing",
                            "content": "<p>How can you prove that your forensic image is a perfect, unaltered copy of the original? By using cryptographic hashes.</p><h3>The Verification Process:</h3><ol><li>Before starting the acquisition, you calculate a cryptographic hash (e.g., SHA-256) of the original evidence drive. This creates a unique digital fingerprint of the source.</li><li>You then perform the bit-for-bit copy to create the forensic image file.</li><li>After the copy is complete, you calculate the SHA-256 hash of the newly created image file.</li><li><strong>If the hash of the source drive and the hash of the image file are identical, you have mathematical proof that your copy is perfect and unaltered.</strong> This verification is documented in the chain of custody.</li></ol><p><strong>Real-time Problem: Imaging a failing drive.</strong> A normal imaging tool might stop when it hits a bad sector. A specialized tool like `dcfldd` or `ddrescue` can be configured to skip bad sectors, log the errors, and continue imaging the rest of the drive, recovering as much data as possible from the failing media.</p>",
                            "image": "https://images.unsplash.com/photo-1551288049-bebda4e38f71?w=800&h=400&fit=crop"
                        }
                    ],
                    "codeExamples": [
                        {
                            "title": "Custom Disk Imaging Script (Python)",
                            "language": "python",
                            "code": "import hashlib\nimport datetime\n\n# WARNING: This is a conceptual script for educational purposes.\n# It does not perform write-blocking. Use professional tools for real cases.\n\ndef create_forensic_image(source_device_path, dest_image_path, block_size=8192):\n    \"\"\"Creates a bit-for-bit image of a source device and verifies its integrity.\"\"\"\n    source_hash = hashlib.sha256()\n    dest_hash = hashlib.sha256()\n\n    print(f\"[*] Starting acquisition of {source_device_path} at {datetime.datetime.now()}\")\n\n    # 1. Calculate the hash of the source device\n    print(\"[*] Calculating hash of source device...\")\n    with open(source_device_path, 'rb') as source_device:\n        while (block := source_device.read(block_size)):\n            source_hash.update(block)\n    source_hex = source_hash.hexdigest()\n    print(f\"[+] Source SHA256: {source_hex}\")\n\n    # 2. Perform the bit-for-bit copy\n    print(\"[*] Creating image...\")\n    with open(source_device_path, 'rb') as source_device, open(dest_image_path, 'wb') as dest_image:\n        while (block := source_device.read(block_size)):\n            dest_image.write(block)\n    print(\"[*] Image creation complete.\")\n\n    # 3. Calculate the hash of the destination image\n    print(\"[*] Calculating hash of destination image...\")\n    with open(dest_image_path, 'rb') as dest_image:\n        while (block := dest_image.read(block_size)):\n            dest_hash.update(block)\n    dest_hex = dest_hash.hexdigest()\n    print(f\"[+] Destination SHA256: {dest_hex}\")\n\n    # 4. Verify that the hashes match\n    print(\"[*] Verifying integrity...\")\n    if source_hex == dest_hex:\n        print(\"[SUCCESS] Verification successful. Hashes match!\")\n    else:\n        print(\"[FAILURE] Verification failed. Hashes do not match!\")"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        {
                            "id": 1,
                            "question": "What is the primary purpose of a hardware write-blocker?",
                            "options": [
                                "To make the imaging process faster.",
                                "To encrypt the forensic image.",
                                "To prevent any data from being written to the original evidence drive during acquisition.",
                                "To format the evidence drive."
                            ],
                            "correct": 2,
                            "explanation": "A write-blocker is a crucial safety device. It enforces the principle of forensic soundness by physically preventing any modification of the original evidence."
                        },
                        {
                            "id": 2,
                            "question": "Which type of acquisition captures the entire contents of a drive, including unallocated space and deleted files?",
                            "options": [
                                "A logical acquisition",
                                "A physical acquisition",
                                "A targeted acquisition",
                                "A live acquisition"
                            ],
                            "correct": 1,
                            "explanation": "A physical acquisition creates a bit-for-bit copy of the entire drive from the first sector to the last, making it the most complete and forensically valuable type of image."
                        },
                        {
                            "id": 3,
                            "question": "How do forensic analysts prove that their forensic image is a perfect copy of the original evidence?",
                            "options": [
                                "By taking a screenshot of the file explorer.",
                                "By using a tool with a good reputation.",
                                "By comparing the file sizes of the source and destination.",
                                "By calculating a cryptographic hash (e.g., SHA-256) of both the source and the destination and confirming they are identical."
                            ],
                            "correct": 3,
                            "explanation": "Cryptographic hashing provides mathematical proof of integrity. If the digital fingerprint of the original and the copy match, it is a verifiable bit-for-bit duplicate."
                        }
                    ]
                }
            },
            {
                "id": "lesson-5",
                "title": "Disk Partitioning and Boot Process Analysis",
                "duration": "100 min",
                "objectives": [
                    "Analyze and interpret partition tables, including MBR and GPT.",
                    "Examine the contents and function of the boot sector.",
                    "Develop techniques for recovering hidden and deleted partitions.",
                    "Understand the forensic implications of dual-boot systems.",
                    "Analyze virtual disk files (VHD, VMDK) as forensic evidence.",
                    "Examine the bootloader and its role in the startup process.",
                    "Investigate system reserved and recovery partitions for hidden artifacts."
                ],
                "content": {
                    "overview": "Before a file system can be loaded, the computer needs a map of the disk. This lesson explores the low-level structures that control the disk's layout and the system's boot process. We will dissect partition tables and boot sectors to understand how the system starts and how to recover partitions that have been intentionally hidden or accidentally deleted.",
                    "sections": [
                        {
                            "title": "Partition Table Analysis: MBR and GPT",
                            "content": "<p>The partition table is the disk's table of contents. It tells the operating system where each partition begins and ends, and what type of file system it contains.</p><h3>Master Boot Record (MBR):</h3><p>Located in the first 512-byte sector of the disk. The partition table itself is only 64 bytes long, which is why it's limited to four primary partitions.</p><h3>GUID Partition Table (GPT):</h3><p>The modern standard. The primary GPT header is stored in the second sector (LBA 1), and a backup copy is stored at the very end of the disk for redundancy. This makes GPT far more resilient to corruption.</p><p><strong>Real-world Example:</strong> An attacker might try to hide data by changing a partition's type code in the partition table. For example, changing an NTFS partition's type from `0x07` to `0x17` (Hidden NTFS). A standard OS will no longer see or mount this partition. A forensic analyst who manually inspects the partition table can easily spot this, change the byte back, and access the hidden data.</p>",
                            "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Deleted Partition Recovery",
                            "content": "<p>When a partition is deleted, the operating system usually just removes its entry from the partition table. The data itself often remains intact on the disk until it is overwritten.</p><p>Forensic tools can recover deleted partitions by scanning the entire disk for file system 'magic numbers' or headers. For example, every NTFS partition begins with the ASCII signature `NTFS`. A tool can scan the disk, and when it finds this signature, it knows it has found the start of a potential NTFS volume. It can then attempt to reconstruct the original partition boundaries.</p><p><strong>Real-time Problem: Recovering accidentally deleted partitions.</strong> A user accidentally deletes a data partition. A forensic analyst can take an image of the drive and use a tool like TestDisk or Autopsy to scan the unallocated space. The tool can find the orphaned NTFS boot sector and suggest the original partition layout, allowing for a full recovery of the file system.</p>",
                            "image": "https://images.unsplash.com/photo-1544197150-b99a580bb7a8?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Virtual Disk File Forensics",
                            "content": "<p>Virtual machines store their 'hard drives' as large files on the host system. These virtual disk files are a critical source of evidence.</p><h3>Common Formats:</h3><ul><li><strong>VMDK (VMware):</strong> Used by VMware products.</li><li><strong>VHD/VHDX (Microsoft):</strong> Used by Hyper-V and Virtual PC.</li><li><strong>VDI (Oracle):</strong> Used by VirtualBox.</li></ul><p>Forensic tools can mount these image files as if they were physical drives. This allows an analyst to perform a complete forensic examination of a virtual machine—including recovering deleted files and analyzing system artifacts—without having to run the VM. The virtual disk file is simply another piece of evidence to be analyzed.</p>",
                            "image": "https://images.unsplash.com/photo-1510915228340-29c85a43dcfe?w=800&h=400&fit=crop"
                        }
                    ],
                    "codeExamples": [
                        {
                            "title": "Partition Table Parser (Python)",
                            "language": "python",
                            "code": "import struct\n\n# This script demonstrates reading and parsing an MBR partition table from a disk image.\n\ndef parse_mbr(image_path):\n    \"\"\"Parses the 4 partition entries from a classic MBR.\"\"\"\n    with open(image_path, 'rb') as f:\n        # The MBR is the first 512 bytes. The partition table starts at offset 446.\n        f.seek(446)\n        partition_table_data = f.read(64)\n\n    print(\"--- MBR Partition Table ---\")\n    for i in range(4):\n        # Each entry is 16 bytes\n        entry = partition_table_data[i*16 : (i+1)*16]\n        \n        # Unpack the 16-byte structure\n        # H = Partition Type, L = Starting LBA, L = Size in Sectors\n        status, _, _, part_type, _, _, start_lba, size_in_sectors = struct.unpack('<B3sB3sLL', entry)\n\n        if part_type != 0:\n            print(f\"Partition #{i+1}:\")\n            print(f\"  Status: {hex(status)} {'(Active/Bootable)' if status == 0x80 else ''}\")\n            print(f\"  Type: {hex(part_type)}\")\n            print(f\"  Start Sector: {start_lba}\")\n            print(f\"  Size: {size_in_sectors * 512 / (1024*1024*1024):.2f} GB\")\n\n# You would run this on a forensic image of a drive.\n# parse_mbr(\"/evidence_locker/drive_image.dd\")"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        {
                            "id": 1,
                            "question": "In a Master Boot Record (MBR), where is the partition table located?",
                            "options": [
                                "At the very end of the disk.",
                                "In the first 512-byte sector of the disk.",
                                "It is stored in the cloud.",
                                "In the Windows Registry."
                            ],
                            "correct": 1,
                            "explanation": "The MBR is a classic structure located in the first sector (LBA 0) of a partitioned disk. It contains both the boot code and the 64-byte partition table."
                        },
                        {
                            "id": 2,
                            "question": "What is a key advantage of the GPT partitioning scheme over MBR?",
                            "options": [
                                "It is simpler and smaller.",
                                "It stores a backup of the partition table at the end of the disk for redundancy.",
                                "It can only support two partitions.",
                                "It does not use sectors."
                            ],
                            "correct": 1,
                            "explanation": "GPT's inclusion of a backup header and partition table at the end of the drive makes it much more resilient to corruption than the MBR, which has only a single copy at the beginning."
                        },
                        {
                            "id": 3,
                            "question": "A VHDX file is an example of what?",
                            "options": [
                                "A system log file.",
                                "A video file format.",
                                "A virtual hard disk file used by Microsoft Hyper-V.",
                                "A type of file system."
                            ],
                            "correct": 2,
                            "explanation": "VHD/VHDX files are virtual hard disks. To a forensic analyst, they are containers that can be mounted and analyzed just like a physical disk image."
                        }
                    ]
                }
            },
            {
                "id": "lesson-6",
                "title": "File Recovery and Carving Techniques",
                "duration": "120 min",
                "objectives": [
                    "Explain the principles of how deleted file recovery works.",
                    "Perform file signature analysis to identify file types.",
                    "Use header and footer information to carve files from raw data.",
                    "Understand the challenges of reconstructing fragmented files.",
                    "Analyze slack space and unallocated space for hidden data.",
                    "Develop custom file signatures for carving unique file types.",
                    "Validate the integrity of carved files."
                ],
                "content": {
                    "overview": "When a file is 'deleted', its data is often not immediately erased. This lesson covers the art and science of data recovery, from simple undelete operations to the advanced technique of 'file carving', where we reconstruct files from raw data streams even when all file system metadata is gone.",
                    "sections": [
                        {
                            "title": "Deleted File Recovery Principles",
                            "content": "<p>In most file systems (like NTFS and FAT), when you delete a file, two things happen:</p><ol><li>The file's entry in the file system index (e.g., the MFT) is marked as 'deleted' or 'not in use'.</li><li>The clusters on the disk that contained the file's data are marked as 'unallocated' or 'free'.</li></ol><p>Crucially, the data in the clusters is *not* wiped. It remains there until the operating system needs that space to write a new file. Forensic tools can scan this unallocated space, find the old file system metadata pointing to the data, and recover the file, as long as it has not been overwritten.</p>",
                            "image": "https://images.unsplash.com/photo-1544197150-b99a580bb7a8?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "File Carving and Signature Analysis",
                            "content": "<p>What if the file system metadata itself is gone (e.g., the partition was formatted)? This is where file carving comes in. File carving ignores the file system and searches the raw data of the disk for known file signatures.</p><h3>Header/Footer Carving:</h3><p>Most common file types have a unique sequence of bytes at the beginning (the header or 'magic number') and sometimes at the end (the footer). For example:</p><ul><li>Every JPEG file starts with the bytes `FF D8 FF E0`.</li><li>Every PDF file starts with the bytes `%PDF-`.</li><li>Every ZIP file starts with `PK`.</li></ul><p>A carving tool scans the disk sector by sector. When it finds a known header (like `%PDF-`), it starts copying data until it either finds the corresponding footer or reaches a maximum file size. This allows it to 'carve' the PDF file out of the raw data stream.</p>",
                            "image": "https://images.unsplash.com/photo-1551288049-bebda4e38f71?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "The Challenge of Fragmentation",
                            "content": "<p>File carving works perfectly for files that are stored contiguously on the disk. However, if a file is fragmented (split into multiple, non-contiguous pieces), a simple header/footer carving will fail.</p><p><strong>Real-time Problem: Recovering fragmented video files.</strong> A simple carving tool finds the header of an MP4 file and starts carving. It hits the end of the first fragment and keeps going, carving the wrong data from an unrelated file. The resulting video file is corrupt and will not play.</p><p>Advanced carving tools use more sophisticated algorithms to recognize the structure of specific file types (like the internal frame structure of a video file) to try and identify and reassemble the different fragments into a valid file. This is a very complex and imperfect process.</p>",
                            "image": "https://images.unsplash.com/photo-1521791136064-7986c2920216?w=800&h=400&fit=crop"
                        }
                    ],
                    "codeExamples": [
                        {
                            "title": "Custom File Carver (Python)",
                            "language": "python",
                            "code": "import re\n\n# This is a simple, conceptual script that demonstrates file carving for JPEGs.\n\ndef carve_jpegs(image_path):\n    \"\"\"Carves for JPEG files based on their header and footer signatures.\"\"\"\n    jpeg_header = b'\\xff\\xd8\\xff\\xe0'\n    jpeg_footer = b'\\xff\\xd9'\n    \n    with open(image_path, 'rb') as f:\n        data = f.read()\n\n    found_files = 0\n    # Use regular expressions to find all occurrences of header...footer\n    for match in re.finditer(re.escape(jpeg_header) + b'.*?' + re.escape(jpeg_footer), data, re.DOTALL):\n        found_files += 1\n        jpeg_data = match.group(0)\n        \n        # Save the carved file\n        output_filename = f\"carved_file_{found_files}.jpg\"\n        with open(output_filename, 'wb') as outfile:\n            outfile.write(jpeg_data)\n        print(f\"Carved {output_filename} ({len(jpeg_data)} bytes)\")\n\n# You would run this on a forensic image.\n# carve_jpegs(\"/evidence_locker/drive_image.dd\")"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        {
                            "id": 1,
                            "question": "The process of searching raw disk data for known file headers and footers to recover files without using file system metadata is known as:",
                            "options": [
                                "File hashing",
                                "File carving",
                                "Disk imaging",
                                "Data wiping"
                            ],
                            "correct": 1,
                            "explanation": "File carving is the technique of recovering files based on their internal structure (signatures) rather than their file system metadata. It is essential for recovering data from formatted drives."
                        },
                        {
                            "id": 2,
                            "question": "The unique sequence of bytes at the beginning of a file that identifies its type (e.g., `%PDF-` for a PDF) is called a:",
                            "options": [
                                "File hash",
                                "Timestamp",
                                "Header or magic number",
                                "Partition type"
                            ],
                            "correct": 2,
                            "explanation": "File headers, also known as magic numbers, are the signatures that file carving tools use to identify the beginning of a potential file in a raw data stream."
                        },
                        {
                            "id": 3,
                            "question": "What is the primary challenge that makes file carving difficult and sometimes inaccurate?",
                            "options": [
                                "Files are too large.",
                                "Files are encrypted.",
                                "File fragmentation.",
                                "There are too many file types."
                            ],
                            "correct": 2,
                            "explanation": "If a file is fragmented, its data is not stored in one continuous block. A simple header-to-footer carver will fail because it will read past the end of the first fragment into unrelated data, resulting in a corrupt carved file."
                        }
                    ]
                }
            },
            {
                "id": "lesson-7",
                "title": "Registry and System Artifacts Analysis",
                "duration": "120 min",
                "objectives": [
                    "Understand the structure of the Windows Registry and its role as an evidence source.",
                    "Analyze key Registry keys to interpret user activity and system configuration.",
                    "Examine system event logs to reconstruct a timeline of events.",
                    "Analyze Prefetch files, thumbnail caches, and Jump Lists for evidence of file execution and access.",
                    "Extract and interpret browser artifacts (history, cache, cookies).",
                    "Trace USB device connection history.",
                    "Reconstruct a user activity timeline using multiple artifacts."
                ],
                "content": {
                    "overview": "Operating systems, especially Windows, maintain a vast number of artifacts that record user and system activity. This lesson dives into the goldmine of forensic evidence found in the Windows Registry, event logs, and other system files. Learning to analyze these artifacts allows an investigator to reconstruct a detailed timeline of what happened on a system.",
                    "sections": [
                        {
                            "title": "Windows Registry: The System's DNA",
                            "content": "<p>The Windows Registry is a hierarchical database that stores low-level settings for the operating system and for applications. For a forensic analyst, it's a log of almost everything that has happened on the computer.</p><h3>Key Registry Hives:</h3><ul><li><strong>NTUSER.DAT:</strong> A file located in each user's profile that contains their specific settings and activity.</li><li><strong>SYSTEM & SOFTWARE:</strong> System-wide configuration files that contain information about the computer's name, timezone, installed software, and network interfaces.</li></ul><h3>Common Forensic Artifacts:</h3><ul><li><strong>RecentDocs:</strong> Lists of recently opened files by the user.</li><li><strong>TypedURLs:</strong> A list of URLs the user typed directly into Internet Explorer.</li><li><strong>UserAssist:</strong> An encrypted list of GUI-based applications that have been executed by the user.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1611162617474-5b21e879e113?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Evidence of Execution: Prefetch, Jump Lists, and Shellbags",
                            "content": "<p>Windows keeps numerous artifacts that prove a program was run or a file was accessed.</p><ul><li><strong>Prefetch Files:</strong> When an application is run, Windows creates a small Prefetch file that contains the program's name, a timestamp of the last time it was run, and a count of how many times it has been run. This is powerful evidence of program execution.</li><li><strong>Jump Lists:</strong> The 'Recent Items' list you see when you right-click an icon in the taskbar. Windows stores this data in special files, providing a record of recently and frequently accessed files for a specific application.</li><li><strong>Shellbags:</strong> Registry keys that store details about a user's folder viewing preferences (like icon size and position). Forensically, they provide a list of all directories that a user has ever browsed to, even if the directory no longer exists.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1515879218367-8466d910aaa4?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "USB Device History",
                            "content": "<p>The Registry is the primary source for determining if a specific USB device has ever been connected to a system. This is critical in data theft investigations.</p><p><strong>Real-time Problem: Tracking malware persistence mechanisms.</strong> An attacker gains access to a machine and wants their malware to run automatically every time the computer starts. A common technique is to create a new entry in the 'Run' key in the Registry (`HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Run`). A forensic analyst will always check this key to find malware that is configured to auto-start.</p><p>By analyzing the `SYSTEM` hive, an analyst can find records of every USB device that has been plugged in, including its make, model, and serial number. By correlating this with timestamps from other artifacts, the analyst can prove that 'this specific USB drive from this manufacturer with this serial number was connected to the computer at this exact time'.</p>",
                            "image": "https://images.unsplash.com/photo-1556075798-4825dfaaf498?w=800&h=400&fit=crop"
                        }
                    ],
                    "codeExamples": [
                        {
                            "title": "Registry Parser and Analyzer (Python)",
                            "language": "python",
                            "code": "from regipy.registry import RegistryHive\n\n# This script uses the 'regipy' library to parse the NTUSER.DAT hive\n# and extract the UserAssist key, which shows executed programs.\n\ndef parse_userassist(ntuser_hive_path):\n    \"\"\"Parses the UserAssist key from an NTUSER.DAT hive file.\"\"\"\n    try:\n        registry_hive = RegistryHive(ntuser_hive_path)\n        # The path to the UserAssist key\n        key_path = r\"\\Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\UserAssist\"\n\n        print(f\"--- UserAssist History from {ntuser_hive_path} ---\")\n        for subkey in registry_hive.get_key(key_path).iter_subkeys():\n            for value in subkey.iter_values():\n                # The values are ROT13 encoded, a simple substitution cipher.\n                # The library handles the decoding automatically.\n                if value.name != \"(Default)\":\n                    print(f\"Executed: {value.name}, Last Run: {subkey.header.last_modified}\")\n    except Exception as e:\n        print(f\"Could not parse hive: {e}\")\n\n# You would run this on an NTUSER.DAT file extracted from a forensic image.\n# parse_userassist(\"/forensic_cases/case001/NTUSER.DAT\")"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        {
                            "id": 1,
                            "question": "Which Windows Registry hive contains user-specific settings and activity?",
                            "options": [
                                "SYSTEM",
                                "SOFTWARE",
                                "SAM",
                                "NTUSER.DAT"
                            ],
                            "correct": 3,
                            "explanation": "The NTUSER.DAT hive is located within each user's profile directory and contains a wealth of forensic information about that specific user's activity, such as their recently opened documents and executed programs."
                        },
                        {
                            "id": 2,
                            "question": "Which Windows artifact provides evidence of program execution, including the last run time and a count of how many times the program was run?",
                            "options": [
                                "Event Logs",
                                "Prefetch files",
                                "The MFT",
                                "The Recycle Bin"
                            ],
                            "correct": 1,
                            "explanation": "Prefetch files are created by Windows to speed up application loading, but in doing so, they create a valuable forensic artifact that directly proves a program was executed on a system."
                        },
                        {
                            "id": 3,
                            "question": "In a data theft case, an investigator needs to prove that a specific USB drive was connected to a computer. Where would they find this information?",
                            "options": [
                                "In the browser history.",
                                "In the Windows Registry, specifically the SYSTEM hive.",
                                "In the computer's power supply unit.",
                                "In the file allocation table."
                            ],
                            "correct": 1,
                            "explanation": "The SYSTEM hive in the Windows Registry maintains a detailed record of hardware connected to the machine, including a history of all USB Mass Storage devices, often with their vendor, product ID, and unique serial number."
                        }
                    ]
                }
            },
            {
                "id": "lesson-8",
                "title": "Database Forensics and Analysis",
                "duration": "90 min",
                "objectives": [
                    "Analyze the file structure of common database formats.",
                    "Apply forensic techniques to investigate SQLite databases.",
                    "Understand the process of examining SQL Server, MySQL, and other enterprise databases.",
                    "Analyze transaction logs to reconstruct database activity.",
                    "Develop techniques for recovering deleted records from database files.",
                    "Investigate NoSQL databases.",
                    "Analyze database index files for residual data."
                ],
                "content": {
                    "overview": "Databases are the structured heart of many applications, from web browsers to enterprise financial systems. This lesson covers the specialized techniques required to perform forensic analysis on database files, focusing on how to parse their structure, analyze their logs, and recover deleted records to reconstruct critical events.",
                    "sections": [
                        {
                            "title": "SQLite Forensics: The Ubiquitous Database",
                            "content": "<p>SQLite is a self-contained, serverless database engine that is used in countless applications. It is the most common database format an investigator will encounter.</p><h3>Where is SQLite Found?</h3><ul><li><strong>Web Browsers:</strong> Stores history, cookies, and cache (e.g., in Chrome's 'History' file).</li><li><strong>Mobile Devices:</strong> The primary database for both iOS and Android apps (e.g., for storing text messages, contacts, and call logs).</li><li><strong>Desktop Applications:</strong> Used by tools like Skype, Dropbox, and many more.</li></ul><h3>Key Forensic Artifacts:</h3><ul><li><strong>Active Records:</strong> The live data in the database tables.</li><li><strong>Free Pages & Unallocated Space:</strong> When a record is deleted, it is often just marked as 'free' but the data remains until overwritten. This space can be carved to recover deleted records.</li><li><strong>Write-Ahead Log (WAL):</strong> A journal file (with a `-wal` extension) that stores new changes before they are committed to the main database file. This can contain very recent or even deleted data.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1556075798-4825dfaaf498?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Enterprise Database Forensics (SQL Server, MySQL)",
                            "content": "<p>Analyzing enterprise databases presents different challenges, as they are live, multi-user systems.</p><h3>Investigation Approach:</h3><p>Directly imaging a live, multi-terabyte production database server is often not feasible. The investigation typically relies on a combination of approaches:</p><ul><li><strong>Acquiring Backups:</strong> The most common method is to acquire the database backup files (`.bak`) for offline analysis.</li><li><strong>Transaction Log Analysis:</strong> The transaction log (`.ldf` in SQL Server) is a critical artifact. It records every single transaction (INSERT, UPDATE, DELETE) that has occurred. An analyst can parse this log to reconstruct the exact sequence of events, including recovering the data from deleted records.</li><li><strong>Live Analysis (with caution):</strong> In some cases, a trusted query may be run on the live server to quickly check for indicators of compromise, but this must be done very carefully to avoid altering evidence.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1516321497487-e288fb19713f?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Recovering Deleted Records",
                            "content": "<p>Databases often do not immediately wipe data upon deletion. This provides a window for recovery.</p><p><strong>Real-time Problem: Recovering deleted financial records.</strong> An employee is suspected of deleting records of fraudulent transactions from an SQL Server database to cover their tracks. The forensic analyst acquires the database backup and, more importantly, the transaction log file that covers the time of the suspected activity. By parsing the transaction log, the analyst can see the `DELETE` statements that were executed and can also recover the full content of the rows that were deleted. This provides definitive proof of the action and the original data.</p>",
                            "image": "https://images.unsplash.com/photo-1554224155-1696413565d3?w=800&h=400&fit=crop"
                        }
                    ],
                    "codeExamples": [
                        {
                            "title": "Database Record Recovery Tool (Python with SQLite)",
                            "language": "python",
                            "code": "import sqlite3\n\n# This script demonstrates connecting to a SQLite database (like a browser history file)\n# and executing a query to extract forensic information.\n\ndef analyze_browser_history(history_db_path):\n    \"\"\"Queries a Chrome history SQLite database for URL and visit information.\"\"\"\n    try:\n        conn = sqlite3.connect(f\"file:{history_db_path}?mode=ro\", uri=True)\n        cursor = conn.cursor()\n\n        # SQL query to join the 'urls' table with the 'visits' table\n        query = \"\"\"\n        SELECT \n            datetime(visits.visit_time/1000000-11644473600, 'unixepoch', 'localtime') as last_visit_time,\n            urls.url,\n            urls.title,\n            urls.visit_count\n        FROM urls, visits\n        WHERE urls.id = visits.url\n        ORDER BY last_visit_time DESC\n        LIMIT 20\n        \"\"\"\n        \n        print(\"--- Recent Browser History ---\")\n        for row in cursor.execute(query):\n            print(f\"[{row[0]}] - {row[2]} ({row[1]})\")\n            \n        conn.close()\n    except Exception as e:\n        print(f\"Could not open or query database: {e}\")\n\n# You would point this to a 'History' file copied from a user's Chrome profile.\n# analyze_browser_history(\"/forensic_cases/case001/Chrome/History\")"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        {
                            "id": 1,
                            "question": "Which database format is most commonly found in web browsers and mobile applications?",
                            "options": [
                                "SQL Server",
                                "Oracle",
                                "MySQL",
                                "SQLite"
                            ],
                            "correct": 3,
                            "explanation": "SQLite is a lightweight, embedded database used in countless applications, making it the most ubiquitous database format that a forensic investigator will encounter."
                        },
                        {
                            "id": 2,
                            "question": "In SQLite, what is the purpose of the Write-Ahead Log (-wal file)?",
                            "options": [
                                "It stores the main database tables.",
                                "It is a journal file that records changes before they are committed to the main database, and can contain very recent or deleted data.",
                                "It stores user passwords for the database.",
                                "It is a backup copy of the entire database."
                            ],
                            "correct": 1,
                            "explanation": "The WAL is a key forensic artifact. Because it acts as a temporary journal, it often contains fragments of data that have already been deleted from the main .db file, making it a prime location for recovering recent activity."
                        },
                        {
                            "id": 3,
                            "question": "In an enterprise SQL Server investigation, which file is most critical for reconstructing a sequence of events and recovering deleted records?",
                            "options": [
                                "The primary data file (.mdf)",
                                "The transaction log file (.ldf)",
                                "The configuration file",
                                "The system event log"
                            ],
                            "correct": 1,
                            "explanation": "The transaction log is a detailed, chronological record of every modification made to the database. By parsing this log, an analyst can see every INSERT, UPDATE, and DELETE statement, and can often recover the full content of the data that was changed or deleted."
                        }
                    ]
                }
            },
            {
                "id": "lesson-9",
                "title": "Email and Communication Forensics",
                "duration": "100 min",
                "objectives": [
                    "Analyze local email client files like PST, OST, and MBOX.",
                    "Extract and analyze artifacts from webmail services.",
                    "Perform a detailed analysis of email headers to trace an email's origin.",
                    "Apply techniques to recover deleted emails and attachments.",
                    "Conduct forensic analysis of instant messaging and chat applications.",
                    "Reconstruct communication timelines from multiple sources.",
                    "Investigate artifacts from VoIP and video conferencing applications."
                ],
                "content": {
                    "overview": "Email and chat messages are a primary source of evidence in almost every type of investigation, from corporate fraud to criminal conspiracies. This lesson covers the forensic analysis of communication data, focusing on how to dissect email files, trace message origins, recover deleted items, and reconstruct conversations.",
                    "sections": [
                        {
                            "title": "Local Email Client Forensics (PST, OST, MBOX)",
                            "content": "<p>Many users still use local email clients like Microsoft Outlook or Thunderbird. These clients store all the user's email in large, local database files.</p><h3>Common Formats:</h3><ul><li><strong>PST (Personal Storage Table):</strong> The primary file format used by Microsoft Outlook to store emails, calendar items, and contacts. It can be imported and exported.</li><li><strong>OST (Offline Storage Table):</strong> A cached, offline copy of a user's mailbox from an Exchange or Office 365 server. It is not meant to be portable but can be a rich source of evidence.</li><li><strong>MBOX (Mailbox):</strong> A simple text-based format where all emails are stored one after another in a single file. Used by many clients like Thunderbird.</li></ul><p>Forensic tools can parse these files, allowing an investigator to view all the emails, analyze attachments, and often recover emails that the user has 'deleted'.</p>",
                            "image": "https://images.unsplash.com/photo-1563206414-99371216c39a?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Email Header Analysis: Tracing the Path",
                            "content": "<p>Every email contains a set of headers that act like a digital postmark, showing the path the email took to get to the recipient. Analyzing these headers is the key to identifying the true source of a suspicious email.</p><h3>Key Headers for Analysis:</h3><ul><li><strong>Received:</strong> Each mail server that handles an email adds a 'Received' header. By reading these from bottom to top, you can trace the email's path.</li><li><strong>Authentication-Results:</strong> Shows the results of DMARC, SPF, and DKIM checks, which can prove if an email is spoofed.</li><li><strong>X-Originating-IP:</strong> Sometimes included by webmail providers, this header can show the IP address of the person who sent the email.</li></ul><p><strong>Real-world Example: Reconstructing deleted email conversations.</strong> In a fraud case, a suspect claims they never communicated with a certain individual. The forensic analyst examines the suspect's OST file and finds several deleted emails between the two parties. Further, by analyzing the transaction logs within the OST file, the analyst can even recover fragments of emails that were permanently deleted ('hard deleted'), providing a timeline of their conversation.</p>",
                            "image": "https://images.unsplash.com/photo-1558004533-28a9c37a78a6?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Instant Messaging and Webmail Forensics",
                            "content": "<p>Much of today's communication happens in chat apps and webmail, which presents new challenges.</p><h3>Webmail (Gmail, Outlook.com):</h3><p>The evidence is on the server, not the local computer. The investigation often relies on browser artifacts: searching the web browser's cache for fragments of emails, or its SQLite database for a history of email addresses contacted.</p><h3>Chat Apps (Slack, Teams, WhatsApp):</h3><p>These applications often store their data in local SQLite databases on the computer or mobile device. A forensic analyst can parse these databases to reconstruct chat histories, see file transfers, and identify all participants in a conversation. For corporate platforms like Slack and Teams, an administrator can also often perform a data export directly from the service (with the proper legal authority).</p>",
                            "image": "https://images.unsplash.com/photo-1542744173-8e7e53415bb0?w=800&h=400&fit=crop"
                        }
                    ],
                    "codeExamples": [
                        {
                            "title": "Email Metadata Extraction Tool (Python)",
                            "language": "python",
                            "code": "import email\nfrom email import policy\n\n# This script demonstrates parsing an email file (.eml) to extract key metadata.\n\ndef analyze_eml_file(eml_path):\n    \"\"\"Parses a single .eml file and prints key headers.\"\"\"\n    with open(eml_path, 'rb') as f:\n        msg = email.message_from_binary_file(f, policy=policy.default)\n\n    print(f\"--- Analysis of {eml_path} ---\")\n    print(f\"Subject: {msg['subject']}\")\n    print(f\"From: {msg['from']}\")\n    print(f\"To: {msg['to']}\")\n    print(f\"Date: {msg['date']}\")\n\n    # Trace the received path\n    print(\"\\n--- Received Path (Bottom to Top) ---\")\n    received_headers = msg.get_all('received', [])\n    for header in reversed(received_headers):\n        print(f\"-> {header.strip()}\")\n\n    # Check for attachments\n    if msg.is_multipart():\n        print(\"\\n--- Attachments ---\")\n        for part in msg.iter_attachments():\n            print(f\"- Filename: {part.get_filename()}\")\n\n# You would run this on an individual .eml file exported from an email client.\n# analyze_eml_file(\"/forensic_cases/case002/suspicious_email.eml\")"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        {
                            "id": 1,
                            "question": "A forensic analyst needs to investigate a user's Microsoft Outlook emails. Which file format will they primarily be analyzing?",
                            "options": [
                                "MBOX",
                                "VHDX",
                                "PST or OST",
                                "SQLite"
                            ],
                            "correct": 2,
                            "explanation": "PST (Personal Storage Table) and OST (Offline Storage Table) are the proprietary database formats used by Microsoft Outlook to store all mailbox data locally."
                        },
                        {
                            "id": 2,
                            "question": "When tracing the path of an email to determine its origin, which email header is most important?",
                            "options": [
                                "The 'Subject' header",
                                "The 'To' header",
                                "The 'Received' headers",
                                "The 'From' header"
                            ],
                            "correct": 2,
                            "explanation": "Each mail server that processes an email adds a 'Received' header. By reading these headers from the bottom up, an analyst can trace the path the email took across the internet, which is crucial for identifying the true source."
                        },
                        {
                            "id": 3,
                            "question": "Where do many modern chat applications, like Slack or WhatsApp, and web browsers store their local data on a computer?",
                            "options": [
                                "In the Master Boot Record (MBR).",
                                "In PST files.",
                                "In SQLite databases.",
                                "In the system event logs."
                            ],
                            "correct": 2,
                            "explanation": "SQLite is the de facto standard for embedded databases in applications. Browser history, chat messages, and mobile app data are very frequently stored in .sqlite files within the application's data directory."
                        }
                    ]
                }
            },
            {
                "id": "lesson-10",
                "title": "Multimedia and Document Forensics",
                "duration": "90 min",
                "objectives": [
                    "Extract and analyze image file metadata (EXIF).",
                    "Conduct forensic examinations of video and audio files.",
                    "Extract hidden metadata from common document formats (Office, PDF).",
                    "Understand and apply steganography detection methods.",
                    "Reconstruct version histories from documents.",
                    "Verify the integrity and authenticity of digital signatures.",
                    "Create a timeline of events using multimedia evidence."
                ],
                "content": {
                    "overview": "Every digital photo, video, and document contains a hidden layer of data called metadata. This lesson explores how to extract and analyze this information to answer critical questions about a file's origin, history, and authenticity. We will also delve into the world of steganography, the art of hiding data in plain sight.",
                    "sections": [
                        {
                            "title": "Image Forensics and EXIF Metadata",
                            "content": "<p>Nearly every photo taken with a digital camera or smartphone contains a trove of hidden data called EXIF (Exchangeable Image File Format) metadata.</p><h3>Common EXIF Tags:</h3><ul><li><strong>Camera Make and Model:</strong> Proves which specific device took the photo.</li><li><strong>Date and Time Original:</strong> A timestamp of when the photo was taken.</li><li><strong>GPS Coordinates:</strong> The precise latitude and longitude where the photo was taken. This is often a critical piece of evidence.</li><li><strong>Thumbnail:</strong> A small, embedded thumbnail of the image. Sometimes, if the main image is edited, the original thumbnail remains, revealing the original content.</li></ul><p><strong>Real-world Example:</strong> A suspect in an alibi investigation provides a photo, claiming to have been in one city at a specific time. A forensic analyst extracts the EXIF data from the photo. The GPS coordinates show the photo was actually taken 200 miles away, and the timestamp is from three days earlier. The EXIF data has just broken the suspect's alibi.</p>",
                            "image": "https://images.unsplash.com/photo-1554080353-a576cf803bda?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Document Metadata Analysis",
                            "content": "<p>Office documents (Word, Excel, PowerPoint) and PDFs also contain valuable metadata that can reveal information about the author and the document's history.</p><h3>Key Document Metadata:</h3><ul><li><strong>Author Name / Username:</strong> Can reveal who created the document.</li><li><strong>Creation and Last Modified Dates:</strong> Provides a timeline of the document's lifecycle.</li><li><strong>Editing History & Comments:</strong> Sometimes, deleted text or comments from previous versions can be recovered from within the document's structure, revealing information the author intended to hide.</li><li><strong>Software Version:</strong> Shows which version of Word or Adobe Acrobat was used to create the file.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Steganography: The Art of Hiding Data",
                            "content": "<p>Steganography is the practice of concealing a file, message, image, or video within another file. Unlike encryption, which conceals the content of a message, steganography conceals the very existence of the message.</p><h3>How it Works:</h3><p>An attacker can use a steganography tool to hide a secret text file (e.g., a list of stolen passwords) inside an innocent-looking image file. To the naked eye, the image looks completely normal. The tool makes tiny, imperceptible changes to the color data of individual pixels to embed the secret data.</p><p><strong>Real-time Problem: Detecting hidden data in images.</strong> An analyst investigating an insider threat notices that an employee has been emailing large, high-resolution photos to their personal email. This seems suspicious. The analyst uses a forensic tool to perform a statistical analysis on the images. The tool detects that the randomness (entropy) of the pixel data is abnormally high, which is an indicator that steganography might have been used. Further analysis with a steganography detection tool reveals the hidden, password-protected ZIP file containing stolen intellectual property.</p>",
                            "image": "https://images.unsplash.com/photo-1629654297299-c8506221ca97?w=800&h=400&fit=crop"
                        }
                    ],
                    "codeExamples": [
                        {
                            "title": "Metadata Extraction Automation (Python with Pillow)",
                            "language": "python",
                            "code": "from PIL import Image\nfrom PIL.ExifTags import TAGS\n\n# This script uses the Pillow library to open an image and extract its EXIF metadata.\n\ndef extract_exif(image_path):\n    \"\"\"Extracts and prints all EXIF tags from a JPEG image.\"\"\"\n    try:\n        image = Image.open(image_path)\n        exif_data = image._getexif()\n\n        if not exif_data:\n            print(\"No EXIF metadata found.\")\n            return\n\n        print(f\"--- EXIF Metadata for {image_path} ---\")\n        for tag_id, value in exif_data.items():\n            # Get the tag name from the tag ID\n            tag_name = TAGS.get(tag_id, tag_id)\n            print(f\"{tag_name}: {value}\")\n\n    except Exception as e:\n        print(f\"Could not process image: {e}\")\n\n# You would run this on a JPEG file.\n# extract_exif(\"/forensic_cases/case003/suspect_photo.jpg\")"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        {
                            "id": 1,
                            "question": "The metadata embedded in a digital photograph that contains information like the camera model, timestamp, and GPS coordinates is known as:",
                            "options": [
                                "NTFS",
                                "MFT",
                                "EXIF",
                                "HTML"
                            ],
                            "correct": 2,
                            "explanation": "EXIF (Exchangeable Image File Format) is the standard for storing metadata within image files, and it is a critical source of evidence for forensic investigators."
                        },
                        {
                            "id": 2,
                            "question": "What is the primary goal of steganography?",
                            "options": [
                                "To encrypt the content of a message so it cannot be read.",
                                "To hide the very existence of a message within another, innocent-looking file.",
                                "To compress a file to make it smaller.",
                                "To add a digital signature to a file."
                            ],
                            "correct": 1,
                            "explanation": "Steganography is about concealment, not confidentiality. While encryption scrambles a message, steganography hides it, so no one even knows a secret message exists."
                        },
                        {
                            "id": 3,
                            "question": "Which of the following would be the most likely place to find the name of the author who created a Microsoft Word document?",
                            "options": [
                                "In the file's hash.",
                                "In the Master File Table (MFT).",
                                "In the document's internal metadata.",
                                "In the file allocation table."
                            ],
                            "correct": 2,
                            "explanation": "Document formats like .docx and .pdf have their own internal structure that contains rich metadata, including author information, editing times, and software versions, all of which can be extracted with forensic tools."
                        }
                    ]
                }
            },
            {
                "id": "lesson-11",
                "title": "Network and Internet Activity Forensics",
                "duration": "120 min",
                "objectives": [
                    "Reconstruct a user's browsing history from multiple artifacts.",
                    "Analyze browser cache files to recover fragments of web pages.",
                    "Examine cookies to track user sessions and website interactions.",
                    "Investigate download histories and search queries.",
                    "Analyze artifacts from social media, webmail, and online banking.",
                    "Understand the challenges of investigating Tor and dark web activity.",
                    "Correlate on-disk artifacts with network logs."
                ],
                "content": {
                    "overview": "A user's interaction with the internet leaves a detailed trail of evidence on their computer. This lesson focuses on the forensic analysis of web browser artifacts. We will learn how to reconstruct a user's browsing activity by dissecting history databases, cache files, cookies, and other remnants of their online life.",
                    "sections": [
                        {
                            "title": "Browser History Reconstruction",
                            "content": "<p>All modern web browsers (Chrome, Firefox, Edge) store their history, bookmarks, and other data in local SQLite databases.</p><h3>Key Artifacts:</h3><ul><li><strong>History Database:</strong> A SQLite file that contains a detailed log of every URL visited, the timestamp of the visit, and the visit count. This is the primary source for reconstructing browsing activity.</li><li><strong>Cache:</strong> The browser stores temporary copies of images, scripts, and HTML from websites to make them load faster. An analyst can examine the cache to see fragments of the web pages a user visited, even if the history has been deleted.</li><li><strong>Cookies:</strong> Small text files that websites store on a computer to track a user's session. They can be used to prove a user logged into a specific website.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1555949963-ff9fe0c870eb?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Beyond the Browser: Other Network Artifacts",
                            "content": "<p>Internet activity is recorded in places other than just the browser.</p><h3>Additional Sources:</h3><ul><li><strong>DNS Cache:</strong> The operating system keeps a temporary cache of recent DNS lookups. This can show what domains a user has recently visited, even in a private browsing session.</li><li><strong>Network Logs:</strong> If available, logs from firewalls, web proxies, and DNS servers provide a network-level view of a user's activity that they cannot delete from their local machine.</li></ul><p><strong>Real-world Example: Tracking cryptocurrency transactions.</strong> A suspect is believed to be using cryptocurrency for illicit payments. The browsing history on their computer is deleted. The forensic analyst examines the browser's cache and finds logos and images from a specific cryptocurrency exchange website. The analyst then examines the system's DNS cache and finds lookups for the API endpoint of that same exchange. By correlating these artifacts, the analyst can prove the suspect was interacting with that specific exchange, providing a crucial lead for the financial investigation.</p>",
                            "image": "https://images.unsplash.com/photo-1621452773352-2a74c35b2917?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Challenges: Private Browsing and Tor",
                            "content": "<p>Attackers and criminals often use tools to try and hide their online activity.</p><h3>Private Browsing (Incognito Mode):</h3><p>When a user closes a private browsing window, the browser is designed to not save the history, cookies, or cache from that session to the normal database files. However, it is not perfectly anonymous. It does *not* hide your activity from your ISP, and it may leave traces in other places, like the DNS cache or in memory.</p><h3>The Onion Router (Tor):</h3><p>Tor is a network designed for anonymous communication. It routes a user's traffic through a series of encrypted relays, making it extremely difficult to trace the traffic back to the original user. While an analyst might see that the user installed and ran the Tor browser, it is often impossible to determine what specific websites they visited using on-disk artifacts alone.</p>",
                            "image": "https://images.unsplash.com/photo-1548092372-2d987bde898b?w=800&h=400&fit-crop"
                        }
                    ],
                    "codeExamples": [
                        {
                            "title": "Browser Artifact Analyzer (Python with SQLite)",
                            "language": "python",
                            "code": "import sqlite3\n\n# This script connects to a Chrome cookies database and prints its contents.\n\ndef analyze_cookies(cookie_db_path):\n    \"\"\"Queries a Chrome cookies SQLite database.\"\"\"\n    try:\n        # Connect in read-only mode\n        conn = sqlite3.connect(f\"file:{cookie_db_path}?mode=ro\", uri=True)\n        cursor = conn.cursor()\n\n        # SQL query to get key cookie information\n        query = \"\"\"\n        SELECT \n            host_key,\n            name,\n            value,\n            datetime(creation_utc/1000000-11644473600, 'unixepoch', 'localtime') as created\n        FROM cookies\n        ORDER BY created DESC\n        LIMIT 20\n        \"\"\"\n        \n        print(\"--- Recent Cookies ---\")\n        for row in cursor.execute(query):\n            print(f\"[{row[3]}] - Host: {row[0]}, Name: {row[1]}, Value: {row[2][:30]}...\")\n            \n        conn.close()\n    except Exception as e:\n        print(f\"Could not process cookie database: {e}\")\n\n# You would point this to a 'Cookies' file copied from a user's Chrome profile.\n# analyze_cookies(\"/forensic_cases/case004/Chrome/Cookies\")"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        {
                            "id": 1,
                            "question": "Where does the Google Chrome browser store its browsing history?",
                            "options": [
                                "In a series of text files.",
                                "In the Windows Registry.",
                                "In a SQLite database file.",
                                "In a PST file."
                            ],
                            "correct": 2,
                            "explanation": "Modern browsers like Chrome, Firefox, and Edge use SQLite databases to store most of their profile data, including history, cookies, and cache information."
                        },
                        {
                            "id": 2,
                            "question": "What is the primary forensic value of a browser's cache?",
                            "options": [
                                "It contains a list of all passwords.",
                                "It stores temporary copies of web page components (like images and text), which can be used to reconstruct pages a user visited, even if the history is deleted.",
                                "It encrypts all browsing activity.",
                                "It has no forensic value."
                            ],
                            "correct": 1,
                            "explanation": "The cache is a critical source of evidence. It can provide visual proof of what a user was seeing online and often outlasts the history database entries."
                        },
                        {
                            "id": 3,
                            "question": "What is a major limitation of Incognito or Private Browsing mode from a forensic perspective?",
                            "options": [
                                "It encrypts the entire hard drive.",
                                "It prevents the browser from saving history and cookies to the standard database files for that session.",
                                "It completely hides your IP address from your Internet Service Provider (ISP).",
                                "It makes the internet faster."
                            ],
                            "correct": 1,
                            "explanation": "Private browsing is designed for local privacy. It tells the browser not to record the activity of that session. However, it doesn't make you anonymous on the network, and can still leave traces in memory or the DNS cache."
                        }
                    ]
                }
            },
            {
                "id": "lesson-12",
                "title": "Anti-Forensics and Evidence Destruction Analysis",
                "duration": "100 min",
                "objectives": [
                    "Identify common anti-forensic techniques used by adversaries.",
                    "Analyze the patterns left by data wiping and file shredding tools.",
                    "Detect the use of encryption and steganography to hide data.",
                    "Recognize evidence of timestamp manipulation.",
                    "Identify log file tampering and deletion.",
                    "Understand how attackers plant false evidence or use misdirection.",
                    "Differentiate between data destruction and data hiding."
                ],
                "content": {
                    "overview": "Forensics is a cat-and-mouse game. As defenders develop new analysis techniques, adversaries develop new anti-forensic techniques to hide their tracks. This lesson covers the methods attackers use to destroy, hide, and tamper with digital evidence, and the forensic techniques used to detect these very actions.",
                    "sections": [
                        {
                            "title": "Data Wiping and Destruction",
                            "content": "<p>These techniques are designed to permanently destroy data, making it unrecoverable.</p><h3>Methods:</h3><ul><li><strong>File Shredding:</strong> Secure deletion tools that overwrite a file's data with random patterns multiple times before deleting it.</li><li><strong>Disk Wiping:</strong> Utilities that overwrite the entire disk, including all unallocated and slack space.</li></ul><p><strong>Forensic Analysis:</strong> While the original data may be gone, the use of a wiping tool itself is a significant finding. An analyst might find remnants of the wiping tool in the MFT or Prefetch files. The presence of large sections of the disk containing only random or zeroed-out data is a strong indicator that a wiping utility was run.</p>",
                            "image": "https://images.unsplash.com/photo-1548092372-2d987bde898b?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Data Hiding: Encryption and Steganography",
                            "content": "<p>These techniques are designed to conceal data rather than destroy it.</p><h3>Methods:</h3><ul><li><strong>Encryption:</strong> Using tools like BitLocker (full disk encryption) or VeraCrypt (encrypted containers) to make data unreadable without the correct key or password.</li><li><strong>Steganography:</strong> Hiding data within other files, like concealing a ZIP archive inside a JPEG image.</li></ul><p><strong>Forensic Analysis:</strong> The presence of encryption is often obvious (e.g., the partition type is listed as BitLocker). An analyst can then pivot to memory forensics to try and find the encryption keys in RAM. Detecting steganography is harder and relies on statistical analysis to find anomalies (like unusually high entropy) in carrier files.</p>",
                            "image": "https://images.unsplash.com/photo-1629654297299-c8506221ca97?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Trail Obfuscation: Manipulating the Truth",
                            "content": "<p>These techniques are designed to mislead an investigator by altering metadata and logs.</p><h3>Methods:</h3><ul><li><strong>Timestamp Manipulation:</strong> Using tools to change the MACB (Modified, Accessed, Created, Birth) timestamps of files to make it look like they were created at a different time. This is known as 'timestomping'.</li><li><strong>Log Tampering:</strong> Clearing or selectively deleting entries from system event logs to hide specific actions.</li></ul><p><strong>Real-time Problem: Investigating sophisticated evidence destruction.</strong> A forensic analyst is examining a system and finds that many critical system files have timestamps that are older than the operating system's installation date, which is logically impossible. This is a red flag for timestomping. The analyst then examines the system's USN Journal (a log of all file system changes) and finds the original, correct timestamps, proving that the file timestamps were deliberately altered to mislead the investigation.</p>",
                            "image": "https://images.unsplash.com/photo-1556091212-a1b6379a05de?w=800&h=400&fit=crop"
                        }
                    ],
                    "codeExamples": [
                        {
                            "title": "Anti-Forensics Detection Toolkit (Timestamp Anomaly)",
                            "language": "python",
                            "code": "import os\nfrom datetime import datetime\n\n# This conceptual script checks for a common timestamp anomaly:\n# a file's creation time being AFTER its last modified time.\n\ndef check_timestamp_anomaly(filepath):\n    \"\"\"Checks for evidence of timestomping on a single file.\"\"\"\n    try:\n        # Get file metadata\n        stat_info = os.stat(filepath)\n        creation_time = datetime.fromtimestamp(stat_info.st_ctime)\n        modification_time = datetime.fromtimestamp(stat_info.st_mtime)\n\n        # In a normal file lifecycle, creation time should always be before modification time.\n        # If this is not the case, it's a strong indicator of manipulation.\n        if creation_time > modification_time:\n            print(f\"[!] ANOMALY DETECTED in {filepath}:\")\n            print(f\"    Creation Time: {creation_time}\")\n            print(f\"    Modification Time: {modification_time}\")\n            print(\"    This is a strong indicator of 'timestomping'.\")\n\n    except FileNotFoundError:\n        print(f\"File not found: {filepath}\")\n\n# Example usage\n# check_timestamp_anomaly(\"/path/to/suspicious_file.exe\")"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        {
                            "id": 1,
                            "question": "The act of deliberately altering a file's timestamps to mislead an investigator is known as:",
                            "options": [
                                "File carving",
                                "Timestomping",
                                "Hashing",
                                "Encryption"
                            ],
                            "correct": 1,
                            "explanation": "Timestomping is a classic anti-forensic technique used to disrupt timeline analysis by making files appear older or newer than they actually are."
                        },
                        {
                            "id": 2,
                            "question": "What is the primary difference between encryption and steganography?",
                            "options": [
                                "There is no difference.",
                                "Encryption conceals the content of a message, while steganography conceals the existence of the message.",
                                "Steganography is stronger than encryption.",
                                "Encryption is only for text files."
                            ],
                            "correct": 1,
                            "explanation": "Encryption makes a message unreadable. Steganography hides a message inside another file so that no one knows it's even there. Both are forms of data hiding."
                        },
                        {
                            "id": 3,
                            "question": "An investigator is analyzing a disk and finds that the Prefetch file for 'Eraser.exe' (a known data wiping tool) was recently created. Even if the suspect's files are gone, what does this artifact prove?",
                            "options": [
                                "It proves nothing.",
                                "It proves that the suspect is innocent.",
                                "It proves that the data wiping tool was executed on the system, which is strong evidence of intent to destroy data.",
                                "It proves that the disk has failed."
                            ],
                            "correct": 2,
                            "explanation": "The presence and execution of an anti-forensic tool is, itself, a powerful piece of evidence. It shows a 'consciousness of guilt' and an active attempt to destroy evidence, which can be very compelling."
                        }
                    ]
                }
            },
            
        {
            "id": "lesson-13",
            "title": "Mobile Device Disk Forensics",
            "duration": "120 min",
            "objectives": [
                "Understand the architecture of mobile storage (e.g., eMMC, UFS).",
                "Analyze the Android and iOS file systems and their key differences.",
                "Extract and analyze application data, focusing on SQLite databases.",
                "Recover deleted SMS messages, call logs, and contacts.",
                "Examine location data from GPS, Wi-Fi, and cell tower artifacts.",
                "Detect and perform a basic analysis of mobile malware."
            ],
            "content": {
                "overview": "Mobile devices are arguably the most personal computers we own, containing a detailed record of our lives. This lesson delves into the specialized world of mobile forensics, covering the unique file systems of Android and iOS, the methods for data extraction, and the types of evidence—from text messages to location history—that can be recovered.",
                "sections": [
                    {
                        "title": "Mobile Storage and File Systems",
                        "content": "<p>Mobile devices use solid-state storage and have file systems that are heavily sandboxed and permission-based to protect application data.</p><h3>Key Platforms:</h3><ul><li><strong>Android:</strong> Uses a Linux-based file system (typically ext4). It has a more open structure than iOS, allowing for different levels of data extraction depending on whether the device is rooted. Key data is often stored in `/data/data/<app_package_name>`.</li><li><strong>iOS:</strong> Uses APFS (Apple File System). It has a very locked-down, sandboxed architecture. A 'file system' extraction is typically only possible on a jailbroken device. Most iOS forensics relies on analyzing iTunes/Finder backups.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1610465213254-2c35a8276b4a?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Data Extraction Methods",
                        "content": "<p>Getting the data off a mobile device is the first major hurdle.</p><h3>Extraction Levels:</h3><ul><li><strong>Logical Extraction:</strong> Acquiring the files and directories accessible through the device's normal API. This is like acquiring an iTunes backup. It gets a lot of user data but misses deleted files and system-level artifacts.</li><li><strong>File System Extraction:</strong> Acquiring the full file system structure, including system files and databases not available in a logical backup. This often requires an exploit or a jailbroken/rooted device.</li><li><strong>Physical Extraction:</strong> A bit-for-bit image of the entire flash memory chip. This is the most complete but also the most difficult, often requiring advanced techniques like 'chip-off' (physically removing the memory chip) or exploiting low-level bootloader vulnerabilities.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1585255428357-ac758950454a?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Key Artifacts: SQLite and Location Data",
                        "content": "<p>The vast majority of mobile application data is stored in SQLite databases.</p><p><strong>Real-time Problem: Recovering deleted messages from a damaged phone.</strong> An Android phone is physically damaged but the memory chip is intact. A forensic analyst performs a 'chip-off' extraction to get a physical image of the flash memory. The analyst then uses a forensic tool to find the SQLite database for the SMS/MMS application (`mmssms.db`). By parsing the database and its associated write-ahead log (`-wal` file), and by carving the unallocated space within the database file itself, the analyst is able to recover text messages that the user had deleted months prior to the phone being damaged.</p><h3>Location Data:</h3><p>Mobile devices are tracking devices. Location history can be recovered from:</p><ul><li><strong>Photos:</strong> EXIF data often contains GPS coordinates.</li><li><strong>Wi-Fi History:</strong> A list of all Wi-Fi networks the device has ever connected to.</li><li><strong>Cell Tower Data:</strong> Logs of which cell towers the phone has connected to.</li><li><strong>Significant Locations (iOS):</strong> A database that tracks the user's most frequently visited locations.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1526628953301-3e589a6a8b74?w=800&h=400&fit-crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Mobile Data Extraction Script (Android ADB)",
                        "language": "bash",
                        "code": "# This script uses the Android Debug Bridge (ADB) for a basic logical extraction.\n# This requires the phone to be unlocked and have USB Debugging enabled.\n\n# Check for connected device\nadb devices\n\n# Create a backup of the entire phone's data (apps, shared storage)\n# The user will be prompted on the phone to approve the backup.\necho \"Please approve the backup on the device screen...\"\nadb backup -all -f backup.ab\n\n# The resulting 'backup.ab' file is an Android Backup file.\n# It can be converted and parsed with tools like Android Backup Extractor (abe.jar)\n# to extract the contents for analysis.\n\n# Example of pulling a specific application's database directly (if rooted)\n# adb pull /data/data/com.whatsapp/databases/msgstore.db"
                    }
                ]
            },
            "quiz": {
                "passingScore": 80,
                "questions": [
                    {
                        "id": 1,
                        "question": "Which data extraction method creates a bit-for-bit copy of a mobile device's entire flash memory, including unallocated space?",
                        "options": [
                            "Logical Extraction",
                            "File System Extraction",
                            "Physical Extraction",
                            "Cloud Extraction"
                        ],
                        "correct": 2,
                        "explanation": "A physical extraction is the mobile equivalent of a full disk image. It is the most complete form of acquisition, capturing all data from the memory chip."
                    },
                    {
                        "id": 2,
                        "question": "What is the most common format for storing application data, such as text messages or browser history, on both iOS and Android?",
                        "options": [
                            "PST files",
                            "The Windows Registry",
                            "Plain text files",
                            "SQLite databases"
                        ],
                        "correct": 3,
                        "explanation": "SQLite is the ubiquitous database for mobile applications. A huge portion of mobile forensics involves parsing various .sqlite or .db files to reconstruct user activity."
                    },
                    {
                        "id": 3,
                        "question": "For a non-jailbroken iPhone, what is the most common source of evidence for a forensic analyst?",
                        "options": [
                            "A physical image of the memory chip.",
                            "A logical acquisition in the form of an iTunes/Finder backup.",
                            "The device's SIM card.",
                            "The phone's charging cable."
                        ],
                        "correct": 1,
                        "explanation": "Due to Apple's strong security, getting a file system or physical extraction from a modern, locked iPhone is nearly impossible. Therefore, most iOS investigations rely on analyzing the logical backup created by iTunes or Finder."
                    }
                ]
            }
        },
        {
            "id": "lesson-14",
            "title": "Cloud Storage and Virtual Environment Forensics",
            "duration": "100 min",
            "objectives": [
                "Analyze on-disk artifacts from cloud storage synchronization clients (Dropbox, Google Drive).",
                "Conduct a forensic examination of virtual machine disk files (VMDK, VHDX).",
                "Understand the fundamentals of container forensics.",
                "Discuss the role and challenges of hypervisor analysis.",
                "Establish procedures for coordinating with Cloud Service Providers (CSPs) for evidence.",
                "Analyze virtual machine snapshots for historical data."
            ],
            "content": {
                "overview": "The line between the local disk and the cloud is blurring. This lesson covers the forensic analysis of data in virtualized environments and the artifacts left behind by cloud storage services. We will explore how to investigate a virtual machine as if it were a physical disk and how to trace a user's cloud activity from their local computer.",
                "sections": [
                    {
                        "title": "Cloud Storage Artifact Analysis",
                        "content": "<p>When a user uses a service like Dropbox, Google Drive, or OneDrive, the application leaves a detailed trail on the user's local hard drive, even if the files themselves are stored online.</p><h3>Local Artifacts:</h3><ul><li><strong>Sync Logs:</strong> The synchronization client keeps detailed logs of every file that was uploaded, downloaded, modified, or deleted, along with timestamps.</li><li><strong>Local Cache:</strong> A portion of the cloud data is often cached locally for performance. This can be a source of files the user thought were 'online only'.</li><li><strong>Databases:</strong> The client uses local SQLite databases to track the state of all synced files, their versions, and sharing status.</li></ul><p><strong>Real-world Example: Investigating data theft via cloud storage.</strong> An employee is suspected of stealing data. Their browsing history is clear, and no USB devices were used. The forensic analyst examines the user's AppData folder and finds the log files for the Google Drive client. The logs show that at 2:15 AM, a new folder was created on the user's desktop, 15,000 files were moved into it, and then the folder was synced to the user's personal Google Drive account. The logs provide a clear timeline of the data exfiltration.</p>",
                        "image": "https://images.unsplash.com/photo-1510915228340-29c85a43dcfe?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Virtual Machine Forensics",
                        "content": "<p>A virtual machine (VM) is a self-contained computer that runs as a file on a host machine. This virtual disk file can be acquired and analyzed like any other evidence.</p><h3>Key Files:</h3><ul><li><strong>Virtual Disk (VMDK, VHDX):</strong> This is the VM's hard drive. It can be mounted with forensic tools to analyze its file system, recover deleted files, and examine system artifacts.</li><li><strong>Snapshots:</strong> A snapshot is a point-in-time copy of the VM's state. Analyzing snapshots is critical, as they can contain older versions of files or even the state of the VM *before* an attacker tried to cover their tracks.</li><li><strong>Memory/State File (.vmem, .vmss):</strong> Some hypervisors save the VM's RAM to a file when it's suspended. This file can be analyzed using memory forensics techniques to find running processes, network connections, and encryption keys.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Container and Hypervisor Forensics",
                        "content": "<p>These are advanced and emerging areas of forensics.</p><h3>Challenges:</h3><ul><li><strong>Containers (e.g., Docker):</strong> Containers are ephemeral by design. They can be created and destroyed in seconds. The key to container forensics is often not the container itself (which may be gone), but the logs from the container orchestration platform (like Kubernetes) and the underlying host operating system.</li><li><strong>Hypervisor (e.g., VMware ESXi, Hyper-V):</strong> The hypervisor is the software that runs the VMs. A compromise of the hypervisor is a catastrophic event, as it gives the attacker control over all guest VMs. Forensic analysis of a hypervisor is extremely difficult and relies on analyzing its logs and configuration files.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1544197150-b99a580bb7a8?w=800&h=400&fit-crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Cloud Artifact Extraction Tool (PowerShell)",
                        "language": "powershell",
                        "code": "# This conceptual PowerShell script shows how to locate and extract\n# key log files from the Google Drive sync client for analysis.\n\nparam (\n    [string]$Username # The username of the user profile to investigate\n)\n\n# The path to the Google Drive logs on a Windows system\n$googleDriveLogPath = \"C:\\Users\\$Username\\AppData\\Local\\Google\\Drive\\user_default\\sync_log.log\"\n\nif (Test-Path $googleDriveLogPath) {\n    Write-Host \"[+] Google Drive sync log found for user $Username.\"\n    \n    # Define a destination for the collected evidence\n    $destination = \"C:\\forensic_cases\\case005\\cloud_artifacts\\\"\n    New-Item -ItemType Directory -Force -Path $destination\n    \n    # Copy the log file for analysis\n    Copy-Item -Path $googleDriveLogPath -Destination $destination\n    Write-Host \"[+] Log file copied to $destination\"\n    \n    # An analyst would now parse this log file to reconstruct file sync activity.\n    Get-Content $googleDriveLogPath -Tail 20\n} else {\n    Write-Host \"[-] Google Drive sync log not found for user $Username.\"\n}"
                    }
                ]
            },
            "quiz": {
                "passingScore": 80,
                "questions": [
                    {
                        "id": 1,
                        "question": "An investigator is analyzing a user's computer for evidence of data theft. The synchronization logs for a cloud storage client (like Dropbox or OneDrive) would be most useful for what?",
                        "options": [
                            "Determining the user's password.",
                            "Creating a timeline of which files were uploaded to the cloud and when.",
                            "Analyzing the user's web browsing history.",
                            "Recovering deleted partitions."
                        ],
                        "correct": 1,
                        "explanation": "The sync logs are the primary artifact for cloud storage forensics. They provide a detailed, timestamped record of every file operation (upload, download, delete, share) performed by the client, which is invaluable for data exfiltration cases."
                    },
                    {
                        "id": 2,
                        "question": "A VMDK file is a virtual disk image associated with which virtualization platform?",
                        "options": [
                            "Microsoft Hyper-V",
                            "Oracle VirtualBox",
                            "VMware",
                            "Docker"
                        ],
                        "correct": 2,
                        "explanation": "VMDK (Virtual Machine Disk) is the primary virtual disk format for VMware products like Workstation, Fusion, and ESXi."
                    },
                    {
                        "id": 3,
                        "question": "What is a major forensic challenge associated with containers (like Docker)?",
                        "options": [
                            "They are too large to analyze.",
                            "They are always encrypted.",
                            "They are often ephemeral (short-lived), meaning the container may be gone by the time the investigation begins.",
                            "They do not have a file system."
                        ],
                        "correct": 2,
                        "explanation": "The ephemeral nature of containers is a key challenge. Forensic analysis often has to shift from the container itself to the more persistent logs of the container host and the orchestration platform (e.g., Kubernetes) to reconstruct what happened."
                    }
                ]
            }
        },
        {
            "id": "lesson-15",
            "title": "Memory and Volatile Data Analysis",
            "duration": "120 min",
            "objectives": [
                "Understand the order of volatility and the importance of preserving volatile data.",
                "Perform memory acquisition (dumping) from live Windows and Linux systems.",
                "Analyze a memory dump to list running processes and open network connections.",
                "Extract command history and other artifacts from memory.",
                "Detect memory-resident malware and rootkits.",
                "Understand how encryption keys and passwords can be recovered from a memory dump."
            ],
            "content": {
                "overview": "Some of the most critical evidence in an investigation exists only in a computer's Random Access Memory (RAM) and is lost forever the moment the machine is turned off. This lesson covers the crucial discipline of memory forensics, teaching you how to acquire and analyze this volatile data to uncover evidence of running malware, user activity, and even encryption keys.",
                "sections": [
                    {
                        "title": "The Order of Volatility",
                        "content": "<p>The order of volatility is a principle that dictates the order in which evidence should be collected. You should always collect the most volatile data first, before it disappears.</p><h3>The Volatility Hierarchy (Most to Least Volatile):</h3><ol><li><strong>CPU Registers, Cache:</strong> Extremely volatile, rarely collected.</li><li><strong>Memory (RAM):</strong> Highly volatile. Contains all running processes, network connections, loaded drivers, passwords, encryption keys. Lost on power down. This is the focus of memory forensics.</li><li><strong>Network State:</strong> Active connections, routing tables.</li><li><strong>Running Processes.</strong></li><li><strong>Disk Data:</strong> Files stored on HDDs and SSDs.</li><li><strong>Backups, Printouts:</strong> The least volatile evidence.</li></ol>",
                        "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Memory Acquisition (Dumping)",
                        "content": "<p>The first step in memory forensics is to create a 'memory dump'—a bit-for-bit copy of the contents of RAM at a specific moment in time. This must be done on the live, running system.</p><h3>Common Acquisition Tools:</h3><ul><li><strong>FTK Imager (Windows):</strong> A popular GUI-based tool that includes a memory capture feature.</li><li><strong>DumpIt (Windows):</strong> A simple command-line utility for dumping memory.</li><li><strong>LiME (Linux Memory Extractor):</strong> A loadable kernel module for acquiring memory from Linux systems.</li></ul><p>The output is a single, large file (e.g., `memory.dmp`, `memory.raw`) that is the same size as the system's physical RAM.</p>",
                        "image": "https://images.unsplash.com/photo-1544197150-b99a580bb7a8?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Memory Analysis with Volatility",
                        "content": "<p>Once a memory dump is acquired, it's just a raw stream of data. A specialized tool is needed to parse it. The Volatility Framework is the open-source industry standard for memory analysis.</p><p><strong>Real-time Problem: Analyzing sophisticated memory-resident malware.</strong> A system is behaving suspiciously, but antivirus scans of the hard drive find nothing. This suggests the malware is 'fileless' and exists only in memory. An analyst acquires a memory dump and uses Volatility to analyze it. They run the `pslist` plugin to see all running processes, but see nothing unusual. They then run the `malfind` plugin, which is designed to find hidden or injected code. `malfind` discovers a malicious code segment that has been injected into a legitimate process like `explorer.exe`. The analyst can then dump this malicious code from memory for further analysis, proving the system was compromised even though no malware existed on the disk.</p><h3>Common Volatility Plugins:</h3><ul><li><strong>`pslist` / `pstree`:</strong> List running processes and show their parent-child relationships.</li><li><strong>`netscan`:</strong> Show all active network connections at the time of the dump.</li><li><strong>`cmdline` / `consoles`:</strong> Show command history from `cmd.exe`.</li><li><strong>`hashdump`:</strong> Can often extract password hashes from memory.</li><li><strong>`malfind`:</strong> A powerful plugin for finding hidden and injected code.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1515879218367-8466d910aaa4?w=800&h=400&fit-crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Memory Analysis Automation Script (Volatility)",
                        "language": "bash",
                        "code": "# This script demonstrates a common workflow for an initial triage of a memory dump\n# using the Volatility 3 framework.\n\nMEMORY_FILE=\"suspicious_host.mem\"\nPROFILE=\"Win10x64_19041\"\n\n# 1. Get basic image information\nvol -f $MEMORY_FILE windows.info\n\n# 2. List all running processes\n# Pipe the output to a file for review\nvol -f $MEMORY_FILE windows.pslist > pslist.txt\n\n# 3. List active and closed network connections\nvol -f $MEMORY_FILE windows.netscan > netscan.txt\n\n# 4. Check for suspicious injected code\nvol -f $MEMORY_FILE windows.malfind > malfind.txt\n\n# 5. Dump command history from any cmd.exe processes\nvol -f $MEMORY_FILE windows.cmdline > cmdline.txt\n\n# 6. Check for loaded drivers, looking for anything unsigned or strange\nvol -f $MEMORY_FILE windows.driverscan > driverscan.txt\n\n\necho \"Initial memory triage complete. Review the output text files for signs of compromise.\""
                    }
                ]
            },
            "quiz": {
                "passingScore": 80,
                "questions": [
                    {
                        "id": 1,
                        "question": "According to the order of volatility, which of the following should be collected first during a live response?",
                        "options": [
                            "Files on the hard drive",
                            "The contents of system RAM",
                            "Data from a network share",
                            "A system backup from last week"
                        ],
                        "correct": 1,
                        "explanation": "RAM is highly volatile; its contents are lost the moment the system is powered off. Therefore, it is the highest priority data to collect during a live investigation."
                    },
                    {
                        "id": 2,
                        "question": "The Volatility Framework is the industry-standard tool for what purpose?",
                        "options": [
                            "Creating a forensic image of a hard drive.",
                            "Analyzing a memory dump (a copy of RAM).",
                            "Parsing the Windows Registry.",
                            "Recovering deleted files."
                        ],
                        "correct": 1,
                        "explanation": "Volatility is specifically designed to parse the complex data structures within a raw memory dump, allowing an analyst to reconstruct running processes, network connections, and other volatile artifacts."
                    },
                    {
                        "id": 3,
                        "question": "Malware that runs entirely in memory and never writes a file to the disk is known as:",
                        "options": [
                            "A virus",
                            "A worm",
                            "'Fileless' malware",
                            "A bootkit"
                        ],
                        "correct": 2,
                        "explanation": "'Fileless' malware is a stealthy technique where the malicious code is injected directly into a legitimate running process. It is very difficult to detect with traditional antivirus but can be found through memory analysis."
                    }
                ]
            }
        },
        {
            "id": "lesson-16",
            "title": "Encryption and Cryptographic Analysis",
            "duration": "100 min",
            "objectives": [
                "Identify the presence of encrypted volumes on a disk.",
                "Understand the forensic challenges of full-disk encryption (BitLocker, FileVault, LUKS).",
                "Analyze file-level encryption and encrypted containers.",
                "Discuss techniques for encryption key recovery, primarily from memory.",
                "Apply password attack methodologies (dictionary, brute-force) to encrypted files.",
                "Analyze cryptographic signatures and digital certificates.",
                "Understand the basics of blockchain and cryptocurrency forensics."
            ],
            "content": {
                "overview": "Encryption is a foundational security technology, but it presents a major obstacle to forensic investigators. This lesson covers the challenges of dealing with encrypted data, from identifying encrypted volumes to the techniques used to bypass or break the encryption and gain access to the underlying evidence.",
                "sections": [
                    {
                        "title": "Full Disk Encryption (FDE)",
                        "content": "<p>FDE encrypts the entire operating system volume, making it unreadable without the correct key or password.</p><h3>Common FDE Technologies:</h3><ul><li><strong>BitLocker (Windows):</strong> The native FDE solution in Windows.</li><li><strong>FileVault 2 (macOS):</strong> The native FDE solution in macOS.</li><li><strong>LUKS (Linux):</strong> The standard for disk encryption on Linux.</li></ul><p><strong>The Forensic Challenge:</strong> If a computer is found powered off and encrypted with a strong password, a standard forensic acquisition of the disk will yield only gibberish. It is forensically impossible to break the AES-256 encryption used by modern FDE. The entire investigation hinges on obtaining the key.</p>",
                        "image": "https://images.unsplash.com/photo-1548092372-2d987bde898b?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Key Recovery and Live Analysis",
                        "content": "<p>Since breaking the encryption is not an option, the focus shifts to recovering the key.</p><h3>Key Recovery Methods:</h3><ul><li><strong>From the User:</strong> Compelling the user to provide the password through legal means.</li><li><strong>From Memory:</strong> This is the most important technical method. If the encrypted computer is found powered on and unlocked, the encryption keys *must* exist in RAM for the system to function. An analyst can perform a live memory acquisition (dump) and then use forensic tools to extract the encryption keys from the memory dump. This key can then be used to decrypt the forensic image of the hard drive.</li><li><strong>From System Artifacts:</strong> Sometimes recovery keys are stored elsewhere, such as in a user's cloud account (e.g., Microsoft Account for BitLocker) or on the TPM chip.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1510915228340-29c85a43dcfe?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "File-Level Encryption and Password Attacks",
                        "content": "<p>Even if the disk isn't fully encrypted, users can encrypt individual files or create encrypted containers (e.g., with VeraCrypt, or password-protected ZIP/PDF files).</p><p><strong>Real-time Problem: Breaking weak encryption implementation.</strong> An investigator recovers a password-protected ZIP file. The encryption on ZIP files can be weak. The analyst uses a password cracking tool like John the Ripper or Hashcat. They first try a 'dictionary attack', using a list of millions of common passwords. When that fails, they launch a 'brute-force attack', systematically trying every possible combination of characters. If the user chose a short or simple password, the tool can often recover it in a matter of hours or days, granting access to the contents.</p>",
                        "image": "https://images.unsplash.com/photo-1555949963-ff9fe0c870eb?w=800&h=400&fit-crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Encryption Detection and Analysis Tool (BitLocker)",
                        "language": "bash",
                        "code": "# This example uses the 'bde-utils' library on Linux to check a forensic image\n# for BitLocker encryption and extract metadata.\n\nIMAGE_FILE=\"/evidence_locker/encrypted_drive.dd\"\n\n# 1. Check for BitLocker signatures on the image\n# The presence of '-FVE-FS-' at a specific offset is a key indicator.\n\nsudo bdeinfo -v $IMAGE_FILE\n\n# The output will show if the volume is encrypted, which version of BitLocker was used,\n# and what protectors are enabled (e.g., Password, Recovery Key, TPM).\n\n# 2. Attempt to unlock the volume using a known recovery key\n# This would be done after extracting the key from memory or another source.\n\nRECOVERY_KEY=\"48-digit-numerical-recovery-password\"\nMOUNT_POINT=\"/mnt/decrypted_volume\"\nmkdir -p $MOUNT_POINT\n\n# Use the bdemount utility to mount the decrypted volume\nsudo bdemount -r $RECOVERY_KEY $IMAGE_FILE $MOUNT_POINT\n\n# If successful, the decrypted file system will be accessible at the mount point.\nls -la $MOUNT_POINT"
                    }
                ]
            },
            "quiz": {
                "passingScore": 80,
                "questions": [
                    {
                        "id": 1,
                        "question": "If a computer with BitLocker full-disk encryption is found powered on and unlocked, what is the most critical first step for an investigator?",
                        "options": [
                            "To immediately power it off to preserve the disk.",
                            "To perform a live memory acquisition (dump) to capture the encryption keys from RAM.",
                            "To start a brute-force password attack.",
                            "To take a picture of the screen."
                        ],
                        "correct": 1,
                        "explanation": "This is a race against time. The encryption keys must exist in RAM for the running system to work. Capturing a memory dump before the machine is powered off is often the only way to obtain the key and decrypt the hard drive."
                    },
                    {
                        "id": 2,
                        "question": "An attack that tries to guess a password by using a large list of common words and phrases is known as a:",
                        "options": [
                            "Brute-force attack",
                            "Dictionary attack",
                            "Denial-of-service attack",
                            "Social engineering attack"
                        ],
                        "correct": 1,
                        "explanation": "A dictionary attack is a common password cracking technique that is much faster than a pure brute-force attack, as it focuses on likely passwords rather than trying every possible combination."
                    },
                    {
                        "id": 3,
                        "question": "BitLocker, FileVault, and LUKS are all examples of what?",
                        "options": [
                            "File systems",
                            "File carving tools",
                            "Native Full Disk Encryption (FDE) technologies",
                            "Anti-forensic tools"
                        ],
                        "correct": 2,
                        "explanation": "These are the built-in FDE solutions for Windows (BitLocker), macOS (FileVault), and Linux (LUKS), respectively. Their presence is a major challenge for disk forensics."
                    }
                ]
            }
        },
        {
            "id": "lesson-17",
            "title": "Large-Scale Disk Analysis and Big Data Forensics",
            "duration": "90 min",
            "objectives": [
                "Understand the challenges of performing forensics on distributed storage systems.",
                "Apply parallel processing and big data platforms (like Hadoop/Spark) to forensic analysis.",
                "Use automated triage techniques to quickly identify relevant evidence in massive datasets.",
                "Leverage machine learning and pattern recognition to find anomalies.",
                "Design and manage a scalable infrastructure for forensic processing.",
                "Optimize forensic workflows for performance in large-scale investigations."
            ],
            "content": {
                "overview": "In corporate and enterprise environments, an investigation may involve not one disk, but thousands, totaling petabytes of data. Traditional, single-machine forensic techniques do not scale. This lesson explores the strategies and technologies used for large-scale digital forensics, applying big data principles to find the needle in a digital haystack.",
                "sections": [
                    {
                        "title": "The Challenge of Scale",
                        "content": "<p>A single forensic analyst working on a single machine cannot effectively investigate a breach that spans an entire enterprise network. The sheer volume of data is overwhelming.</p><h3>The 'Big Data' Problems in Forensics:</h3><ul><li><strong>Volume:</strong> Terabytes or petabytes of data from servers, laptops, and logs.</li><li><strong>Velocity:</strong> New data is being generated constantly, requiring real-time analysis.</li><li><strong>Variety:</strong> Data comes from many different sources and formats (disk images, network logs, memory dumps, cloud logs).</li></ul><p>The solution is to stop bringing the data to the tool and start bringing the tool to the data, using distributed processing.</p>",
                        "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Distributed Processing and Automated Triage",
                        "content": "<p>Large-scale forensics relies on parallel processing to analyze many sources of evidence at once.</p><h3>The Workflow:</h3><ol><li><strong>Acquisition:</strong> Evidence is collected from many endpoints simultaneously using remote acquisition agents.</li><li><strong>Processing:</strong> Instead of one analyst processing one image, a framework like Hadoop or Spark is used. The forensic image is broken into chunks, and hundreds of virtual machines (nodes) work in parallel, each analyzing a small piece of the data.</li><li><strong>Triage & Super-Timeline:</strong> The framework automatically extracts key artifacts (e.g., running processes, log entries, file creations) from all sources and puts them into a single, massive 'super-timeline'.</li><li><strong>Analysis:</strong> The analyst does not look at the raw images. They query the super-timeline to find anomalies and pivot between related events across multiple systems.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1551288049-bebda4e38f71?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Machine Learning in Forensics",
                        "content": "<p>With massive datasets, machine learning can be used to find patterns that are impossible for a human to spot.</p><p><strong>Real-time Problem: Analyzing petabytes of enterprise data.</strong> In a major data breach investigation, a company has collected 5,000 disk images. It would take a single analyst years to review them. Instead, they use a distributed processing framework. It takes 24 hours to process all the images and create a super-timeline with billions of events. The lead investigator then runs a query to find a specific piece of malware seen on one machine. The framework instantly returns a list of the 15 other machines where that malware's hash was also seen, allowing the team to immediately understand the scope of the breach. They then use machine learning to find other, unknown malware by looking for statistical outliers in process behavior.</p>",
                        "image": "https://images.unsplash.com/photo-1620712943543-285f212a5a54?w=800&h=400&fit-crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Distributed Forensic Analysis Framework (Plaso/Log2Timeline)",
                        "language": "bash",
                        "code": "# This is a conceptual example of using Plaso (Log2Timeline), a key tool for\n# creating super-timelines, in a distributed fashion.\n\n# The forensic images are stored in a distributed file system like HDFS.\nIMAGE_PATH=\"hdfs:///forensic_images/host-001.E01\"\nOUTPUT_PATH=\"hdfs:///timelines/host-001.plaso\"\n\n# Step 1: Run the processing job on a distributed computing cluster (e.g., Spark).\n# This command would be submitted to the cluster scheduler.\n\nspark-submit \\\n  --class org.log2timeline.plaso.cli.SparkTool \\\n  plaso-spark.jar \\\n  --source $IMAGE_PATH \\\n  --output $OUTPUT_PATH\n\n# This process would be repeated for thousands of images in parallel.\n\n# Step 2: Once all images are processed, the analyst can use a tool like\n# Timesketch to load all the .plaso files and analyze the combined super-timeline.\n\n# Step 3: An analyst queries the final timeline.\n# psort.py -o dynamic -w results.csv \"SELECT * FROM l2t_events WHERE source_long = 'WEBHIST' AND hostname = 'ceo-laptop'\" hdfs:///timelines/*.plaso"
                    }
                ]
            },
            "quiz": {
                "passingScore": 80,
                "questions": [
                    {
                        "id": 1,
                        "question": "What are the 'three V's' that define a big data problem in forensics?",
                        "options": [
                            "Volatility, Value, and VHDs",
                            "Volume, Velocity, and Variety",
                            "Validation, Verification, and Virtualization",
                            "Vector, Vulnerability, and Victim"
                        ],
                        "correct": 1,
                        "explanation": "These are the classic definitions of a big data environment: a massive volume of data, being generated with high velocity, from a wide variety of sources."
                    },
                    {
                        "id": 2,
                        "question": "What is the primary goal of creating a 'super-timeline' in a large-scale investigation?",
                        "options": [
                            "To make the investigation report longer.",
                            "To aggregate and normalize key events from thousands of evidence sources into a single, searchable dataset.",
                            "To prove that the timestamps on the systems are correct.",
                            "To delete irrelevant data."
                        ],
                        "correct": 1,
                        "explanation": "A super-timeline is the core of modern large-scale forensics. It allows an analyst to pivot across huge datasets and see the chronological relationship between an event on one computer and an event on another."
                    },
                    {
                        "id": 3,
                        "question": "In the context of enterprise forensics, what does 'automated triage' mean?",
                        "options": [
                            "Letting an AI decide who is guilty.",
                            "Using automated, parallel processing to rapidly extract the most critical artifacts from a large number of systems to quickly identify compromised machines.",
                            "A new type of forensic imaging format.",
                            "A legal process for handling evidence."
                        ],
                        "correct": 1,
                        "explanation": "Triage is the process of rapid prioritization. In large-scale forensics, automation is used to perform a quick, high-level analysis on all systems to find the 'smoking guns', allowing human analysts to focus their deep-dive efforts on the most critical evidence."
                    }
                ]
            }
        },
        {
            "id": "lesson-18",
            "title": "Specialized System Forensics",
            "duration": "100 min",
            "objectives": [
                "Perform forensic analysis on common server systems (web, database, domain controllers).",
                "Extract and analyze web server logs to reconstruct attacker activity.",
                "Investigate backup systems for historical data and evidence of tampering.",
                "Understand the forensic challenges of network appliances like firewalls and routers.",
                "Discuss the unique aspects of embedded systems, ICS, and POS system forensics.",
                "Analyze artifacts from a compromised medical device."
            ],
            "content": {
                "overview": "Not all disks are created equal. A web server, a domain controller, and a point-of-sale system are all computers, but they have unique roles, configurations, and artifacts. This lesson covers the specialized forensic analysis of common server types and embedded systems, focusing on the unique evidence each one provides.",
                "sections": [
                    {
                        "title": "Web Server Forensics",
                        "content": "<p>When a website is hacked, the web server's logs are the primary source of evidence.</p><h3>Key Artifacts:</h3><ul><li><strong>Access Logs:</strong> A record of every single HTTP request made to the server. An analyst can search these logs for evidence of vulnerability scanning, SQL injection attempts, or access to a web shell.</li><li><strong>Error Logs:</strong> Can reveal failed attack attempts or problems caused by an attacker's activity.</li><li><strong>Web Shells:</strong> The attacker's primary tool. A web shell is a malicious script (e.g., in PHP, ASPX) uploaded to the server that gives the attacker the ability to execute commands. Finding the web shell file itself is a critical goal.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1555949963-ff9fe0c870eb?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Domain Controller Forensics",
                        "content": "<p>A Domain Controller (DC) is the heart of a Windows network. It manages authentication and is a prime target for attackers.</p><h3>Key Artifacts:</h3><ul><li><strong>Security Event Log (ID 4624/4625):</strong> The DC logs every successful (4624) and failed (4625) login attempt on the entire network. Analyzing these logs is key to tracking lateral movement and brute-force attacks.</li><li><strong>NTDS.dit file:</strong> The Active Directory database. Attackers will attempt to steal this file so they can crack all the user password hashes offline.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1521791136064-7986c2920216?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Point-of-Sale (POS) and Embedded Systems",
                        "content": "<p>These systems are often stripped-down, legacy computers running specialized software.</p><p><strong>Real-time Problem: Investigating a compromised payment system.</strong> A retail company suffers a breach of credit card data. The investigation focuses on the POS terminals in the stores. The forensic analyst discovers that the attackers used a weak remote administration password to gain access to one terminal. From there, they deployed specialized malware known as a 'RAM scraper'. This malware sits in memory, inspects the memory of the payment processing application, and 'scrapes' credit card numbers from RAM at the moment they are swiped, before they are encrypted for storage. The analysis of the POS terminal's memory dump is the key to identifying the malware and understanding how the data was stolen.</p>",
                        "image": "https://images.unsplash.com/photo-1556742502-ec7c0e9f34b1?w=800&h=400&fit-crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Server Artifact Correlation Tool (Log Parser)",
                        "language": "bash",
                        "code": "# This is a simple shell command to perform a common web server log analysis task:\n# finding which IP addresses are scanning for vulnerabilities.\n\nACCESS_LOG=\"/var/log/apache2/access.log\"\n\n# Search the access log for requests that generated a '404 Not Found' error.\n# Attackers and scanners frequently request common vulnerability paths that don't exist.\n\ngrep \" 404 \" $ACCESS_LOG | \\\n\n# Extract just the IP address from the beginning of each line.\nawk '{print $1}' | \\\n\n# Count the occurrences of each IP address and sort them.\nsort | uniq -c | sort -nr | \\\n\n# Display the top 10 IPs that are generating the most 404 errors.\nhead -10\n\n# An IP address with thousands of 404 errors is very likely a malicious scanner."
                    }
                ]
            },
            "quiz": {
                "passingScore": 80,
                "questions": [
                    {
                        "id": 1,
                        "question": "In a web server breach investigation, which artifact would provide the most detailed record of every HTTP request the attacker made?",
                        "options": [
                            "The server's RAM",
                            "The server's access log",
                            "The Master File Table (MFT)",
                            "The Windows Registry"
                        ],
                        "correct": 1,
                        "explanation": "The access log is specifically designed to record every incoming request, including the source IP, the requested URL, the user agent, and the server's response code. It is the primary source for reconstructing an attacker's web-based activity."
                    },
                    {
                        "id": 2,
                        "question": "An investigator needs to track an attacker's lateral movement through a Windows network. Which server would contain the centralized logs of all successful and failed login attempts?",
                        "options": [
                            "The Web Server",
                            "The Database Server",
                            "The Domain Controller",
                            "The File Server"
                        ],
                        "correct": 2,
                        "explanation": "The Domain Controller is responsible for authentication in a Windows Active Directory environment. Its security event log is the definitive source for tracking login activity across the entire domain."
                    },
                    {
                        "id": 3,
                        "question": "Malware specifically designed to steal credit card numbers by reading them directly from the memory of a payment application on a Point-of-Sale (POS) terminal is known as a:",
                        "options": [
                            "A virus",
                            "A worm",
                            "A keylogger",
                            "A RAM scraper"
                        ],
                        "correct": 3,
                        "explanation": "RAM scrapers are a specialized class of POS malware. They target the small window of time where credit card data exists in memory in an unencrypted state, just before it's processed and encrypted for storage or transmission."
                    }
                ]
            }
        },
        {
            "id": "lesson-19",
            "title": "Forensic Tool Development and Automation",
            "duration": "100 min",
            "objectives": [
                "Understand the principles of custom tool development for forensic analysis.",
                "Use APIs to integrate and extend existing forensic tools.",
                "Develop automation scripts (e.g., in Python) to streamline common forensic tasks.",
                "Understand the critical importance of tool validation and testing.",
                "Automate the generation of forensic reports.",
                "Follow quality assurance procedures for custom-developed code."
            ],
            "content": {
                "overview": "Commercial forensic tools are powerful, but they can't do everything. The most advanced investigators are not just users of tools; they are builders. This lesson introduces the principles of forensic tool development and automation, showing how scripting and programming can be used to solve unique challenges, accelerate investigations, and ensure consistency.",
                "sections": [
                    {
                        "title": "Why Develop Custom Tools?",
                        "content": "<p>While comprehensive forensic suites exist, there are common situations where a custom script or tool is needed.</p><h3>Common Use Cases:</h3><ul><li><strong>Parsing a New Artifact:</strong> A new application becomes popular, and no commercial tool knows how to parse its unique log file format yet. A custom script is needed to extract the evidence.</li><li><strong>Automating Repetitive Tasks:</strong> An investigator finds themselves running the same 10 commands on every single disk image. A script can automate this workflow, saving time and preventing errors.</li><li><strong>Large-Scale Triage:</strong> A script can be written to quickly scan thousands of files and flag only those that meet specific criteria (e.g., contain a certain keyword, were created in a certain date range), allowing an analyst to focus on the most relevant data.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1515879218367-8466d910aaa4?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Python: The Language of Forensics",
                        "content": "<p>While many languages can be used, Python has become the de facto standard for forensic scripting and tool development.</p><h3>Why Python?</h3><ul><li><strong>Easy to Learn:</strong> It has a simple and readable syntax.</li><li><strong>Powerful Libraries:</strong> A vast ecosystem of libraries exists for everything from parsing binary data (`struct`) and analyzing registry hives (`regipy`) to interacting with APIs (`requests`).</li><li><strong>Cross-Platform:</strong> The same script can often be run on Windows, macOS, and Linux with minimal changes.</li></ul><p>By learning Python, an investigator can move from being a passive user of a tool's GUI to being able to directly interact with and manipulate any data source.</p>",
                        "image": "https://images.unsplash.com/photo-1587620962725-abab7fe55159?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Tool Validation and Testing: The Scientific Standard",
                        "content": "<p>Any tool used in a forensic investigation—whether commercial or custom-built—must be validated. Validation is the process of proving that the tool works as expected.</p><p><strong>Real-time Problem: Developing a tool for a new file format.</strong> An investigator is analyzing a new chat application. They write a Python script to parse the application's proprietary database and extract messages. Before they can use this script in a real case, they must validate it. They create a test phone, send specific messages, and then use their script to extract the data. They compare the output of their script to the known messages they sent. They must prove, for example, that their script correctly interprets timestamps and does not alter the content of the messages. This validation process is documented and is essential for the evidence to be defensible in court.</p>",
                        "image": "https://images.unsplash.com/photo-1542744173-05336fcc7ad4?w=800&h=400&fit-crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Complete Forensic Analysis Suite (Conceptual Automation Script)",
                        "language": "python",
                        "code": "import os\nimport subprocess\n\n# This is a conceptual master script that automates a common forensic triage workflow.\n\ndef triage_disk_image(image_path, case_folder):\n    \"\"\"Runs a series of forensic tools against a disk image and outputs reports.\"\"\"\n    print(f\"[*] Starting triage on {image_path}\")\n\n    # 1. Run Plaso/Log2Timeline to create a super-timeline\n    print(\"[*] Generating timeline with Plaso...\")\n    plaso_output = os.path.join(case_folder, \"timeline.plaso\")\n    # subprocess.run([\"log2timeline.py\", plaso_output, image_path])\n\n    # 2. Run a file carving tool like Foremost\n    print(\"[*] Carving files with Foremost...\")\n    carve_output = os.path.join(case_folder, \"carved_files\")\n    # subprocess.run([\"foremost\", \"-i\", image_path, \"-o\", carve_output])\n\n    # 3. Run a registry parsing tool\n    print(\"[*] Parsing registry hives...\")\n    registry_report = os.path.join(case_folder, \"registry_report.txt\")\n    # You would first need to extract the hive files from the image.\n    # then run a tool like 'rip.pl' against them, piping output to the report.\n\n    # 4. Generate a final summary report\n    print(\"[*] Generating final report...\")\n    # Code to aggregate the findings from the previous steps into a single HTML report.\n    \n    print(\"[+] Triage complete. Reports are in {case_folder}\")\n\n# Example usage\n# triage_disk_image(\"/evidence_locker/image.dd\", \"/forensic_cases/case006/\")"
                    }
                ]
            },
            "quiz": {
                "passingScore": 80,
                "questions": [
                    {
                        "id": 1,
                        "question": "What is the primary reason for a forensic analyst to develop a custom script?",
                        "options": [
                            "Because commercial tools are always wrong.",
                            "To automate a repetitive task or to parse a new type of digital artifact that existing tools don't support.",
                            "To get a job as a software developer.",
                            "To make the investigation more difficult."
                        ],
                        "correct": 1,
                        "explanation": "Custom scripting is about solving specific problems and increasing efficiency. It's used to fill the gaps that commercial, general-purpose tools might have."
                    },
                    {
                        "id": 2,
                        "question": "The process of testing and documenting that a forensic tool works as expected is known as:",
                        "options": [
                            "Debugging",
                            "Compilation",
                            "Validation",
                            "Marketing"
                        ],
                        "correct": 2,
                        "explanation": "Tool validation is a critical part of the scientific methodology of digital forensics. Before any tool's output can be trusted as evidence, the analyst must prove that the tool is accurate and reliable."
                    },
                    {
                        "id": 3,
                        "question": "Which programming language has become the de facto standard for forensic automation and tool development due to its ease of use and extensive libraries?",
                        "options": [
                            "C++",
                            "Java",
                            "Assembly",
                            "Python"
                        ],
                        "correct": 3,
                        "explanation": "Python's combination of simplicity, power, and a massive ecosystem of third-party libraries specifically for security and forensics has made it the go-to language for investigators and analysts."
                    }
                ]
            }
        },
        {
            "id": "lesson-20",
            "title": "Legal Considerations and Expert Testimony",
            "duration": "100 min",
            "objectives": [
                "Understand the rules of evidence as they apply to digital forensics.",
                "Define the qualifications and responsibilities of an expert witness.",
                "Prepare for giving testimony in court, including direct and cross-examination.",
                "Learn to present complex technical findings in a way that is understandable to a non-technical jury.",
                "Navigate international legal frameworks and privacy laws.",
                "Differentiate the procedural requirements for criminal vs. civil cases.",
                "Uphold the professional and ethical standards of the forensic community."
            ],
            "content": {
                "overview": "The final output of a forensic investigation is often not a technical report, but testimony in a court of law. This lesson covers the crucial final stage of the forensic process: preparing and presenting your findings as an expert witness. We will explore the rules of evidence, the art of translating technical concepts for a jury, and the professional ethics that govern an expert's conduct.",
                "sections": [
                    {
                        "title": "The Expert Witness",
                        "content": "<p>In a legal setting, a normal witness can only testify about facts they personally observed. An expert witness is given a special privilege: they can offer their professional opinion based on the evidence.</p><h3>Qualifying as an Expert:</h3><p>To be qualified as an expert, an individual must demonstrate to the court that they have specialized knowledge, skills, training, or experience in a particular field. This is why certifications, education, and years of experience are so important.</p><p><strong>The Expert's Duty:</strong> The primary duty of an expert witness is to the court and to the truth. An expert is an impartial educator, not an advocate for the side that hired them.</p>",
                        "image": "https://images.unsplash.com/photo-1505664194779-8beace7a2044?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Testifying in Court: Direct and Cross-Examination",
                        "content": "<p>Giving testimony is a structured process.</p><h3>The Two Phases:</h3><ul><li><strong>Direct Examination:</strong> The lawyer for the side that hired you asks you questions. This is a friendly examination designed to let you tell the story of your investigation and explain your findings to the jury.</li><li><strong>Cross-Examination:</strong> The lawyer for the opposing side asks you questions. Their goal is to challenge your findings, methodology, and credibility. This is an adversarial process.</li></ul><p><strong>Real-time Problem: Preparing for a high-profile case.</strong> An expert is preparing to testify. They must anticipate the questions from the opposing counsel. They will be asked: 'Did you follow your lab's standard operating procedures? Is your tool validated? Is there another possible explanation for your findings?' The expert must have clear, confident, and well-documented answers for every step of their process. The key to surviving cross-examination is a meticulous and methodologically sound investigation from the very beginning.</p>",
                        "image": "https://images.unsplash.com/photo-1542744173-8e7e53415bb0?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Communicating to a Jury",
                        "content": "<p>The single biggest challenge for an expert witness is to explain highly complex technical concepts to a non-technical audience (the judge and jury).</p><h3>Keys to Effective Communication:</h3><ul><li><strong>Use Analogies:</strong> Explain a complex idea by comparing it to something simple and relatable. 'The MFT is like the card catalog in a library, and the disk clusters are like the books on the shelves.'</li><li><strong>Be a Teacher:</strong> Your role is to educate, not to sound smart. Avoid jargon.</li><li><strong>Visual Aids:</strong> Use charts, diagrams, and timelines to make your findings clear and easy to follow.</li><li><strong>Remain Objective:</strong> Present the facts of your analysis. Do not speculate or offer opinions outside your area of expertise. Your credibility is your most important asset.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1552664730-d307ca884978?w=800&h=400&fit-crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Mock Trial Preparation Exercise (Report Snippet)",
                        "language": "markdown",
                        "code": "# Expert Report Snippet: Explaining Timestamps\n\n**Finding:** The malicious file 'evil.exe' was created on the suspect's computer at 2025-09-10 14:35:10 UTC.\n\n### Explanation for a Non-Technical Audience:\n\n*   **Analogy:** Think of a file on a computer like a library book. Every book has a check-out card that gets stamped with dates. Computer files have a similar, hidden 'check-out card' that records several different timestamps.\n\n*   **What we found:** We analyzed the file system, which is the computer's detailed record-keeping system. We found an entry for the file 'evil.exe'. This entry contained four different timestamps.\n\n*   **The 'Created' Stamp:** One of these stamps, the 'Created' time, shows the exact moment the file first appeared on this computer's hard drive. In this case, that time was 14:35:10 UTC on September 10th, 2025.\n\n*   **Conclusion:** Based on this timestamp, which is a normal and automatic function of the Windows operating system, it is my expert opinion that the file 'evil.exe' was introduced to the system at that specific time."
                    }
                ]
            },
            "quiz": {
                "passingScore": 80,
                "questions": [
                    {
                        "id": 1,
                        "question": "What is the primary duty of an expert witness in court?",
                        "options": [
                            "To ensure that the side that hired them wins the case.",
                            "To provide their impartial, expert opinion to help the court understand the evidence.",
                            "To confuse the jury with technical jargon.",
                            "To argue with the opposing lawyer."
                        ],
                        "correct": 1,
                        "explanation": "An expert's primary duty is to the court and to the truth, regardless of which side is paying them. They are there to be an objective and impartial educator."
                    },
                    {
                        "id": 2,
                        "question": "The questioning of an expert witness by the opposing side's lawyer is known as:",
                        "options": [
                            "Direct examination",
                            "Cross-examination",
                            "A deposition",
                            "An affidavit"
                        ],
                        "correct": 1,
                        "explanation": "Cross-examination is the adversarial process where the opposing counsel tests the expert's findings, methodology, and credibility."
                    },
                    {
                        "id": 3,
                        "question": "What is the most important skill for an expert witness when testifying in front of a jury?",
                        "options": [
                            "The ability to use as much technical jargon as possible.",
                            "The ability to speak very quickly.",
                            "The ability to explain complex technical concepts in a simple, clear, and understandable way.",
                            "The ability to refuse to answer questions."
                        ],
                        "correct": 2,
                        "explanation": "The jury is made up of non-technical people. If they cannot understand what you are saying, your testimony is useless. The ability to teach and explain complex topics simply is the key to being an effective expert witness."
                    }
                ]
            }
        },
        {
            "id": "lesson-21",
            "title": "Quality Assurance and Validation",
            "duration": "90 min",
            "objectives": [
                "Understand the importance of a formal Quality Management System (QMS) in a forensic lab.",
                "Develop and implement Standard Operating Procedures (SOPs).",
                "Establish a process for peer review of forensic reports.",
                "Conduct tool validation and reproducibility testing.",
                "Prepare for laboratory certification and accreditation (e.g., ISO 17025).",
                "Implement a continuous improvement process for all forensic procedures."
            ],
            "content": {
                "overview": "Digital forensics is a science, and science requires rigor, consistency, and quality control. This lesson covers the essential elements of quality assurance in a forensic laboratory. We will explore how to validate tools, write standard operating procedures, and implement a peer review process to ensure that all findings are accurate, repeatable, and defensible.",
                "sections": [
                    {
                        "title": "Standard Operating Procedures (SOPs)",
                        "content": "<p>An SOP is a detailed, written, step-by-step set of instructions for performing a routine task. In forensics, there should be an SOP for everything from receiving evidence to imaging a drive to writing a final report.</p><h3>Benefits of SOPs:</h3><ul><li><strong>Consistency:</strong> Ensures that every analyst performs a task in the exact same, approved way every single time.</li><li><strong>Defensibility:</strong> In court, you can show that you followed a documented, standard procedure, which strengthens the credibility of your findings.</li><li><strong>Training:</strong> SOPs are an invaluable tool for training new analysts.</li><li><strong>Error Reduction:</strong> A well-written SOP acts as a checklist, reducing the chance that an analyst will forget a critical step.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1542744173-8e7e53415bb0?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Tool Validation and Reproducibility",
                        "content": "<p>As discussed previously, all forensic tools must be validated. But a core part of quality assurance is ensuring that your *entire process* is reproducible.</p><p><strong>Reproducibility</strong> means that if another qualified analyst, following your documented notes and SOPs, were to perform the same analysis on the same evidence, they should arrive at the exact same conclusion. This is the scientific standard for a valid finding. It removes individual bias and proves that the conclusion is based on the evidence and the methodology, not the person.</p>",
                        "image": "https://images.unsplash.com/photo-1519389950473-47ba0277781c?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Peer Review and Lab Accreditation",
                        "content": "<p>A Quality Management System incorporates checks and balances to ensure high standards.</p><h3>Key QA Processes:</h3><ul><li><strong>Technical Peer Review:</strong> Before any forensic report is finalized, it should be reviewed by another qualified analyst. The reviewer checks for technical errors, ensures the conclusions are supported by the evidence, and looks for grammatical mistakes.</li><li><strong>Administrative Review:</strong> A final check to ensure the report meets all formatting, branding, and legal requirements.</li></ul><p><strong>Real-time Problem: Validating controversial forensic findings.</strong> An analyst's findings in a major case are going to be heavily challenged in court. To prepare, the lab manager performs an external validation. They provide a copy of the evidence and the analyst's draft report to another trusted, independent forensic lab. This second lab performs their own analysis. If they independently reach the same conclusions, it provides extremely strong validation of the original findings and prepares the primary analyst for cross-examination.</p><p>The highest level of quality assurance is formal laboratory accreditation, such as to the **ISO/IEC 17025** standard, which is the international standard for the competence of testing and calibration laboratories.</p>",
                        "image": "https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?w=800&h=400&fit-crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Automated Quality Assurance System (Conceptual)",
                        "language": "python",
                        "code": "import json\n\n# This conceptual script checks a draft forensic report for compliance with an SOP.\n\ndef check_report_compliance(report_json_path, sop_checklist_path):\n    \"\"\"Checks a report against a quality assurance checklist.\"\"\"\n    with open(report_json_path, 'r') as f:\n        report = json.load(f)\n    with open(sop_checklist_path, 'r') as f:\n        checklist = json.load(f)\n\n    print(\"--- Running QA Check on Forensic Report ---\")\n    is_compliant = True\n    for item in checklist['required_sections']:\n        if item['section_name'] not in report:\n            print(f\"[FAILURE] Missing required section: {item['section_name']}\")\n            is_compliant = False\n        else:\n            print(f\"[SUCCESS] Section '{item['section_name']}' is present.\")\n            \n    # Check if all evidence items have a hash value\n    for evidence in report.get('evidence_list', []):\n        if 'sha256_hash' not in evidence:\n            print(f\"[FAILURE] Evidence item {evidence['item_id']} is missing a hash.\")\n            is_compliant = False\n\n    return is_compliant"
                    }
                ]
            },
            "quiz": {
                "passingScore": 80,
                "questions": [
                    {
                        "id": 1,
                        "question": "A detailed, step-by-step written document that explains how to perform a routine task like imaging a hard drive is called a:",
                        "options": [
                            "Chain of Custody",
                            "Standard Operating Procedure (SOP)",
                            "Forensic Report",
                            "Legal Hold"
                        ],
                        "correct": 1,
                        "explanation": "SOPs are the backbone of a quality management system. They ensure that all tasks are performed in a consistent, repeatable, and defensible manner."
                    },
                    {
                        "id": 2,
                        "question": "The principle that another qualified analyst should be able to follow your notes and arrive at the same conclusion is known as:",
                        "options": [
                            "Validation",
                            "Peer Review",
                            "Reproducibility",
                            "Accreditation"
                        ],
                        "correct": 2,
                        "explanation": "Reproducibility is a core tenet of the scientific method and is essential for forensic findings to be considered reliable and objective."
                    },
                    {
                        "id": 3,
                        "question": "What is the purpose of a technical peer review for a forensic report?",
                        "options": [
                            "To check for spelling and grammar errors.",
                            "To ensure the report is formatted correctly.",
                            "To have another qualified analyst check for technical errors and ensure the conclusions are supported by the evidence.",
                            "To get the report approved by the legal department."
                        ],
                        "correct": 2,
                        "explanation": "The technical peer review is a critical quality control step. It's a sanity check by a colleague to catch any mistakes or unsupported conclusions before the report is finalized and sent to a client or court."
                    }
                ]
            }
        },
        {
            "id": "lesson-22",
            "title": "Advanced Analysis Techniques",
            "duration": "90 min",
            "objectives": [
                "Understand how Artificial Intelligence (AI) and Machine Learning (ML) are being applied to forensics.",
                "Use ML for pattern recognition and anomaly detection in large datasets.",
                "Apply Natural Language Processing (NLP) to analyze text-based evidence.",
                "Leverage image recognition for sorting and comparing multimedia evidence.",
                "Use advanced visualization techniques to uncover hidden relationships in data.",
                "Apply statistical analysis to forensic data to strengthen findings."
            ],
            "content": {
                "overview": "As data volumes explode, manual analysis is becoming increasingly difficult. This lesson explores the cutting edge of forensic analysis, showing how advanced techniques like machine learning and artificial intelligence are being used to automate analysis, find hidden patterns, and help investigators make sense of massive datasets.",
                "sections": [
                    {
                        "title": "Machine Learning for Anomaly Detection",
                        "content": "<p>Machine learning excels at finding the 'needle in a haystack'. An ML model can be trained on a baseline of 'normal' activity, and it can then flag any event that deviates significantly from that baseline.</p><h3>Real-World Example:</h3><p>An investigator has a super-timeline with billions of log entries from a company's network. It's impossible for a human to read it all. They use a machine learning model to analyze the login activity. The model knows that employees normally log in from 8 AM to 6 PM from specific countries. The model automatically flags a successful login at 3 AM from an unusual country as a high-priority anomaly, even though it was a 'successful' login. This allows the investigator to immediately focus on a likely compromised account.</p>",
                        "image": "https://images.unsplash.com/photo-1620712943543-285f212a5a54?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Natural Language Processing (NLP) and Image Recognition",
                        "content": "<p>AI can also be used to analyze the content of unstructured data like documents and images.</p><h3>Applications:</h3><ul><li><strong>NLP for eDiscovery:</strong> In a corporate investigation, lawyers may need to review millions of emails. An NLP model can be trained to automatically identify and prioritize documents that are relevant to the case (e.g., ones that discuss a specific project or have a negative sentiment).</li><li><strong>Image Recognition:</strong> In a law enforcement case involving illicit images, an AI model can perform image hashing and recognition to automatically identify known illegal material, saving a human analyst from having to manually review every single image.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1554080353-a576cf803bda?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Advanced Visualization",
                        "content": "<p>A picture is worth a thousand words, especially in a complex investigation. Advanced visualization tools can turn massive spreadsheets of data into intuitive graphs that reveal hidden connections.</p><p><strong>Real-world Example:</strong> An investigator has a log of all email communications within a company. It's just a massive table of 'From' and 'To' addresses. They load this data into a graph visualization tool like Gephi or Maltego. The tool automatically creates a 'social network' graph, showing each person as a node and each email as an edge. The investigator immediately sees a small, isolated cluster of people who email each other frequently but rarely email anyone else in the company. This visual outlier is a strong indicator of a potential conspiracy or insider threat group that requires further investigation.</p>",
                        "image": "https://images.unsplash.com/photo-1551288049-bebda4e38f71?w=800&h=400&fit-crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "AI-Powered Forensic Analysis System (Conceptual)",
                        "language": "python",
                        "code": "from sklearn.ensemble import IsolationForest\nimport pandas as pd\n\n# This conceptual script demonstrates using an anomaly detection algorithm\n# (Isolation Forest) to find suspicious login activity.\n\n# 1. Load login data (in a real case, this would be millions of events)\ndata = {\n    'hour_of_day': [9, 10, 14, 17, 10, 11, 3, 15],\n    'is_weekend': [0, 0, 0, 0, 0, 0, 1, 0], # 0=False, 1=True\n    'country_code': ['US', 'US', 'US', 'US', 'US', 'US', 'RU', 'US']\n}\ndf = pd.get_dummies(pd.DataFrame(data)) # Convert country to numeric\n\n# 2. Train the anomaly detection model\nmodel = IsolationForest(contamination=0.1) # Expect 10% anomalies\nmodel.fit(df)\n\n# 3. Predict which events are anomalous\n# -1 indicates an anomaly, 1 indicates a normal event\ndf['anomaly'] = model.predict(df)\n\nprint(\"--- Anomaly Detection Results ---\")\nprint(df[df['anomaly'] == -1])"
                    }
                ]
            },
            "quiz": {
                "passingScore": 80,
                "questions": [
                    {
                        "id": 1,
                        "question": "What is the primary application of machine learning in large-scale forensic investigations?",
                        "options": [
                            "To automatically write the final report.",
                            "To conduct interviews with suspects.",
                            "To analyze massive datasets to find patterns and anomalies that a human investigator would miss.",
                            "To validate forensic tools."
                        ],
                        "correct": 2,
                        "explanation": "Machine learning excels at finding the 'needle in a haystack'. Its main forensic use is in anomaly detection and pattern recognition within vast amounts of log and system data."
                    },
                    {
                        "id": 2,
                        "question": "An investigator using an AI model to analyze millions of emails to find relevant documents for a lawsuit is an application of what technology?",
                        "options": [
                            "Image Recognition",
                            "Natural Language Processing (NLP)",
                            "Disk Imaging",
                            "Steganography"
                        ],
                        "correct": 1,
                        "explanation": "NLP is the branch of AI that deals with understanding and processing human language. It is heavily used in eDiscovery to automate the review of text-based evidence like emails and documents."
                    },
                    {
                        "id": 3,
                        "question": "Graph visualization tools like Gephi or Maltego are most useful for what purpose in an investigation?",
                        "options": [
                            "Recovering deleted files.",
                            "Analyzing the contents of a memory dump.",
                            "Uncovering hidden relationships and connections between different pieces of evidence (like people, emails, and websites).",
                            "Cracking passwords."
                        ],
                        "correct": 2,
                        "explanation": "Graph visualization turns tabular data into a network graph, making it much easier for the human brain to spot connections, clusters, and outliers that would be invisible in a spreadsheet."
                    }
                ]
            }
        },
        {
            "id": "lesson-23",
            "title": "Real-World Case Studies and Scenarios",
            "duration": "120 min",
            "objectives": [
                "Apply all learned techniques to a complex, multi-faceted case.",
                "Analyze a corporate espionage investigation from start to finish.",
                "Deconstruct an intellectual property theft case involving an insider threat.",
                "Walk through a financial fraud examination.",
                "Understand the unique challenges of criminal investigations (e.g., child exploitation, terrorism).",
                "Synthesize findings from disk, memory, and network forensics into a single timeline."
            ],
            "content": {
                "overview": "Theory is essential, but forensics is a practical discipline. This capstone lesson synthesizes everything we have learned throughout the course by walking through a complex, real-world case study from the initial alert to the final report. We will see how different types of evidence from disk, memory, and the network are correlated to tell a complete story.",
                "sections": [
                    {
                        "title": "Case Study: The 'Titan' Corporate Espionage Investigation",
                        "content": "<p>This case involves a suspected insider threat at a technology company who is believed to be stealing secret design documents for a new product, codenamed 'Titan'.</p><h3>The Initial Lead:</h3><p>A User Behavior Analytics (UBA) system generates an alert for an engineer named John Doe. The alert was triggered by him downloading an unusually large volume of files from the 'Project_Titan' SharePoint site at 2:00 AM.</p>",
                        "image": "https://images.unsplash.com/photo-1516321497487-e288fb19713f?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "The Investigation: Connecting the Dots",
                        "content": "<p>The investigation proceeds by collecting and correlating evidence from multiple sources in a specific order.</p><ol><li><strong>Live Analysis:</strong> The team performs a live memory acquisition of John's laptop. Analysis of the memory dump shows a running process for the Google Drive sync client and an active network connection to Google's servers.</li><li><strong>Disk Imaging:</strong> A forensic image of John's laptop hard drive is created.</li><li><strong>Disk Forensics:</strong><ul><li>Analysis of the Google Drive client's local SQLite database and sync logs shows that a file named `Titan_Blueprints.zip` was uploaded to a personal Gmail account.</li><li>Analysis of the browser history shows searches for 'how to securely wipe a hard drive'.</li><li>Analysis of the Windows Registry shows that a USB drive was connected shortly after the large download. Its serial number is recorded.</li></ul></li><li><strong>Network Forensics:</strong> A review of the company's web proxy logs confirms a 2.5 GB upload from John's machine to `drive.google.com` at the time of the UBA alert.</li></ol>",
                        "image": "https://images.unsplash.com/photo-1526628953301-3e589a6a8b74?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "The Conclusion: A Synthesized Timeline",
                        "content": "<p>By combining all these artifacts, the investigator can create a detailed, second-by-second timeline of events that tells a clear and defensible story.</p><h3>The Timeline:</h3><ul><li><strong>01:55 AM:</strong> John Doe logs into his laptop (Source: Windows Event Log).</li><li><strong>02:01 AM:</strong> John Doe downloads 2.5 GB of data from SharePoint (Source: UBA Alert, SharePoint Audit Log).</li><li><strong>02:10 AM:</strong> A file named `Titan_Blueprints.zip` is created (Source: MFT Analysis).</li><li><strong>02:15 AM:</strong> An upload of 2.5 GB to `drive.google.com` begins (Source: Network Proxy Logs).</li><li><strong>02:20 AM:</strong> The file `Titan_Blueprints.zip` is synced (Source: Google Drive Sync Log).</li><li><strong>02:30 AM:</strong> John Doe's browser history shows searches for data wiping tools (Source: Browser History Database).</li></ul><p>The combination of evidence from different, independent sources creates a powerful and highly credible case, proving the data theft beyond a reasonable doubt.</p>",
                        "image": "https://images.unsplash.com/photo-1552664730-d307ca884978?w=800&h=400&fit-crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "End-to-End Complex Case Investigation (Timeline)",
                        "language": "markdown",
                        "code": "# Snippet from the Final Forensic Report Timeline\n\n| Timestamp (UTC)     | Source of Evidence  | Hostname      | User      | Event Description                                                                   |\n|---------------------|---------------------|---------------|-----------|-------------------------------------------------------------------------------------|\n| 2025-09-11 01:55:12 | Security Event Log  | LPT-JDOE-01   | John.Doe  | Successful Logon (Event ID 4624)                                                    |\n| 2025-09-11 02:01:35 | SharePoint Logs     | SharePoint-01 | John.Doe  | Accessed file library 'Project_Titan_Designs'                                       |\n| 2025-09-11 02:10:05 | MFT ($FILE_NAME)    | LPT-JDOE-01   | N/A       | File Created: C:\\Users\\John.Doe\\Desktop\\Titan_Blueprints.zip                        |\n| 2025-09-11 02:15:22 | Web Proxy Log       | LPT-JDOE-01   | John.Doe  | HTTP POST to drive.google.com, 2,516,582,400 bytes                                  |\n| 2025-09-11 02:20:48 | GDrive Sync Log     | LPT-JDOE-01   | John.Doe  | SUCCESS: Upload of Titan_Blueprints.zip to account johndoe123@gmail.com             |\n| 2025-09-11 02:30:11 | Browser History DB  | LPT-JDOE-01   | John.Doe  | Visited URL: https://www.google.com/search?q=best+secure+file+eraser              |"
                    }
                ]
            },
            "quiz": {
                "passingScore": 80,
                "questions": [
                    {
                        "id": 1,
                        "question": "In the case study, what was the primary value of analyzing the memory dump?",
                        "options": [
                            "It showed which files were on the desktop.",
                            "It proved that the Google Drive client was actively running and connected to the network at the time of the incident.",
                            "It recovered the user's password.",
                            "It showed the computer's hardware specifications."
                        ],
                        "correct": 1,
                        "explanation": "Memory forensics provides a snapshot of what was happening on a system at a specific moment. In this case, it proved the suspect's computer was actively running the data exfiltration tool (the sync client) and was connected to the destination."
                    },
                    {
                        "id": 2,
                        "question": "What is the purpose of creating a synthesized 'super-timeline' in a complex investigation?",
                        "options": [
                            "To make the evidence look more complicated than it is.",
                            "To combine artifacts from multiple, independent sources (disk, memory, network) into a single chronological narrative.",
                            "It is a legal requirement in all cases.",
                            "To determine the time zone of the suspect."
                        ],
                        "correct": 1,
                        "explanation": "A timeline is the story of the crime. By correlating different types of evidence, an investigator can build a powerful, detailed narrative that is much more compelling and defensible than any single piece of evidence on its own."
                    },
                    {
                        "id": 3,
                        "question": "In the case study, finding the USB connection history in the Registry and the Google Drive sync logs on the disk are both examples of what discipline?",
                        "options": [
                            "Memory Forensics",
                            "Network Forensics",
                            "Disk Forensics",
                            "Live Analysis"
                        ],
                        "correct": 2,
                        "explanation": "Both the Windows Registry and application log files are artifacts that are stored on the hard drive. Analyzing them is a core part of disk forensics."
                    }
                ]
            }
        },
        {
            "id": "lesson-24",
            "title": "Emerging Technologies and Future Challenges",
            "duration": "90 min",
            "objectives": [
                "Discuss the potential impact of quantum computing on forensic evidence and encryption.",
                "Understand the forensic challenges posed by the massive scale of the Internet of Things (IoT).",
                "Explore the difficulties of tracing transactions and identifying actors on the blockchain.",
                "Analyze the challenge of authenticating evidence in the age of AI-generated deepfakes.",
                "Consider the forensic implications of 5G, edge computing, and augmented reality.",
                "Discuss the need for continuous adaptation and learning in the field of digital forensics."
            ],
            "content": {
                "overview": "The field of digital forensics is in a constant state of evolution, driven by the rapid pace of technological change. This final lesson looks to the horizon, exploring the future challenges and opportunities that will shape the next generation of digital investigation. From AI-generated evidence to the explosion of IoT devices, we will discuss how investigators must adapt to a constantly changing world.",
                "sections": [
                    {
                        "title": "The IoT Explosion: A Tsunami of Evidence",
                        "content": "<p>The Internet of Things (IoT) will create an unprecedented volume and variety of digital evidence. Every smart device in a home or city—from a doorbell to a car—will be a potential source of data.</p><h3>Future Challenges:</h3><ul><li><strong>Scale:</strong> An investigation might involve seizing and analyzing hundreds of disparate devices, each with its own proprietary file system and data format.</li><li><strong>Proprietary Systems:</strong> Many IoT devices have no standard way to access their data, requiring new and specialized extraction techniques.</li><li><strong>Data Correlation:</strong> The main challenge will be correlating tiny bits of data from hundreds of sources to reconstruct a single event.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1535683416248-8495c6b8159b?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "Blockchain and Cryptocurrency Forensics",
                        "content": "<p>Blockchain, the technology behind cryptocurrencies like Bitcoin, creates a public, immutable ledger of all transactions. This presents both opportunities and challenges.</p><h3>Forensic Aspects:</h3><ul><li><strong>Opportunity (Traceability):</strong> Every transaction is public. Specialized tools can be used to trace the flow of illicit funds across the blockchain from one wallet to another.</li><li><strong>Challenge (Anonymity):</strong> While the transactions are public, the identities behind the wallet addresses are pseudonymous. The key challenge of blockchain forensics is 'de-anonymization'—linking a specific wallet address to a real-world person, often by finding a transaction where they interacted with a regulated exchange that required them to provide identification.</li></ul>",
                        "image": "https://images.unsplash.com/photo-1621452773352-2a74c35b2917?w=800&h=400&fit-crop"
                    },
                    {
                        "title": "AI and the Deepfake Dilemma",
                        "content": "<p>Perhaps the greatest future challenge to digital evidence is the rise of AI-generated 'deepfakes'.</p><p><strong>Real-time Problem: Investigating AI-generated deepfake evidence.</strong> In a harassment case, the primary piece of evidence is a video showing a person making threatening statements. The defense claims the video is a deepfake. The forensic analyst can no longer simply say 'the video shows what happened'. They must now perform a highly technical analysis of the video file itself, looking for subtle artifacts of AI manipulation, such as unnatural blinking, strange lighting inconsistencies, or digital compression anomalies. The field of forensics will have to evolve new techniques to authenticate digital media in a world where seeing is no longer believing.</p>",
                        "image": "https://images.unsplash.com/photo-1611162617474-5b21e879e113?w=800&h=400&fit-crop"
                    }
                ],
                "codeExamples": [
                    {
                        "title": "Next-Generation Forensic Framework (Conceptual)",
                        "language": "python",
                        "code": "class ForensicCase:\n    def __init__(self, case_id):\n        self.case_id = case_id\n        self.evidence_streams = []\n\n    def add_evidence(self, evidence_type, data_source):\n        # Ingest data from diverse sources (IoT, Blockchain, Disk)\n        self.evidence_streams.append({'type': evidence_type, 'source': data_source})\n        print(f\"Ingested {evidence_type} evidence.\")\n\n    def correlate_events(self):\n        \"\"\"Uses AI/ML to find connections between disparate evidence streams.\"\"\"\n        print(\"\\nCorrelating events across all evidence streams...\")\n        # This would be a complex AI model in a real system.\n        # Conceptual Logic:\n        # IF (IoT_Door_Sensor.event == 'open' at Time X)\n        # AND (Blockchain_Transaction.value > 1000 at Time X+1min)\n        # AND (Deepfake_Detection_Tool.result == 'likely fake' on video from Time X+5min)\n        # THEN generate a high-priority alert for the analyst.\n        print(\"Potential correlation found: IoT event followed by financial transaction.\")\n\n# --- Future Scenario ---\ncase = ForensicCase(\"Case-Future-001\")\ncase.add_evidence(\"IoT\", \"door_sensor.log\")\ncase.add_evidence(\"Blockchain\", \"bitcoin_ledger.csv\")\ncase.add_evidence(\"Multimedia\", \"disputed_video.mp4\")\ncase.correlate_events()"
                    }
                ]
            },
            "quiz": {
                "passingScore": 80,
                "questions": [
                    {
                        "id": 1,
                        "question": "What is the primary challenge in blockchain forensics?",
                        "options": [
                            "The transactions are all secret and hidden.",
                            "Linking a pseudonymous wallet address to a real-world identity.",
                            "The blockchain is too slow.",
                            "There are not enough forensic tools."
                        ],
                        "correct": 1,
                        "explanation": "The challenge isn't seeing the transactions (which are public), but de-anonymizing the actors. This usually involves finding a point where the suspect moved cryptocurrency through a regulated exchange where they had to provide their real identity."
                    },
                    {
                        "id": 2,
                        "question": "The rise of AI-generated deepfakes will require forensic analysts to develop new skills in what area?",
                        "options": [
                            "Recovering deleted files.",
                            "Authenticating the integrity of digital multimedia evidence.",
                            "Analyzing network traffic.",
                            "Writing Standard Operating Procedures."
                        ],
                        "correct": 1,
                        "explanation": "In a world with deepfakes, an analyst can no longer take a video or audio file at face value. They will need new tools and techniques to detect the subtle artifacts of AI manipulation to determine if a piece of media is real or synthetic."
                    },
                    {
                        "id": 3,
                        "question": "What is the biggest forensic challenge posed by the massive growth of IoT devices?",
                        "options": [
                            "IoT devices do not store any data.",
                            "The sheer volume and variety of devices, each with its own proprietary data format and extraction method.",
                            "IoT devices are too expensive.",
                            "IoT devices are never involved in criminal cases."
                        ],
                        "correct": 1,
                        "explanation": "The scale and lack of standardization are the key problems. An investigation may require analyzing hundreds of different types of devices, making the acquisition and analysis process incredibly complex and time-consuming."
                    }
                ]
            }
        }
    ]
}
      // =====================================================
      // GLOBAL VARIABLES
      // =====================================================
      let currentUser = null;
      let currentLessonIndex = 0;
      let courseProgress = {};
      let userStats = {};
      let quizState = {
        currentQuestion: 0,
        answers: [],
        score: 0,
        isComplete: false,
        timeStarted: null,
        timeCompleted: null,
        currentQuestionIndex: 0,
      };

      // Enhanced session tracking
      let courseSession = {
        startTime: null,
        totalStudyTime: 0,
        lessonsStarted: 0,
        lessonsCompleted: 0,
        pageLoadTime: new Date(),
        lastActive: new Date(),
        interactions: 0,
        completedSections: [],
        totalTime: 0,
        interactionCount: 0,
        lastActivityTime: new Date(),
      };

      // Music Player Variables
      let audioPlayer = new Audio();

      // Achievement notification system
      let notificationQueue = [];
      let isShowingNotification = false;

      // =====================================================
      // INITIALIZATION
      // =====================================================
      document.addEventListener("DOMContentLoaded", async () => {
        try {
          showLoadingScreen();
          await checkAuth();

          if (currentUser) {
            // Initialize session tracking
            startCourseSession();

            // Load course data and progress
            await loadCourseData();
            await loadUserProfile();
            await loadProgress();

            // Initialize UI
            initializeEventListeners();
            renderSidebar();
            loadLesson(currentLessonIndex);

            // Initialize additional features
            initMusicPlayer();
            addMusicIndicator();
            initializeActivityTracking();

            hideLoadingScreen();
          } else {
            openAuthModal();
          }
        } catch (error) {
          console.error("Error initializing course:", error);
          hideLoadingScreen();
          showToast("Failed to initialize course system", "error");
        }
      });

      // =====================================================
      // AUTHENTICATION SYSTEM
      // =====================================================
      async function checkAuth() {
        try {
          const {
            data: { session },
            error,
          } = await supabase.auth.getSession();

          if (error) {
            console.error("Auth error:", error);
            currentUser = null;
            openAuthModal();
            return;
          }

          if (!session) {
            currentUser = null;
            openAuthModal();
            return;
          }

          currentUser = session.user;
          updateUIWithUser();
        } catch (error) {
          console.error("Error checking auth:", error);
          currentUser = null;
          openAuthModal();
        }
      }

      function updateUIWithUser() {
        if (!currentUser) return;

        const name =
          currentUser.user_metadata?.full_name ||
          currentUser.email.split("@")[0];
        const userElements = document.querySelectorAll("[data-user-name]");
        userElements.forEach((el) => (el.textContent = name));
      }

      // =====================================================
      // USER PROFILE & STATS MANAGEMENT
      // =====================================================
      async function loadUserProfile() {
        try {
          // 🔍 Step 1: Try to fetch existing profile
          const { data: profile, error } = await supabase
            .from("profiles")
            .select("*")
            .eq("id", currentUser.id)
            .single();

          if (error && error.code !== "PGRST116") {
            throw error;
          }

          if (!profile) {
            // 🆕 Step 2: Create new profile if missing
            await createUserProfile();
          } else {
            // ✅ Step 3: Use existing profile
            userStats = profile;
            await updateLastActivity();
          }
        } catch (error) {
          console.error("❌ Error loading user profile:", error);
          showToast("Failed to load user profile", "error");
        }
      }
      async function createUserProfile() {
        try {
          const newProfile = {
            id: currentUser.id,
            full_name: currentUser.user_metadata?.full_name || "",
            email: currentUser.email,
            level: "Script Kiddie",
            total_points: 0,
            completed_courses: 0,
            current_streak: 0,
            total_certificates: 0,
            total_achievements: 0,
            sections_visited: 0,
            bonus_points: 0,
            in_progress_courses: 0,
            settings_changed: 0,
            midnight_sessions: 0,
            early_sessions: 0,
            weekend_sessions: 0,
            last_activity: new Date().toISOString(),
            created_at: new Date().toISOString(),
          };

          const { error } = await supabase
            .from("profiles")
            .insert([newProfile]);

          if (!error) {
            userStats = newProfile;
            // Award first login achievement
            setTimeout(() => checkAndUnlockAchievement("first_login"), 1000);
          }
        } catch (error) {
          console.error("Error creating user profile:", error);
        }
      }

      async function updateLastActivity() {
        try {
          const now = new Date();

          // Update activity tracking
          courseSession.lastActivityTime = now;

          // Update database
          await supabase
            .from("profiles")
            .update({
              last_activity: now.toISOString(),
            })
            .eq("id", currentUser.id);

          // Check time-based achievements
          await checkTimeBasedAchievements(now);
        } catch (error) {
          console.error("Error updating last activity:", error);
        }
      }

      // =====================================================
      // COURSE SESSION MANAGEMENT
      // =====================================================
      function startCourseSession() {
        courseSession.startTime = new Date();
        courseSession.pageLoadTime = new Date();

        logUserActivity("course_session_start", {
          course_id: COURSE_DATA.id,
          course_title: COURSE_DATA.title,
          user_agent: navigator.userAgent,
          screen_resolution: `${screen.width}x${screen.height}`,
        });

        // Check daily streak
        checkDailyStreak();
      }

      function initializeActivityTracking() {
        // Track page focus/blur for accurate study time
        document.addEventListener("visibilitychange", handleVisibilityChange);

        // Track user interactions
        ["click", "keydown", "scroll", "mousemove"].forEach((event) => {
          document.addEventListener(event, trackUserInteraction, {
            passive: true,
          });
        });

        // Periodic activity updates
        setInterval(updateStudyTime, 60000); // Every minute

        // Save session data before page unload
        window.addEventListener("beforeunload", saveSessionData);
      }

      function handleVisibilityChange() {
        if (document.hidden) {
          courseSession.lastActivityTime = new Date();
        } else {
          // Page became visible again - update activity
          updateLastActivity();
        }
      }

      function trackUserInteraction() {
        courseSession.interactionCount++;
        courseSession.lastActivityTime = new Date();

        // Throttle activity updates
        if (courseSession.interactionCount % 50 === 0) {
          updateLastActivity();
        }
      }

      function updateStudyTime() {
        if (!courseSession.startTime || document.hidden) return;

        const now = new Date();
        const sessionDuration = now - courseSession.startTime;
        courseSession.totalStudyTime = Math.floor(sessionDuration / 1000 / 60); // in minutes

        // Update progress with study time
        saveProgress();
      }

      function saveSessionData() {
        if (!currentUser || !courseSession.startTime) return;

        const sessionData = {
          user_id: currentUser.id,
          course_id: COURSE_DATA.id,
          session_duration: courseSession.totalStudyTime,
          lessons_viewed: courseSession.lessonsStarted,
          lessons_completed: courseSession.lessonsCompleted,
          interactions: courseSession.interactionCount,
          session_date: courseSession.startTime.toISOString().split("T")[0],
        };

        // Store in localStorage as backup
        localStorage.setItem(
          "course_session_backup",
          JSON.stringify(sessionData)
        );

        // Try to save to database
        logUserActivity("course_session_end", sessionData);
      }

      // =====================================================
      // COURSE DATA & PROGRESS MANAGEMENT
      // =====================================================
      async function loadCourseData() {
        try {
          // Update course info in UI
          document.getElementById("courseTitle").textContent =
            COURSE_DATA.title;
          document.getElementById("totalLessons").textContent =
            COURSE_DATA.lessons.length;

          // Log course access
          logUserActivity("course_access", {
            course_id: COURSE_DATA.id,
            course_title: COURSE_DATA.title,
          });
        } catch (error) {
          console.error("Error loading course data:", error);
        }
      }

      async function loadProgress() {
        try {
          // Get existing progress from database
          const { data, error } = await supabase
            .from("course_progress")
            .select("*")
            .eq("user_id", currentUser.id)
            .eq("course_id", COURSE_DATA.id)
            .single();

          if (error && error.code !== "PGRST116") {
            throw error;
          }

          if (data) {
            courseProgress = JSON.parse(data.lesson_progress || "{}");
            currentLessonIndex = data.current_lesson || 0;

            // Update session tracking
            courseSession.lessonsStarted = Object.keys(courseProgress).length;
            courseSession.lessonsCompleted = Object.values(
              courseProgress
            ).filter((p) => p.completed).length;
          } else {
            // Initialize new progress
            courseProgress = {};
            currentLessonIndex = 0;
            await saveProgress();

            // Award first course start achievement
            await checkAndUnlockAchievement("first_course_start");
          }

          updateProgressDisplay();
        } catch (error) {
          console.error("Error loading progress:", error);
          showToast("Failed to load progress", "error");
        }
      }

      async function saveProgress() {
        try {
          if (!currentUser) return;

          const now = new Date();
          const progressData = {
            user_id: currentUser.id,
            course_id: COURSE_DATA.id,
            course_title: COURSE_DATA.title,
            current_lesson: currentLessonIndex,
            lesson_progress: JSON.stringify(courseProgress),
            progress: calculateOverallProgress(),
            lessons_completed: getCompletedLessonsCount(),
            lessons_started: Object.keys(courseProgress).length,
            study_time_minutes: courseSession.totalStudyTime,
            last_accessed: now.toISOString(),
            updated_at: now.toISOString(),
          };

          // Upsert progress
          const { error } = await supabase
            .from("course_progress")
            .upsert([progressData]);

          if (error) throw error;

          // Update user stats
          await updateUserStats();

          updateProgressDisplay();
        } catch (error) {
          console.error("Error saving progress:", error);
          showToast("Failed to save progress", "error");
        }
      }

      async function updateUserStats() {
        try {
          // Get all course progress for this user
          const { data: allProgress, error } = await supabase
            .from("course_progress")
            .select("progress, course_id, study_time_minutes")
            .eq("user_id", currentUser.id);

          if (error) throw error;

          // Calculate stats
          const completedCourses =
            allProgress?.filter((p) => p.progress >= 100).length || 0;
          const inProgressCourses =
            allProgress?.filter((p) => p.progress > 0 && p.progress < 100)
              .length || 0;
          const totalStudyTime =
            allProgress?.reduce(
              (sum, p) => sum + (p.study_time_minutes || 0),
              0
            ) || 0;

          // Calculate points (500 per completed course + achievement points)
          const coursePoints = completedCourses * 500;
          const bonusPoints = userStats.bonus_points || 0;
          const totalPoints = coursePoints + bonusPoints;

          // Update profile
          const updateData = {
            completed_courses: completedCourses,
            in_progress_courses: inProgressCourses,
            total_points: totalPoints,
            total_study_time: totalStudyTime,
            last_activity: new Date().toISOString(),
          };

          const { error: updateError } = await supabase
            .from("profiles")
            .update(updateData)
            .eq("id", currentUser.id);

          if (updateError) throw updateError;

          // Update local stats
          Object.assign(userStats, updateData);
        } catch (error) {
          console.error("Error updating user stats:", error);
        }
      }

      function calculateOverallProgress() {
        const completedLessons = getCompletedLessonsCount();
        return Math.round(
          (completedLessons / COURSE_DATA.lessons.length) * 100
        );
      }

      function getCompletedLessonsCount() {
        return Object.values(courseProgress).filter(
          (lesson) => lesson.completed
        ).length;
      }

      function updateProgressDisplay() {
        const completedCount = getCompletedLessonsCount();
        const progressPercent = calculateOverallProgress();

        // Update UI elements
        const elements = {
          completedLessons: completedCount,
          courseProgressPercent: `${progressPercent}%`,
        };

        Object.entries(elements).forEach(([id, value]) => {
          const element = document.getElementById(id);
          if (element) element.textContent = value;
        });

        // Update progress bar
        const progressBar = document.getElementById("courseProgressFill");
        if (progressBar) progressBar.style.width = `${progressPercent}%`;
      }

      // =====================================================
      // LESSON MANAGEMENT
      // =====================================================
      function loadLesson(index) {
        if (index < 0 || index >= COURSE_DATA.lessons.length) return;

        const lesson = COURSE_DATA.lessons[index];
        currentLessonIndex = index;

        // Mark lesson as started and track activity
        if (!courseProgress[lesson.id]) {
          courseProgress[lesson.id] = {
            started: true,
            completed: false,
            startedAt: new Date().toISOString(),
            timeSpent: 0,
          };

          courseSession.lessonsStarted++;
          saveProgress();

          // Log lesson start
          logUserActivity("lesson_start", {
            lesson_id: lesson.id,
            lesson_title: lesson.title,
            lesson_index: index,
          });
        }

        // Update lesson start time for time tracking
        courseProgress[lesson.id].currentSessionStart = new Date();

        // Update sidebar and navigation
        renderSidebar();
        updateNavigationButtons();

        // Update header info
        updateLessonHeader(lesson, index);

        // Render lesson content
        renderLessonContent(lesson);

        // Smooth scroll and animations
        window.scrollTo({ top: 0, behavior: "smooth" });
        document.getElementById("contentBody").scrollTop = 0;

        const contentBody = document.getElementById("contentBody");
        contentBody.classList.add("fade-in");
        setTimeout(() => contentBody.classList.remove("fade-in"), 500);

        // Check lesson-based achievements
        checkLessonAchievements(index + 1);
      }

      function updateLessonHeader(lesson, index) {
        const elements = {
          currentLessonNumber: index + 1,
          currentLessonTitle: lesson.title,
          navInfo: `Lesson ${index + 1} of ${COURSE_DATA.lessons.length}`,
        };

        Object.entries(elements).forEach(([id, value]) => {
          const element = document.getElementById(id);
          if (element) element.textContent = value;
        });
      }

      function renderSidebar() {
        const lessonNav = document.getElementById("lessonNav");
        if (!lessonNav) return;

        lessonNav.innerHTML = "";

        COURSE_DATA.lessons.forEach((lesson, index) => {
          const lessonItem = document.createElement("div");
          lessonItem.className = "lesson-item";

          // Determine lesson status
          const lessonProgress = courseProgress[lesson.id];
          const isCompleted = lessonProgress?.completed || false;
          const isInProgress = lessonProgress?.started || false;
          const isLocked = !isCompleted && !canAccessLesson(index);
          const isActive = index === currentLessonIndex;

          // Apply status classes
          if (isCompleted) lessonItem.classList.add("completed");
          if (isLocked) lessonItem.classList.add("locked");
          if (isActive) lessonItem.classList.add("active");

          // Determine status display
          let statusClass = "not-started";
          let statusIcon = index + 1;

          if (isCompleted) {
            statusClass = "completed";
            statusIcon = "✓";
          } else if (isInProgress) {
            statusClass = "in-progress";
            statusIcon = "◐";
          }

          // Create lesson item HTML
          lessonItem.innerHTML = `
            <div class="lesson-status ${statusClass}">${statusIcon}</div>
            <div class="lesson-info">
                <div class="lesson-title">${lesson.title}</div>
                <div class="lesson-meta">
                    ${
                      isCompleted
                        ? "Completed"
                        : isInProgress
                        ? "In Progress"
                        : isLocked
                        ? "Locked"
                        : "Not Started"
                    }
                </div>
            </div>
            <div class="lesson-duration">${lesson.duration}</div>
        `;

          // Add click handler if not locked
          if (!isLocked) {
            lessonItem.addEventListener("click", () => {
              if (index !== currentLessonIndex) {
                // Track lesson time before switching
                trackLessonTime();

                currentLessonIndex = index;
                loadLesson(index);
                closeSidebar();
              }
            });
          }

          lessonNav.appendChild(lessonItem);
        });
      }

      function canAccessLesson(index) {
        if (index === 0) return true; // First lesson always accessible

        // Can access if previous lesson is completed
        const previousLessonId = COURSE_DATA.lessons[index - 1].id;
        return courseProgress[previousLessonId]?.completed || false;
      }

      function trackLessonTime() {
        const currentLesson = COURSE_DATA.lessons[currentLessonIndex];
        const lessonProgress = courseProgress[currentLesson.id];

        if (lessonProgress?.currentSessionStart) {
          const sessionTime = Math.floor(
            (new Date() - new Date(lessonProgress.currentSessionStart)) /
              1000 /
              60
          );
          lessonProgress.timeSpent =
            (lessonProgress.timeSpent || 0) + sessionTime;
          delete lessonProgress.currentSessionStart;
        }
      }

      // =====================================================
      // LESSON CONTENT RENDERING
      // =====================================================
      function renderLessonContent(lesson) {
        const contentContainer = document.getElementById("lessonContent");
        if (!contentContainer) return;

        let contentHTML = `
        <div class="content-section">
            <h2>Learning Objectives</h2>
            <ul>
                ${lesson.objectives.map((obj) => `<li>${obj}</li>`).join("")}
            </ul>
        </div>
        
        <div class="content-section">
            <h2>Overview</h2>
            <p>${lesson.content.overview}</p>
        </div>
    `;

        // Render content sections
        lesson.content.sections.forEach((section) => {
          contentHTML += `
            <div class="content-section">
                <h2>${section.title}</h2>
                ${section.content}
                ${
                  section.image
                    ? `<img src="${section.image}" alt="${section.title}" class="content-image" loading="lazy">`
                    : ""
                }
            </div>
        `;
        });

        // Render code examples
        if (
          lesson.content.codeExamples &&
          lesson.content.codeExamples.length > 0
        ) {
          contentHTML += `<div class="content-section"><h2>Code Examples</h2></div>`;

          lesson.content.codeExamples.forEach((example, index) => {
            const codeId = `code-${lesson.id}-${index}`;
            contentHTML += `
                <div class="code-section">
                    <div class="code-header">
                        <span class="code-title">${example.title}</span>
                        <button class="copy-btn" onclick="copyCode('${codeId}')">
                            <i class="fas fa-copy"></i> Copy
                        </button>
                    </div>
                    <pre class="code-block"><code id="${codeId}" class="language-${
              example.language
            }">${escapeHtml(example.code)}</code></pre>
                </div>
            `;
          });
        }

        // Render quiz
        contentHTML += renderQuiz(lesson.quiz);

        contentContainer.innerHTML = contentHTML;

        // Highlight code syntax if Prism is available
        setTimeout(() => {
          if (window.Prism) {
            Prism.highlightAll();
          }
        }, 100);
      }

      // =====================================================
      // QUIZ SYSTEM
      // =====================================================
      function renderQuiz(quiz) {
        const currentLessonProgress =
          courseProgress[COURSE_DATA.lessons[currentLessonIndex].id];
        const isCompleted = currentLessonProgress?.completed || false;

        let quizHTML = `
        <div class="quiz-section" id="quizSection">
            <div class="quiz-header">
                <h2 class="quiz-title">
                    <i class="fas fa-clipboard-check"></i>
                    Knowledge Check
                </h2>
                <p class="quiz-info">
                    Complete this quiz with ${quiz.passingScore}% or higher to unlock the next lesson.
                </p>
            </div>
    `;

        if (isCompleted) {
          const savedScore = currentLessonProgress.quizScore || 0;
          quizHTML += `
            <div class="quiz-results show">
                <div class="quiz-score pass">${savedScore}%</div>
                <div class="quiz-message">
                    <strong>Lesson Completed!</strong><br>
                    You've successfully passed this lesson's quiz.
                </div>
            </div>
        `;
        } else {
          // Render quiz questions
          quiz.questions.forEach((question, qIndex) => {
            quizHTML += `
                <div class="quiz-question ${
                  qIndex === 0 ? "active" : ""
                }" data-question="${qIndex}">
                    <div class="question-header">
                        <span class="question-number">Question ${
                          qIndex + 1
                        }</span>
                        <span class="question-progress">${qIndex + 1}/${
              quiz.questions.length
            }</span>
                    </div>
                    <div class="question-text">${question.question}</div>
                    <div class="question-options">
                        ${question.options
                          .map(
                            (option, oIndex) => `
                            <div class="option" data-option="${oIndex}" onclick="selectOption(${qIndex}, ${oIndex})">
                                <span class="option-letter">${String.fromCharCode(
                                  65 + oIndex
                                )}</span>
                                <span class="option-text">${option}</span>
                            </div>
                        `
                          )
                          .join("")}
                    </div>
                </div>
            `;
          });

          quizHTML += `
            <div class="quiz-controls">
                <button class="btn btn-secondary" id="prevQuestionBtn" onclick="previousQuestion()" disabled>
                    <i class="fas fa-chevron-left"></i>
                    Previous
                </button>
                <div>
                    <button class="btn btn-secondary" id="nextQuestionBtn" onclick="nextQuestion()" disabled>
                        Next
                        <i class="fas fa-chevron-right"></i>
                    </button>
                    <button class="btn btn-primary" id="submitQuizBtn" onclick="submitQuiz()" style="display: none;">
                        <i class="fas fa-check"></i>
                        Submit Quiz
                    </button>
                </div>
            </div>

            <div class="quiz-results" id="quizResults">
                <div class="quiz-score" id="quizScore">0%</div>
                <div class="quiz-message" id="quizMessage"></div>
                <div class="quiz-actions">
                    <button class="btn btn-primary" id="continueBtn" onclick="completeLesson()" style="display: none;">
                        <i class="fas fa-arrow-right"></i>
                        Continue to Next Lesson
                    </button>
                    <button class="btn btn-secondary" onclick="retakeQuiz()">
                        <i class="fas fa-redo"></i>
                        Retake Quiz
                    </button>
                </div>
            </div>
        `;
        }

        quizHTML += "</div>";
        return quizHTML;
      }

      // Quiz interaction functions
      function selectOption(questionIndex, optionIndex) {
        // Clear previous selections
        document
          .querySelectorAll(`[data-question="${questionIndex}"] .option`)
          .forEach((opt) => {
            opt.classList.remove("selected");
          });

        // Select current option
        const selectedOption = document.querySelector(
          `[data-question="${questionIndex}"] [data-option="${optionIndex}"]`
        );
        selectedOption.classList.add("selected");

        // Store answer
        quizState.answers[questionIndex] = optionIndex;

        // Update navigation
        const isLastQuestion =
          questionIndex ===
          COURSE_DATA.lessons[currentLessonIndex].quiz.questions.length - 1;
        if (isLastQuestion) {
          document.getElementById("submitQuizBtn").style.display =
            "inline-flex";
          document.getElementById("nextQuestionBtn").style.display = "none";
        } else {
          document.getElementById("nextQuestionBtn").disabled = false;
        }
      }

      function nextQuestion() {
        const currentQuestionEl = document.querySelector(
          ".quiz-question.active"
        );
        const nextQuestionEl = currentQuestionEl.nextElementSibling;

        if (
          nextQuestionEl &&
          nextQuestionEl.classList.contains("quiz-question")
        ) {
          currentQuestionEl.classList.remove("active");
          nextQuestionEl.classList.add("active");
          quizState.currentQuestion++;
          updateQuizNavigation();
        }
      }

      function previousQuestion() {
        const currentQuestionEl = document.querySelector(
          ".quiz-question.active"
        );
        const prevQuestionEl = currentQuestionEl.previousElementSibling;

        if (
          prevQuestionEl &&
          prevQuestionEl.classList.contains("quiz-question")
        ) {
          currentQuestionEl.classList.remove("active");
          prevQuestionEl.classList.add("active");
          quizState.currentQuestion--;
          updateQuizNavigation();
        }
      }

      function updateQuizNavigation() {
        const totalQuestions =
          COURSE_DATA.lessons[currentLessonIndex].quiz.questions.length;
        const prevBtn = document.getElementById("prevQuestionBtn");
        const nextBtn = document.getElementById("nextQuestionBtn");
        const submitBtn = document.getElementById("submitQuizBtn");

        prevBtn.disabled = quizState.currentQuestion === 0;

        const hasAnswer =
          quizState.answers[quizState.currentQuestion] !== undefined;
        const isLastQuestion = quizState.currentQuestion === totalQuestions - 1;

        if (isLastQuestion) {
          nextBtn.style.display = "none";
          submitBtn.style.display = hasAnswer ? "inline-flex" : "none";
        } else {
          nextBtn.style.display = "inline-flex";
          nextBtn.disabled = !hasAnswer;
          submitBtn.style.display = "none";
        }
      }

      async function submitQuiz() {
        const lesson = COURSE_DATA.lessons[currentLessonIndex];
        const quiz = lesson.quiz;
        let correctAnswers = 0;

        // Hide questions and controls
        document
          .querySelectorAll(".quiz-question")
          .forEach((q) => (q.style.display = "none"));
        document.querySelector(".quiz-controls").style.display = "none";

        // Calculate score and highlight answers
        quiz.questions.forEach((question, index) => {
          const userAnswer = quizState.answers[index];
          const correctAnswer = question.correct;
          const isCorrect = userAnswer === correctAnswer;

          if (isCorrect) correctAnswers++;

          // Highlight answers
          const questionEl = document.querySelector(
            `[data-question="${index}"]`
          );
          const options = questionEl.querySelectorAll(".option");

          options[correctAnswer].classList.add("correct");
          if (userAnswer !== correctAnswer && userAnswer !== undefined) {
            options[userAnswer].classList.add("incorrect");
          }
        });

        const score = Math.round(
          (correctAnswers / quiz.questions.length) * 100
        );
        const passed = score >= quiz.passingScore;

        // Update quiz results UI
        const quizScore = document.getElementById("quizScore");
        const quizMessage = document.getElementById("quizMessage");
        const quizActions = document.querySelector(".quiz-actions");

        quizScore.textContent = `${score}%`;
        quizScore.className = `quiz-score ${passed ? "pass" : "fail"}`;

        if (passed) {
          quizMessage.innerHTML = `
            <strong>Congratulations!</strong><br>
            You passed with ${score}%. You can now proceed to the next lesson.
        `;

          quizActions.innerHTML = `
            <button class="btn btn-primary" onclick="completeLesson()">
                <i class="fas fa-arrow-right"></i>
                Continue to Next Lesson
            </button>
        `;

          // Mark lesson as completed
          await markLessonComplete(score);
        } else {
          quizMessage.innerHTML = `
            <strong>Not quite there yet.</strong><br>
            You scored ${score}%. You need ${quiz.passingScore}% to pass. Review the material and try again.
        `;

          quizActions.innerHTML = `
            <button class="btn btn-secondary" onclick="retakeQuiz()">
                <i class="fas fa-redo"></i>
                Retake Quiz
            </button>
        `;
        }

        document.getElementById("quizResults").classList.add("show");

        // Log quiz completion
        logUserActivity("quiz_completed", {
          lesson_id: lesson.id,
          lesson_title: lesson.title,
          score: score,
          passed: passed,
          attempts: (courseProgress[lesson.id]?.quizAttempts || 0) + 1,
        });

        // Scroll to results
        document
          .getElementById("quizResults")
          .scrollIntoView({ behavior: "smooth" });
      }

      function retakeQuiz() {
        // Reset quiz state
        quizState = {
          currentQuestion: 0,
          answers: [],
          score: 0,
          isComplete: false,
        };

        // Track quiz retry
        const lessonId = COURSE_DATA.lessons[currentLessonIndex].id;
        if (!courseProgress[lessonId]) courseProgress[lessonId] = {};
        courseProgress[lessonId].quizAttempts =
          (courseProgress[lessonId].quizAttempts || 0) + 1;

        // Reload lesson content
        loadLesson(currentLessonIndex);

        // Scroll to quiz
        setTimeout(() => {
          document
            .getElementById("quizSection")
            .scrollIntoView({ behavior: "smooth" });
        }, 500);
      }

      async function markLessonComplete(score) {
        const lesson = COURSE_DATA.lessons[currentLessonIndex];
        const lessonId = lesson.id;

        // Track lesson completion time
        trackLessonTime();

        // Update lesson progress
        courseProgress[lessonId] = {
          ...courseProgress[lessonId],
          completed: true,
          quizScore: score,
          completedAt: new Date().toISOString(),
          finalScore: score,
        };

        // Update session tracking
        courseSession.lessonsCompleted++;

        // Save progress to database
        await saveProgress();

        // Update UI
        renderSidebar();
        updateNavigationButtons();

        // Check various achievements
        await checkLessonCompletionAchievements();
        await checkPerfectScoreAchievements(score);
        await checkStudyTimeAchievements();

        // Log lesson completion
        logUserActivity("lesson_completed", {
          lesson_id: lessonId,
          lesson_title: lesson.title,
          final_score: score,
          time_spent: courseProgress[lessonId].timeSpent || 0,
          lesson_number: currentLessonIndex + 1,
        });

        showToast("Lesson completed successfully!", "success");
      }

      async function completeLesson() {
        if (currentLessonIndex < COURSE_DATA.lessons.length - 1) {
          // Move to next lesson
          currentLessonIndex++;
          loadLesson(currentLessonIndex);
        } else {
          // Course completion
          await completeCourse();
        }
      }

      async function completeCourse() {
        try {
          const completionTime = courseSession.totalStudyTime;

          // Update course progress to 100% completed
          await supabase
            .from("course_progress")
            .update({
              progress: 100,
              completed_at: new Date().toISOString(),
              completion_time_minutes: completionTime,
            })
            .eq("user_id", currentUser.id)
            .eq("course_id", COURSE_DATA.id);

          // Award course completion achievements
          await checkAndUnlockAchievement("course_completion_1");
          await checkSpeedCompletionAchievements(completionTime);
          await checkCourseStreakAchievements();

          // Update user stats
          await updateUserStats();

          // Show completion message
          showToast(
            "Congratulations! Course completed successfully!",
            "certificate"
          );

          // Log course completion
          logUserActivity("course_completed", {
            course_id: COURSE_DATA.id,
            course_title: COURSE_DATA.title,
            completion_time_minutes: completionTime,
            total_lessons: COURSE_DATA.lessons.length,
            average_quiz_score: calculateAverageQuizScore(),
          });

          // Redirect to dashboard after delay
          setTimeout(() => {
            window.location.href = "/dashboard.html";
          }, 3000);
        } catch (error) {
          console.error("Error completing course:", error);
          showToast("Error marking course as complete", "error");
        }
      }

      // =====================================================
      // ACHIEVEMENT INTEGRATION SYSTEM
      // =====================================================
      async function checkAndUnlockAchievement(
        achievementId,
        skipNotification = false
      ) {
        try {
          // Prevent duplicate checks
          const cacheKey = `achievement_${achievementId}_${currentUser.id}`;
          if (sessionStorage.getItem(cacheKey)) return false;

          // Check if already unlocked
          const { data: existing, error } = await supabase
            .from("user_achievements")
            .select("id")
            .eq("user_id", currentUser.id)
            .eq("achievement_id", achievementId)
            .single();

          if (existing) {
            sessionStorage.setItem(cacheKey, "true");
            return false;
          }

          // Award achievement
          const achievementData = {
            user_id: currentUser.id,
            achievement_id: achievementId,
            unlocked_at: new Date().toISOString(),
            points_awarded: getAchievementPoints(achievementId),
            context: "course_system",
          };

          const { data, error: insertError } = await supabase
            .from("user_achievements")
            .insert([achievementData])
            .select()
            .single();

          if (insertError) {
            if (insertError.code === "23505") return false; // Already exists
            throw insertError;
          }

          // Update user points
          await supabase.rpc('increment_user_stats', {
  user_id_param: currentUser.id,
  points_to_add: achievementData.points_awarded,
  achievements_to_add: 1
});

          // Cache and queue notification
          sessionStorage.setItem(cacheKey, "true");

          if (!skipNotification) {
            queueAchievementNotification({
              id: achievementId,
              name: getAchievementName(achievementId),
              description: getAchievementDescription(achievementId),
              points: achievementData.points_awarded,
              rarity: getAchievementRarity(achievementId),
              icon: getAchievementIcon(achievementId),
            });
          }

          return true;
        } catch (error) {
          console.error("Error unlocking achievement:", error);
          return false;
        }
      }

      // Helper functions for achievement data (replace with your actual achievement definitions)
      function getAchievementPoints(id) {
        const pointsMap = {
          first_course_start: 75,
          first_lesson: 100,
          course_completion_1: 500,
          perfect_score: 250,
          speed_demon: 750,
          marathon_learner: 500,
          night_owl: 200,
          early_bird: 200,
          weekend_warrior: 150,
          // Add more as needed
        };
        return pointsMap[id] || 100;
      }

      function getAchievementName(id) {
        const nameMap = {
          first_course_start: "Learning Initiated",
          first_lesson: "First Steps",
          course_completion_1: "Course Conqueror",
          perfect_score: "Perfectionist",
          speed_demon: "Speed Demon",
          // Add more as needed
        };
        return nameMap[id] || "Achievement Unlocked";
      }

      function getAchievementDescription(id) {
        const descMap = {
          first_course_start: "Start your first cybersecurity course",
          first_lesson: "Complete your first lesson",
          course_completion_1: "Complete your first course",
          perfect_score: "Score 100% on any quiz",
          speed_demon: "Complete a course in under 2 hours",
          // Add more as needed
        };
        return descMap[id] || "Achievement description";
      }

      function getAchievementRarity(id) {
        const rarityMap = {
          first_course_start: "common",
          first_lesson: "bronze",
          course_completion_1: "silver",
          perfect_score: "gold",
          speed_demon: "legendary",
          // Add more as needed
        };
        return rarityMap[id] || "common";
      }

      function getAchievementIcon(id) {
        const iconMap = {
          first_course_start: "fas fa-play",
          first_lesson: "fas fa-baby",
          course_completion_1: "fas fa-trophy",
          perfect_score: "fas fa-star",
          speed_demon: "fas fa-rocket",
          // Add more as needed
        };
        return iconMap[id] || "fas fa-award";
      }

      async function checkLessonAchievements(lessonNumber) {
        if (lessonNumber === 1) {
          await checkAndUnlockAchievement("first_lesson");
        }

        // Check if user has completed multiple lessons in one day
        const today = new Date().toISOString().split("T")[0];
        const todayCompletions = Object.values(courseProgress).filter(
          (p) => p.completed && p.completedAt?.startsWith(today)
        ).length;

        if (todayCompletions >= 3) {
          await checkAndUnlockAchievement("lesson_marathon");
        }
      }

      async function checkLessonCompletionAchievements() {
        const completedCount = getCompletedLessonsCount();

        // Lesson-based achievements
        const lessonMilestones = [1, 5, 10, 25, 50, 100];
        for (const milestone of lessonMilestones) {
          if (completedCount >= milestone) {
            await checkAndUnlockAchievement(`lessons_${milestone}`);
          }
        }

        // Course completion achievements
        if (completedCount === COURSE_DATA.lessons.length) {
          await checkAndUnlockAchievement("course_completion_1");

          // Check for additional course completion achievements
          const { data: allCourses } = await supabase
            .from("course_progress")
            .select("course_id")
            .eq("user_id", currentUser.id)
            .eq("progress", 100);

          const totalCompleted = allCourses?.length || 0;

          const courseMilestones = [1, 5, 10, 25];
          for (const milestone of courseMilestones) {
            if (totalCompleted >= milestone) {
              await checkAndUnlockAchievement(`course_completion_${milestone}`);
            }
          }
        }
      }

      async function checkPerfectScoreAchievements(score) {
        if (score === 100) {
          await checkAndUnlockAchievement("perfect_score");

          // Check for consecutive perfect scores
          const recentScores = Object.values(courseProgress)
            .filter((p) => p.completed && p.quizScore)
            .slice(-5) // Last 5 completed
            .map((p) => p.quizScore);

          if (
            recentScores.length >= 3 &&
            recentScores.every((s) => s === 100)
          ) {
            await checkAndUnlockAchievement("perfectionist_streak");
          }
        }
      }

      async function checkSpeedCompletionAchievements(completionTime) {
        // Speed demon: Complete course in under 2 hours (120 minutes)
        if (completionTime <= 120) {
          await checkAndUnlockAchievement("speed_demon");
        }

        // Quick learner: Complete course in under 4 hours (240 minutes)
        if (completionTime <= 240) {
          await checkAndUnlockAchievement("quick_learner");
        }
      }

      async function checkStudyTimeAchievements() {
        const totalTime = courseSession.totalStudyTime;

        // Marathon learner: Study for 8+ hours in a course session
        if (totalTime >= 480) {
          // 8 hours
          await checkAndUnlockAchievement("marathon_learner");
        }

        // Dedicated learner: Study for 4+ hours
        if (totalTime >= 240) {
          // 4 hours
          await checkAndUnlockAchievement("dedicated_learner");
        }
      }

      async function checkCourseStreakAchievements() {
        try {
          // Check for consecutive course completions
          const { data: recentCourses, error } = await supabase
            .from("course_progress")
            .select("completed_at, course_id")
            .eq("user_id", currentUser.id)
            .eq("progress", 100)
            .order("completed_at", { ascending: false })
            .limit(10);

          if (error || !recentCourses) return;

          // Check for courses completed on consecutive days
          let consecutiveDays = 1;
          for (let i = 1; i < recentCourses.length; i++) {
            const prevDate = new Date(
              recentCourses[i - 1].completed_at
            ).toDateString();
            const currentDate = new Date(
              recentCourses[i].completed_at
            ).toDateString();
            const dayDiff =
              Math.abs(new Date(prevDate) - new Date(currentDate)) /
              (1000 * 60 * 60 * 24);

            if (dayDiff <= 1) {
              consecutiveDays++;
            } else {
              break;
            }
          }

          if (consecutiveDays >= 3) {
            await checkAndUnlockAchievement("learning_streak");
          }
        } catch (error) {
          console.error("Error checking course streak achievements:", error);
        }
      }

      // =====================================================
      // TIME-BASED ACHIEVEMENTS
      // =====================================================
      async function checkTimeBasedAchievements(timestamp) {
        const hour = timestamp.getHours();
        const dayOfWeek = timestamp.getDay();

        // Night owl (after midnight, before 6 AM)
        if (hour >= 0 && hour < 6) {
          await incrementTimeBasedCounter("midnight_sessions", "night_owl");
        }

        // Early bird (4 AM to 6 AM)
        if (hour >= 4 && hour < 6) {
          await incrementTimeBasedCounter("early_sessions", "early_bird");
        }

        // Weekend warrior (Saturday = 6, Sunday = 0)
        if (dayOfWeek === 0 || dayOfWeek === 6) {
          await incrementTimeBasedCounter(
            "weekend_sessions",
            "weekend_warrior"
          );
        }
      }

      async function incrementTimeBasedCounter(counterType, achievementId) {
        try {
          const dateStr = new Date().toISOString().split("T")[0];
          const cacheKey = `${counterType}_${currentUser.id}_${dateStr}`;

          // Prevent multiple increments per day
          if (sessionStorage.getItem(cacheKey)) return;

          // Update counter
          await supabase
            .from("profiles")
            .update({
              [counterType]: supabase.sql`${counterType} + 1`,
            })
            .eq("id", currentUser.id);

          // Cache to prevent double counting
          sessionStorage.setItem(cacheKey, "true");

          // Check related achievement
          if (achievementId) {
            await checkAndUnlockAchievement(achievementId, true);
          }
        } catch (error) {
          console.error(`Error incrementing ${counterType}:`, error);
        }
      }

      async function checkDailyStreak() {
        try {
          const { data: profile, error } = await supabase
            .from("profiles")
            .select("last_activity, current_streak, last_streak_date")
            .eq("id", currentUser.id)
            .single();

          if (error) throw error;

          const now = new Date();
          const today = now.toDateString();
          const lastActivity = profile.last_activity
            ? new Date(profile.last_activity)
            : null;
          const lastStreakDate = profile.last_streak_date
            ? new Date(profile.last_streak_date).toDateString()
            : null;

          let newStreak = profile.current_streak || 0;
          let shouldUpdateStreak = false;

          if (!lastActivity) {
            // First time user
            newStreak = 1;
            shouldUpdateStreak = true;
          } else {
            const daysSinceLastActivity = Math.floor(
              (now - lastActivity) / (1000 * 60 * 60 * 24)
            );

            if (lastStreakDate === today) {
              // Already counted today's streak
              return newStreak;
            } else if (
              daysSinceLastActivity === 1 ||
              (daysSinceLastActivity === 0 && lastStreakDate !== today)
            ) {
              // Consecutive day or same day but not counted yet
              newStreak += 1;
              shouldUpdateStreak = true;
            } else if (daysSinceLastActivity > 1) {
              // Streak broken
              newStreak = 1;
              shouldUpdateStreak = true;
            }
          }

          if (shouldUpdateStreak) {
            await supabase
              .from("profiles")
              .update({
                current_streak: newStreak,
                last_activity: now.toISOString(),
                last_streak_date: now.toISOString(),
              })
              .eq("id", currentUser.id);

            userStats.current_streak = newStreak;

            showToast(`Daily streak: ${newStreak} days!`, "success");
            await checkStreakAchievements(newStreak);
          }

          return newStreak;
        } catch (error) {
          console.error("Error checking daily streak:", error);
          return 0;
        }
      }

      async function checkStreakAchievements(currentStreak) {
        const streakMilestones = [3, 7, 14, 30, 100, 365];

        for (const milestone of streakMilestones) {
          if (currentStreak >= milestone) {
            await checkAndUnlockAchievement(`streak_${milestone}`);
          }
        }
      }

      // =====================================================
      // USER ACTIVITY LOGGING
      // =====================================================
      async function logUserActivity(activityType, metadata = {}) {
        try {
          const now = new Date();

          const activityData = {
            user_id: currentUser.id,
            activity_type: activityType,
            timestamp: now.toISOString(),
            course_id: COURSE_DATA.id,
            lesson_index: currentLessonIndex,
            session_duration: courseSession.totalStudyTime,
            metadata: JSON.stringify(metadata),
            created_at: now.toISOString(),
          };

          // Try to log to activities table
          const { error } = await supabase
            .from("user_activities")
            .insert([activityData]);

          if (error && error.code !== "42P01") {
            console.warn("Activity logging failed:", error.message);
          }

          // Always update last activity in profile
          await supabase
            .from("profiles")
            .update({ last_activity: now.toISOString() })
            .eq("id", currentUser.id);
        } catch (error) {
          console.error("Error logging user activity:", error);
        }
      }

      // =====================================================
      // NAVIGATION SYSTEM
      // =====================================================
      function updateNavigationButtons() {
        const prevBtn = document.getElementById("prevLessonBtn");
        const nextBtn = document.getElementById("nextLessonBtn");

        if (!prevBtn || !nextBtn) return;

        // Previous button
        prevBtn.disabled = currentLessonIndex === 0;

        // Next button logic
        const isLastLesson =
          currentLessonIndex === COURSE_DATA.lessons.length - 1;
        const canGoNext =
          currentLessonIndex < COURSE_DATA.lessons.length - 1 &&
          canAccessLesson(currentLessonIndex + 1);

        if (isLastLesson) {
          const isCurrentCompleted =
            courseProgress[COURSE_DATA.lessons[currentLessonIndex].id]
              ?.completed;
          nextBtn.disabled = !isCurrentCompleted;
          nextBtn.innerHTML = '<i class="fas fa-trophy"></i> Complete Course';
        } else {
          nextBtn.disabled = !canGoNext;
          nextBtn.innerHTML = 'Next <i class="fas fa-chevron-right"></i>';
        }
      }

      // Navigation button event handlers
      function goToPreviousLesson() {
        if (currentLessonIndex > 0) {
          trackLessonTime(); // Track time spent on current lesson
          currentLessonIndex--;
          loadLesson(currentLessonIndex);
        }
      }

      function goToNextLesson() {
        if (currentLessonIndex < COURSE_DATA.lessons.length - 1) {
          const canGoNext = canAccessLesson(currentLessonIndex + 1);
          if (canGoNext) {
            trackLessonTime();
            currentLessonIndex++;
            loadLesson(currentLessonIndex);
          } else {
            showToast("Complete the current lesson quiz to proceed", "warning");
          }
        } else {
          // Complete course
          completeCourse();
        }
      }

      // =====================================================
      // SIDEBAR FUNCTIONS
      // =====================================================
      function toggleSidebar() {
        const sidebar = document.getElementById("sidebar");
        const overlay = document.getElementById("sidebarOverlay");

        if (sidebar) sidebar.classList.toggle("open");
        if (overlay) overlay.classList.toggle("active");
      }

      function closeSidebar() {
        const sidebar = document.getElementById("sidebar");
        const overlay = document.getElementById("sidebarOverlay");

        if (sidebar) sidebar.classList.remove("open");
        if (overlay) overlay.classList.remove("active");
      }

      // =====================================================
      // ACHIEVEMENT NOTIFICATION SYSTEM
      // =====================================================
      function queueAchievementNotification(achievement) {
        notificationQueue.push(achievement);
        processNotificationQueue();
      }

      function processNotificationQueue() {
        if (isShowingNotification || notificationQueue.length === 0) return;

        isShowingNotification = true;
        const achievement = notificationQueue.shift();
        showAchievementNotification(achievement);

        const duration =
          achievement.rarity === "mythic"
            ? 8000
            : achievement.rarity === "legendary"
            ? 7000
            : 6000;

        setTimeout(() => {
          isShowingNotification = false;
          processNotificationQueue();
        }, duration + 500);
      }

      function showAchievementNotification(achievement) {
        const notification = document.getElementById("achievementNotification");
        if (!notification) return;

        const icon = document.getElementById("notificationIcon");
        const title = document.getElementById("notificationTitle");
        const description = document.getElementById("notificationDescription");
        const points = document.getElementById("notificationPoints");

        if (icon) {
          icon.innerHTML = `<i class="${achievement.icon}"></i>`;
          icon.className = `notification-icon ${achievement.rarity}`;
        }
        if (title) title.textContent = achievement.name;
        if (description) description.textContent = achievement.description;
        if (points) points.textContent = `+${achievement.points} Points`;

        notification.className = `achievement-notification ${achievement.rarity}`;
        notification.classList.add("show");

        const duration =
          achievement.rarity === "mythic"
            ? 8000
            : achievement.rarity === "legendary"
            ? 7000
            : 6000;

        setTimeout(() => {
          notification.classList.remove("show");
        }, duration);
      }

      // =====================================================
      // UTILITY FUNCTIONS
      // =====================================================
      function calculateAverageQuizScore() {
        const scores = Object.values(courseProgress)
          .filter((p) => p.completed && p.quizScore)
          .map((p) => p.quizScore);

        if (scores.length === 0) return 0;
        return Math.round(
          scores.reduce((sum, score) => sum + score, 0) / scores.length
        );
      }

      async function resetProgress() {
        if (
          !confirm(
            "Are you sure you want to reset your progress? This action cannot be undone."
          )
        ) {
          return;
        }

        try {
          // Track lesson time before reset
          trackLessonTime();

          // Reset local state
          courseProgress = {};
          currentLessonIndex = 0;
          courseSession = {
            startTime: new Date(),
            totalStudyTime: 0,
            lessonsStarted: 0,
            lessonsCompleted: 0,
            pageLoadTime: new Date(),
            interactionCount: 0,
            lastActivityTime: new Date(),
          };

          // Delete from database
          await supabase
            .from("course_progress")
            .delete()
            .eq("user_id", currentUser.id)
            .eq("course_id", COURSE_DATA.id);

          // Log reset activity
          logUserActivity("progress_reset", {
            course_id: COURSE_DATA.id,
            reset_reason: "manual",
          });

          // Reinitialize
          await saveProgress();
          renderSidebar();
          loadLesson(0);

          showToast("Progress reset successfully", "success");
        } catch (error) {
          console.error("Error resetting progress:", error);
          showToast("Failed to reset progress", "error");
        }
      }

      function copyCode(codeId) {
        const codeElement = document.getElementById(codeId);
        if (!codeElement) return;

        const text = codeElement.textContent;

        navigator.clipboard
          .writeText(text)
          .then(() => {
            showToast("Code copied to clipboard!", "success");

            // Track code copy for achievements
            logUserActivity("code_copied", {
              code_section: codeId,
              lesson_id: COURSE_DATA.lessons[currentLessonIndex].id,
            });
          })
          .catch((err) => {
            console.error("Failed to copy code:", err);
            showToast("Failed to copy code", "error");

            // Fallback for older browsers
            const textArea = document.createElement("textarea");
            textArea.value = text;
            document.body.appendChild(textArea);
            textArea.select();
            try {
              document.execCommand("copy");
              showToast("Code copied to clipboard!", "success");
            } catch (fallbackError) {
              showToast(
                "Copy failed - please select and copy manually",
                "error"
              );
            }
            document.body.removeChild(textArea);
          });
      }

      function escapeHtml(text) {
        const div = document.createElement("div");
        div.textContent = text;
        return div.innerHTML;
      }

      // =====================================================
      // UI FEEDBACK SYSTEMS
      // =====================================================
      function showToast(message, type = "success") {
        const toast = document.getElementById("toast");
        const messageEl = document.getElementById("toastMessage");

        if (!toast || !messageEl) {
          console.log(`Toast: ${message} (${type})`);
          return;
        }

        messageEl.textContent = message;
        toast.className = `toast ${type} show`;

        setTimeout(() => {
          toast.classList.remove("show");
        }, 4000);
      }

      function showLoadingScreen() {
        const loadingScreen = document.getElementById("loadingScreen");
        if (loadingScreen) loadingScreen.classList.remove("hidden");
      }

      function hideLoadingScreen() {
        const loadingScreen = document.getElementById("loadingScreen");
        if (loadingScreen) {
          setTimeout(() => {
            loadingScreen.classList.add("hidden");
          }, 1000);
        }
      }

      // =====================================================
      // MUSIC PLAYER INTEGRATION
      // =====================================================
      function initMusicPlayer() {
        const btnText = document.getElementById("music-button-text");
        const icon = document.getElementById("music-icon");
        const dropdown = document.getElementById("music-dropdown-content");

        if (!btnText || !icon || !dropdown) return;

        function setUI(state) {
          btnText.textContent =
            state === "Playing" ? "PAUSE MUSIC" : "STUDY MUSIC";
          icon.className =
            state === "Playing"
              ? "fa-solid fa-circle-pause"
              : "fa-solid fa-music";
        }

        // Load saved music state
        const savedSrc = localStorage.getItem("cybersec_music_src");
        const savedTime = parseFloat(
          localStorage.getItem("cybersec_music_time") || 0
        );

        if (savedSrc) {
          audioPlayer.src = savedSrc;
          audioPlayer.currentTime = savedTime;
          audioPlayer
            .play()
            .then(() => setUI("Playing"))
            .catch(() => setUI("Stopped"));
        }

        // Music button click handler
        document
          .getElementById("music-dropdown")
          .querySelector("button")
          .addEventListener("click", (e) => {
            e.stopPropagation();
            dropdown.style.display =
              dropdown.style.display === "block" ? "none" : "block";

            if (audioPlayer.src && !audioPlayer.paused) {
              audioPlayer.pause();
              setUI("Stopped");
            } else if (audioPlayer.src) {
              audioPlayer.play().then(() => setUI("Playing"));
            }
          });

        // Music selection handlers
        dropdown.querySelectorAll("a[data-src]").forEach((link) => {
          link.addEventListener("click", (e) => {
            e.preventDefault();
            audioPlayer.src = link.dataset.src;
            audioPlayer.play().then(() => setUI("Playing"));
            localStorage.setItem("cybersec_music_src", link.dataset.src);
            dropdown.style.display = "none";
          });
        });

        // Stop music handler
        const stopLink = document.getElementById("stop-music-link");
        if (stopLink) {
          stopLink.addEventListener("click", (e) => {
            e.preventDefault();
            audioPlayer.pause();
            audioPlayer.currentTime = 0;
            audioPlayer.removeAttribute("src");
            setUI("Stopped");
            localStorage.removeItem("cybersec_music_src");
            localStorage.removeItem("cybersec_music_time");
            dropdown.style.display = "none";
          });
        }

        // Save music state before page unload
        window.addEventListener("beforeunload", () => {
          if (!audioPlayer.paused && audioPlayer.src) {
            localStorage.setItem("cybersec_music_src", audioPlayer.src);
            localStorage.setItem(
              "cybersec_music_time",
              audioPlayer.currentTime
            );
          }
        });

        // Close dropdown when clicking outside
        window.addEventListener("click", (e) => {
          if (!e.target.closest("#music-dropdown")) {
            dropdown.style.display = "none";
          }
        });
      }

      // Show initial music indicator
      function addMusicIndicator() {
        const musicBtn = document.querySelector("#music-dropdown");
        if (musicBtn) {
          const indicator = document.createElement("div");
          indicator.className = "music-indicator";
          indicator.innerHTML = `<i class="fa-solid fa-music"></i> Try Study Music!`;

          musicBtn.style.position = "relative";
          musicBtn.appendChild(indicator);

          setTimeout(() => indicator.remove(), 3000);
        }
      }

      // Initialize Event Listeners
      function initializeEventListeners() {
        // Navigation buttons
        document
          .getElementById("prevLessonBtn")
          ?.addEventListener("click", goToPreviousLesson);
        document
          .getElementById("nextLessonBtn")
          ?.addEventListener("click", goToNextLesson);

        // Reset progress button
        document
          .getElementById("resetProgressBtn")
          ?.addEventListener("click", resetProgress);

        // Mobile menu toggle
        document
          .getElementById("menuToggle")
          ?.addEventListener("click", toggleSidebar);
        document
          .getElementById("sidebarOverlay")
          ?.addEventListener("click", closeSidebar);

        // Keyboard shortcuts
        document.addEventListener("keydown", handleKeyboardShortcuts);

        // Window resize handler
        window.addEventListener("resize", handleWindowResize);

        // Content interaction tracking
        document.getElementById("contentBody")?.addEventListener(
          "scroll",
          debounce(() => {
            trackUserInteraction();
          }, 1000)
        );
      }

      // Keyboard Shortcuts
      function handleKeyboardShortcuts(e) {
        if (document.querySelector(".quiz-question.active")) return;

        if (e.key === "ArrowLeft" && e.ctrlKey) {
          e.preventDefault();
          goToPreviousLesson();
        } else if (e.key === "ArrowRight" && e.ctrlKey) {
          e.preventDefault();
          goToNextLesson();
        }
      }

      // Window Resize Handler
      function handleWindowResize() {
        if (window.innerWidth > 768) {
          closeSidebar();
        }
      }

      // Debounce Helper
      function debounce(func, wait) {
        let timeout;
        return function executedFunction(...args) {
          const later = () => {
            clearTimeout(timeout);
            func(...args);
          };
          clearTimeout(timeout);
          timeout = setTimeout(later, wait);
        };
      }

      // Initialize responsive behavior
      if (window.innerWidth <= 768) {
        document.getElementById("menuToggle").style.display = "inline-flex";
      }

      // Auto-save progress periodically
      setInterval(async () => {
        if (currentUser && Object.keys(courseProgress).length > 0) {
          await saveProgress();
        }
      }, 60000); // Save every minute

      // System initialization logging
      console.log("CyberSec Academy Course System Initialized");
      console.log("Current Course:", COURSE_DATA.title);
      console.log("Total Lessons:", COURSE_DATA.lessons.length);

      // Google OAuth Integration
      const googleBtn = document.querySelector(".btn-google");
      if (googleBtn) {
        googleBtn.addEventListener("click", async () => {
          const { data, error } = await supabase.auth.signInWithOAuth({
            provider: "google",
            options: {
              redirectTo:
                window.location.origin +
                "/courses/public-key-infrastructure-pki.html",
            },
          });

          if (error) {
            console.error("Google login error:", error.message);
            showToast("Google login failed: " + error.message, "error");
          }
        });
      }

      // Check for existing session
      supabase.auth.getSession().then(({ data }) => {
        if (data.session) {
          console.log("User already logged in:", data.session.user);
          currentUser = data.session.user;
          startCourseSession();
        }
      });

      // Add missing auth modal functions
      function openAuthModal() {
        const modal = document.getElementById("authModal");
        if (modal) {
          modal.style.display = "flex";
        }
      }

      function closeAuthModal() {
        const modal = document.getElementById("authModal");
        if (modal) {
          modal.style.display = "none";
        }
      }

      // Add auth tab switching functionality
      document.getElementById("tabSignIn")?.addEventListener("click", () => {
        document.getElementById("tabSignIn").classList.add("active");
        document.getElementById("tabSignUp").classList.remove("active");
        document.getElementById("signInForm").style.display = "block";
        document.getElementById("signUpForm").style.display = "none";
      });

      document.getElementById("tabSignUp")?.addEventListener("click", () => {
        document.getElementById("tabSignUp").classList.add("active");
        document.getElementById("tabSignIn").classList.remove("active");
        document.getElementById("signUpForm").style.display = "block";
        document.getElementById("signInForm").style.display = "none";
      });

      document
        .getElementById("closeAuthModal")
        ?.addEventListener("click", closeAuthModal);

      // Improved error handling for auth session
      supabase.auth.onAuthStateChange((event, session) => {
        if (event === "SIGNED_IN") {
          currentUser = session.user;
          closeAuthModal();
          startCourseSession();
        } else if (event === "SIGNED_OUT") {
          currentUser = null;
          openAuthModal();
        }
      });

      // Add form submission handlers
      document
        .getElementById("emailSignInForm")
        ?.addEventListener("submit", async (e) => {
          e.preventDefault();
          const email = document.getElementById("signInEmail").value;
          const password = document.getElementById("signInPassword").value;

          try {
            const { data, error } = await supabase.auth.signInWithPassword({
              email,
              password,
            });

            if (error) throw error;

            closeAuthModal();
          } catch (error) {
            showToast(error.message, "error");
          }
        });

      document
        .getElementById("emailSignUpForm")
        ?.addEventListener("submit", async (e) => {
          e.preventDefault();
          const email = document.getElementById("signUpEmail").value;
          const password = document.getElementById("signUpPassword").value;
          const name = document.getElementById("signUpName").value;

          try {
            const { data, error } = await supabase.auth.signUp({
              email,
              password,
              options: {
                data: {
                  full_name: name,
                },
              },
            });

            if (error) throw error;

            showToast(
              "Account created successfully! Please check your email.",
              "success"
            );
          } catch (error) {
            showToast(error.message, "error");
          }
        });
    </script>
  </body>
</html>
