


<!DOCTYPE html>
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <!-- ========== Start: SEO & Schema Enhancement ========== -->
    <title>AWS Security Fundamentals Course | CipherHall</title>
    <meta name="description" content="A 50-lesson roadmap to mastering AWS security. Learn IAM, VPC, KMS, GuardDuty, and prepare for certifications with hands-on labs.">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon.png" />
    <link rel="shortcut icon" href="/favicon.png" type="image/x-icon" />
    <link rel="apple-touch-icon" sizes="180x180" href="/favicon.png" />
    <link rel="canonical" href="https://www.cipherhall.com/courses/aws-security-fundamentals.html" />
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Course",
      "name": "AWS Security Fundamentals Roadmap",
      "description": "A comprehensive 50-lesson course taking you from foundational principles to advanced security practices for architecting, deploying, and managing secure solutions on AWS.",
      "provider": {
        "@type": "Organization",
        "name": "CipherHall",
        "sameAs": "https://www.cipherhall.com"
      },
      "hasCourseInstance": {
        "@type": "CourseInstance",
        "courseMode": "Online",
        "instructor": {
          "@type": "Person",
          "name": "Dr. Aisha Khan"
        }
      }
    }
    </script>
    <!-- ========== End: SEO & Schema Enhancement ========== -->

    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Roboto+Mono:wght@400;700&family=Exo+2:wght@700;800;900&display=swap"
      rel="stylesheet"
    />
    <script src="https://cdn.jsdelivr.net/npm/@supabase/supabase-js@2.39.7/dist/umd/supabase.min.js"></script>
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-okaidia.min.css"
    />
    <link rel="stylesheet" href="assets/css/coursepages.css">
</head>
  <body>
    <!-- Loading Screen -->
    <div id="loadingScreen" class="loading-screen">
      <div class="loader-icon">
        <i class="fas fa-graduation-cap"></i>
      </div>
      <div class="loader-text">Loading Course Content...</div>
    </div>

    <!-- Sidebar Overlay for Mobile -->
    <div class="sidebar-overlay" id="sidebarOverlay"></div>

    <!-- Music Player (fixed at top right) -->
    <div class="header-controls">
      <div class="music-dropdown" id="music-dropdown">
        <button class="btn btn-secondary">
          <span id="music-button-text">STUDY MUSIC</span>
          <i id="music-icon" class="fa-solid fa-music"></i>
        </button>
        <div class="music-dropdown-content" id="music-dropdown-content">
          <a
            href="#"
            data-src="https://www.learningcontainer.com/wp-content/uploads/2020/02/Kalimba.mp3"
            >1. Coffee Shop Vibes</a
          >
          <a
            href="#"
            data-src="https://www.soundhelix.com/examples/mp3/SoundHelix-Song-16.mp3"
            >2. City Lights Lofi</a
          >
          <a
            href="#"
            data-src="https://www.soundhelix.com/examples/mp3/SoundHelix-Song-15.mp3"
            >3. Mellow Thoughts</a
          >
          <a
            href="#"
            data-src="https://www.soundhelix.com/examples/mp3/SoundHelix-Song-13.mp3"
            >4. Rainy Mood</a
          >
          <a
            href="#"
            data-src="https://www.soundhelix.com/examples/mp3/SoundHelix-Song-10.mp3"
            >5. Time Alone</a
          >
          <a href="#" id="stop-music-link"
            ><i class="fa-solid fa-stop-circle"></i> Stop Music</a
          >
        </div>
      </div>

      <button class="btn btn-secondary" id="resetProgressBtn">
        <i class="fas fa-redo"></i>
        Reset Progress
      </button>
    </div>

    <!-- Auth Modal -->
    <div id="authModal" class="modal" style="display: none">
      <div class="modal-overlay"></div>
      <div class="modal-content">
        <span class="close" id="closeAuthModal">&times;</span>
        <div class="auth-tabs">
          <button id="tabSignIn" class="auth-tab active">Sign In</button>
          <button id="tabSignUp" class="auth-tab">Sign Up</button>
        </div>
        <div
          id="authLoader"
          style="display: none; text-align: center; padding: 2rem"
        >
          <i
            class="fas fa-spinner fa-spin fa-2x"
            style="color: var(--color-green)"
          ></i>
          <p style="margin-top: 0.5rem">Authenticating...</p>
        </div>
        <div id="signInForm" class="auth-form">
          <h2>Sign In to CipherHall</h2>
          <button id="googleSignIn" class="btn btn-google">
            <i class="fab fa-google"></i> Continue with Google
          </button>
          <div class="divider"><span>or</span></div>
          <form id="emailSignInForm">
            <input
              type="email"
              id="signInEmail"
              placeholder="Email Address"
              required
            />
            <input
              type="password"
              id="signInPassword"
              placeholder="Password"
              required
            />
            <button type="submit" class="btn btn-primary">Sign In</button>
          </form>
        </div>
        <div id="signUpForm" class="auth-form" style="display: none">
          <h2>Join CipherHall</h2>
          <button id="googleSignUp" class="btn btn-google">
            <i class="fab fa-google"></i> Continue with Google
          </button>
          <div class="divider"><span>or</span></div>
          <form id="emailSignUpForm">
            <input
              type="text"
              id="signUpName"
              placeholder="Full Name"
              required
            />
            <input
              type="email"
              id="signUpEmail"
              placeholder="Email Address"
              required
            />
            <input
              type="password"
              id="signUpPassword"
              placeholder="Password (min. 8 characters)"
              required
            />
            <button type="submit" class="btn btn-secondary">
              Create Account
            </button>
          </form>
        </div>
        <div id="authMessage"></div>
      </div>
    </div>

    <!-- Sidebar -->
    <aside class="sidebar" id="sidebar">
      <div class="sidebar-header">
        <div class="course-info">
          <h1 class="course-title" id="courseTitle">Loading...</h1>
          <div class="course-progress">
            <div class="progress-header">
              <span class="progress-label">Course Progress</span>
              <span class="progress-percentage" id="courseProgressPercent"
                >0%</span
              >
            </div>
            <div class="progress-bar">
              <div
                class="progress-fill"
                id="courseProgressFill"
                style="width: 0%"
              ></div>
            </div>
            <div class="progress-stats">
              <span id="completedLessons">0</span>
              <span id="totalLessons">0</span>
            </div>
          </div>
          <a href="/dashboard.html" class="back-to-dashboard">
            <i class="fas fa-arrow-left"></i>
            Back to Dashboard
          </a>
        </div>
      </div>

      <nav class="lesson-nav" id="lessonNav">
        <!-- Lessons will be loaded dynamically -->
      </nav>
    </aside>

    <!-- Main Content -->
    <main class="main-content">
      <header class="content-header">
        <div class="lesson-header">
          <div class="lesson-header-left">
            <span class="lesson-number" id="currentLessonNumber">1</span>
            <h1 class="lesson-header-title" id="currentLessonTitle">
              Loading...
            </h1>
          </div>
          <div class="lesson-actions">
            <button class="mbtn btn-primary" id="menuToggle">
              <i class="fas fa-bars"></i>
            </button>
          </div>
        </div>
      </header>

      <div class="content-body" id="contentBody">
        <div class="lesson-content" id="lessonContent">
          <!-- Lesson content will be loaded dynamically -->
        </div>
      </div>

      <footer class="lesson-navigation">
        <div class="nav-info" id="navInfo">Lesson 1 of 10</div>
        <div class="nav-controls">
          <button class="btn btn-secondary" id="prevLessonBtn" disabled>
            <i class="fas fa-chevron-left"></i>
            Previous
          </button>
          <button class="btn btn-primary" id="nextLessonBtn" disabled>
            Next
            <i class="fas fa-chevron-right"></i>
          </button>
        </div>
      </footer>
    </main>

    <!-- Achievement Notification -->
    <div id="achievementNotification" class="achievement-notification">
      <div class="notification-header">
        <div class="notification-icon" id="notificationIcon">
          <i class="fas fa-trophy"></i>
        </div>
        <div class="notification-content">
          <h3 id="notificationTitle">Achievement Unlocked!</h3>
          <p id="notificationDescription">Description here...</p>
        </div>
      </div>
      <div class="notification-reward" id="notificationReward">
        <i class="fas fa-coins"></i>
        <span id="notificationPoints">+100 Points</span>
      </div>
    </div>

    <!-- Toast Notification -->
    <div id="toast" class="toast">
      <span id="toastMessage"></span>
    </div>

    <script>
      // =====================================================
      // SYNCHRONIZED COURSE SYSTEM WITH DASHBOARD INTEGRATION
      // =====================================================

      // Supabase Configuration - Replace with your config
      const supabaseUrl = "https://lzcmzulemfubjaksoqor.supabase.co";
      const supabaseKey =
        "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Imx6Y216dWxlbWZ1Ympha3NvcW9yIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTUzMzM5MDgsImV4cCI6MjA3MDkwOTkwOH0.crhPH4YWtRsr1BJTpAQcmPbWSpwIWRbzoI4sRb2_fPI";
      const supabase = window.supabase.createClient(supabaseUrl, supabaseKey);

      // =====================================================
      // COURSE DATA STRUCTURE - REPLACE WITH YOUR COURSE JSON
      // =====================================================
      const COURSE_DATA = {
        "id": "aws-security-fundamentals",
        "title": "AWS Security Fundamentals Roadmap",
        "description": "A comprehensive 50-lesson course taking you from foundational principles to advanced security practices for architecting, deploying, and managing secure solutions on AWS.",
        "category": "cloud-security",
        "difficulty": "Beginner to Advanced",
        "duration": "100 hours",
        "instructor": "Dr. Aisha Khan",
        "lessons": [
            {
                "id": "lesson-1-aws-security-overview",
                "title": "Lesson 1: AWS Security Overview",
                "duration": "120 min",
                "objectives": [
                    "Define the AWS Shared Responsibility Model",
                    "Differentiate between Security 'of' the Cloud and Security 'in' the Cloud",
                    "Understand the core pillars of AWS security",
                    "Recognize AWS's compliance and certification posture"
                ],
                "content": {
                    "overview": "This foundational lesson introduces the fundamental concepts of security on AWS. You will learn about the crucial Shared Responsibility Model, which defines your security obligations versus AWS's, and gain an understanding of the principles that guide a secure architecture in the cloud.",
                    "sections": [
                        {
                            "title": "AWS Shared Responsibility Model",
                            "content": "<p>The AWS Shared Responsibility Model is the cornerstone of cloud security. It dictates the division of security responsibilities between AWS and the customer.</p><h3>Key Responsibilities:</h3><ul><li><strong>AWS is responsible for 'Security OF the Cloud':</strong> This includes securing the physical hardware, infrastructure, and the foundational software services that run the entire AWS cloud. They manage the physical datacenters, the network infrastructure, and the virtualization layer.</li><li><strong>You (the Customer) are responsible for 'Security IN the Cloud':</strong> This includes everything you put *in* the cloud. You are responsible for managing your data, configuring your operating systems, setting up firewall rules (security groups), and managing identity and access management (IAM).</li></ul><div class='info-box tip'><div class='info-box-header'><i class='fas fa-lightbulb'></i><strong>Simple Analogy</strong></div><p>Think of it like an apartment building. The landlord (AWS) is responsible for the security of the building itselfâ€”the locks on the main door, the structural integrity. You (the customer) are responsible for locking the door to your own apartment and who you give your keys to.</p></div>",
                            "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "AWS Security Pillars",
                            "content": "<p>AWS security is built upon a framework of key pillars that provide a structured approach to securing your environment. These are often aligned with the AWS Well-Architected Framework.</p><h3>The Pillars Include:</h3><ul><li><strong>Identity and Access Management:</strong> Controlling who can access what. The principle of least privilege is paramount.</li><li><strong>Detective Controls:</strong> Gaining visibility. The ability to detect and investigate security events through logging and monitoring.</li><li><strong>Infrastructure Protection:</strong> Securing your network and host-level boundaries.</li><li><strong>Data Protection:</strong> Protecting your data, both at rest and in transit, through encryption and access control.</li><li><strong>Incident Response:</strong> Being prepared to respond to and recover from a security incident.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1510915228340-29c85a43dcfe?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Check IAM Credential Report",
                        "language": "bash",
                        "code": "# This CLI command generates a report on the status of all IAM user credentials in your account.\naws iam generate-credential-report\n\n# After it generates, you can download and review it.\naws iam get-credential-report --query 'Content' --output text | base64 --decode > credential-report.csv"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "Under the Shared Responsibility Model, what is AWS responsible for?", "options": ["Configuring your application's security groups", "Patching your EC2 instance's operating system", "Securing the physical datacenter hardware", "Managing your IAM users' passwords"], "correct": 2, "explanation": "AWS is responsible for the security 'of' the cloud, which includes the physical infrastructure." },
                        { "id": 2, "question": "Encrypting your data stored in an S3 bucket is the responsibility of:", "options": ["AWS", "The Customer", "The Internet Service Provider", "A third-party auditor"], "correct": 1, "explanation": "Data protection, including configuring encryption for your data, is part of the customer's responsibility for security 'in' the cloud." },
                        { "id": 3, "question": "Controlling who can do what within your AWS account falls under which security pillar?", "options": ["Data Protection", "Incident Response", "Identity and Access Management", "Infrastructure Protection"], "correct": 2, "explanation": "Identity and Access Management (IAM) is the pillar dedicated to managing permissions and access controls." }
                    ]
                }
            },
            {
                "id": "lesson-2-iam",
                "title": "Lesson 2: AWS Identity and Access Management (IAM)",
                "duration": "150 min",
                "objectives": [
                    "Define and create IAM users, groups, and roles",
                    "Understand the structure and syntax of IAM policies (JSON)",
                    "Apply the Principle of Least Privilege when granting permissions",
                    "Follow IAM best practices for securing your account"
                ],
                "content": {
                    "overview": "IAM is the nervous system of AWS security. It controls access to all AWS services and resources. This lesson provides a deep dive into the core components of IAM, teaching you how to manage permissions effectively and securely.",
                    "sections": [
                        {
                            "title": "IAM Users, Groups, and Roles",
                            "content": "<p>IAM provides several identity types for different use cases.</p><h3>Identity Types:</h3><ul><li><strong>Users:</strong> An identity for a specific person or service that needs long-term credentials (like a password for the console or access keys for the CLI).</li><li><strong>Groups:</strong> A collection of IAM users. You apply permissions to the group, and all users in that group inherit those permissions. This is much easier to manage than applying permissions to individual users.</li><li><strong>Roles:</strong> An identity with temporary credentials that can be assumed by trusted entities. This is the most secure way to grant permissions, as no long-term keys are involved. Roles can be assumed by AWS services (like EC2), users from another AWS account, or users federated from your corporate directory.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1554224155-83e8b835d07a?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "IAM Policies and Permissions",
                            "content": "<p>An IAM policy is a JSON document that defines permissions. It specifies what actions are allowed or denied on which AWS resources.</p><h3>Policy Structure:</h3><ul><li><strong>Effect:</strong> `Allow` or `Deny`. Deny always wins.</li><li><strong>Action:</strong> The specific AWS API action you are allowing or denying (e.g., `s3:GetObject`, `ec2:StartInstances`). Wildcards (`*`) can be used.</li><li><strong>Resource:</strong> The Amazon Resource Name (ARN) of the resource the action applies to (e.g., a specific S3 bucket or EC2 instance).</li><li><strong>Condition (Optional):</strong> Conditions under which the policy is in effect (e.g., only if the request is coming from a specific IP address).</li></ul><div class='info-box tip'><div class='info-box-header'><i class='fas fa-lightbulb'></i><strong>The Principle of Least Privilege</strong></div><p>This is the golden rule of IAM. Grant only the minimum permissions necessary for a user or service to perform its required tasks, and nothing more. Always start with a minimal set of permissions and add more as needed.</p></div>",
                            "image": "https://images.unsplash.com/photo-1522252234503-e356032cafd5?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Create an IAM User (AWS CLI)",
                        "language": "bash",
                        "code": "aws iam create-user --user-name my-test-user"
                    },
                    {
                        "title": "Example IAM Policy (JSON)",
                        "language": "json",
                        "code": "{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:GetObject\",\n                \"s3:ListBucket\"\n            ],\n            \"Resource\": [\n                \"arn:aws:s3:::my-example-bucket\",\n                \"arn:aws:s3:::my-example-bucket/*\"\n            ]\n        }\n    ]\n}"
                    },
                    {
                        "title": "Attach a Policy to a Group (AWS CLI)",
                        "language": "bash",
                        "code": "aws iam attach-group-policy --group-name my-developer-group --policy-arn arn:aws:iam::aws:policy/PowerUserAccess"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the most secure way to grant an EC2 instance permission to access an S3 bucket?", "options": ["Hard-code access keys in the application code", "Store access keys in a text file on the instance", "Assign an IAM Role to the instance with a policy granting S3 access", "Make the S3 bucket public"], "correct": 2, "explanation": "IAM Roles use temporary credentials that are automatically rotated, eliminating the risk of long-lived access keys being compromised." },
                        { "id": 2, "question": "The security principle that states you should only grant the minimum permissions required is known as:", "options": ["The Principle of Most Privilege", "The Principle of Least Privilege", "The Shared Responsibility Model", "Multi-Factor Authentication"], "correct": 1, "explanation": "This is the most important concept in IAM. Always start with zero permissions and grant only what is absolutely necessary." },
                        { "id": 3, "question": "An explicit `Deny` in an IAM policy will always override an `Allow`.", "options": ["True", "False"], "correct": 0, "explanation": "The presence of any `Deny` for a specific action will always win, which is an important safety feature of IAM." }
                    ]
                }
            },
            {
                "id": "lesson-3-account-security",
                "title": "Lesson 3: AWS Account Security Setup",
                "duration": "120 min",
                "objectives": [
                    "Secure the all-powerful root account",
                    "Enforce Multi-Factor Authentication (MFA) for all users",
                    "Understand how to use AWS Organizations for multi-account governance",
                    "Implement preventative controls with Service Control Policies (SCPs)"
                ],
                "content": {
                    "overview": "Your AWS account itself is the ultimate security boundary. This lesson covers the foundational, day-one best practices for securing your account, including protecting the root user and using AWS Organizations to manage security across multiple accounts.",
                    "sections": [
                        {
                            "title": "Root Account Protection",
                            "content": "<p>The root user is the most privileged identity in an AWS account. It has unrestricted access to everything. A compromise of the root user is a catastrophic event. Therefore, the root user should NEVER be used for daily tasks.</p><h3>Root Account Best Practices:</h3><ol><li><strong>Do Not Use It:</strong> For all day-to-day administrative tasks, use a regular IAM user with administrative privileges instead.</li><li><strong>Set a Very Strong Password:</strong> Use a long, complex password stored in a secure password manager.</li><li><strong>Enable MFA:</strong> This is the most critical step. Enable a Multi-Factor Authentication device on the root user. A hardware MFA device is recommended.</li><li><strong>Delete Access Keys:</strong> The root user should not have programmatic access keys. Delete them if they exist.</li></ol>",
                            "image": "https://images.unsplash.com/photo-1554224155-83e8b835d07a?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "AWS Organizations and SCPs",
                            "content": "<p>AWS Organizations allows you to centrally manage and govern a multi-account environment. Service Control Policies (SCPs) are a key feature of Organizations for security.</p><h3>Service Control Policies (SCPs):</h3><p>SCPs are preventative guardrails. They act like a filter on top of all IAM permissions for an account. An SCP can specify the maximum permissions for all accounts in an Organizational Unit (OU).</p><p>For example, you can apply an SCP to a development OU that explicitly **denies** the ability to create certain expensive resources or to delete critical logging configurations. Even if a developer has an IAM policy that says `Allow ec2:*`, the SCP `Deny ec2:CreateVpc` would prevent them from creating a new VPC. This is a powerful tool for enforcing central governance.</p>",
                            "image": "https://images.unsplash.com/photo-1521791136064-7986c2920216?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Example Service Control Policy (SCP)",
                        "language": "json",
                        "code": "{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Deny\",\n      \"Action\": [\n        \"iam:DeleteAccessKey\",\n        \"organizations:LeaveOrganization\",\n        \"s3:DeleteBucket\"\n      ],\n      \"Resource\": \"*\",\n      \"Condition\": {\n        \"StringNotEquals\": {\n          \"aws:PrincipalArn\": \"arn:aws:iam::123456789012:role/OrganizationAdmin\"\n        }\n      }\n    }\n  ]\n}"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary security best practice for the AWS account root user?", "options": ["Use it for all daily administrative tasks", "Share its password with the whole team", "Enable MFA, set a strong password, and do not use it for daily tasks", "Delete the root user"], "correct": 2, "explanation": "The root user is too powerful for daily use. It should be locked down and used only for a few specific account management tasks." },
                        { "id": 2, "question": "What is the function of a Service Control Policy (SCP) in AWS Organizations?", "options": ["It grants permissions to users", "It acts as a preventative guardrail, limiting the maximum permissions for accounts within an OU", "It monitors for threats", "It automatically patches operating systems"], "correct": 1, "explanation": "SCPs are a powerful central governance tool. They don't grant permissions, but they can deny them, overriding any local IAM policies within an account." },
                        { "id": 3, "question": "Multi-Factor Authentication (MFA) adds what to the authentication process?", "options": ["A longer password", "A second factor of authentication, like something you have (a device) or something you are (a biometric)", "An extra security question", "A different username"], "correct": 1, "explanation": "MFA provides a crucial second layer of security beyond just a password (something you know)." }
                    ]
                }
            },
            {
                "id": "lesson-4-security-services-overview",
                "title": "Lesson 4: AWS Security Services Overview",
                "duration": "120 min",
                "objectives": [
                    "Identify the major native AWS security services",
                    "Categorize services by their primary function (e.g., threat detection, data protection)",
                    "Understand the high-level use case for key services like GuardDuty, Inspector, and Macie",
                    "Consider the cost implications of enabling various security services"
                ],
                "content": {
                    "overview": "AWS provides a vast and ever-growing portfolio of native security services. This lesson provides a high-level map of the landscape, organizing the key services into logical categories so you can understand what tool to use for which security problem.",
                    "sections": [
                        {
                            "title": "Service Categories and Use Cases",
                            "content": "<p>It's helpful to group the many AWS security services by their core function.</p><h3>Major Categories:</h3><ul><li><strong>Identity & Access Management:</strong> IAM, AWS Organizations, AWS Directory Service.</li><li><strong>Detective Controls:</strong> CloudTrail (audit), AWS Config (configuration tracking), GuardDuty (threat detection), Security Hub (centralized findings).</li><li><strong>Infrastructure Protection:</strong> VPC (network isolation), Security Groups/NACLs (firewalls), AWS WAF (web application firewall), AWS Shield (DDoS protection).</li><li><strong>Data Protection:</strong> KMS (key management), Secrets Manager, Macie (data discovery), Certificate Manager.</li><li><strong>Incident Response:</strong> Amazon Detective (investigation), Systems Manager (automation/patching).</li></ul>",
                            "image": "https://images.unsplash.com/photo-1542744173-8e7e53415bb0?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Key Detective Services",
                            "content": "<ul><li><strong>Amazon GuardDuty:</strong> A smart, managed threat detection service. It analyzes your VPC Flow Logs, CloudTrail logs, and DNS logs using machine learning and threat intelligence to detect threats like cryptomining, C2 beacons, and unusual API activity. It is a 'set it and forget it' service that provides high-fidelity alerts.</li><li><strong>Amazon Inspector:</strong> An automated vulnerability assessment service. It scans your EC2 instances and container images for software vulnerabilities and unintended network exposure.</li><li><strong>Amazon Macie:</strong> A data security service that uses machine learning to automatically discover, classify, and protect sensitive data (like PII or financial information) stored in Amazon S3.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1614064548237-02f8f17374b2?w=800&h=400&fit-crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "Which AWS service is a managed threat detection service that analyzes logs to find malicious activity like cryptomining?", "options": ["Amazon Inspector", "Amazon Macie", "Amazon GuardDuty", "AWS Shield"], "correct": 2, "explanation": "GuardDuty is the primary AWS service for threat detection, acting like an intelligent IDS for your AWS account." },
                        { "id": 2, "question": "To automatically discover and classify Personally Identifiable Information (PII) stored in your S3 buckets, you would use which service?", "options": ["AWS Config", "Amazon Macie", "Amazon Inspector", "AWS WAF"], "correct": 1, "explanation": "Macie is specifically designed for sensitive data discovery and protection, helping you find where your critical data resides." },
                        { "id": 3, "question": "Which service is used to scan your EC2 instances for software vulnerabilities?", "options": ["Amazon GuardDuty", "Amazon Detective", "Amazon Inspector", "AWS CloudTrail"], "correct": 2, "explanation": "Inspector is the AWS native vulnerability scanning service." }
                    ]
                }
            },
            {
                "id": "lesson-5-vpc-security",
                "title": "Lesson 5: VPC Security Fundamentals",
                "duration": "150 min",
                "objectives": [
                    "Design a secure Virtual Private Cloud (VPC) architecture",
                    "Implement effective network segmentation using public and private subnets",
                    "Understand the security function of Internet Gateways, NAT Gateways, and VPC Endpoints",
                    "Build a secure VPC from scratch in a lab environment"
                ],
                "content": {
                    "overview": "The Amazon VPC is your own logically isolated section of the AWS cloud. It is the foundational building block of network security. This lesson covers how to design and build a secure VPC architecture from the ground up, focusing on the principle of network segmentation.",
                    "sections": [
                        {
                            "title": "VPC Architecture and Segmentation",
                            "content": "<p>A VPC allows you to provision resources in a virtual network that you define. The most important security practice is segmentation.</p><h3>The Public/Private Subnet Model:</h3><p>A standard secure architecture involves creating multiple subnets within your VPC.</p><ul><li><strong>Public Subnets:</strong> These subnets have a route to an Internet Gateway (IGW). Only resources that absolutely must be directly accessible from the internet, like a load balancer, are placed here.</li><li><strong>Private Subnets:</strong> These subnets do *not* have a route to the IGW. Your application servers, databases, and other sensitive resources are placed here. They cannot be reached directly from the internet.</li><li><strong>NAT Gateway:</strong> To allow resources in a private subnet to initiate outbound connections to the internet (e.g., to download software patches) without being reachable from the internet, you place a NAT Gateway in the public subnet and route the private subnet's outbound traffic through it.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit-crop"
                        },
                        {
                            "title": "VPC Endpoints",
                            "content": "<p>By default, if your EC2 instance in a private subnet needs to talk to an AWS service like S3, that traffic has to go out through the NAT Gateway to the public internet and back to the S3 public endpoint. This is inefficient and less secure.</p><h3>VPC Endpoints for Security:</h3><p>A VPC Endpoint allows you to connect privately to supported AWS services without requiring an IGW or a NAT Gateway. The traffic stays entirely on the private AWS network.</p><ul><li><strong>Gateway Endpoints:</strong> Used for S3 and DynamoDB.</li><li><strong>Interface Endpoints (PrivateLink):</strong> Used for most other services. It creates an Elastic Network Interface (ENI) in your subnet that acts as a private entry point to the service.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1542744173-8e7e53415bb0?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Create a VPC (AWS CLI)",
                        "language": "bash",
                        "code": "aws ec2 create-vpc --cidr-block 10.0.0.0/16"
                    },
                    {
                        "title": "Create a Public Subnet (AWS CLI)",
                        "language": "bash",
                        "code": "aws ec2 create-subnet --vpc-id vpc-12345678 --cidr-block 10.0.1.0/24"
                    },
                    {
                        "title": "Create an Internet Gateway and Attach it (AWS CLI)",
                        "language": "bash",
                        "code": "aws ec2 create-internet-gateway\naws ec2 attach-internet-gateway --vpc-id vpc-12345678 --internet-gateway-id igw-87654321"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "In a secure VPC design, where should you place your database servers?", "options": ["In a public subnet", "Directly on the internet", "In a private subnet", "In a different AWS account"], "correct": 2, "explanation": "Databases should never be directly exposed to the internet. They should always be in a private subnet, accessed only through your application layer." },
                        { "id": 2, "question": "What is the function of a NAT Gateway?", "options": ["To allow inbound traffic from the internet to your private subnets", "To allow outbound traffic from private subnets to the internet", "To act as a firewall", "To store data"], "correct": 1, "explanation": "A NAT (Network Address Translation) Gateway provides a secure way for instances in a private subnet to initiate outbound connections without being publicly exposed." },
                        { "id": 3, "question": "A VPC Endpoint allows private connectivity to AWS services without:", "options": ["Using IAM roles", "Paying any money", "Traffic leaving the AWS network to traverse the public internet", "Using subnets"], "correct": 2, "explanation": "VPC Endpoints are a key security feature that keeps traffic between your VPC and other AWS services on the private, secure AWS backbone." }
                    ]
                }
            },
            {
                "id": "lesson-6-security-groups-nacls",
                "title": "Lesson 6: Security Groups and NACLs",
                "duration": "120 min",
                "objectives": [
                    "Configure Security Groups to act as stateful firewalls for EC2 instances",
                    "Implement Network ACLs (NACLs) as stateless firewalls for subnets",
                    "Understand the key differences between stateful and stateless filtering",
                    "Analyze traffic flow and rule evaluation order"
                ],
                "content": {
                    "overview": "Security Groups and Network ACLs are the two primary firewall services within a VPC. They are both fundamental to infrastructure protection, but they operate at different levels and in different ways. This lesson provides a deep dive into how to use both effectively.",
                    "sections": [
                        {
                            "title": "Security Groups (Stateful)",
                            "content": "<p>A Security Group (SG) acts as a virtual firewall for your EC2 instances. It controls inbound and outbound traffic at the instance level.</p><h3>Key Properties:</h3><ul><li><strong>Stateful:</strong> This is the most important feature. If you allow an inbound connection (e.g., on port 80), the SG automatically allows the return traffic for that connection back out, regardless of the outbound rules. You don't have to define rules for the return traffic.</li><li><strong>Allow Rules Only:</strong> You cannot create 'deny' rules in a Security Group. By default, everything is denied, and you add rules to allow specific traffic.</li><li><strong>Instance-level:</strong> They are associated with the Elastic Network Interface (ENI) of an instance. A single instance can have multiple SGs, and a single SG can apply to many instances.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1544890225-2fde1e46f71b?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Network ACLs (Stateless)",
                            "content": "<p>A Network Access Control List (NACL) is a firewall for your subnets. It controls inbound and outbound traffic at the subnet level, acting as a second layer of defense.</p><h3>Key Properties:</h3><ul><li><strong>Stateless:</strong> Unlike a Security Group, a NACL does not track connection state. If you allow an inbound connection on a certain port, you must *also* create a separate outbound rule to allow the return traffic.</li><li><strong>Allow and Deny Rules:</strong> NACLs have both `Allow` and `Deny` rules. Rules are evaluated in order by rule number, from lowest to highest. The first rule that matches the traffic is applied.</li><li><strong>Subnet-level:</strong> They are associated with one or more subnets. All instances within that subnet are affected by the NACL.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1599691888286-93e433f064b8?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Create a Security Group Allowing SSH and HTTP (AWS CLI)",
                        "language": "bash",
                        "code": "aws ec2 create-security-group --group-name WebServerSG --description \"Allow SSH and HTTP\"\n\naws ec2 authorize-security-group-ingress --group-name WebServerSG --protocol tcp --port 22 --cidr 54.32.10.1/32\naws ec2 authorize-security-group-ingress --group-name WebServerSG --protocol tcp --port 80 --cidr 0.0.0.0/0"
                    },
                    {
                        "title": "Create a Network ACL Entry (AWS CLI)",
                        "language": "bash",
                        "code": "# This rule allows inbound HTTP traffic.\n# You would need another outbound rule for the return traffic on ephemeral ports (1024-65535).\naws ec2 create-network-acl-entry --network-acl-id acl-12345678 --ingress --rule-number 100 --protocol tcp --port-range From=80,To=80 --cidr-block 0.0.0.0/0 --rule-action allow"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "Which AWS firewall service is 'stateful'?", "options": ["Network ACL", "Security Group", "AWS WAF", "AWS Shield"], "correct": 1, "explanation": "Security Groups are stateful, meaning return traffic for an allowed inbound connection is automatically permitted." },
                        { "id": 2, "question": "A Network ACL operates at the ______ level, while a Security Group operates at the ______ level.", "options": ["instance / subnet", "VPC / account", "subnet / instance", "region / Availability Zone"], "correct": 2, "explanation": "This is a key distinction. NACLs are for subnets; SGs are for instances." },
                        { "id": 3, "question": "You create a NACL rule with `Rule #100: Deny All` and `Rule #110: Allow Port 80`. What will happen to traffic on Port 80?", "options": ["It will be allowed", "It will be denied", "Half will be allowed, half denied", "The NACL will crash"], "correct": 1, "explanation": "NACL rules are evaluated in numerical order. Since Rule #100 matches the traffic first, the `Deny` action is applied, and no further rules are evaluated." }
                    ]
                }
            },
            {
                "id": "lesson-7-waf-shield",
                "title": "Lesson 7: AWS WAF and Shield",
                "duration": "120 min",
                "objectives": [
                    "Understand the role of a Web Application Firewall (WAF)",
                    "Create WAF rules to block common attacks like SQL injection and XSS",
                    "Differentiate between AWS Shield Standard and Advanced for DDoS protection",
                    "Implement rate limiting to defend against bots"
                ],
                "content": {
                    "overview": "Protecting your web applications requires specialized defenses. This lesson covers AWS WAF and AWS Shield, the primary services for defending against application-layer attacks and large-scale Distributed Denial-of-Service (DDoS) attacks.",
                    "sections": [
                        {
                            "title": "AWS WAF (Web Application Firewall)",
                            "content": "<p>AWS WAF is a firewall that operates at Layer 7 (the application layer). It inspects HTTP and HTTPS requests before they reach your web servers, allowing you to filter and block malicious traffic.</p><h3>What WAF Protects Against:</h3><ul><li><strong>OWASP Top 10:</strong> It has built-in rule sets to help protect against common vulnerabilities like SQL Injection (SQLi) and Cross-Site Scripting (XSS).</li><li><strong>Bad Bots and Scrapers:</strong> You can block traffic from known malicious bots or specific user-agents.</li><li><strong>Geographic Blocking:</strong> You can block traffic originating from specific countries.</li><li><strong>Rate Limiting:</strong> You can create rules to automatically block IP addresses that are making an excessive number of requests in a short period.</li></ul><p>WAF can be attached to Application Load Balancers, CloudFront distributions, and API Gateway.</p>",
                            "image": "https://images.unsplash.com/photo-1605379399642-870262d3d051?w=800&h=400&fit-crop"
                        },
                        {
                            "title": "AWS Shield",
                            "content": "<p>AWS Shield is a managed Distributed Denial of Service (DDoS) protection service. It protects against volumetric attacks (like UDP floods) that try to overwhelm your application with traffic.</p><h3>Shield Tiers:</h3><ul><li><strong>Shield Standard:</strong> This is enabled automatically and free of charge for all AWS customers. It provides protection against the most common network and transport layer DDoS attacks.</li><li><strong>Shield Advanced:</strong> This is a paid, premium service for customers who need a higher level of protection. It provides more advanced detection and mitigation, 24/7 access to the AWS DDoS Response Team (DRT), and financial protection ('cost protection') against usage spikes caused by a DDoS attack.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1544197150-b99a5808e7ee?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary purpose of AWS WAF?", "options": ["To protect against DDoS attacks", "To filter malicious HTTP/HTTPS requests and protect against web application attacks like SQLi", "To act as a firewall for EC2 instances", "To scan for vulnerabilities"], "correct": 1, "explanation": "WAF is a Layer 7 firewall focused on the content of web requests, which is how it can detect and block application-specific attacks." },
                        { "id": 2, "question": "Which service provides baseline DDoS protection for all AWS customers at no extra cost?", "options": ["AWS WAF", "Amazon GuardDuty", "AWS Shield Advanced", "AWS Shield Standard"], "correct": 3, "explanation": "Shield Standard is automatically enabled to protect against common, volumetric DDoS attacks." },
                        { "id": 3, "question": "Creating a WAF rule to block any IP address that makes more than 2,000 requests in a 5-minute period is an example of:", "options": ["Geographic blocking", "SQL injection protection", "Rate limiting", "Cross-site scripting protection"], "correct": 2, "explanation": "Rate limiting is a key defense against bots and application-layer denial of service attacks." }
                    ]
                }
            },
            {
                "id": "lesson-8-network-monitoring",
                "title": "Lesson 8: Network Monitoring and Logging",
                "duration": "120 min",
                "objectives": [
                    "Enable and configure VPC Flow Logs to capture IP traffic information",
                    "Analyze CloudTrail logs for network-related API calls",
                    "Understand options for deep packet inspection in AWS",
                    "Use logs to trace network traffic and troubleshoot security issues"
                ],
                "content": {
                    "overview": "You cannot protect what you cannot see. This lesson covers the essential AWS services for network visibility, focusing on VPC Flow Logs. You will learn how to enable and analyze these logs to monitor traffic, detect anomalies, and investigate security events.",
                    "sections": [
                        {
                            "title": "VPC Flow Logs",
                            "content": "<p>VPC Flow Logs is a feature that enables you to capture information about the IP traffic going to and from network interfaces in your VPC. It's the AWS equivalent of NetFlow.</p><h3>What Flow Logs Record:</h3><p>For each IP flow, a log entry is created that includes:</p><ul><li>Source and destination IP addresses</li><li>Source and destination ports</li><li>The protocol used (e.g., TCP, UDP)</li><li>The number of packets and bytes transferred</li><li>The start and end time of the flow</li><li>The action: `ACCEPT` or `REJECT` (based on Security Group or NACL rules)</li></ul><p>Flow logs can be published to Amazon CloudWatch Logs or directly to an S3 bucket for analysis. They are a primary input for threat detection services like GuardDuty.</p>",
                            "image": "https://images.unsplash.com/photo-1594917951231-98745c43d779?w=800&h=400&fit-crop"
                        },
                        {
                            "title": "Network Packet Inspection",
                            "content": "<p>While Flow Logs provide metadata, sometimes you need to inspect the actual packet content. AWS provides several options for this.</p><h3>Packet Inspection Options:</h3><ul><li><strong>AWS Gateway Load Balancer:</strong> This service allows you to deploy, scale, and manage a fleet of third-party virtual appliances (like an IDS/IPS or a next-gen firewall) and transparently route all your VPC traffic through them for inspection.</li><li><strong>VPC Traffic Mirroring:</strong> This feature allows you to copy network traffic from an ENI of an EC2 instance and send it to an out-of-band security appliance for inspection. This is useful for monitoring without putting an appliance in the direct traffic path.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1544890225-2fde1e46f71b?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is VPC Flow Logs?", "options": ["A full packet capture service", "A service that captures metadata about IP traffic in your VPC, similar to NetFlow", "A web application firewall", "A DDoS protection service"], "correct": 1, "explanation": "Flow Logs provide essential metadata (source, destination, port, protocol, accept/reject) but do not contain the payload of the packets." },
                        { "id": 2, "question": "If a VPC Flow Log entry shows an action of 'REJECT', what does this mean?", "options": ["The traffic was successfully delivered", "The traffic was blocked by a Security Group or a Network ACL", "The traffic was encrypted", "The source IP address was spoofed"], "correct": 1, "explanation": "The 'action' field directly tells you whether your firewall rules allowed or denied the traffic, which is critical for troubleshooting and investigations." },
                        { "id": 3, "question": "VPC Flow Logs, AWS CloudTrail logs, and DNS logs are the primary data sources for which AWS threat detection service?", "options": ["Amazon Inspector", "Amazon Macie", "AWS WAF", "Amazon GuardDuty"], "correct": 3, "explanation": "GuardDuty's power comes from its ability to analyze these key log sources at scale to find threats that would be nearly impossible for a human to find manually." }
                    ]
                }
            },
            {
                "id": "lesson-9-s3-security",
                "title": "Lesson 9: S3 Security Configuration",
                "duration": "120 min",
                "objectives": [
                    "Implement S3 security best practices to prevent data exposure",
                    "Differentiate between and apply Access Control Lists (ACLs) and Bucket Policies",
                    "Effectively use the S3 Block Public Access feature",
                    "Securely configure Cross-Origin Resource Sharing (CORS)"
                ],
                "content": {
                    "overview": "Amazon S3 is a massively popular and powerful object storage service, but misconfigurations can easily lead to data breaches. This lesson is dedicated to the best practices for securing your S3 buckets, with a primary focus on access control.",
                    "sections": [
                        {
                            "title": "Access Control: Policies vs. ACLs",
                            "content": "<p>S3 offers two main ways to control access to your data.</p><h3>The Two Mechanisms:</h3><ul><li><strong>Bucket Policies:</strong> This is the modern, preferred, and most powerful method. A bucket policy is a JSON document, very similar to an IAM policy, that you attach to an entire bucket. It allows for very granular control, such as granting access only from a specific VPC Endpoint or requiring MFA for object deletion.</li><li><strong>Access Control Lists (ACLs):</strong> This is a legacy mechanism for managing access. It is less granular than a bucket policy. As a best practice, ACLs should be disabled, and all access control should be managed exclusively through IAM and Bucket Policies.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1542382156942-0268579cf259?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "S3 Block Public Access",
                            "content": "<p>Due to historical S3 misconfigurations leading to public data breaches, AWS introduced the 'Block Public Access' feature. This is a simple, account-wide or bucket-level setting that provides a powerful safety net.</p><h3>What It Does:</h3><p>When enabled, it blocks any and all policies or ACLs that would grant public access to the bucket. It is a 'master override' that makes it impossible to accidentally make a bucket public. This feature should be enabled on all accounts and buckets unless you have a very specific, validated use case for public data (like hosting a public website).</p>",
                            "image": "https://images.unsplash.com/photo-1518932945647-7a1c969f8be2?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "S3 Bucket Policy to Force Encryption",
                        "language": "json",
                        "code": "{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Deny\",\n      \"Principal\": \"*\",\n      \"Action\": \"s3:PutObject\",\n      \"Resource\": \"arn:aws:s3:::my-secure-bucket/*\",\n      \"Condition\": {\n        \"StringNotEquals\": {\n          \"s3:x-amz-server-side-encryption\": \"AES256\"\n        }\n      }\n    }\n  ]\n}"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary function of the 'S3 Block Public Access' feature?", "options": ["To encrypt all data in the bucket", "To act as a central, master override to prevent buckets from being made public, regardless of other policies", "To create a log of all access to the bucket", "To make the bucket faster"], "correct": 1, "explanation": "This feature is a critical safety control designed to prevent the most common type of S3 data leak." },
                        { "id": 2, "question": "What is the modern, recommended way to control access to an S3 bucket?", "options": ["Using Access Control Lists (ACLs)", "Making the bucket public", "Using a combination of IAM policies and S3 Bucket Policies", "Storing the data on an EC2 instance instead"], "correct": 2, "explanation": "Policies provide the most power, flexibility, and clarity for S3 access control. Legacy ACLs should generally be disabled." },
                        { "id": 3, "question": "You want to ensure that files uploaded to an S3 bucket are always encrypted. What is the best way to enforce this?", "options": ["Trusting your users to remember to do it", "Creating an S3 Bucket Policy with a condition that denies uploads that don't have the server-side encryption header", "Running a manual check once a week", "Storing the data unencrypted"], "correct": 1, "explanation": "A bucket policy provides a preventative, automated control to enforce your security requirements at the API level." }
                    ]
                }
            },
            {
                "id": "lesson-10-encryption-at-rest",
                "title": "Lesson 10: Encryption at Rest",
                "duration": "120 min",
                "objectives": [
                    "Understand the role of AWS Key Management Service (KMS) for managing encryption keys",
                    "Enable server-side encryption for EBS volumes, RDS databases, and S3 buckets",
                    "Differentiate between AWS managed keys and customer managed keys",
                    "Implement a key rotation policy"
                ],
                "content": {
                    "overview": "Data protection is a core security pillar. This lesson covers encryption at rest in AWS, focusing on the central role of the AWS Key Management Service (KMS). You will learn how to enable encryption for the most common storage and database services.",
                    "sections": [
                        {
                            "title": "AWS Key Management Service (KMS)",
                            "content": "<p>AWS KMS is a managed service that makes it easy to create and control the encryption keys used to encrypt your data. It is integrated with almost all other AWS services.</p><h3>Key Concepts:</h3><ul><li><strong>Customer Master Keys (CMKs):</strong> The primary resource in KMS. A CMK is a logical representation of a key. The actual key material never leaves the FIPS 140-2 validated Hardware Security Modules (HSMs) that power KMS.</li><li><strong>Envelope Encryption:</strong> A common pattern used by KMS. Your data is encrypted with a unique data key. That data key is then itself encrypted by the CMK. The encrypted data and the encrypted data key are stored together. This is more efficient than sending large amounts of data to KMS to be encrypted directly.</li><li><strong>AWS Managed vs. Customer Managed Keys:</strong> AWS offers different levels of control. You can use keys that are fully managed by AWS, or you can create and manage your own 'Customer Managed Keys' (CMKs), which gives you full control over their policies and rotation.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1599373922312-5b9340d8a5a5?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Service Encryption",
                            "content": "<p>Most AWS services that store data have a simple checkbox to enable encryption at rest, using KMS.</p><h3>Examples:</h3><ul><li><strong>EBS Volume Encryption:</strong> When you create an EC2 instance, you can specify that its EBS volume (hard drive) should be encrypted. All data written to the disk will be automatically encrypted.</li><li><strong>S3 Server-Side Encryption (SSE):</strong> S3 can automatically encrypt every object as it is written to the bucket. You can configure it to use keys managed by S3 (SSE-S3) or by KMS (SSE-KMS).</li><li><strong>RDS Encryption:</strong> When you create a database instance, you can enable encryption. This will encrypt the underlying storage, all automated backups, and read replicas.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Create a Customer Managed Key (CMK) in KMS",
                        "language": "bash",
                        "code": "aws kms create-key --description \"My application key\""
                    },
                    {
                        "title": "Enable automatic key rotation for a CMK",
                        "language": "bash",
                        "code": "aws kms enable-key-rotation --key-id 1234abcd-12ab-34cd-56ef-1234567890ab"
                    },
                    {
                        "title": "Launch an encrypted EBS-backed EC2 Instance",
                        "language": "bash",
                        "code": "aws ec2 run-instances --image-id ami-12345678 --block-device-mappings '[{\"DeviceName\":\"/dev/sdh\",\"Ebs\":{\"Encrypted\":true}}]' --instance-type t2.micro"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the central AWS service for creating and managing encryption keys?", "options": ["IAM", "AWS Config", "AWS Key Management Service (KMS)", "S3"], "correct": 2, "explanation": "KMS is the core service for all cryptographic operations and is deeply integrated with other AWS services for encryption." },
                        { "id": 2, "question": "In KMS, what does a Customer Managed Key (CMK) allow you to do that an AWS Managed Key does not?", "options": ["Use a stronger encryption algorithm", "Have full control over the key's policy, and manage its rotation schedule", "Use the key in more than one region", "Get the key for free"], "correct": 1, "explanation": "Customer Managed Keys provide a higher level of control, allowing you to define exactly who can use the key and to enable features like automatic annual rotation." },
                        { "id": 3, "question": "The process where a data key encrypts the data, and a master key encrypts the data key, is called:", "options": ["Envelope Encryption", "Symmetric Encryption", "Asymmetric Encryption", "Transport Encryption"], "correct": 0, "explanation": "Envelope encryption is a highly secure and efficient pattern used by KMS and many other cryptographic systems." }
                    ]
                }
            },
            {
                "id": "lesson-11-encryption-in-transit",
                "title": "Lesson 11: Encryption in Transit",
                "duration": "120 min",
                "objectives": [
                    "Understand the importance of Transport Layer Security (TLS/SSL)",
                    "Deploy SSL certificates on Application Load Balancers (ALBs) using ACM",
                    "Enforce end-to-end encryption for your applications",
                    "Recognize the role of VPN and Direct Connect for secure network connectivity"
                ],
                "content": {
                    "overview": "Data must be protected not just when it's stored, but also when it's moving across a network. This lesson covers encryption in transit, focusing on the use of TLS/SSL to secure application traffic and the AWS services that make this easy to implement.",
                    "sections": [
                        {
                            "title": "TLS/SSL with ACM and Load Balancers",
                            "content": "<p>The standard for encrypting web traffic is Transport Layer Security (TLS), the successor to SSL. To use TLS, you need a public SSL certificate.</p><h3>Key Services:</h3><ul><li><strong>AWS Certificate Manager (ACM):</strong> ACM is a service that lets you easily provision, manage, and deploy public and private SSL/TLS certificates. A major benefit is that public SSL certificates provisioned through ACM are free.</li><li><strong>Application Load Balancer (ALB):</strong> The standard practice is to terminate SSL on your ALB. The connection from the user's browser to the ALB is encrypted. The ALB then decrypts the traffic and sends it unencrypted over your private VPC network to your backend EC2 instances. This offloads the overhead of SSL processing from your web servers.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1544890225-2fde1e46f71b?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "End-to-End Encryption",
                            "content": "<p>For applications that require a higher level of security, you can implement end-to-end encryption. In this model, the ALB does *not* decrypt the traffic. Instead, it re-encrypts the traffic before sending it to the backend instances. This means the traffic is encrypted from the user to the load balancer, *and* from the load balancer to the EC2 instance.</p><div class='info-box warning'><div class='info-box-header'><i class='fas fa-exclamation-triangle'></i><strong>Enforce It!</strong></div><p>You can configure your ALBs and CloudFront to automatically redirect all HTTP traffic to HTTPS. This ensures users are always using the secure, encrypted channel.</p></div>",
                            "image": "https://images.unsplash.com/photo-1599691888286-93e433f064b8?w=800&h=400&fit-crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary purpose of TLS/SSL?", "options": ["To encrypt data at rest", "To encrypt data in transit over a network", "To manage user identities", "To scan for vulnerabilities"], "correct": 1, "explanation": "TLS/SSL is the cryptographic protocol used to create a secure, encrypted communication channel, most commonly for HTTPS." },
                        { "id": 2, "question": "Which AWS service allows you to provision and manage SSL certificates for free?", "options": ["EC2", "S3", "AWS Certificate Manager (ACM)", "KMS"], "correct": 2, "explanation": "A key benefit of ACM is providing free public SSL certificates that can be easily integrated with ALBs and CloudFront." },
                        { "id": 3, "question": "The process of decrypting traffic at the load balancer and sending it unencrypted to the backend is known as:", "options": ["End-to-end encryption", "SSL Termination", "A DDoS attack", "Envelope encryption"], "correct": 1, "explanation": "SSL Termination is a common and efficient pattern, but for higher security needs, re-encrypting the traffic from the load balancer to the backend provides end-to-end protection." }
                    ]
                }
            },
            {
                "id": "lesson-12-secrets-manager",
                "title": "Lesson 12: AWS Secrets Manager",
                "duration": "120 min",
                "objectives": [
                    "Understand the risks of hard-coding secrets in applications",
                    "Use Secrets Manager to securely store and retrieve secrets like passwords and API keys",
                    "Configure automatic secret rotation for services like RDS",
                    "Integrate an application with Secrets Manager using IAM Roles"
                ],
                "content": {
                    "overview": "Passwords, database credentials, and API keys are some of your most sensitive data. Hard-coding them into application code is a major security risk. This lesson covers AWS Secrets Manager, a service designed to help you protect secrets needed to access your applications, services, and IT resources.",
                    "sections": [
                        {
                            "title": "Secret Storage and Rotation",
                            "content": "<p>The core function of Secrets Manager is to replace hard-coded credentials with a dynamic, API-based lookup.</p><h3>The Secure Workflow:</h3><ol><li>You create a 'secret' in Secrets Manager, storing a database password or API key.</li><li>The secret is encrypted at rest using AWS KMS.</li><li>You grant an IAM Role to your EC2 instance or Lambda function with permission to *read* that specific secret.</li><li>When the application starts, it uses its IAM Role to make an API call to Secrets Manager, retrieve the secret, and use it to connect to the database.</li></ol><p>The secret never exists in the source code or in a configuration file on the disk.</p>",
                            "image": "https://images.unsplash.com/photo-1599373922312-5b9340d8a5a5?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Automatic Rotation",
                            "content": "<p>A key feature of Secrets Manager is its ability to automatically rotate secrets. For supported services like Amazon RDS, you can configure Secrets Manager to change the database password on a schedule (e.g., every 30 days).</p><p>It will generate a new strong password, update the database with that new password, and then update the secret's value in its own store. Applications that retrieve the secret will automatically get the new password on the next rotation, all with zero downtime and no manual intervention.</p>",
                            "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Retrieve a Secret (AWS CLI)",
                        "language": "bash",
                        "code": "aws secretsmanager get-secret-value --secret-id MyTestDatabaseSecret"
                    },
                    {
                        "title": "Retrieve a Secret (Python Boto3)",
                        "language": "python",
                        "code": "import boto3\n\nclient = boto3.client('secretsmanager')\n\nresponse = client.get_secret_value(\n    SecretId='MyTestDatabaseSecret'\n)\n\nsecret = response['SecretString']\n# Now you can parse the secret string (often JSON) to get the password"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary risk that AWS Secrets Manager is designed to mitigate?", "options": ["DDoS attacks", "Hard-coded credentials in application source code", "Vulnerable operating systems", "Public S3 buckets"], "correct": 1, "explanation": "Secrets Manager provides a secure, central place to store and retrieve credentials, eliminating the dangerous practice of hard-coding them in code." },
                        { "id": 2, "question": "How does an application running on EC2 get permission to retrieve a secret from Secrets Manager?", "options": ["By using the root account's access keys", "Through a special security group rule", "By assuming an IAM Role that has a policy allowing it to read the secret", "The secret is made public"], "correct": 2, "explanation": "Access to Secrets Manager is controlled through standard IAM permissions, with IAM Roles being the most secure method for granting access to AWS resources." },
                        { "id": 3, "question": "A key feature of Secrets Manager is its ability to automatically _______ secrets for services like RDS.", "options": ["delete", "publish to the internet", "rotate", "sell"], "correct": 2, "explanation": "Automatic rotation dramatically improves security posture by ensuring credentials are changed on a regular schedule without manual effort or application downtime." }
                    ]
                }
            },
            {
                "id": "lesson-13-cloudtrail",
                "title": "Lesson 13: AWS CloudTrail",
                "duration": "120 min",
                "objectives": [
                    "Understand CloudTrail's role as the audit log for your AWS account",
                    "Enable a multi-region trail to capture all account activity",
                    "Configure log file integrity validation",
                    "Analyze CloudTrail events to answer 'who did what, and when?'"
                ],
                "content": {
                    "overview": "AWS CloudTrail is the ground truth for your AWS account. It is one of the most important security services, providing a complete audit trail of every API call made. This lesson covers how to configure CloudTrail correctly and how to use its logs for security analysis and investigation.",
                    "sections": [
                        {
                            "title": "CloudTrail Event Logging",
                            "content": "<p>CloudTrail answers the question: who did what, and when? It logs every API call made in your account, whether it was from the management console, the AWS CLI, or an SDK.</p><h3>What's in a CloudTrail Event?:</h3><ul><li><strong>Event Time:</strong> The exact time the API call was made.</li><li><strong>Identity:</strong> Who made the call (e.g., an IAM user, an assumed role, the root user).</li><li><strong>Source IP Address:</strong> The IP address the call originated from.</li><li><strong>Event Name:</strong> The API action that was called (e.g., `ec2:RunInstances`, `s3:PutObject`).</li><li><strong>Request Parameters:</strong> The parameters that were sent with the call.</li><li><strong>Response Elements:</strong> The response from the service.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1510915228340-29c85a43dcfe?w=800&h=400&fit-crop"
                        },
                        {
                            "title": "CloudTrail Best Practices",
                            "content": "<h3>Enable It Everywhere:</h3><p>You must create a 'trail' to have your CloudTrail events delivered to an S3 bucket for long-term storage and analysis.</p><ul><li><strong>Apply to all Regions:</strong> Your trail should be configured to apply to all AWS regions. This ensures you capture activity no matter where it happens.</li><li><strong>Enable for your Organization:</strong> In AWS Organizations, you can create a single trail that captures all events for every single account in your organization and delivers the logs to a central security S3 bucket.</li><li><strong>Enable Log File Integrity Validation:</strong> This feature creates a cryptographic hash of your log files, allowing you to prove that they have not been tampered with after being delivered.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1499750310107-5fef28a66643?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary function of AWS CloudTrail?", "options": ["To protect against DDoS attacks", "To provide a detailed audit log of all API calls made in your AWS account", "To store your application data", "To manage user passwords"], "correct": 1, "explanation": "CloudTrail is the fundamental service for audit and governance, answering the 'who, what, when, where' for every action in your account." },
                        { "id": 2, "question": "What is a critical best practice when configuring a CloudTrail trail?", "options": ["Only enable it for one region", "Apply the trail to all regions to ensure you capture all activity", "Store the logs in a public S3 bucket", "Turn it off to save money"], "correct": 1, "explanation": "Attackers may try to operate in a region you don't normally use to evade detection. A multi-region trail is essential." },
                        { "id": 3, "question": "The log file integrity validation feature helps you prove that:", "options": ["The logs are easy to read", "The API calls were successful", "The log files have not been tampered with or altered after they were delivered", "You have enough storage space"], "correct": 2, "explanation": "This feature provides a cryptographic guarantee of log integrity, which is crucial for forensic investigations and compliance." }
                    ]
                }
            },
            {
                "id": "lesson-14-aws-config",
                "title": "Lesson 14: AWS Config",
                "duration": "120 min",
                "objectives": [
                    "Use AWS Config to track all configuration changes to your resources",
                    "Implement Config Rules to check for compliance with security best practices",
                    "Understand how Config can be used for automated remediation",
                    "Analyze a resource's configuration history"
                ],
                "content": {
                    "overview": "While CloudTrail tells you 'who made an API call', AWS Config tells you 'what did my resource's configuration look like at a specific point in time'. This lesson covers AWS Config, a service that provides a detailed inventory of your resources and their configuration history.",
                    "sections": [
                        {
                            "title": "Configuration Change Tracking",
                            "content": "<p>AWS Config is a service that continuously monitors and records your AWS resource configurations. It allows you to automate the evaluation of recorded configurations against desired best practices.</p><h3>What Config Tracks:</h3><p>For every resource it supports, Config creates a 'Configuration Item' (CI) whenever a change is detected. This CI is a point-in-time snapshot of that resource's entire configuration. This gives you a complete history of how a resource has changed over time. For example, you can see exactly when a rule was added to a security group and what its previous state was.</p>",
                            "image": "https://images.unsplash.com/photo-1542744173-8e7e53415bb0?w=800&h=400&fit-crop"
                        },
                        {
                            "title": "Compliance with Config Rules",
                            "content": "<p>The real power of AWS Config comes from Config Rules. A rule represents your desired configuration settings.</p><ul><li><strong>Managed Rules:</strong> AWS provides a library of pre-built managed rules for common best practices (e.g., 'check if S3 buckets have public read access', 'check if MFA is enabled for the root account').</li><li><strong>Custom Rules:</strong> You can also create your own custom rules using AWS Lambda.</li></ul><p>Config continuously evaluates your resources against these rules. If a resource violates a rule, it is flagged as 'non-compliant'. This allows for automated, continuous compliance monitoring.</p><div class='info-box note'><div class='info-box-header'><i class='fas fa-info-circle'></i><strong>Automated Remediation</strong></div><p>You can configure AWS Config to automatically trigger an action when a resource becomes non-compliant. For example, if the rule 's3-bucket-public-read-prohibited' is violated, it can automatically trigger a Systems Manager Automation document to disable public access.</p></div>",
                            "image": "https://images.unsplash.com/photo-1556742044-15b56a42a033?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary function of AWS Config?", "options": ["To track API calls", "To continuously monitor and record the configuration of your AWS resources", "To detect threats", "To encrypt data"], "correct": 1, "explanation": "Config is all about resource configuration state and history, making it a key tool for compliance, audit, and operational troubleshooting." },
                        { "id": 2, "question": "In AWS Config, what is used to check if a resource's configuration complies with a desired best practice?", "options": ["A Security Group", "An IAM Policy", "A Config Rule", "A VPC"], "correct": 2, "explanation": "Config Rules are the mechanism used to define your security and compliance requirements and evaluate your resources against them." },
                        { "id": 3, "question": "If an EC2 instance is found to be 'non-compliant' with a Config Rule, what can Config be configured to do automatically?", "options": ["Nothing, it can only report", "Delete the instance", "Trigger an automated remediation action, for example using AWS Systems Manager", "Send an email to the AWS CEO"], "correct": 2, "explanation": "The ability to link compliance findings to automated remediation actions is a powerful feature for maintaining a secure state." }
                    ]
                }
            },
            {
                "id": "lesson-15-guardduty",
                "title": "Lesson 15: Amazon GuardDuty",
                "duration": "120 min",
                "objectives": [
                    "Enable and manage Amazon GuardDuty for threat detection",
                    "Understand the different types and severities of GuardDuty findings",
                    "Integrate GuardDuty findings with other security tools like Security Hub",
                    "Ingest custom threat intelligence to enhance detections"
                ],
                "content": {
                    "overview": "Amazon GuardDuty is your intelligent, 24/7 security guard for your AWS accounts and workloads. This lesson covers how GuardDuty works, the types of threats it can detect, and how to interpret and respond to its findings.",
                    "sections": [
                        {
                            "title": "Threat Detection Capabilities",
                            "content": "<p>GuardDuty is a managed threat detection service that doesn't require you to deploy any agents or sensors. You enable it with a single click, and it immediately starts analyzing your key log sources.</p><h3>Data Sources Analyzed:</h3><ul><li><strong>AWS CloudTrail Event Logs:</strong> For unusual API activity and account compromise.</li><li><strong>VPC Flow Logs:</strong> For anomalous network traffic and communication with malicious IPs.</li><li><strong>DNS Logs:</strong> For C2 communication and data exfiltration attempts.</li></ul><h3>What it Detects:</h3><p>GuardDuty uses a combination of threat intelligence (lists of known-malicious IPs and domains) and machine learning (to detect anomalies and behavioral deviations) to identify a wide range of threats, including reconnaissance, instance compromise (e.g., cryptomining), and account compromise.</p>",
                            "image": "https://images.unsplash.com/photo-1614064548237-02f8f17374b2?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Finding Types and Severity",
                            "content": "<p>When GuardDuty detects a potential security issue, it generates a 'finding'. Each finding is assigned a severity level (High, Medium, or Low) to help you prioritize your response.</p><h3>Example Findings:</h3><ul><li><strong>High Severity:</strong> `UnauthorizedAccess:IAMUser/InstanceCredentialExfiltration.OutsideAWS` (Indicates access keys from an EC2 instance are being used from an IP outside of AWS, a strong sign of compromise).</li><li><strong>Medium Severity:</strong> `Recon:EC2/PortProbeUnprotectedPort` (Indicates a known malicious IP is probing one of your EC2 instances on a port that is open to the world).</li><li><strong>Low Severity:</strong> `Policy:IAMUser/RootCredentialUsage` (Indicates the root account was used, which is against best practices).</li></ul>",
                            "image": "https://images.unsplash.com/photo-1543286386-2e659306cd6c?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What are the three main data sources that Amazon GuardDuty analyzes?", "options": ["S3, EC2, and RDS logs", "IAM, KMS, and WAF logs", "CloudTrail logs, VPC Flow Logs, and DNS logs", "Your application's custom logs"], "correct": 2, "explanation": "GuardDuty's intelligence is derived from its ability to analyze these three key, high-volume log sources for signs of malicious activity." },
                        { "id": 2, "question": "A GuardDuty finding indicates that an EC2 instance is communicating with an IP address known to be a Bitcoin mining command-and-control server. This is an example of GuardDuty using:", "options": ["Machine learning", "Threat intelligence", "Vulnerability scanning", "Compliance checking"], "correct": 1, "explanation": "This type of finding is based on comparing observed traffic against GuardDuty's built-in, curated threat intelligence feeds of known-bad IPs and domains." },
                        { "id": 3, "question": "Is it necessary to install an agent on your EC2 instances to use GuardDuty?", "options": ["Yes, an agent is required on every instance", "No, GuardDuty is an agentless service that analyzes existing logs", "Only on Windows instances", "Only on Linux instances"], "correct": 1, "explanation": "The agentless nature of GuardDuty is a key benefit, as you can enable it for your entire account with a single click without any complex deployment." }
                    ]
                }
            },
            {
                "id": "lesson-16-security-hub",
                "title": "Lesson 16: AWS Security Hub",
                "duration": "120 min",
                "objectives": [
                    "Use Security Hub as a single pane of glass for security findings",
                    "Aggregate findings from services like GuardDuty, Inspector, and Macie",
                    "Map findings to compliance standards like CIS AWS Foundations",
                    "Automate responses to findings using EventBridge integration"
                ],
                "content": {
                    "overview": "With so many security services generating alerts, it's easy to get overwhelmed. AWS Security Hub solves this problem by providing a single place to view, manage, and act on security findings from across your AWS environment.",
                    "sections": [
                        {
                            "title": "Security Finding Aggregation",
                            "content": "<p>The core function of Security Hub is to aggregate, normalize, and prioritize security findings from a wide range of sources.</p><h3>Integrated Sources:</h3><ul><li><strong>AWS Security Services:</strong> It natively integrates with GuardDuty, Inspector, Macie, IAM Access Analyzer, and AWS Config.</li><li><strong>Third-Party Tools:</strong> Many partner security products from the AWS Marketplace can also send their findings to Security Hub.</li></ul><p>By bringing all these findings into one place and normalizing them into a standard format (the AWS Security Finding Format - ASFF), Security Hub gives you a 'single pane of glass' for security posture management.</p>",
                            "image": "https://images.unsplash.com/photo-1551288049-bebda4e38f71?w=800&h=400&fit-crop"
                        },
                        {
                            "title": "Compliance Standards",
                            "content": "<p>Security Hub can automatically and continuously check your environment against security best practices and compliance standards.</p><h3>Key Standards:</h3><ul><li><strong>CIS AWS Foundations Benchmark:</strong> A set of industry-standard best practices for securing AWS.</li><li><strong>AWS Foundational Security Best Practices:</strong> A standard developed by AWS security experts.</li><li><strong>PCI DSS:</strong> A set of checks relevant to the Payment Card Industry Data Security Standard.</li></ul><p>Security Hub runs these checks and provides a compliance score, showing you exactly where you are failing to meet a specific control and what to do about it.</p>",
                            "image": "https://images.unsplash.com/photo-1542626991-cbc4e32524cc?w=800&h=400&fit-crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary purpose of AWS Security Hub?", "options": ["To detect threats", "To act as a central 'single pane of glass' to aggregate, normalize, and manage findings from other security services", "To encrypt data", "To perform vulnerability scans"], "correct": 1, "explanation": "Security Hub's main role is aggregation and management, giving you a unified view of your security posture." },
                        { "id": 2, "question": "What is the AWS Security Finding Format (ASFF)?", "options": ["A new type of encryption", "A proprietary file format", "A standardized JSON format for security findings that allows for normalization across different tools", "A type of IAM policy"], "correct": 2, "explanation": "The ASFF is key to Security Hub's ability to ingest findings from many different sources and treat them in a consistent way." },
                        { "id": 3, "question": "Security Hub's ability to check your environment against the CIS AWS Foundations Benchmark is a feature for what?", "options": ["Threat detection", "Incident response", "Automated compliance checking", "Data encryption"], "correct": 2, "explanation": "This feature provides continuous compliance monitoring against well-defined industry standards." }
                    ]
                }
            },
            {
                "id": "lesson-17-inspector",
                "title": "Lesson 17: Amazon Inspector",
                "duration": "120 min",
                "objectives": [
                    "Automate vulnerability assessments for EC2 instances and container images",
                    "Differentiate between agent-based and agentless scanning with Inspector",
                    "Prioritize vulnerability findings based on severity and context",
                    "Use Inspector's findings to guide remediation efforts"
                ],
                "content": {
                    "overview": "Finding and patching software vulnerabilities is a fundamental security task. This lesson covers Amazon Inspector, AWS's automated vulnerability management service, which helps you continuously scan your AWS workloads for vulnerabilities.",
                    "sections": [
                        {
                            "title": "Vulnerability Assessment Automation",
                            "content": "<p>Amazon Inspector automates the process of scanning your workloads for two main types of vulnerabilities:</p><ul><li><strong>Software Vulnerabilities:</strong> It checks for known Common Vulnerabilities and Exposures (CVEs) in the operating system packages and programming language libraries installed on your EC2 instances or in your container images.</li><li><strong>Unintended Network Exposure:</strong> It analyzes your network configurations (like security groups) to determine if your EC2 instances are reachable from the internet on potentially insecure ports.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1614064548237-02f8f17374b2?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Agent vs. Agentless Scanning",
                            "content": "<p>The new version of Amazon Inspector uses a hybrid model that provides the best of both worlds.</p><ul><li><strong>Agent-based (for EC2):</strong> To scan for software vulnerabilities *inside* an EC2 instance, Inspector uses the AWS Systems Manager (SSM) agent. The SSM agent is pre-installed on most modern AMIs. This provides deep visibility into the installed software.</li><li><strong>Agentless (for Network Exposure):</strong> To scan for network exposure, Inspector does not need an agent. It can analyze the network configuration of your VPC from the outside.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1510915228340-29c85a43dcfe?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "Amazon Inspector is primarily used for what security function?", "options": ["Threat detection", "DDoS protection", "Automated vulnerability assessment", "Encryption key management"], "correct": 2, "explanation": "Inspector's core job is to scan for known software vulnerabilities (CVEs) and network exposure issues." },
                        { "id": 2, "question": "To perform a deep scan for software vulnerabilities inside an EC2 instance, Amazon Inspector relies on what?", "options": ["The instance's metadata", "The AWS Systems Manager (SSM) agent", "VPC Flow Logs", "A third-party tool"], "correct": 1, "explanation": "The SSM agent provides the necessary inventory of installed packages on the EC2 instance for Inspector to perform its analysis." },
                        { "id": 3, "question": "Besides software vulnerabilities (CVEs), what else does Inspector scan for?", "options": ["Misconfigured IAM policies", "Public S3 buckets", "Unintended network exposure of EC2 instances", "The cost of your AWS bill"], "correct": 2, "explanation": "The network reachability analysis is a key feature that helps you identify instances that are accidentally exposed to the internet." }
                    ]
                }
            },
            {
                "id": "lesson-18-macie",
                "title": "Lesson 18: Amazon Macie",
                "duration": "120 min",
                "objectives": [
                    "Use Macie to discover and classify sensitive data in S3",
                    "Understand how Macie uses managed and custom data identifiers",
                    "Monitor for privacy compliance and data security risks",
                    "Configure alerts for sensitive data discovery findings"
                ],
                "content": {
                    "overview": "To protect your data, you first have to know where your sensitive data lives. This lesson covers Amazon Macie, a data security service that uses machine learning to solve this problem by automatically discovering, classifying, and protecting sensitive data stored in Amazon S3.",
                    "sections": [
                        {
                            "title": "Data Classification and Discovery",
                            "content": "<p>Amazon Macie gives you visibility into your data security and data privacy posture in S3. It helps answer critical questions like 'Where is my PII stored?' and 'Is any of this data publicly accessible?'.</p><h3>How it Works:</h3><ol><li>Macie first generates a comprehensive inventory of all your S3 buckets and evaluates your security controls, alerting you to things like unencrypted buckets or publicly accessible buckets.</li><li>It then allows you to run sensitive data discovery jobs. These jobs use a combination of machine learning and pattern matching to scan the objects in your S3 buckets and identify sensitive data.</li></ol>",
                            "image": "https://images.unsplash.com/photo-1542382156942-0268579cf259?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Sensitive Data Detection",
                            "content": "<p>Macie can identify a wide range of sensitive data types from various countries and regions.</p><h3>What it Finds:</h3><ul><li><strong>Personally Identifiable Information (PII):</strong> Names, addresses, passport numbers, driver's license numbers.</li><li><strong>Financial Information:</strong> Credit card numbers, bank account numbers.</li><li><strong>Health Information (PHI):</strong> As defined by regulations like HIPAA.</li><li><strong>Credentials and Secrets:</strong> It can find files that contain things like AWS access keys or private keys.</li><li><strong>Custom Data Identifiers:</strong> You can also define your own custom identifiers using regular expressions to find data specific to your business, like 'employee ID numbers' or 'customer account numbers'.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1599373922312-5b9340d8a5a5?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary mission of Amazon Macie?", "options": ["To scan EC2 instances for vulnerabilities", "To automatically discover and classify sensitive data, like PII, stored in Amazon S3", "To provide DDoS protection", "To manage encryption keys"], "correct": 1, "explanation": "Macie is a data-centric security service focused on solving the 'where is my sensitive data?' problem." },
                        { "id": 2, "question": "Macie helps organizations comply with privacy regulations like GDPR and HIPAA by:", "options": ["Automatically deleting all sensitive data it finds", "Identifying the location of regulated data so that appropriate controls can be applied", "Encrypting the entire internet", "Making all data public"], "correct": 1, "explanation": "You can't protect data if you don't know you have it. Macie provides the necessary visibility for data privacy compliance." },
                        { "id": 3, "question": "To find a company-specific data type, like a 'customer ID' that follows a specific format, you would create a what in Macie?", "options": ["A managed data identifier", "A custom data identifier using a regular expression", "A new S3 bucket", "An IAM policy"], "correct": 1, "explanation": "Custom data identifiers allow you to extend Macie's built-in detection capabilities to find data patterns that are unique to your organization." }
                    ]
                }
            },
            {
                "id": "lesson-19-detective",
                "title": "Lesson 19: AWS Detective",
                "duration": "120 min",
                "objectives": [
                    "Use Detective to simplify security investigations",
                    "Analyze the behavioral graph to find related security findings",
                    "Visualize event timelines to understand root cause",
                    "Correlate findings from GuardDuty, VPC Flow Logs, and CloudTrail"
                ],
                "content": {
                    "overview": "Investigating a security finding can involve analyzing huge volumes of log data from multiple sources. Amazon Detective simplifies this process by automatically collecting log data and using machine learning to build a 'behavior graph' that helps you easily visualize and conduct faster, more efficient security investigations.",
                    "sections": [
                        {
                            "title": "Behavioral Graph Analysis",
                            "content": "<p>When you enable Detective, it starts ingesting logs from CloudTrail, VPC Flow Logs, and GuardDuty findings from all of your accounts. It uses this data to build a linked graph that represents the relationships and interactions between your resources over time.</p><h3>What the Graph Shows:</h3><p>When you investigate a finding (e.g., from GuardDuty), Detective provides you with a set of visualizations and summaries. It automatically shows you all the related activity, such as:</p><ul><li>Unusual API calls made by the compromised role.</li><li>The history of traffic to and from the suspicious IP address.</li><li>A timeline of all events related to the finding.</li></ul><p>This saves you the manual work of having to pivot between different services and write complex queries to find these relationships yourself.</p>",
                            "image": "https://images.unsplash.com/photo-1551288049-bebda4e38f71?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary purpose of Amazon Detective?", "options": ["To discover sensitive data", "To block DDoS attacks", "To simplify and accelerate security investigations by automatically analyzing logs and visualizing relationships", "To patch operating systems"], "correct": 2, "explanation": "Detective is a post-detection investigation tool that dramatically reduces the time it takes to understand the 'story' behind a security finding." },
                        { "id": 2, "question": "The central data structure that Detective builds to link resources and findings together is called a:", "options": ["Blockchain", "Relational database", "Behavior graph", "Text file"], "correct": 2, "explanation": "The behavior graph is the machine learning model that Detective constructs to understand the relationships and normal patterns within your environment." },
                        { "id": 3, "question": "Amazon Detective automatically ingests and analyzes data from which sources?", "options": ["Only S3 Access Logs", "Your company's HR database", "AWS CloudTrail, VPC Flow Logs, and Amazon GuardDuty findings", "Your local machine's event logs"], "correct": 2, "explanation": "Detective's investigative power comes from its ability to process and correlate data from these three key security log sources." }
                    ]
                }
            },
            {
                "id": "lesson-20-systems-manager",
                "title": "Lesson 20: AWS Systems Manager (SSM)",
                "duration": "150 min",
                "objectives": [
                    "Use SSM Patch Manager to automate OS patching at scale",
                    "Scan for patch compliance against a defined baseline",
                    "Securely connect to EC2 instances using Session Manager instead of SSH",
                    "Use Parameter Store to securely store and manage configuration data"
                ],
                "content": {
                    "overview": "AWS Systems Manager (SSM) is a powerful suite of tools for operational management and automation. This lesson focuses on its key security capabilities, including automated patching and a much more secure alternative to traditional SSH access.",
                    "sections": [
                        {
                            "title": "Patch Management Automation",
                            "content": "<p>Keeping operating systems patched is a fundamental security requirement. SSM Patch Manager automates this process across your entire fleet of EC2 instances (and on-premises servers).</p><h3>How it Works:</h3><ol><li>You define a 'patch baseline' that specifies which types of patches should be approved for installation (e.g., 'all critical security updates').</li><li>You configure a 'maintenance window' that defines a schedule when patching can occur.</li><li>Patch Manager uses the SSM Agent on your instances to scan for missing patches against the baseline and can automatically install them during the maintenance window.</li><li>It provides detailed compliance dashboards showing the patch status of your entire fleet.</li></ol>",
                            "image": "https://images.unsplash.com/photo-1605152334438-6b3a69a4891e?w=800&h=400&fit-crop"
                        },
                        {
                            "title": "Session Manager",
                            "content": "<p>Traditionally, administrators connect to Linux instances using SSH and Windows instances using RDP. This requires opening inbound ports in your security groups and managing SSH keys or passwords, which can be a security risk.</p><h3>A More Secure Alternative:</h3><p>SSM Session Manager provides secure, browser-based shell access (or CLI access) to your instances without needing to open any inbound ports. It works through the SSM agent making a secure outbound connection to the AWS control plane. All sessions can be logged to CloudWatch or S3, providing a full audit trail of every command that was run.</p>",
                            "image": "https://images.unsplash.com/photo-1515879218367-8466d910aaa4?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary security benefit of using SSM Session Manager instead of SSH to connect to an EC2 instance?", "options": ["It is faster", "You do not need to open any inbound SSH ports in the instance's security group", "It costs less", "It uses a nicer color scheme"], "correct": 1, "explanation": "Eliminating open inbound ports significantly reduces the attack surface of your instances." },
                        { "id": 2, "question": "What is the function of SSM Patch Manager?", "options": ["To detect threats", "To store secrets", "To automate the process of patching operating systems at scale", "To manage SSL certificates"], "correct": 2, "explanation": "Patch Manager is a critical tool for automating vulnerability management and maintaining compliance." },
                        { "id": 3, "question": "SSM Parameter Store is used to securely store and manage what?", "options": ["User data", "Disk images", "Configuration data and simple secrets", "Network traffic logs"], "correct": 2, "explanation": "Parameter Store (along with Secrets Manager) provides a secure way to manage configuration strings and secrets, separating them from your application code." }
                    ]
                }
            },
            {
                "id": "lesson-21-ecs-eks-security",
                "title": "Lesson 21: ECS and EKS Security",
                "duration": "120 min",
                "objectives": [
                    "Scan container images for vulnerabilities before deployment",
                    "Understand runtime security monitoring for containers",
                    "Implement network segmentation using Kubernetes Network Policies",
                    "Securely manage secrets in a containerized environment"
                ],
                "content": {
                    "overview": "Containers have revolutionized application deployment, but they also introduce new security considerations. This lesson covers the core security principles for AWS's main container services: ECS (Elastic Container Service) and EKS (Elastic Kubernetes Service).",
                    "sections": [
                        {
                            "title": "Container Image Scanning",
                            "content": "<p>Container security starts before the container is ever run. The container image itself must be free from known vulnerabilities.</p><h3>The 'Shift Left' Principle:</h3><p>The idea is to find and fix vulnerabilities as early as possible in the development lifecycle ('shifting left').</p><ul><li><strong>ECR Scanning:</strong> Amazon Elastic Container Registry (ECR) has a built-in feature that can automatically scan your container images for OS and package vulnerabilities every time you push a new image.</li><li><strong>CI/CD Integration:</strong> This scanning should be integrated into your CI/CD pipeline. If an image scan detects a critical vulnerability, the pipeline should fail, preventing the insecure image from ever being deployed to production.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1579543183319-a16eee1b1fd3?w=800&h=400&fit-crop"
                        },
                        {
                            "title": "Runtime and Network Security",
                            "content": "<h3>Runtime Security:</h3><p>This focuses on protecting the running container. This can involve using third-party tools to detect anomalous behavior within a container, such as unexpected process executions or file modifications.</p><h3>Network Policies (for EKS/Kubernetes):</h3><p>By default, all pods (containers) in a Kubernetes cluster can talk to all other pods. This is not secure. Kubernetes Network Policies act as a micro-firewall for your pods. You can create rules that say, for example, 'Pods with the label 'frontend' are only allowed to connect to pods with the label 'backend' on port 8080'. This is a critical tool for network segmentation within your cluster.</p>",
                            "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit-crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "The process of scanning a container image for vulnerabilities before it is deployed is often called what?", "options": ["Runtime security", "Shifting left", "Orchestration", "Secrets management"], "correct": 1, "explanation": "'Shifting left' is a core DevSecOps concept about building security into the earliest stages of the development process." },
                        { "id": 2, "question": "What is the function of a Kubernetes Network Policy?", "options": ["To scan the container image for vulnerabilities", "To act as a micro-firewall, controlling which pods can communicate with each other", "To manage user access to the Kubernetes cluster", "To encrypt data at rest"], "correct": 1, "explanation": "Network Policies are the primary mechanism for implementing network segmentation and the principle of least privilege at the network level within a Kubernetes cluster." }
                    ]
                }
            },
            {
                "id": "lesson-22-lambda-security",
                "title": "Lesson 22: Lambda Security",
                "duration": "120 min",
                "objectives": [
                    "Apply the principle of least privilege to Lambda function IAM Roles",
                    "Securely manage secrets and environment variables",
                    "Configure Lambda functions to run within a VPC for network isolation",
                    "Understand serverless runtime security monitoring"
                ],
                "content": {
                    "overview": "Serverless computing with AWS Lambda simplifies development, but security is still a critical concern. This lesson focuses on the security best practices for Lambda functions, from a heavy emphasis on IAM permissions to network configuration and protecting your application's secrets.",
                    "sections": [
                        {
                            "title": "Function Permissions and Roles",
                            "content": "<p>The most important security control for a Lambda function is its execution role. This is the IAM role that the function assumes when it runs. This role, and its attached policies, dictate exactly what the Lambda function is allowed to do.</p><h3>Least Privilege is Everything:</h3><p>A Lambda function's role must be scoped down to the absolute minimum permissions it needs. If a function's only job is to read an object from a specific S3 bucket, its role should grant `s3:GetObject` permission on *only that bucket*, and nothing more. Granting wildcard permissions (like `s3:*` on `*`) to a Lambda function is extremely dangerous, as a compromise of that function would grant the attacker broad access.</p>",
                            "image": "https://images.unsplash.com/photo-1522252234503-e356032cafd5?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "VPC Configuration for Lambda",
                            "content": "<p>By default, Lambda functions run in a special AWS-managed VPC and can access the internet. If your function needs to access resources in your own VPC (like an RDS database in a private subnet), you must configure it to run within your VPC.</p><p>When you place a function in your VPC, it loses its default internet access. If it still needs to reach the internet, you must provide a NAT Gateway, just like for an EC2 instance in a private subnet. This provides network isolation and control.</p>",
                            "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the single most important security control for a Lambda function?", "options": ["Its runtime language", "Its execution role and the attached IAM policies", "The region it runs in", "The amount of memory it's configured with"], "correct": 1, "explanation": "The execution role defines the function's permissions and is the primary boundary for what a compromised function can do." },
                        { "id": 2, "question": "Why would you configure a Lambda function to run inside your VPC?", "options": ["To allow it to access the public internet", "To make it run faster", "To allow it to securely access resources in your private subnets, like an RDS database", "To make it cheaper"], "correct": 2, "explanation": "Placing a Lambda in a VPC is the standard and secure way to grant it access to your private network resources." },
                        { "id": 3, "question": "You should use AWS Secrets Manager or Parameter Store to handle sensitive data in Lambda instead of putting it directly in:", "options": ["The function code", "Environment variables", "A text file in the deployment package", "All of the above"], "correct": 3, "explanation": "Environment variables can be viewed by anyone with console access to the function's configuration. They should not be used for sensitive secrets like passwords or API keys; Secrets Manager is the correct tool for this." }
                    ]
                }
            },
            {
                "id": "lesson-23-ecr-security",
                "title": "Lesson 23: ECR Security",
                "duration": "120 min",
                "objectives": [
                    "Automate container image vulnerability scanning on push",
                    "Use repository access policies to control who can push and pull images",
                    "Implement image signing to ensure image integrity",
                    "Manage the lifecycle of images to remove old, stale images"
                ],
                "content": {
                    "overview": "The container registry is a critical part of the software supply chain. Securing your Amazon Elastic Container Registry (ECR) is essential for ensuring that only trusted, vulnerability-free images are deployed into your environment. This lesson covers the security features of ECR.",
                    "sections": [
                        {
                            "title": "Image Vulnerability Scanning",
                            "content": "<p>ECR has a built-in image scanning feature, powered by the open-source Clair project. It can be configured to automatically scan an image as soon as it is pushed to the repository.</p><h3>Scan on Push:</h3><p>This is a critical security practice. By enabling 'scan on push', you get immediate feedback on any known CVEs in your newly built image. This allows you to integrate security directly into your CI/CD pipeline, failing the build if the scan finds critical vulnerabilities and thus preventing vulnerable code from ever reaching production.</p>",
                            "image": "https://images.unsplash.com/photo-1579543183319-a16eee1b1fd3?w=800&h=400&fit-crop"
                        },
                        {
                            "title": "Repository Access Policies",
                            "content": "<p>Similar to S3 bucket policies, you can apply a repository policy to an ECR repository. This is a JSON document that gives you fine-grained control over who can perform actions like pushing new images or pulling existing ones. You should scope these policies down using the principle of least privilege, for example, by only allowing your trusted CI/CD pipeline's IAM Role to push new images.</p>",
                            "image": "https://images.unsplash.com/photo-1522252234503-e356032cafd5?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary benefit of enabling 'scan on push' in ECR?", "options": ["It makes the image smaller", "It provides immediate feedback on vulnerabilities in an image, allowing you to catch them early in the CI/CD pipeline", "It makes the push process faster", "It makes the repository public"], "correct": 1, "explanation": "'Scan on push' is a key DevSecOps practice that integrates security into the build process." },
                        { "id": 2, "question": "ECR Repository Policies are used to control what?", "options": ["The network access to the container", "The security of the underlying EC2 host", "Who has permission to push (upload) and pull (download) container images", "How many images can be stored"], "correct": 2, "explanation": "Repository policies are the IAM-based access control mechanism for the ECR service itself." }
                    ]
                }
            },
            {
                "id": "lesson-24-fargate-security",
                "title": "Lesson 24: Fargate Security",
                "duration": "120 min",
                "objectives": [
                    "Understand the Fargate security model and its benefits",
                    "Securely configure task definitions and networking",
                    "Implement logging and monitoring for Fargate tasks",
                    "Recognize compliance considerations for serverless containers"
                ],
                "content": {
                    "overview": "AWS Fargate is a serverless compute engine for containers that removes the need to manage the underlying EC2 instances. This changes the security model. This lesson covers the security considerations specific to Fargate, focusing on what you still need to secure when AWS manages the host.",
                    "sections": [
                        {
                            "title": "Fargate Security Model",
                            "content": "<p>With Fargate, AWS takes on the responsibility for securing the underlying host, including patching the OS and isolating the container workloads. This is a significant security benefit.</p><h3>Your Responsibilities with Fargate:</h3><p>While AWS secures the host, you are still responsible for the security *of* your container application. Your focus shifts from host security to:</p><ul><li><strong>Container Image Security:</strong> Ensuring your image is scanned and vulnerability-free.</li><li><strong>IAM Permissions:</strong> Assigning a granular, least-privilege IAM Role (the 'Task Role') to your Fargate task. This is the most important security control.</li><li><strong>Network Security:</strong> Securely configuring the task's networking, including placing it in the correct VPC subnets and assigning it a restrictive security group.</li><li><strong>Application Security:</strong> Securing the code of the application running inside the container.</li><li><strong>Secrets Management:</strong> Securely providing secrets to the container, for example by using Secrets Manager integration.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the major security benefit of using AWS Fargate instead of EC2 for running containers?", "options": ["It is always cheaper", "You do not have to manage or secure the underlying host operating system", "Containers run faster", "There are no security responsibilities for the customer"], "correct": 1, "explanation": "Fargate abstracts away the host, meaning AWS is responsible for host patching and security, which reduces your operational burden." },
                        { "id": 2, "question": "In Fargate, what is the most critical security control for determining what the containerized application is allowed to do?", "options": ["The container image", "The VPC it runs in", "The Task IAM Role", "The Fargate service itself"], "correct": 2, "explanation": "The Task IAM Role is the Fargate equivalent of an EC2 instance profile. It provides the permissions the container uses to interact with other AWS services, making it the most important security boundary." }
                    ]
                }
            },
            {
                "id": "lesson-25-rds-security",
                "title": "Lesson 25: RDS Security",
                "duration": "120 min",
                "objectives": [
                    "Implement network isolation for RDS instances",
                    "Enforce encryption at rest and in transit for your databases",
                    "Use IAM for database authentication",
                    "Securely manage database backups and recovery"
                ],
                "content": {
                    "overview": "Your databases often contain your most sensitive data. This lesson covers the security best practices for Amazon Relational Database Service (RDS), ensuring your databases are properly isolated, encrypted, and accessed in a secure manner.",
                    "sections": [
                        {
                            "title": "Database Instance Security",
                            "content": "<p>Securing an RDS instance involves multiple layers of controls.</p><h3>Key Security Controls:</h3><ul><li><strong>Network Isolation:</strong> An RDS instance should ALWAYS be deployed in a private subnet. It should not have a public IP address and should not be directly accessible from the internet. Access should only be allowed from your application servers in the same VPC via its security group.</li><li><strong>Encryption at Rest:</strong> Always enable encryption when creating an RDS instance. This encrypts the underlying storage volume, its data, and all automated backups and read replicas using AWS KMS.</li><li><strong>Encryption in Transit:</strong> Enforce the use of SSL/TLS for all connections to your database. Most database engines have a parameter you can set to require all clients to connect using SSL.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1542382156942-0268579cf259?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "IAM Database Authentication",
                            "content": "<p>Instead of managing database user passwords manually, you can use IAM Database Authentication. This allows your applications and users to authenticate to the database using an IAM role and temporary credentials instead of a password.</p><h3>Benefits:</h3><ul><li><strong>No Passwords:</strong> You don't have to manage passwords or store them in your application configuration.</li><li><strong>Centralized Access Control:</strong> All authentication is controlled through standard IAM policies.</li><li><strong>Temporary Credentials:</strong> The authentication tokens are short-lived, reducing the risk of a compromised credential.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1554224155-83e8b835d07a?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the most important network security best practice for an RDS database?", "options": ["Place it in a public subnet with a public IP address", "Open its security group to the entire internet (0.0.0.0/0)", "Place it in a private subnet and only allow access from your application servers via a restrictive security group", "Use a weak password"], "correct": 2, "explanation": "Network isolation is the single most important control to prevent an external attacker from directly accessing your database." },
                        { "id": 2, "question": "When you enable encryption at rest for an RDS instance, what gets encrypted?", "options": ["Only the data", "Only the backups", "The underlying storage, backups, and read replicas", "Only the network traffic"], "correct": 2, "explanation": "RDS encryption is comprehensive, protecting the entire lifecycle of your data at rest." },
                        { "id": 3, "question": "What is the primary benefit of using IAM Database Authentication?", "options": ["It makes the database faster", "It allows you to authenticate using temporary IAM credentials instead of managing traditional database passwords", "It encrypts the data", "It is the only way to connect to a database"], "correct": 1, "explanation": "IAM authentication eliminates the need to manage static user passwords, which is a major security and operational benefit." }
                    ]
                }
            },
                        {
                "id": "lesson-26-dynamodb-security",
                "title": "Lesson 26: DynamoDB Security",
                "duration": "120 min",
                "objectives": [
                    "Implement fine-grained access control for DynamoDB tables",
                    "Configure encryption for data at rest",
                    "Securely connect to DynamoDB from a VPC",
                    "Understand and use Point-in-Time Recovery for data protection"
                ],
                "content": {
                    "overview": "DynamoDB is a fully managed NoSQL database service. Securing it involves controlling access to data both at the table level and within the table itself. This lesson covers the security controls for DynamoDB.",
                    "sections": [
                        {
                            "title": "Fine-Grained Access Control",
                            "content": "<p>IAM policies can be used to control not only which tables a user or role can access, but which specific items and attributes they can see or modify within that table.</p><p>This is achieved by using IAM condition keys that are specific to DynamoDB. You can write a policy that says, for example, 'Allow user Alice to read items from the UserProfile table, but only for the item where the primary key (the userId) matches her own user ID'. This allows for the creation of powerful multi-tenant applications with strong data isolation.</p>",
                            "image": "https://images.unsplash.com/photo-1522252234503-e356032cafd5?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Encryption and Recovery",
                            "content": "<ul><li><strong>Encryption at Rest:</strong> All DynamoDB tables are encrypted by default using an AWS owned key. You can also choose to encrypt your tables using an AWS managed key or a customer managed key in KMS for more control and auditability.</li><li><strong>Point-in-Time Recovery (PITR):</strong> PITR is a critical data protection feature. It automatically backs up your table and allows you to restore it to any single second in the preceding 35 days. This protects against accidental write or delete operations.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1542382156942-0268579cf259?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "IAM Policy for Fine-Grained Access",
                        "language": "json",
                        "code": "{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": \"dynamodb:GetItem\",\n            \"Resource\": \"arn:aws:dynamodb:us-east-1:123456789012:table/MyDataTable\",\n            \"Condition\": {\n                \"ForAllValues:StringEquals\": {\n                    \"dynamodb:LeadingKeys\": [\n                        \"${www.amazon.com:user_id}\"\n                    ]\n                }\n            }\n        }\n    ]\n}"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "The IAM feature that allows you to restrict access to specific rows in a DynamoDB table based on the user's ID is known as:", "options": ["Encryption at rest", "Point-in-Time Recovery", "Fine-grained access control using condition keys", "Security Groups"], "correct": 2, "explanation": "DynamoDB's specific condition keys allow for very powerful, row-level (item-level) and attribute-level access control directly within an IAM policy." },
                        { "id": 2, "question": "To protect against an accidental `DELETE` operation, which DynamoDB feature should you enable?", "options": ["Encryption", "VPC Endpoints", "Fine-grained access control", "Point-in-Time Recovery (PITR)"], "correct": 3, "explanation": "PITR provides continuous backups and allows you to restore your table to a specific second, which is the primary defense against accidental data deletion or modification." }
                    ]
                }
            },
            {
                "id": "lesson-27-efs-fsx-security",
                "title": "Lesson 27: EFS and FSx Security",
                "duration": "120 min",
                "objectives": [
                    "Control file system access using network and IAM controls",
                    "Enforce encryption for file systems at rest and in transit",
                    "Secure Network File System (NFS) traffic",
                    "Develop a backup strategy for shared file systems"
                ],
                "content": {
                    "overview": "AWS offers managed file services like Amazon EFS (for Linux-based NFS workloads) and Amazon FSx (for Windows File Server and other file systems). This lesson covers the security controls for these services.",
                    "sections": [
                        {
                            "title": "File System Access Controls",
                            "content": "<p>Access to these network file systems is controlled by multiple layers.</p><ul><li><strong>Network Controls:</strong> The primary control. A file system's 'mount targets' are placed in your private subnets. The security group attached to the mount target dictates which EC2 instances can communicate with the file system on the NFS port (2049).</li><li><strong>IAM Controls (for EFS):</strong> You can create an EFS Access Point, which enforces a specific user identity for all traffic coming from that point. You can also use IAM policies to enforce things like read-only access or to require encryption in transit.</li><li><strong>OS-Level Controls:</strong> It's important to remember that standard POSIX file permissions (owner, group, other) on the files and directories within the file system are still in effect.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1599691888286-93e433f064b8?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary network-level control used to determine which EC2 instances can mount an EFS file system?", "options": ["An IAM Policy", "A Network ACL", "The Security Group attached to the EFS mount target", "The EC2 instance's OS firewall"], "correct": 2, "explanation": "The security group acts as a firewall, and you must explicitly allow inbound traffic on the NFS port (2049) from the security groups of your application instances." },
                        { "id": 2, "question": "In EFS, requiring all clients to connect using TLS is an example of what?", "options": ["Encryption at rest", "Encryption in transit", "OS-level permissions", "Fine-grained access control"], "correct": 1, "explanation": "Enforcing TLS for NFS encrypts the data as it travels over the network between your EC2 instance and the EFS file system." }
                    ]
                }
            },
            {
                "id": "lesson-28-backup-disaster-recovery",
                "title": "Lesson 28: Backup and Disaster Recovery",
                "duration": "120 min",
                "objectives": [
                    "Use AWS Backup to centrally manage and automate backups",
                    "Implement a cross-region replication strategy for disaster recovery",
                    "Understand the importance of regular recovery testing",
                    "Differentiate between Recovery Time Objective (RTO) and Recovery Point Objective (RPO)"
                ],
                "content": {
                    "overview": "Backups and a tested disaster recovery (DR) plan are non-negotiable for protecting your data against deletion, corruption, or a regional outage. This lesson covers how to build a secure and resilient backup and DR strategy on AWS.",
                    "sections": [
                        {
                            "title": "AWS Backup Service Security",
                            "content": "<p>AWS Backup is a centralized service that simplifies the management of backups across multiple AWS services (like EBS, RDS, EFS, and DynamoDB).</p><h3>Key Features:</h3><ul><li><strong>Centralized Policy:</strong> You create a single 'backup plan' that defines the frequency, retention, and lifecycle rules for your backups.</li><li><strong>Cross-Region Copy:</strong> A crucial DR feature. You can configure your backup plan to automatically and securely copy your backups to a different AWS Region. If your primary region suffers an outage, you can restore your systems from the copies in the DR region.</li><li><strong>Backup Vault Lock (WORM):</strong> To protect backups from ransomware or accidental deletion, you can use Vault Lock. It makes your backups immutable for their retention period, meaning they cannot be deleted by anyone, including the root user.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1579548122216-3841a12d1b5a?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "RTO and RPO",
                            "content": "<p>These two metrics are the foundation of any disaster recovery plan.</p><ul><li><strong>Recovery Time Objective (RTO):</strong> How quickly do you need to be back online after a disaster? This dictates your recovery strategy. An RTO of minutes requires a hot standby, while an RTO of hours can be met with a backup and restore approach.</li><li><strong>Recovery Point Objective (RPO):</strong> How much data are you willing to lose? This dictates your backup frequency. An RPO of 1 hour means you need to be taking backups at least every hour.</li></ul><p>The business, not the IT department, must define the RTO and RPO for each application.</p>",
                            "image": "https://images.unsplash.com/photo-1542744173-8e7e53415bb0?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "To protect backups from being deleted by ransomware, which AWS Backup feature should you use?", "options": ["Cross-Region Copy", "Backup Vault Lock (Write-Once, Read-Many)", "Lifecycle policies", "On-demand backups"], "correct": 1, "explanation": "Vault Lock makes your backups immutable, providing a strong defense against threats that try to delete your recovery points." },
                        { "id": 2, "question": "The maximum amount of data your business is willing to lose in the event of a disaster is defined by the:", "options": ["Recovery Time Objective (RTO)", "Service Level Agreement (SLA)", "Recovery Point Objective (RPO)", "Key Performance Indicator (KPI)"], "correct": 2, "explanation": "RPO dictates how far back you might have to go, and therefore, your backup frequency. If your RPO is 1 hour, you can't rely on nightly backups." },
                        { "id": 3, "question": "Automating the replication of backups to a different AWS Region is a key strategy for:", "options": ["Reducing costs", "Disaster Recovery (DR)", "Improving performance", "Patch management"], "correct": 1, "explanation": "Cross-region copies ensure you can recover even if your entire primary region becomes unavailable." }
                    ]
                }
            },
            {
                "id": "lesson-29-aws-incident-response",
                "title": "Lesson 29: AWS Incident Response",
                "duration": "120 min",
                "objectives": [
                    "Adapt the standard IR process for cloud environments",
                    "Securely collect evidence like disk snapshots and logs in AWS",
                    "Understand how and when to escalate to AWS Support for security incidents",
                    "Create forensic images from EBS snapshots"
                ],
                "content": {
                    "overview": "When an incident happens in the cloud, the response process must adapt to the new environment. This lesson covers the unique aspects of incident response in AWS, focusing on how to collect evidence when you don't have physical access to the hardware.",
                    "sections": [
                        {
                            "title": "Evidence Collection in AWS",
                            "content": "<p>In the cloud, evidence collection is done via API calls, not by physically seizing hardware.</p><h3>The 'Isolate and Snapshot' Process:</h3><ol><li><strong>Containment:</strong> The first step is to isolate the compromised EC2 instance. The best way to do this is by changing its security group to one that denies all inbound and outbound traffic except for connections from your forensics team.</li><li><strong>Memory Acquisition (Optional but recommended):</strong> Use a tool like AWS Systems Manager to run a memory acquisition script on the live instance to capture volatile data.</li><li><strong>Disk Acquisition (Snapshot):</strong> Take a snapshot of the instance's EBS volume. This snapshot is a point-in-time, forensically sound copy of the disk. It is the primary piece of evidence.</li><li><strong>Preserve Logs:</strong> Ensure that all relevant logs (CloudTrail, VPC Flow Logs, etc.) for the timeframe of the incident are preserved and are not subject to automated deletion policies.</li></ol>",
                            "image": "https://images.unsplash.com/photo-1618498263386-339c9a7593c6?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Forensic Analysis Workflow",
                            "content": "<p>Once you have the snapshot, you create a dedicated 'forensic VPC' and a clean 'analysis' instance within it. You then create a new EBS volume from the snapshot and attach it as a secondary drive to the analysis instance. You can then mount the volume as read-only and begin your investigation using standard forensic tools, all without ever touching the original compromised system.</p>",
                            "image": "https://images.unsplash.com/photo-1593110022831-292911b3b194?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the AWS equivalent of creating a bit-for-bit forensic image of a hard drive?", "options": ["Creating a new IAM user", "Taking an EBS Snapshot of the instance's volume", "Running a vulnerability scan", "Enabling GuardDuty"], "correct": 1, "explanation": "An EBS snapshot is the foundational evidence acquisition method for virtual machine disks in AWS." },
                        { "id": 2, "question": "What is the best way to isolate a compromised EC2 instance while still allowing your forensics team to access it?", "options": ["Unplugging the network cable from the server", "Deleting the instance immediately", "Changing the instance's security group to a special 'quarantine' group that denies all traffic except from the forensics team's IP addresses", "Terminating the instance"], "correct": 2, "explanation": "This method of containment is both effective and precise, allowing for safe, continued investigation." }
                    ]
                }
            },
            {
                "id": "lesson-30-cloudformation-security",
                "title": "Lesson 30: CloudFormation Security",
                "duration": "120 min",
                "objectives": [
                    "Understand the security benefits of Infrastructure as Code (IaC)",
                    "Scan CloudFormation templates for security misconfigurations before deployment",
                    "Use Stack Policies to protect stack resources from unintended updates",
                    "Detect and remediate configuration drift"
                ],
                "content": {
                    "overview": "Infrastructure as Code (IaC) is the practice of defining your infrastructure in code. AWS CloudFormation is the primary service for this. This lesson covers how to secure your IaC pipeline, ensuring that the infrastructure you deploy is secure by default.",
                    "sections": [
                        {
                            "title": "Template Security Scanning",
                            "content": "<p>A CloudFormation template is the blueprint for your infrastructure. You should scan these blueprints for security issues *before* you ever deploy them. This is a key 'shift left' security practice.</p><p>Open-source tools (like `cfn-lint` or `checkov`) can be integrated directly into your CI/CD pipeline. These tools will automatically scan your templates for common security misconfigurations, such as a security group that is open to the world or an unencrypted S3 bucket, and will fail the build if issues are found.</p>",
                            "image": "https://images.unsplash.com/photo-1555099962-4199c345e541?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Drift Detection and Remediation",
                            "content": "<p>CloudFormation allows you to detect 'drift'. Drift occurs when a resource's actual configuration in the AWS account has changed from what is defined in the CloudFormation template (e.g., someone manually changed a security group rule in the console).</p><p>Running regular drift detection allows you to find these unauthorized, out-of-band changes. This is critical for maintaining a known, secure baseline and ensuring your infrastructure's state always matches what's defined in your version-controlled code.</p>",
                            "image": "https://images.unsplash.com/photo-1498050108023-c5249f4df085?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "The practice of defining your AWS infrastructure in a file that can be version-controlled and peer-reviewed is called:", "options": ["Manual deployment", "Infrastructure as Code (IaC)", "Incident Response", "Data encryption"], "correct": 1, "explanation": "IaC is a foundational concept in modern cloud operations and security." },
                        { "id": 2, "question": "What is the purpose of scanning a CloudFormation template with a tool like `cfn-lint`?", "options": ["To deploy the template", "To check the template for security misconfigurations *before* it is deployed", "To see how much the infrastructure will cost", "To delete the template"], "correct": 1, "explanation": "This 'shift left' practice prevents insecure infrastructure from being created in the first place." },
                        { "id": 3, "question": "In CloudFormation, what is 'drift'?", "options": ["When a template deploys very slowly", "When a resource's actual configuration differs from what is defined in the template", "A feature that makes templates more secure automatically", "A type of billing alert"], "correct": 1, "explanation": "Drift detection is a key feature for identifying unauthorized manual changes and ensuring the integrity of your IaC deployments." }
                    ]
                }
            },
            {
                "id": "lesson-31-cost-billing-security",
                "title": "Lesson 31: Cost and Billing Security",
                "duration": "120 min",
                "objectives": [
                    "Configure billing alerts to detect unexpected cost spikes",
                    "Use AWS Cost Anomaly Detection to find unusual spending",
                    "Set budgets and limits to control costs",
                    "Use resource tags for security and cost allocation"
                ],
                "content": {
                    "overview": "While not a traditional security topic, securing your AWS bill is a critical governance function. A sudden, unexpected spike in your costs is often a high-fidelity indicator of a security compromise, such as an attacker using your account for cryptocurrency mining.",
                    "sections": [
                        {
                            "title": "Cost Anomaly Detection",
                            "content": "<p>AWS Cost Anomaly Detection is a service that uses machine learning to learn your normal spending patterns. It can automatically detect unusual spending and send you an alert. For example, if your daily compute spend is normally $100 and it suddenly jumps to $5,000 because an attacker has deployed a fleet of expensive GPU instances for cryptomining, this service will flag it as an anomaly.</p>",
                            "image": "https://images.unsplash.com/photo-1551288049-bebda4e38f71?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Resource Tagging for Security",
                            "content": "<p>Tagging is the practice of applying key-value metadata to your AWS resources. While often used for cost allocation, it's also a powerful security tool.</p><h3>Security Use Cases for Tagging:</h3><ul><li><strong>Data Classification:</strong> Tagging resources with `data-classification=confidential` allows you to write specific IAM policies or security checks for those resources.</li><li><strong>Incident Response:</strong> During an incident, you can tag all compromised resources with a tag like `incident-id=IR-2023-091`, making them easy to track and query.</li><li><strong>Automation:</strong> Security automation scripts can target resources based on their tags (e.g., 'apply this patch to all servers with the tag `environment=production`').</li></ul>",
                            "image": "https://images.unsplash.com/photo-1516321497487-e288fb19713f?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "Why is monitoring your AWS bill a security best practice?", "options": ["Because AWS gives you a reward if your bill is low", "A sudden, unexplained spike in costs is a strong indicator of a potential security compromise (like cryptomining)", "It is required by all compliance frameworks", "It has no security value"], "correct": 1, "explanation": "Cost is often the first and most obvious signal that an attacker is abusing your account's resources." },
                        { "id": 2, "question": "Which service uses machine learning to automatically find unusual spending patterns in your account?", "options": ["Amazon GuardDuty", "AWS Budgets", "AWS Cost Anomaly Detection", "Amazon Inspector"], "correct": 2, "explanation": "Cost Anomaly Detection is specifically designed for this purpose, moving beyond simple static budget thresholds." }
                    ]
                }
            },
            {
                "id": "lesson-32-third-party-security",
                "title": "Lesson 32: Third-Party Integration Security",
                "duration": "120 min",
                "objectives": [
                    "Assess the security posture of solutions from the AWS Marketplace",
                    "Securely grant third-party access to your account using IAM Roles",
                    "Understand vendor risk management in a cloud context"
                ],
                "content": {
                    "overview": "Most organizations use third-party tools and services as part of their cloud environment. This lesson covers how to integrate these tools securely, with a focus on managing the permissions you grant them within your AWS account.",
                    "sections": [
                        {
                            "title": "Marketplace and Vendor Risk",
                            "content": "<p>The AWS Marketplace is a digital catalog with thousands of software listings from independent software vendors. While AWS performs some baseline checks, you are still responsible for the due diligence on any third-party software you deploy into your account.</p>",
                            "image": "https://images.unsplash.com/photo-1556742044-15b56a42a033?w=800&h=400&fit=crop"
                        },
                        {
                            "title": "Secure Cross-Account Access",
                            "content": "<p>Often, a third-party SaaS security tool will need access to your AWS account to perform its function (e.g., a cloud security posture management tool needs to list your resources). The secure way to grant this access is with an IAM Role.</p><h3>The Cross-Account Role Method:</h3><ol><li>You create an IAM Role in your account.</li><li>In the role's trust policy, you specify that the third-party vendor's AWS account is a trusted principal.</li><li>You attach a permissions policy to the role, granting the vendor the *least privilege* necessary for their tool to work.</li><li>You provide the ARN of this role to the vendor. Their tool can then *assume* this role to gain temporary, limited access to your account.</li></ol><p>This is far more secure than creating an IAM user with long-lived access keys and giving those keys to the vendor.</p>",
                            "image": "https://images.unsplash.com/photo-1554224155-83e8b835d07a?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the most secure method for granting a third-party SaaS vendor access to your AWS account?", "options": ["Creating an IAM user with admin privileges and giving them the access keys", "Making your S3 buckets public", "Using a cross-account IAM Role with a least-privilege permissions policy", "Giving them your root account password"], "correct": 2, "explanation": "A cross-account role provides temporary, auditable, and easily revocable access, which is the standard for secure third-party integration." }
                    ]
                }
            },
            {
                "id": "lesson-33-well-architected-security",
                "title": "Lesson 33: AWS Well-Architected Security",
                "duration": "120 min",
                "objectives": [
                    "Perform a deep dive into the Security Pillar of the Well-Architected Framework",
                    "Implement the design principles of the Security Pillar",
                    "Use the Well-Architected Tool to review your architectures",
                    "Understand and manage security trade-offs"
                ],
                "content": {
                    "overview": "The AWS Well-Architected Framework provides architectural best practices across five pillars. This lesson provides a deep dive into the Security Pillar, which outlines the principles and best practices for building secure applications in the cloud.",
                    "sections": [
                        {
                            "title": "Security Pillar Design Principles",
                            "content": "<p>The Security Pillar is built on a set of core design principles that should guide all your architectural decisions.</p><ul><li><strong>Implement a strong identity foundation:</strong> Use IAM and the principle of least privilege. Centralize identity management.</li><li><strong>Enable traceability:</strong> Monitor, alert, and audit all actions and changes in your environment in real time. Integrate logs and metrics.</li><li><strong>Apply security at all layers:</strong> Use a defense-in-depth approach, applying security controls at the edge, the VPC, the subnet, the load balancer, and the instance level.</li><li><strong>Automate security best practices:</strong> Use Infrastructure as Code and automated checks to create secure, repeatable processes.</li><li><strong>Protect data in transit and at rest:</strong> Classify your data and implement encryption everywhere.</li><li><strong>Prepare for security events:</strong> Have an incident response plan and practice it through simulations.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1498050108023-c5249f4df085?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "Which of the following is a design principle of the AWS Well-Architected Security Pillar?", "options": ["Apply security only at the edge", "Use long-lived access keys wherever possible", "Enable traceability by monitoring and logging all actions", "Perform all tasks as the root user"], "correct": 2, "explanation": "Traceability through services like CloudTrail, CloudWatch, and VPC Flow Logs is a foundational principle of a secure and auditable cloud environment." }
                    ]
                }
            },
            {
                "id": "lesson-34-multi-account-security",
                "title": "Lesson 34: Multi-Account Security Strategy",
                "duration": "120 min",
                "objectives": [
                    "Use AWS Organizations to structure and govern a multi-account environment",
                    "Design and implement a centralized logging architecture",
                    "Use advanced Service Control Policies (SCPs) to enforce guardrails",
                    "Securely manage cross-account access patterns"
                ],
                "content": {
                    "overview": "As an organization grows, using a single AWS account becomes unmanageable and insecure. A multi-account strategy provides strong security boundaries and simplifies governance. This lesson covers the best practices for architecting a secure multi-account environment.",
                    "sections": [
                        {
                            "title": "The AWS Landing Zone / Control Tower",
                            "content": "<p>AWS provides a prescriptive framework, now automated by a service called AWS Control Tower, for setting up a secure, multi-account environment known as a 'landing zone'.</p><h3>A Typical Landing Zone Structure:</h3><ul><li><strong>Management Account:</strong> The root of the organization. Used only for billing and central governance.</li><li><strong>Security Tooling Account:</strong> A central account where services like GuardDuty, Security Hub, and Amazon Detective are managed. Security-related logs are often shipped here.</li><li><strong>Log Archive Account:</strong> A dedicated, highly restricted account that acts as a secure repository for all CloudTrail and other audit logs from every account in the organization. The S3 buckets here should have immutable policies.</li><li><strong>Organizational Units (OUs):</strong> Accounts are organized into OUs, such as 'Prod', 'Dev', and 'Test'. SCPs are applied at the OU level to enforce different guardrails for different environments.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1521791136064-7986c2920216?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary security benefit of using a multi-account AWS strategy?", "options": ["It costs less than a single account", "It provides a strong blast radius limitation; a compromise in one account is isolated from others", "It is easier to manage for a single developer", "It makes networking faster"], "correct": 1, "explanation": "The AWS account is the strongest security boundary. Separating workloads into different accounts is a fundamental best practice for limiting the potential impact of a security breach." },
                        { "id": 2, "question": "In a secure landing zone, what is the purpose of the 'Log Archive' account?", "options": ["To run production web servers", "To act as a central, immutable repository for all audit logs from all other accounts", "To manage billing for the organization", "To be used by developers for testing"], "correct": 1, "explanation": "Centralizing logs in a dedicated, highly restricted account ensures their integrity and provides a single place for security and audit teams to access them." }
                    ]
                }
            },
            {
                "id": "lesson-35-security-automation",
                "title": "Lesson 35: Automation and Orchestration",
                "duration": "120 min",
                "objectives": [
                    "Use services like Lambda, EventBridge, and Step Functions to automate security workflows",
                    "Develop custom 'auto-remediation' actions for security findings",
                    "Build a basic security automation pipeline"
                ],
                "content": {
                    "overview": "You cannot scale security without automation. This lesson explores how to use AWS's serverless and event-driven services to build powerful security automation and orchestration workflows, moving beyond simple alerting to automated response.",
                    "sections": [
                        {
                            "title": "Event-Driven Security",
                            "content": "<p>Event-driven architecture is the core of security automation in AWS. The central service for this is Amazon EventBridge.</p><h3>The Automation Workflow:</h3><ol><li><strong>An Event Occurs:</strong> A security service generates a finding. For example, GuardDuty detects a malicious IP or AWS Config finds a non-compliant resource.</li><li><strong>EventBridge Rule:</strong> All of these findings are automatically sent as events to the EventBridge event bus. You create a rule on the bus that says, 'If an event matches this specific pattern (e.g., a GuardDuty finding with High severity)...'.</li><li><strong>Trigger an Action:</strong> '...then invoke this target'. The target can be a Lambda function, a Step Functions state machine, or a Systems Manager Automation document.</li></ol><p>This 'event -> rule -> target' pattern is the foundation for building any automated response on AWS.</p>",
                            "image": "https://images.unsplash.com/photo-1542708944-9721d234a413?w=800&h=400&fit-crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "EventBridge Rule for High Severity GuardDuty Findings",
                        "language": "json",
                        "code": "{\n  \"source\": [\"aws.guardduty\"],\n  \"detail-type\": [\"GuardDuty Finding\"],\n  \"detail\": {\n    \"severity\": [7, 7.0, 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 7.7, 7.8, 7.9, 8, 8.0, 8.1, 8.2, 8.3, 8.4, 8.5, 8.6, 8.7, 8.8, 8.9]\n  }\n}"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the central AWS service for building event-driven security automation by routing events between services?", "options": ["EC2", "S3", "Amazon EventBridge", "RDS"], "correct": 2, "explanation": "EventBridge (formerly CloudWatch Events) is the serverless event bus that acts as the 'glue' for building event-driven architectures." },
                        { "id": 2, "question": "A workflow where a finding from GuardDuty automatically triggers a Lambda function to isolate a host is an example of:", "options": ["Manual incident response", "Automated remediation", "Billing alarm", "Data encryption"], "correct": 1, "explanation": "This is a classic 'auto-remediation' pattern, where the system is programmed to automatically take a corrective action in response to a specific security event." }
                    ]
                }
            },
            {
                "id": "lesson-36-threat-modeling-aws",
                "title": "Lesson 36: Threat Modeling for AWS",
                "duration": "120 min",
                "objectives": [
                    "Apply threat modeling methodologies (like STRIDE) to AWS architectures",
                    "Identify potential threats and attack surfaces in a cloud-native design",
                    "Develop and prioritize mitigation strategies based on the threat model",
                    "Integrate threat modeling into the design phase of the application lifecycle"
                ],
                "content": {
                    "overview": "Threat modeling is a proactive, structured process for identifying and prioritizing potential threats to a system. This lesson covers how to apply the principles of threat modeling specifically to AWS architectures, helping you find and fix security flaws before a single line of code is written.",
                    "sections": [
                        {
                            "title": "The Threat Modeling Process",
                            "content": "<p>Threat modeling is a thinking exercise, best done as a collaborative, whiteboarding session.</p><h3>Four Key Questions:</h3><ol><li><strong>What are we building?</strong> (Diagram the architecture).</li><li><strong>What can go wrong?</strong> (Brainstorm threats for each component).</li><li><strong>What are we going to do about it?</strong> (Propose mitigations).</li><li><strong>Did we do a good enough job?</strong> (Review and iterate).</li></ol><h3>Using STRIDE:</h3><p>STRIDE is a mnemonic that helps with the 'What can go wrong?' step. For each component in your diagram, consider these threats:</p><ul><li><strong>S</strong>poofing: Impersonating an identity.</li><li><strong>T</strong>ampering: Modifying data.</li><li><strong>R</strong>epudiation: Denying an action was taken.</li><li><strong>I</strong>nformation Disclosure: Exposing data.</li><li><strong>D</strong>enial of Service: Making a system unavailable.</li><li><strong>E</strong>levation of Privilege: Gaining higher-level permissions.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1542626991-cbc4e32524cc?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary goal of threat modeling?", "options": ["To reactively respond to security incidents", "To proactively identify and mitigate potential security threats during the design phase of a system", "To scan an application for vulnerabilities", "To track your security budget"], "correct": 1, "explanation": "Threat modeling is the quintessential 'shift left' activity, focused on building security in from the very beginning." },
                        { "id": 2, "question": "The mnemonic STRIDE is used to help with what part of the threat modeling process?", "options": ["Diagramming the system", "Brainstorming and categorizing potential threats", "Proposing mitigations", "Writing the final report"], "correct": 1, "explanation": "STRIDE provides a useful framework to ensure you are thinking about a wide range of different threat types." }
                    ]
                }
            },
            {
                "id": "lesson-37-iot-security",
                "title": "Lesson 37: AWS IoT Security",
                "duration": "120 min",
                "objectives": [
                    "Securely authenticate IoT devices using certificates",
                    "Implement least-privilege authorization for devices in the AWS IoT message broker",
                    "Understand how to use IoT Device Defender to monitor for anomalies"
                ],
                "content": {
                    "overview": "Securing an IoT deployment involves managing the security of potentially millions of small, constrained devices. This lesson covers the core security features of AWS IoT Core, focusing on device identity and authorization.",
                    "sections": [
                        {
                            "title": "IoT Device Authentication and Authorization",
                            "content": "<p>The foundation of IoT security is ensuring that only trusted devices can connect to your platform and that they only have permission to do what they need to do.</p><h3>Device Identity:</h3><p>Each device needs a unique identity. The most secure way to do this is with X.509 client certificates. Each device is provisioned with a unique certificate that it presents to AWS IoT Core to authenticate itself.</p><h3>Authorization:</h3><p>AWS IoT uses a policy-based system, similar to IAM, to control authorization. You attach a policy to a device's certificate that specifies what MQTT topics it is allowed to publish or subscribe to. This allows you to enforce least privilege; for example, a temperature sensor should only have permission to publish to the `sensors/temperature` topic and nothing else.</p>",
                            "image": "https://images.unsplash.com/photo-1544890225-2fde1e46f71b?w=800&h=400&fit-crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the most secure method for authenticating a large fleet of devices to AWS IoT Core?", "options": ["Using the same password for all devices", "Using a unique X.509 client certificate for each device", "Disabling authentication", "Using the AWS root account's access keys"], "correct": 1, "explanation": "Client certificates provide a strong, unique, and scalable identity mechanism for IoT devices." },
                        { "id": 2, "question": "In AWS IoT, policies attached to a device's identity are used to control what?", "options": ["The device's firmware version", "The MQTT topics the device is allowed to publish and subscribe to", "The physical location of the device", "The device's network speed"], "correct": 1, "explanation": "These policies are the authorization mechanism for the MQTT message broker, ensuring a device can only send and receive data from its designated topics." }
                    ]
                }
            },
            {
                "id": "lesson-38-ml-security",
                "title": "Lesson 38: Machine Learning Security",
                "duration": "120 min",
                "objectives": [
                    "Secure a data science environment using Amazon SageMaker",
                    "Protect machine learning models from theft or tampering",
                    "Secure the data pipelines used for training and inference"
                ],
                "content": {
                    "overview": "Machine learning workloads have unique security requirements, from protecting sensitive training data to securing the valuable trained models themselves. This lesson covers the best practices for securing ML workloads using Amazon SageMaker.",
                    "sections": [
                        {
                            "title": "SageMaker Security Configuration",
                            "content": "<p>Amazon SageMaker is a fully managed service for building, training, and deploying ML models. It has several built-in security features.</p><h3>Securing the Environment:</h3><ul><li><strong>Network Isolation:</strong> You can configure SageMaker Studio and training jobs to run within your VPC, providing network-level isolation.</li><li><strong>IAM Roles:</strong> All SageMaker activities are governed by IAM. The 'SageMaker execution role' must be scoped down to grant least-privilege access to the S3 buckets containing training data and model artifacts.</li><li><strong>Encryption:</strong> All data, including training data in S3, model artifacts, and the storage volumes on training instances, can be encrypted using KMS.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1620712943543-959bab121695?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the primary mechanism for controlling a SageMaker notebook's access to resources like S3?", "options": ["A security group", "Its name", "The IAM execution role attached to the notebook instance", "The version of Python it is using"], "correct": 2, "explanation": "Like most AWS services, the IAM role is the foundational security control for SageMaker permissions." }
                    ]
                }
            },
            {
                "id": "lesson-39-big-data-security",
                "title": "Lesson 39: Big Data Security",
                "duration": "120 min",
                "objectives": [
                    "Secure Amazon EMR clusters using Kerberos and IAM",
                    "Implement data protection for an Amazon Redshift data warehouse",
                    "Secure a data lake built on Amazon S3"
                ],
                "content": {
                    "overview": "Big data and analytics platforms handle massive volumes of potentially sensitive information. This lesson covers the security controls for AWS's main big data services, including EMR for data processing and Redshift for data warehousing.",
                    "sections": [
                        {
                            "title": "EMR and Redshift Security",
                            "content": "<ul><li><strong>Amazon EMR:</strong> EMR is a managed cluster platform for running big data frameworks like Apache Spark and Hadoop. Security involves securing the cluster's EC2 instances with security groups, enabling at-rest and in-transit encryption, and using Kerberos for strong authentication within the cluster.</li><li><strong>Amazon Redshift:</strong> Redshift is a petabyte-scale data warehouse. Security focuses on network isolation (running the cluster in a VPC), encrypting the cluster's data at rest, enforcing SSL for all client connections, and managing database user permissions within Redshift itself.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "To secure an Amazon EMR cluster, which authentication protocol is commonly used for strong authentication within the Hadoop ecosystem?", "options": ["HTTP Basic Auth", "Kerberos", "API Keys", "Passwords stored in a text file"], "correct": 1, "explanation": "Kerberos is the industry standard for strong authentication in distributed big data systems like Hadoop and is natively supported by Amazon EMR." }
                    ]
                }
            },
            {
                "id": "lesson-40-edge-cdn-security",
                "title": "Lesson 40: Edge and CDN Security",
                "duration": "120 min",
                "objectives": [
                    "Use Amazon CloudFront to improve security and performance",
                    "Secure serverless logic at the edge with Lambda@Edge",
                    "Restrict direct access to origin servers"
                ],
                "content": {
                    "overview": "Edge services bring your content and applications closer to your users. This lesson covers the security of AWS's Content Delivery Network (CDN), Amazon CloudFront, and its ability to run serverless code at the edge.",
                    "sections": [
                        {
                            "title": "CloudFront Security",
                            "content": "<p>Amazon CloudFront is a global CDN that securely delivers content with low latency and high transfer speeds.</p><h3>Security Benefits:</h3><ul><li><strong>Reduced Attack Surface:</strong> By caching your content at the edge, CloudFront absorbs much of the traffic that would otherwise hit your origin server. This can help mitigate DDoS attacks.</li><li><strong>Integration with WAF and Shield:</strong> CloudFront is a primary integration point for AWS WAF and Shield, allowing you to block attacks at the edge before they ever reach your network.</li><li><strong>Origin Access Identity (OAI):</strong> This is a critical feature for securing S3 origins. You can create a special CloudFront identity (an OAI) and modify your S3 bucket policy to *only* allow access from that OAI. This prevents users from bypassing CloudFront and accessing your S3 bucket directly using the S3 URL.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1544890225-2fde1e46f71b?w=800&h=400&fit-crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "What is the function of a CloudFront Origin Access Identity (OAI)?", "options": ["To act as the public URL for your content", "To provide a special identity that you can use in an S3 bucket policy to ensure users can only access your S3 content through CloudFront", "To speed up your origin server", "To scan your S3 buckets for malware"], "correct": 1, "explanation": "OAI is the key mechanism for locking down your S3 origin, preventing bypass and ensuring all access goes through your CloudFront distribution where it can be controlled and logged." }
                    ]
                }
            },
            {
                "id": "lesson-41-compliance-frameworks",
                "title": "Lesson 41: Compliance Frameworks",
                "duration": "120 min",
                "objectives": [
                    "Understand how to build an environment that is compliant with SOC 2, PCI DSS, and HIPAA",
                    "Leverage AWS services to meet specific compliance controls",
                    "Generate compliance evidence using AWS Artifact and Security Hub"
                ],
                "content": {
                    "overview": "Many organizations must comply with specific industry or regulatory frameworks. This lesson covers how to architect your AWS environment to meet the requirements of common frameworks like PCI DSS and HIPAA.",
                    "sections": [
                        {
                            "title": "Implementing PCI DSS in AWS",
                            "content": "<p>The Payment Card Industry Data Security Standard (PCI DSS) is required for any organization that handles credit card data. Building a compliant environment in AWS requires a combination of AWS services and your own secure configuration.</p><h3>Key AWS Services for PCI:</h3><ul><li><strong>Requirement 3 (Protect stored cardholder data):</strong> Use encryption at rest with KMS on EBS, RDS, and S3.</li><li><strong>Requirement 4 (Encrypt transmission):</strong> Use encryption in transit with TLS on ALBs and CloudFront.</li><li><strong>Requirement 10 (Track and monitor all access):</strong> Use AWS CloudTrail for a complete audit log of all activity.</li><li><strong>Requirement 11 (Regularly test):</strong> Use Amazon Inspector for vulnerability scanning.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1579873436214-a4b5683938a4?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "To get a copy of AWS's own compliance reports (like their SOC 2 report) to provide to your auditors, you would use which service?", "options": ["Amazon Inspector", "AWS Artifact", "Amazon GuardDuty", "Amazon S3"], "correct": 1, "explanation": "AWS Artifact is a self-service portal that provides on-demand access to AWS's compliance reports." }
                    ]
                }
            },
            {
                "id": "lesson-42-security-governance",
                "title": "Lesson 42: Security Governance",
                "duration": "120 min",
                "objectives": [
                    "Develop and enforce security policies in a cloud environment",
                    "Implement a risk management framework for AWS",
                    "Define and track security KPIs to measure program effectiveness"
                ],
                "content": {
                    "overview": "Governance is the framework of policies, processes, and controls that direct your security program. This lesson covers how to establish a strong security governance program for your AWS environment, ensuring that security is managed consistently and aligned with business goals.",
                    "sections": [
                        {
                            "title": "Continuous Compliance Monitoring",
                            "content": "<p>In the cloud, compliance is not a point-in-time activity. The environment is dynamic, and you need to continuously monitor your posture.</p><h3>Tools for Continuous Monitoring:</h3><ul><li><strong>AWS Config:</strong> The primary tool. Continuously evaluates your resource configurations against your defined rules.</li><li><strong>AWS Security Hub:</strong> Aggregates findings from Config and other services and provides a dashboard view of your compliance against standards like the CIS Benchmark.</li><li><strong>AWS Systems Manager:</strong> Can be used to scan for patch compliance and other configuration settings on your EC2 instances.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1542626991-cbc4e32524cc?w=800&h=400&fit-crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "Which two services are most essential for creating an automated, continuous compliance monitoring program in AWS?", "options": ["EC2 and S3", "AWS Config and AWS Security Hub", "Lambda and RDS", "Route 53 and CloudFront"], "correct": 1, "explanation": "AWS Config is the engine that checks for compliance, and Security Hub is the dashboard that aggregates and visualizes the results." }
                    ]
                }
            },
            {
                "id": "lesson-43-audit-assessment",
                "title": "Lesson 43: Audit and Assessment",
                "duration": "120 min",
                "objectives": [
                    "Prepare for and facilitate a third-party security audit",
                    "Understand the rules and procedures for conducting penetration testing in AWS",
                    "Automate evidence gathering for audits"
                ],
                "content": {
                    "overview": "Audits and assessments are a normal part of any mature security program. This lesson covers how to prepare for an audit in an AWS environment and the specific rules of engagement for performing penetration testing on your own cloud resources.",
                    "sections": [
                        {
                            "title": "Penetration Testing in AWS",
                            "content": "<p>AWS allows customers to conduct penetration tests on their own AWS infrastructure. However, there are specific rules you must follow.</p><h3>Key Rules:</h3><ul><li><strong>Permitted Services:</strong> You are generally allowed to test common services like EC2, RDS, and CloudFront.</li><li><strong>Prohibited Activities:</strong> You are prohibited from conducting tests that could impact other customers or the AWS infrastructure itself. This includes things like DoS attacks, DNS zone walking, and testing instances you do not own. You should always review the latest AWS penetration testing policy.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1614064548237-02f8f17374b2?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "Before conducting a penetration test of your AWS infrastructure, what should you do?", "options": ["Nothing, you can test anything you want", "Review the latest AWS policy on penetration testing to understand the rules of engagement", "Ask AWS support to turn off their security monitoring", "Notify the media"], "correct": 1, "explanation": "AWS has a clear and updated policy that outlines what is and is not permitted. Violating this policy can result in the suspension of your account." }
                    ]
                }
            },
            {
                "id": "lesson-44-bc-security",
                "title": "Lesson 44: Business Continuity Security",
                "duration": "120 min",
                "objectives": [
                    "Integrate security into your disaster recovery (DR) plans",
                    "Securely replicate data and infrastructure across regions",
                    "Incorporate security checks into recovery testing procedures"
                ],
                "content": {
                    "overview": "Your disaster recovery plan needs to be secure. This lesson focuses on the intersection of business continuity and security, ensuring that when you fail over to your DR site, you are not failing over to an insecure environment.",
                    "sections": [
                        {
                            "title": "Security in Recovery Testing",
                            "content": "<p>When you conduct a DR test, it's not enough to just validate that you can bring your systems back online. You must also validate that they come back online *securely*.</p><h3>DR Test Security Checks:</h3><ul><li>After restoring from backup in the DR region, verify that all necessary security controls (like security groups, IAM roles, and encryption settings) were replicated and configured correctly.</li><li>Run a vulnerability scan on the recovered systems in the DR environment.</li><li>Ensure your logging and monitoring tools are functioning correctly in the DR region and that your security team has visibility.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1517048676732-d65bc937f952?w=800&h=400&fit-crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "Why is it important to include security checks in your disaster recovery testing?", "options": ["It is not important", "To ensure that your recovered environment is as secure as your production environment", "To make the DR test take longer", "To generate more alerts"], "correct": 1, "explanation": "A successful recovery is one that brings the business back online securely. Your DR plan and tests must explicitly include security validation steps." }
                    ]
                }
            },
            {
                "id": "lesson-45-hybrid-cloud-security",
                "title": "Lesson 45: Hybrid Cloud Security",
                "duration": "120 min",
                "objectives": [
                    "Securely connect on-premises data centers to AWS",
                    "Understand the security of AWS Direct Connect and VPN",
                    "Implement a hybrid identity management strategy",
                    "Extend your security monitoring to cover a hybrid environment"
                ],
                "content": {
                    "overview": "Many organizations operate in a hybrid model, with resources both on-premises and in the AWS cloud. This lesson covers how to securely connect these two environments and extend your security controls across them.",
                    "sections": [
                        {
                            "title": "Secure Connectivity",
                            "content": "<p>There are two primary ways to securely connect your on-premises datacenter to your VPC.</p><ul><li><strong>AWS Site-to-Site VPN:</strong> Creates an encrypted, IPsec VPN tunnel over the public internet between your on-premises network and your VPC. This is a fast and cost-effective way to establish a secure connection.</li><li><strong>AWS Direct Connect:</strong> Provides a dedicated, private, physical network connection from your datacenter to AWS. This offers higher and more consistent bandwidth than a VPN, and the traffic does not traverse the public internet. For the highest security, you can use MACsec encryption over your Direct Connect link.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1542744173-8e7e53415bb0?w=800&h=400&fit-crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "Which AWS service provides a dedicated, private physical connection between your on-premises datacenter and AWS?", "options": ["AWS Site-to-Site VPN", "The internet", "AWS Direct Connect", "Amazon EC2"], "correct": 2, "explanation": "Direct Connect is the service for establishing a private, high-bandwidth connection for hybrid cloud scenarios." }
                    ]
                }
            },
            {
                "id": "lesson-46-devsecops",
                "title": "Lesson 46: DevSecOps in AWS",
                "duration": "120 min",
                "objectives": [
                    "Integrate security into your CI/CD pipeline",
                    "Automate security testing for code and infrastructure",
                    "Use AWS services like CodePipeline, CodeBuild, and CodeDeploy securely"
                ],
                "content": {
                    "overview": "DevSecOps is a culture and a set of practices that aims to bake security into every phase of the software development lifecycle. This lesson covers how to implement DevSecOps principles in an AWS environment using the AWS developer tools.",
                    "sections": [
                       {
  "title": "CI/CD Pipeline Security",
  "content": "<p>Your CI/CD pipeline automates how your code gets from a developer's laptop to production. It is a critical piece of infrastructure and must be secured.</p><h3>Securing the Pipeline:</h3><ul><li><strong>Source Stage (e.g., CodeCommit):</strong> Protect your source code repositories with fine-grained IAM policies. Enforce MFA for developers.</li><li><strong>Build Stage (e.g., CodeBuild):</strong> Integrate automated security testing into your build process. This is where you would add steps to perform:<ul><li><strong>SAST (Static Application Security Testing):</strong> Scan your source code for vulnerabilities.</li><li><strong>SCA (Software Composition Analysis):</strong> Scan for known vulnerabilities in your third-party libraries and dependencies.</li><li><strong>IaC Scanning:</strong> Scan your CloudFormation templates for security misconfigurations.</li></ul>If any of these scans find a critical issue, the build should fail.</li><li><strong>Deploy Stage (e.g., CodeDeploy):</strong> Use IAM roles with least privilege for your deployment service to ensure it only has permission to deploy to the correct environment.</li></ul>",
  "image": "https://images.unsplash.com/photo-1498050108023-c5249f4df085?w=800&h=400&fit=crop"
}

                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "The practice of integrating automated security checks, like source code scanning, directly into the build stage of a CI/CD pipeline is a core component of:", "options": ["Incident Response", "DevSecOps", "Billing management", "Physical security"], "correct": 1, "explanation": "DevSecOps is all about making security an automated, integrated part of the development workflow." }
                    ]
                }
            },
            {
                "id": "lesson-47-security-analytics",
                "title": "Lesson 47: Security Analytics and Intelligence",
                "duration": "120 min",
                "objectives": [
                    "Integrate AWS logs with a SIEM platform",
                    "Build a security data lake on S3",
                    "Use Amazon Athena to query security logs directly in S3"
                ],
                "content": {
                    "overview": "For large-scale security operations, you need a centralized platform for security analytics. This lesson covers how to build a security data lake on AWS and integrate your AWS logs with SIEM platforms for advanced analysis and threat hunting.",
                    "sections": [
                        {
                            "title": "Security Data Lake",
                            "content": "<p>A security data lake is a centralized repository where you can store all your security logs and telemetry data in a structured, queryable format.</p><h3>Architecture:</h3><ul><li><strong>Storage:</strong> The foundation is Amazon S3. You configure all your log sources (CloudTrail, VPC Flow Logs, application logs, etc.) to deliver their logs to a central S3 bucket.</li><li><strong>Querying:</strong> You can then use Amazon Athena to run interactive SQL queries directly on the log files in S3. This allows you to perform complex analysis and threat hunting without needing to ingest all the data into a traditional SIEM first.</li><li><strong>Visualization:</strong> Tools like Amazon QuickSight can then be used to build dashboards and visualizations on top of your Athena queries.</li></ul>",
                            "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop"
                        }
                    ]
                },
                "codeExamples": [
                    {
                        "title": "Example Athena Query on CloudTrail Logs",
                        "language": "sql",
                        "code": "SELECT \n    eventname, \n    awsregion, \n    useridentity.username\nFROM \n    cloudtrail_logs\nWHERE \n    eventname = 'ConsoleLogin'\nAND \n    responseelements LIKE '%Failure%'\nLIMIT 10;"
                    }
                ],
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "In a security data lake architecture on AWS, which service is typically used as the central, scalable storage layer?", "options": ["RDS", "Amazon S3", "EBS", "DynamoDB"], "correct": 1, "explanation": "S3's scalability, durability, and low cost make it the ideal foundation for a security data lake." },
                        { "id": 2, "question": "Which service allows you to run interactive SQL queries directly on log files stored in S3?", "options": ["Amazon RDS", "Amazon GuardDuty", "Amazon Athena", "Amazon EC2"], "correct": 2, "explanation": "Amazon Athena is a serverless query engine specifically designed for this purpose, enabling powerful ad-hoc analysis of large datasets in S3." }
                    ]
                }
            },
            {
                "id": "lesson-48-ir-automation",
                "title": "Lesson 48: Incident Response Automation",
                "duration": "120 min",
                "objectives": [
                    "Develop automated response workflows for common security events",
                    "Integrate AWS security services with SOAR platforms",
                    "Automate incident documentation and evidence gathering"
                ],
                "content": {
                    "overview": "Building on the foundation of event-driven security, this lesson provides a deeper look into creating sophisticated incident response automation. The goal is to develop playbooks that can automatically investigate, contain, and even resolve common security incidents, dramatically reducing your Mean Time to Respond (MTTR).",
                    "sections": [
                        {
                            "title": "Security Playbook Development",
                            "content": "<p>An automated IR playbook is a sequence of steps that codifies your response process for a specific type of finding.</p><h3>Example: Unprotected Port Playbook</h3><ol><li><strong>Trigger (Event):</strong> A GuardDuty finding `Recon:EC2/PortProbeUnprotectedPort` is generated.</li><li><strong>Enrichment (Automation):</strong> An EventBridge rule triggers a Lambda function. The function gets the instance ID from the finding. It checks the instance's tags to see who the owner is and if it's a production system.</li><li><strong>Notification (Automation):</strong> The function sends a detailed alert to the security team's chat channel with all the enriched information.</li><li><strong>Remediation (Automation):</strong> If the instance has a tag `auto-remediate=true`, the function will automatically create a new version of the instance's security group with the exposed port rule removed and apply it to the instance.</li><li><strong>Documentation (Automation):</strong> The function logs its findings and the actions it took to a central security case management system.</li></ol>",
                            "image": "https://images.unsplash.com/photo-1542708944-9721d234a413?w=800&h=400&fit-crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "The primary goal of incident response automation is to reduce which key metric?", "options": ["The number of IAM users", "The cost of S3 storage", "Mean Time to Respond (MTTR)", "The number of security tools"], "correct": 2, "explanation": "By automating the manual steps of investigation and containment, automation can reduce the time it takes to respond to an incident from hours to minutes or even seconds." }
                    ]
                }
            },
            {
                "id": "lesson-49-enterprise-security-architecture",
                "title": "Lesson 49: Enterprise Security Architecture",
                "duration": "120 min",
                "objectives": [
                    "Design a large-scale, global security architecture on AWS",
                    "Implement a defense-in-depth strategy for a complex application",
                    "Establish a Security Center of Excellence (CoE) within your organization"
                ],
                "content": {
                    "overview": "This lesson brings together all the concepts of the course to discuss how they apply to designing a holistic security architecture for a large enterprise. We will cover high-level strategy, organizational structure, and the creation of a Security Center of Excellence.",
                    "sections": [
                        {
                            "title": "Security Center of Excellence (CoE)",
                            "content": "<p>A Security CoE is a central team of experts that is responsible for establishing best practices, creating reusable security patterns, and providing guidance and consultation to the application development teams throughout the organization. Their goal is not to be a gatekeeper, but an enabler, making it easy for developers to build secure applications by providing them with secure-by-default tools and architectures.</p>",
                            "image": "https://images.unsplash.com/photo-1521791136064-7986c2920216?w=800&h=400&fit-crop"
                        }
                    ]
                },
                "quiz": {
                    "passingScore": 80,
                    "questions": [
                        { "id": 1, "question": "The purpose of a Security Center of Excellence (CoE) is to:", "options": ["Manually review every line of code", "Act as a central team of experts to create and evangelize security best practices and patterns across the organization", "Handle all incident response", "Only manage the security budget"], "correct": 1, "explanation": "A CoE helps to scale security in a large organization by empowering development teams with the tools and knowledge to build securely themselves." }
                    ]
                }
            },
            {
                "id": "lesson-50-final-capstone-project",
                "title": "Lesson 50: Final Capstone Project",
                "duration": "240 min",
                "objectives": [
                    "Design and implement a complete, end-to-end secure AWS solution for a realistic scenario",
                    "Integrate multiple services across networking, data protection, and monitoring",
                    "Assess and test the security of your deployed architecture",
                    "Produce a full documentation and handover package for your solution"
                ],
                "content": {
                    "overview": "The final capstone project requires you to act as the lead security architect for a fictional company and build a secure, well-architected solution on AWS from the ground up. This project will test your mastery of all the concepts covered in this course in a practical, hands-on manner.",
                    "sections": [
                      {
  "title": "The Capstone Scenario",
  "content": "<p><strong>The Task:</strong> A startup company needs you to design and build the cloud infrastructure for their new three-tier web application. Their primary concerns are security and compliance.</p><h3>Your Deliverables:</h3><ol><li><strong>Architectural Diagram:</strong> A detailed diagram of your proposed secure architecture.</li><li><strong>Infrastructure as Code:</strong> A set of CloudFormation templates that will deploy your entire solution.</li><li><strong>Security Controls Implementation:</strong> Your solution must implement key security controls, including (but not limited to):<ul><li>A secure, multi-tier VPC with public and private subnets.</li><li>Least-privilege IAM roles for all compute resources.</li><li>Encryption at rest and in transit.</li><li>A WAF to protect the web application.</li><li>Centralized logging with CloudTrail.</li><li>Threat detection with GuardDuty.</li><li>Continuous compliance checking with AWS Config.</li></ul></li><li><strong>Documentation:</strong> A handover document explaining your architecture and its security features.</li></ol>",
  "image": "https://images.unsplash.com/photo-1498050108023-c5249f4df085?w=800&h=400&fit=crop"
}

                    ]
                },
                "quiz": {
                    "passingScore": 100,
                    "questions": [
                        { "id": 1, "question": "The final capstone project assesses your ability to:", "options": ["Answer multiple choice questions", "Write a single IAM policy", "Synthesize the knowledge from the entire course to design, build, and document a real-world secure cloud solution", "Perform a single command in the AWS CLI"], "correct": 2, "explanation": "This project is the ultimate test, requiring you to apply your knowledge in a practical and holistic way to solve a complex security architecture problem." }
                    ]
                }
            }
        ]
    }
      // =====================================================
      // GLOBAL VARIABLES
      // =====================================================
      let currentUser = null;
      let currentLessonIndex = 0;
      let courseProgress = {};
      let userStats = {};
      let quizState = {
        currentQuestion: 0,
        answers: [],
        score: 0,
        isComplete: false,
      };

      // Enhanced session tracking
      let courseSession = {
        startTime: null,
        totalStudyTime: 0,
        lessonsStarted: 0,
        lessonsCompleted: 0,
        pageLoadTime: new Date(),
        interactionCount: 0,
        lastActivityTime: new Date(),
      };

      // Music Player Variables
      let audioPlayer = new Audio();

      // Achievement notification system
      let notificationQueue = [];
      let isShowingNotification = false;

      // =====================================================
      // INITIALIZATION
      // =====================================================
      document.addEventListener("DOMContentLoaded", async () => {
        try {
          showLoadingScreen();
          await checkAuth();

          if (currentUser) {
            // Initialize session tracking
            startCourseSession();

            // Load course data and progress
            await loadCourseData();
            await loadUserProfile();
            await loadProgress();

            // Initialize UI
            initializeEventListeners();
            renderSidebar();
            loadLesson(currentLessonIndex);

            // Initialize additional features
            initMusicPlayer();
            addMusicIndicator();
            initializeActivityTracking();

            hideLoadingScreen();
          } else {
            openAuthModal();
          }
        } catch (error) {
          console.error("Error initializing course:", error);
          hideLoadingScreen();
          showToast("Failed to initialize course system", "error");
        }
      });

      // =====================================================
      // AUTHENTICATION SYSTEM
      // =====================================================
      async function checkAuth() {
        try {
          const {
            data: { session },
            error,
          } = await supabase.auth.getSession();

          if (error) {
            console.error("Auth error:", error);
            currentUser = null;
            openAuthModal();
            return;
          }

          if (!session) {
            currentUser = null;
            openAuthModal();
            return;
          }

          currentUser = session.user;
          updateUIWithUser();
        } catch (error) {
          console.error("Error checking auth:", error);
          currentUser = null;
          openAuthModal();
        }
      }

      function updateUIWithUser() {
        if (!currentUser) return;

        const name =
          currentUser.user_metadata?.full_name ||
          currentUser.email.split("@")[0];
        const userElements = document.querySelectorAll("[data-user-name]");
        userElements.forEach((el) => (el.textContent = name));
      }

      // =====================================================
      // USER PROFILE & STATS MANAGEMENT
      // =====================================================
      async function loadUserProfile() {
        try {
          // ðŸ” Step 1: Try to fetch existing profile
          const { data: profile, error } = await supabase
            .from("profiles")
            .select("*")
            .eq("id", currentUser.id)
            .single();

          if (error && error.code !== "PGRST116") {
            throw error;
          }

          if (!profile) {
            // ðŸ†• Step 2: Create new profile if missing
            await createUserProfile();
          } else {
            // âœ… Step 3: Use existing profile
            userStats = profile;
            await updateLastActivity();
          }
        } catch (error) {
          console.error("âŒ Error loading user profile:", error);
          showToast("Failed to load user profile", "error");
        }
      }
      async function createUserProfile() {
        try {
          const newProfile = {
            id: currentUser.id,
            full_name: currentUser.user_metadata?.full_name || "",
            email: currentUser.email,
            level: "Script Kiddie",
            total_points: 0,
            completed_courses: 0,
            current_streak: 0,
            total_certificates: 0,
            total_achievements: 0,
            sections_visited: 0,
            bonus_points: 0,
            in_progress_courses: 0,
            settings_changed: 0,
            midnight_sessions: 0,
            early_sessions: 0,
            weekend_sessions: 0,
            last_activity: new Date().toISOString(),
            created_at: new Date().toISOString(),
          };

          const { error } = await supabase
            .from("profiles")
            .insert([newProfile]);

          if (!error) {
            userStats = newProfile;
            // Award first login achievement
            setTimeout(() => checkAndUnlockAchievement("first_login"), 1000);
          }
        } catch (error) {
          console.error("Error creating user profile:", error);
        }
      }

      async function updateLastActivity() {
        try {
          const now = new Date();

          // Update activity tracking
          courseSession.lastActivityTime = now;

          // Update database
          await supabase
            .from("profiles")
            .update({
              last_activity: now.toISOString(),
            })
            .eq("id", currentUser.id);

          // Check time-based achievements
          await checkTimeBasedAchievements(now);
        } catch (error) {
          console.error("Error updating last activity:", error);
        }
      }

      // =====================================================
      // COURSE SESSION MANAGEMENT
      // =====================================================
      function startCourseSession() {
        courseSession.startTime = new Date();
        courseSession.pageLoadTime = new Date();

        logUserActivity("course_session_start", {
          course_id: COURSE_DATA.id,
          course_title: COURSE_DATA.title,
          user_agent: navigator.userAgent,
          screen_resolution: `${screen.width}x${screen.height}`,
        });

        // Check daily streak
        checkDailyStreak();
      }

      function initializeActivityTracking() {
        // Track page focus/blur for accurate study time
        document.addEventListener("visibilitychange", handleVisibilityChange);

        // Track user interactions
        ["click", "keydown", "scroll", "mousemove"].forEach((event) => {
          document.addEventListener(event, trackUserInteraction, {
            passive: true,
          });
        });

        // Periodic activity updates
        setInterval(updateStudyTime, 60000); // Every minute

        // Save session data before page unload
        window.addEventListener("beforeunload", saveSessionData);
      }

      function handleVisibilityChange() {
        if (document.hidden) {
          courseSession.lastActivityTime = new Date();
        } else {
          // Page became visible again - update activity
          updateLastActivity();
        }
      }

      function trackUserInteraction() {
        courseSession.interactionCount++;
        courseSession.lastActivityTime = new Date();

        // Throttle activity updates
        if (courseSession.interactionCount % 50 === 0) {
          updateLastActivity();
        }
      }

      function updateStudyTime() {
        if (!courseSession.startTime || document.hidden) return;

        const now = new Date();
        const sessionDuration = now - courseSession.startTime;
        courseSession.totalStudyTime = Math.floor(sessionDuration / 1000 / 60); // in minutes

        // Update progress with study time
        saveProgress();
      }

      function saveSessionData() {
        if (!currentUser || !courseSession.startTime) return;

        const sessionData = {
          user_id: currentUser.id,
          course_id: COURSE_DATA.id,
          session_duration: courseSession.totalStudyTime,
          lessons_viewed: courseSession.lessonsStarted,
          lessons_completed: courseSession.lessonsCompleted,
          interactions: courseSession.interactionCount,
          session_date: courseSession.startTime.toISOString().split("T")[0],
        };

        // Store in localStorage as backup
        localStorage.setItem(
          "course_session_backup",
          JSON.stringify(sessionData)
        );

        // Try to save to database
        logUserActivity("course_session_end", sessionData);
      }

      // =====================================================
      // COURSE DATA & PROGRESS MANAGEMENT
      // =====================================================
      async function loadCourseData() {
        try {
          // Update course info in UI
          document.getElementById("courseTitle").textContent =
            COURSE_DATA.title;
          document.getElementById("totalLessons").textContent =
            COURSE_DATA.lessons.length;

          // Log course access
          logUserActivity("course_access", {
            course_id: COURSE_DATA.id,
            course_title: COURSE_DATA.title,
          });
        } catch (error) {
          console.error("Error loading course data:", error);
        }
      }

      async function loadProgress() {
        try {
          // Get existing progress from database
          const { data, error } = await supabase
            .from("course_progress")
            .select("*")
            .eq("user_id", currentUser.id)
            .eq("course_id", COURSE_DATA.id)
            .single();

          if (error && error.code !== "PGRST116") {
            throw error;
          }

          if (data) {
            courseProgress = JSON.parse(data.lesson_progress || "{}");
            currentLessonIndex = data.current_lesson || 0;

            // Update session tracking
            courseSession.lessonsStarted = Object.keys(courseProgress).length;
            courseSession.lessonsCompleted = Object.values(
              courseProgress
            ).filter((p) => p.completed).length;
          } else {
            // Initialize new progress
            courseProgress = {};
            currentLessonIndex = 0;
            await saveProgress();

            // Award first course start achievement
            await checkAndUnlockAchievement("first_course_start");
          }

          updateProgressDisplay();
        } catch (error) {
          console.error("Error loading progress:", error);
          showToast("Failed to load progress", "error");
        }
      }

      async function saveProgress() {
        try {
          if (!currentUser) return;

          const now = new Date();
          const progressData = {
            user_id: currentUser.id,
            course_id: COURSE_DATA.id,
            course_title: COURSE_DATA.title,
            current_lesson: currentLessonIndex,
            lesson_progress: JSON.stringify(courseProgress),
            progress: calculateOverallProgress(),
            lessons_completed: getCompletedLessonsCount(),
            lessons_started: Object.keys(courseProgress).length,
            study_time_minutes: courseSession.totalStudyTime,
            last_accessed: now.toISOString(),
            updated_at: now.toISOString(),
          };

          // Upsert progress
          const { error } = await supabase
            .from("course_progress")
            .upsert([progressData]);

          if (error) throw error;

          // Update user stats
          await updateUserStats();

          updateProgressDisplay();
        } catch (error) {
          console.error("Error saving progress:", error);
          showToast("Failed to save progress", "error");
        }
      }

      async function updateUserStats() {
        try {
          // Get all course progress for this user
          const { data: allProgress, error } = await supabase
            .from("course_progress")
            .select("progress, course_id, study_time_minutes")
            .eq("user_id", currentUser.id);

          if (error) throw error;

          // Calculate stats
          const completedCourses =
            allProgress?.filter((p) => p.progress >= 100).length || 0;
          const inProgressCourses =
            allProgress?.filter((p) => p.progress > 0 && p.progress < 100)
              .length || 0;
          const totalStudyTime =
            allProgress?.reduce(
              (sum, p) => sum + (p.study_time_minutes || 0),
              0
            ) || 0;

          // Calculate points (500 per completed course + achievement points)
          const coursePoints = completedCourses * 500;
          const bonusPoints = userStats.bonus_points || 0;
          const totalPoints = coursePoints + bonusPoints;

          // Update profile
          const updateData = {
            completed_courses: completedCourses,
            in_progress_courses: inProgressCourses,
            total_points: totalPoints,
            total_study_time: totalStudyTime,
            last_activity: new Date().toISOString(),
          };

          const { error: updateError } = await supabase
            .from("profiles")
            .update(updateData)
            .eq("id", currentUser.id);

          if (updateError) throw updateError;

          // Update local stats
          Object.assign(userStats, updateData);
        } catch (error) {
          console.error("Error updating user stats:", error);
        }
      }

      function calculateOverallProgress() {
        const completedLessons = getCompletedLessonsCount();
        return Math.round(
          (completedLessons / COURSE_DATA.lessons.length) * 100
        );
      }

      function getCompletedLessonsCount() {
        return Object.values(courseProgress).filter(
          (lesson) => lesson.completed
        ).length;
      }

      function updateProgressDisplay() {
        const completedCount = getCompletedLessonsCount();
        const progressPercent = calculateOverallProgress();

        // Update UI elements
        const elements = {
          completedLessons: completedCount,
          courseProgressPercent: `${progressPercent}%`,
        };

        Object.entries(elements).forEach(([id, value]) => {
          const element = document.getElementById(id);
          if (element) element.textContent = value;
        });

        // Update progress bar
        const progressBar = document.getElementById("courseProgressFill");
        if (progressBar) progressBar.style.width = `${progressPercent}%`;
      }

      // =====================================================
      // LESSON MANAGEMENT
      // =====================================================
      function loadLesson(index) {
        if (index < 0 || index >= COURSE_DATA.lessons.length) return;

        const lesson = COURSE_DATA.lessons[index];
        currentLessonIndex = index;

        // Mark lesson as started and track activity
        if (!courseProgress[lesson.id]) {
          courseProgress[lesson.id] = {
            started: true,
            completed: false,
            startedAt: new Date().toISOString(),
            timeSpent: 0,
          };

          courseSession.lessonsStarted++;
          saveProgress();

          // Log lesson start
          logUserActivity("lesson_start", {
            lesson_id: lesson.id,
            lesson_title: lesson.title,
            lesson_index: index,
          });
        }

        // Update lesson start time for time tracking
        courseProgress[lesson.id].currentSessionStart = new Date();

        // Update sidebar and navigation
        renderSidebar();
        updateNavigationButtons();

        // Update header info
        updateLessonHeader(lesson, index);

        // Render lesson content
        renderLessonContent(lesson);

        // Smooth scroll and animations
        window.scrollTo({ top: 0, behavior: "smooth" });
        document.getElementById("contentBody").scrollTop = 0;

        const contentBody = document.getElementById("contentBody");
        contentBody.classList.add("fade-in");
        setTimeout(() => contentBody.classList.remove("fade-in"), 500);

        // Check lesson-based achievements
        checkLessonAchievements(index + 1);
      }

      function updateLessonHeader(lesson, index) {
        const elements = {
          currentLessonNumber: index + 1,
          currentLessonTitle: lesson.title,
          navInfo: `Lesson ${index + 1} of ${COURSE_DATA.lessons.length}`,
        };

        Object.entries(elements).forEach(([id, value]) => {
          const element = document.getElementById(id);
          if (element) element.textContent = value;
        });
      }

      function renderSidebar() {
        const lessonNav = document.getElementById("lessonNav");
        if (!lessonNav) return;

        lessonNav.innerHTML = "";

        COURSE_DATA.lessons.forEach((lesson, index) => {
          const lessonItem = document.createElement("div");
          lessonItem.className = "lesson-item";

          // Determine lesson status
          const lessonProgress = courseProgress[lesson.id];
          const isCompleted = lessonProgress?.completed || false;
          const isInProgress = lessonProgress?.started || false;
          const isLocked = !isCompleted && !canAccessLesson(index);
          const isActive = index === currentLessonIndex;

          // Apply status classes
          if (isCompleted) lessonItem.classList.add("completed");
          if (isLocked) lessonItem.classList.add("locked");
          if (isActive) lessonItem.classList.add("active");

          // Determine status display
          let statusClass = "not-started";
          let statusIcon = index + 1;

          if (isCompleted) {
            statusClass = "completed";
            statusIcon = "âœ“";
          } else if (isInProgress) {
            statusClass = "in-progress";
            statusIcon = "â—";
          }

          // Create lesson item HTML
          lessonItem.innerHTML = `
            <div class="lesson-status ${statusClass}">${statusIcon}</div>
            <div class="lesson-info">
                <div class="lesson-title">${lesson.title}</div>
                <div class="lesson-meta">
                    ${
                      isCompleted
                        ? "Completed"
                        : isInProgress
                        ? "In Progress"
                        : isLocked
                        ? "Locked"
                        : "Not Started"
                    }
                </div>
            </div>
            <div class="lesson-duration">${lesson.duration}</div>
        `;

          // Add click handler if not locked
          if (!isLocked) {
            lessonItem.addEventListener("click", () => {
              if (index !== currentLessonIndex) {
                // Track lesson time before switching
                trackLessonTime();

                currentLessonIndex = index;
                loadLesson(index);
                closeSidebar();
              }
            });
          }

          lessonNav.appendChild(lessonItem);
        });
      }

      function canAccessLesson(index) {
        if (index === 0) return true; // First lesson always accessible

        // Can access if previous lesson is completed
        const previousLessonId = COURSE_DATA.lessons[index - 1].id;
        return courseProgress[previousLessonId]?.completed || false;
      }

      function trackLessonTime() {
        const currentLesson = COURSE_DATA.lessons[currentLessonIndex];
        const lessonProgress = courseProgress[currentLesson.id];

        if (lessonProgress?.currentSessionStart) {
          const sessionTime = Math.floor(
            (new Date() - new Date(lessonProgress.currentSessionStart)) /
              1000 /
              60
          );
          lessonProgress.timeSpent =
            (lessonProgress.timeSpent || 0) + sessionTime;
          delete lessonProgress.currentSessionStart;
        }
      }

      // =====================================================
      // LESSON CONTENT RENDERING
      // =====================================================
      function renderLessonContent(lesson) {
        const contentContainer = document.getElementById("lessonContent");
        if (!contentContainer) return;

        let contentHTML = `
        <div class="content-section">
            <h2>Learning Objectives</h2>
            <ul>
                ${lesson.objectives.map((obj) => `<li>${obj}</li>`).join("")}
            </ul>
        </div>
        
        <div class="content-section">
            <h2>Overview</h2>
            <p>${lesson.content.overview}</p>
        </div>
    `;

        // Render content sections
        lesson.content.sections.forEach((section) => {
          contentHTML += `
            <div class="content-section">
                <h2>${section.title}</h2>
                ${section.content}
                ${
                  section.image
                    ? `<img src="${section.image}" alt="${section.title}" class="content-image" loading="lazy">`
                    : ""
                }
            </div>
        `;
        });

        // Render code examples
        if (
          lesson.content.codeExamples &&
          lesson.content.codeExamples.length > 0
        ) {
          contentHTML += `<div class="content-section"><h2>Code Examples</h2></div>`;

          lesson.content.codeExamples.forEach((example, index) => {
            const codeId = `code-${lesson.id}-${index}`;
            contentHTML += `
                <div class="code-section">
                    <div class="code-header">
                        <span class="code-title">${example.title}</span>
                        <button class="copy-btn" onclick="copyCode('${codeId}')">
                            <i class="fas fa-copy"></i> Copy
                        </button>
                    </div>
                    <pre class="code-block"><code id="${codeId}" class="language-${
              example.language
            }">${escapeHtml(example.code)}</code></pre>
                </div>
            `;
          });
        }

        // Render quiz
        contentHTML += renderQuiz(lesson.quiz);

        contentContainer.innerHTML = contentHTML;

        // Highlight code syntax if Prism is available
        setTimeout(() => {
          if (window.Prism) {
            Prism.highlightAll();
          }
        }, 100);
      }

      // =====================================================
      // QUIZ SYSTEM
      // =====================================================
      function renderQuiz(quiz) {
        const currentLessonProgress =
          courseProgress[COURSE_DATA.lessons[currentLessonIndex].id];
        const isCompleted = currentLessonProgress?.completed || false;

        let quizHTML = `
        <div class="quiz-section" id="quizSection">
            <div class="quiz-header">
                <h2 class="quiz-title">
                    <i class="fas fa-clipboard-check"></i>
                    Knowledge Check
                </h2>
                <p class="quiz-info">
                    Complete this quiz with ${quiz.passingScore}% or higher to unlock the next lesson.
                </p>
            </div>
    `;

        if (isCompleted) {
          const savedScore = currentLessonProgress.quizScore || 0;
          quizHTML += `
            <div class="quiz-results show">
                <div class="quiz-score pass">${savedScore}%</div>
                <div class="quiz-message">
                    <strong>Lesson Completed!</strong><br>
                    You've successfully passed this lesson's quiz.
                </div>
            </div>
        `;
        } else {
          // Render quiz questions
          quiz.questions.forEach((question, qIndex) => {
            quizHTML += `
                <div class="quiz-question ${
                  qIndex === 0 ? "active" : ""
                }" data-question="${qIndex}">
                    <div class="question-header">
                        <span class="question-number">Question ${
                          qIndex + 1
                        }</span>
                        <span class="question-progress">${qIndex + 1}/${
              quiz.questions.length
            }</span>
                    </div>
                    <div class="question-text">${question.question}</div>
                    <div class="question-options">
                        ${question.options
                          .map(
                            (option, oIndex) => `
                            <div class="option" data-option="${oIndex}" onclick="selectOption(${qIndex}, ${oIndex})">
                                <span class="option-letter">${String.fromCharCode(
                                  65 + oIndex
                                )}</span>
                                <span class="option-text">${option}</span>
                            </div>
                        `
                          )
                          .join("")}
                    </div>
                </div>
            `;
          });

          quizHTML += `
            <div class="quiz-controls">
                <button class="btn btn-secondary" id="prevQuestionBtn" onclick="previousQuestion()" disabled>
                    <i class="fas fa-chevron-left"></i>
                    Previous
                </button>
                <div>
                    <button class="btn btn-secondary" id="nextQuestionBtn" onclick="nextQuestion()" disabled>
                        Next
                        <i class="fas fa-chevron-right"></i>
                    </button>
                    <button class="btn btn-primary" id="submitQuizBtn" onclick="submitQuiz()" style="display: none;">
                        <i class="fas fa-check"></i>
                        Submit Quiz
                    </button>
                </div>
            </div>

            <div class="quiz-results" id="quizResults">
                <div class="quiz-score" id="quizScore">0%</div>
                <div class="quiz-message" id="quizMessage"></div>
                <div class="quiz-actions">
                    <button class="btn btn-primary" id="continueBtn" onclick="completeLesson()" style="display: none;">
                        <i class="fas fa-arrow-right"></i>
                        Continue to Next Lesson
                    </button>
                    <button class="btn btn-secondary" onclick="retakeQuiz()">
                        <i class="fas fa-redo"></i>
                        Retake Quiz
                    </button>
                </div>
            </div>
        `;
        }

        quizHTML += "</div>";
        return quizHTML;
      }

      // Quiz interaction functions
      function selectOption(questionIndex, optionIndex) {
        // Clear previous selections
        document
          .querySelectorAll(`[data-question="${questionIndex}"] .option`)
          .forEach((opt) => {
            opt.classList.remove("selected");
          });

        // Select current option
        const selectedOption = document.querySelector(
          `[data-question="${questionIndex}"] [data-option="${optionIndex}"]`
        );
        selectedOption.classList.add("selected");

        // Store answer
        quizState.answers[questionIndex] = optionIndex;

        // Update navigation
        const isLastQuestion =
          questionIndex ===
          COURSE_DATA.lessons[currentLessonIndex].quiz.questions.length - 1;
        if (isLastQuestion) {
          document.getElementById("submitQuizBtn").style.display =
            "inline-flex";
          document.getElementById("nextQuestionBtn").style.display = "none";
        } else {
          document.getElementById("nextQuestionBtn").disabled = false;
        }
      }

      function nextQuestion() {
        const currentQuestionEl = document.querySelector(
          ".quiz-question.active"
        );
        const nextQuestionEl = currentQuestionEl.nextElementSibling;

        if (
          nextQuestionEl &&
          nextQuestionEl.classList.contains("quiz-question")
        ) {
          currentQuestionEl.classList.remove("active");
          nextQuestionEl.classList.add("active");
          quizState.currentQuestion++;
          updateQuizNavigation();
        }
      }

      function previousQuestion() {
        const currentQuestionEl = document.querySelector(
          ".quiz-question.active"
        );
        const prevQuestionEl = currentQuestionEl.previousElementSibling;

        if (
          prevQuestionEl &&
          prevQuestionEl.classList.contains("quiz-question")
        ) {
          currentQuestionEl.classList.remove("active");
          prevQuestionEl.classList.add("active");
          quizState.currentQuestion--;
          updateQuizNavigation();
        }
      }

      function updateQuizNavigation() {
        const totalQuestions =
          COURSE_DATA.lessons[currentLessonIndex].quiz.questions.length;
        const prevBtn = document.getElementById("prevQuestionBtn");
        const nextBtn = document.getElementById("nextQuestionBtn");
        const submitBtn = document.getElementById("submitQuizBtn");

        prevBtn.disabled = quizState.currentQuestion === 0;

        const hasAnswer =
          quizState.answers[quizState.currentQuestion] !== undefined;
        const isLastQuestion = quizState.currentQuestion === totalQuestions - 1;

        if (isLastQuestion) {
          nextBtn.style.display = "none";
          submitBtn.style.display = hasAnswer ? "inline-flex" : "none";
        } else {
          nextBtn.style.display = "inline-flex";
          nextBtn.disabled = !hasAnswer;
          submitBtn.style.display = "none";
        }
      }

      async function submitQuiz() {
        const lesson = COURSE_DATA.lessons[currentLessonIndex];
        const quiz = lesson.quiz;
        let correctAnswers = 0;

        // Hide questions and controls
        document
          .querySelectorAll(".quiz-question")
          .forEach((q) => (q.style.display = "none"));
        document.querySelector(".quiz-controls").style.display = "none";

        // Calculate score and highlight answers
        quiz.questions.forEach((question, index) => {
          const userAnswer = quizState.answers[index];
          const correctAnswer = question.correct;
          const isCorrect = userAnswer === correctAnswer;

          if (isCorrect) correctAnswers++;

          // Highlight answers
          const questionEl = document.querySelector(
            `[data-question="${index}"]`
          );
          const options = questionEl.querySelectorAll(".option");

          options[correctAnswer].classList.add("correct");
          if (userAnswer !== correctAnswer && userAnswer !== undefined) {
            options[userAnswer].classList.add("incorrect");
          }
        });

        const score = Math.round(
          (correctAnswers / quiz.questions.length) * 100
        );
        const passed = score >= quiz.passingScore;

        // Update quiz results UI
        const quizScore = document.getElementById("quizScore");
        const quizMessage = document.getElementById("quizMessage");
        const quizActions = document.querySelector(".quiz-actions");

        quizScore.textContent = `${score}%`;
        quizScore.className = `quiz-score ${passed ? "pass" : "fail"}`;

        if (passed) {
          quizMessage.innerHTML = `
            <strong>Congratulations!</strong><br>
            You passed with ${score}%. You can now proceed to the next lesson.
        `;

          quizActions.innerHTML = `
            <button class="btn btn-primary" onclick="completeLesson()">
                <i class="fas fa-arrow-right"></i>
                Continue to Next Lesson
            </button>
        `;

          // Mark lesson as completed
          await markLessonComplete(score);
        } else {
          quizMessage.innerHTML = `
            <strong>Not quite there yet.</strong><br>
            You scored ${score}%. You need ${quiz.passingScore}% to pass. Review the material and try again.
        `;

          quizActions.innerHTML = `
            <button class="btn btn-secondary" onclick="retakeQuiz()">
                <i class="fas fa-redo"></i>
                Retake Quiz
            </button>
        `;
        }

        document.getElementById("quizResults").classList.add("show");

        // Log quiz completion
        logUserActivity("quiz_completed", {
          lesson_id: lesson.id,
          lesson_title: lesson.title,
          score: score,
          passed: passed,
          attempts: (courseProgress[lesson.id]?.quizAttempts || 0) + 1,
        });

        // Scroll to results
        document
          .getElementById("quizResults")
          .scrollIntoView({ behavior: "smooth" });
      }

      function retakeQuiz() {
        // Reset quiz state
        quizState = {
          currentQuestion: 0,
          answers: [],
          score: 0,
          isComplete: false,
        };

        // Track quiz retry
        const lessonId = COURSE_DATA.lessons[currentLessonIndex].id;
        if (!courseProgress[lessonId]) courseProgress[lessonId] = {};
        courseProgress[lessonId].quizAttempts =
          (courseProgress[lessonId].quizAttempts || 0) + 1;

        // Reload lesson content
        loadLesson(currentLessonIndex);

        // Scroll to quiz
        setTimeout(() => {
          document
            .getElementById("quizSection")
            .scrollIntoView({ behavior: "smooth" });
        }, 500);
      }

      async function markLessonComplete(score) {
        const lesson = COURSE_DATA.lessons[currentLessonIndex];
        const lessonId = lesson.id;

        // Track lesson completion time
        trackLessonTime();

        // Update lesson progress
        courseProgress[lessonId] = {
          ...courseProgress[lessonId],
          completed: true,
          quizScore: score,
          completedAt: new Date().toISOString(),
          finalScore: score,
        };

        // Update session tracking
        courseSession.lessonsCompleted++;

        // Save progress to database
        await saveProgress();

        // Update UI
        renderSidebar();
        updateNavigationButtons();

        // Check various achievements
        await checkLessonCompletionAchievements();
        await checkPerfectScoreAchievements(score);
        await checkStudyTimeAchievements();

        // Log lesson completion
        logUserActivity("lesson_completed", {
          lesson_id: lessonId,
          lesson_title: lesson.title,
          final_score: score,
          time_spent: courseProgress[lessonId].timeSpent || 0,
          lesson_number: currentLessonIndex + 1,
        });

        showToast("Lesson completed successfully!", "success");
      }

      async function completeLesson() {
        if (currentLessonIndex < COURSE_DATA.lessons.length - 1) {
          // Move to next lesson
          currentLessonIndex++;
          loadLesson(currentLessonIndex);
        } else {
          // Course completion
          await completeCourse();
        }
      }

      async function completeCourse() {
        try {
          const completionTime = courseSession.totalStudyTime;

          // Update course progress to 100% completed
          await supabase
            .from("course_progress")
            .update({
              progress: 100,
              completed_at: new Date().toISOString(),
              completion_time_minutes: completionTime,
            })
            .eq("user_id", currentUser.id)
            .eq("course_id", COURSE_DATA.id);

          // Award course completion achievements
          await checkAndUnlockAchievement("course_completion_1");
          await checkSpeedCompletionAchievements(completionTime);
          await checkCourseStreakAchievements();

          // Update user stats
          await updateUserStats();

          // Show completion message
          showToast(
            "Congratulations! Course completed successfully!",
            "certificate"
          );

          // Log course completion
          logUserActivity("course_completed", {
            course_id: COURSE_DATA.id,
            course_title: COURSE_DATA.title,
            completion_time_minutes: completionTime,
            total_lessons: COURSE_DATA.lessons.length,
            average_quiz_score: calculateAverageQuizScore(),
          });

          // Redirect to dashboard after delay
          setTimeout(() => {
            window.location.href = "/dashboard.html";
          }, 3000);
        } catch (error) {
          console.error("Error completing course:", error);
          showToast("Error marking course as complete", "error");
        }
      }

      // =====================================================
      // ACHIEVEMENT INTEGRATION SYSTEM
      // =====================================================
      async function checkAndUnlockAchievement(
        achievementId,
        skipNotification = false
      ) {
        try {
          // Prevent duplicate checks
          const cacheKey = `achievement_${achievementId}_${currentUser.id}`;
          if (sessionStorage.getItem(cacheKey)) return false;

          // Check if already unlocked
          const { data: existing, error } = await supabase
            .from("user_achievements")
            .select("id")
            .eq("user_id", currentUser.id)
            .eq("achievement_id", achievementId)
            .single();

          if (existing) {
            sessionStorage.setItem(cacheKey, "true");
            return false;
          }

          // Award achievement
          const achievementData = {
            user_id: currentUser.id,
            achievement_id: achievementId,
            unlocked_at: new Date().toISOString(),
            points_awarded: getAchievementPoints(achievementId),
            context: "course_system",
          };

          const { data, error: insertError } = await supabase
            .from("user_achievements")
            .insert([achievementData])
            .select()
            .single();

          if (insertError) {
            if (insertError.code === "23505") return false; // Already exists
            throw insertError;
          }

          // Update user points
         await supabase.rpc('increment_user_stats', {
  user_id_param: currentUser.id,
  points_to_add: achievementData.points_awarded,
  achievements_to_add: 1
});

          // Cache and queue notification
          sessionStorage.setItem(cacheKey, "true");

          if (!skipNotification) {
            queueAchievementNotification({
              id: achievementId,
              name: getAchievementName(achievementId),
              description: getAchievementDescription(achievementId),
              points: achievementData.points_awarded,
              rarity: getAchievementRarity(achievementId),
              icon: getAchievementIcon(achievementId),
            });
          }

          return true;
        } catch (error) {
          console.error("Error unlocking achievement:", error);
          return false;
        }
      }

      // Helper functions for achievement data (replace with your actual achievement definitions)
      function getAchievementPoints(id) {
        const pointsMap = {
          first_course_start: 75,
          first_lesson: 100,
          course_completion_1: 500,
          perfect_score: 250,
          speed_demon: 750,
          marathon_learner: 500,
          night_owl: 200,
          early_bird: 200,
          weekend_warrior: 150,
          // Add more as needed
        };
        return pointsMap[id] || 100;
      }

      function getAchievementName(id) {
        const nameMap = {
          first_course_start: "Learning Initiated",
          first_lesson: "First Steps",
          course_completion_1: "Course Conqueror",
          perfect_score: "Perfectionist",
          speed_demon: "Speed Demon",
          // Add more as needed
        };
        return nameMap[id] || "Achievement Unlocked";
      }

      function getAchievementDescription(id) {
        const descMap = {
          first_course_start: "Start your first cybersecurity course",
          first_lesson: "Complete your first lesson",
          course_completion_1: "Complete your first course",
          perfect_score: "Score 100% on any quiz",
          speed_demon: "Complete a course in under 2 hours",
          // Add more as needed
        };
        return descMap[id] || "Achievement description";
      }

      function getAchievementRarity(id) {
        const rarityMap = {
          first_course_start: "common",
          first_lesson: "bronze",
          course_completion_1: "silver",
          perfect_score: "gold",
          speed_demon: "legendary",
          // Add more as needed
        };
        return rarityMap[id] || "common";
      }

      function getAchievementIcon(id) {
        const iconMap = {
          first_course_start: "fas fa-play",
          first_lesson: "fas fa-baby",
          course_completion_1: "fas fa-trophy",
          perfect_score: "fas fa-star",
          speed_demon: "fas fa-rocket",
          // Add more as needed
        };
        return iconMap[id] || "fas fa-award";
      }

      async function checkLessonAchievements(lessonNumber) {
        if (lessonNumber === 1) {
          await checkAndUnlockAchievement("first_lesson");
        }

        // Check if user has completed multiple lessons in one day
        const today = new Date().toISOString().split("T")[0];
        const todayCompletions = Object.values(courseProgress).filter(
          (p) => p.completed && p.completedAt?.startsWith(today)
        ).length;

        if (todayCompletions >= 3) {
          await checkAndUnlockAchievement("lesson_marathon");
        }
      }

      async function checkLessonCompletionAchievements() {
        const completedCount = getCompletedLessonsCount();

        // Lesson-based achievements
        const lessonMilestones = [1, 5, 10, 25, 50, 100];
        for (const milestone of lessonMilestones) {
          if (completedCount >= milestone) {
            await checkAndUnlockAchievement(`lessons_${milestone}`);
          }
        }

        // Course completion achievements
        if (completedCount === COURSE_DATA.lessons.length) {
          await checkAndUnlockAchievement("course_completion_1");

          // Check for additional course completion achievements
          const { data: allCourses } = await supabase
            .from("course_progress")
            .select("course_id")
            .eq("user_id", currentUser.id)
            .eq("progress", 100);

          const totalCompleted = allCourses?.length || 0;

          const courseMilestones = [1, 5, 10, 25];
          for (const milestone of courseMilestones) {
            if (totalCompleted >= milestone) {
              await checkAndUnlockAchievement(`course_completion_${milestone}`);
            }
          }
        }
      }

      async function checkPerfectScoreAchievements(score) {
        if (score === 100) {
          await checkAndUnlockAchievement("perfect_score");

          // Check for consecutive perfect scores
          const recentScores = Object.values(courseProgress)
            .filter((p) => p.completed && p.quizScore)
            .slice(-5) // Last 5 completed
            .map((p) => p.quizScore);

          if (
            recentScores.length >= 3 &&
            recentScores.every((s) => s === 100)
          ) {
            await checkAndUnlockAchievement("perfectionist_streak");
          }
        }
      }

      async function checkSpeedCompletionAchievements(completionTime) {
        // Speed demon: Complete course in under 2 hours (120 minutes)
        if (completionTime <= 120) {
          await checkAndUnlockAchievement("speed_demon");
        }

        // Quick learner: Complete course in under 4 hours (240 minutes)
        if (completionTime <= 240) {
          await checkAndUnlockAchievement("quick_learner");
        }
      }

      async function checkStudyTimeAchievements() {
        const totalTime = courseSession.totalStudyTime;

        // Marathon learner: Study for 8+ hours in a course session
        if (totalTime >= 480) {
          // 8 hours
          await checkAndUnlockAchievement("marathon_learner");
        }

        // Dedicated learner: Study for 4+ hours
        if (totalTime >= 240) {
          // 4 hours
          await checkAndUnlockAchievement("dedicated_learner");
        }
      }

      async function checkCourseStreakAchievements() {
        try {
          // Check for consecutive course completions
          const { data: recentCourses, error } = await supabase
            .from("course_progress")
            .select("completed_at, course_id")
            .eq("user_id", currentUser.id)
            .eq("progress", 100)
            .order("completed_at", { ascending: false })
            .limit(10);

          if (error || !recentCourses) return;

          // Check for courses completed on consecutive days
          let consecutiveDays = 1;
          for (let i = 1; i < recentCourses.length; i++) {
            const prevDate = new Date(
              recentCourses[i - 1].completed_at
            ).toDateString();
            const currentDate = new Date(
              recentCourses[i].completed_at
            ).toDateString();
            const dayDiff =
              Math.abs(new Date(prevDate) - new Date(currentDate)) /
              (1000 * 60 * 60 * 24);

            if (dayDiff <= 1) {
              consecutiveDays++;
            } else {
              break;
            }
          }

          if (consecutiveDays >= 3) {
            await checkAndUnlockAchievement("learning_streak");
          }
        } catch (error) {
          console.error("Error checking course streak achievements:", error);
        }
      }

      // =====================================================
      // TIME-BASED ACHIEVEMENTS
      // =====================================================
      async function checkTimeBasedAchievements(timestamp) {
        const hour = timestamp.getHours();
        const dayOfWeek = timestamp.getDay();

        // Night owl (after midnight, before 6 AM)
        if (hour >= 0 && hour < 6) {
          await incrementTimeBasedCounter("midnight_sessions", "night_owl");
        }

        // Early bird (4 AM to 6 AM)
        if (hour >= 4 && hour < 6) {
          await incrementTimeBasedCounter("early_sessions", "early_bird");
        }

        // Weekend warrior (Saturday = 6, Sunday = 0)
        if (dayOfWeek === 0 || dayOfWeek === 6) {
          await incrementTimeBasedCounter(
            "weekend_sessions",
            "weekend_warrior"
          );
        }
      }

      async function incrementTimeBasedCounter(counterType, achievementId) {
        try {
          const dateStr = new Date().toISOString().split("T")[0];
          const cacheKey = `${counterType}_${currentUser.id}_${dateStr}`;

          // Prevent multiple increments per day
          if (sessionStorage.getItem(cacheKey)) return;

          // Update counter
          await supabase
            .from("profiles")
            .update({
              [counterType]: supabase.sql`${counterType} + 1`,
            })
            .eq("id", currentUser.id);

          // Cache to prevent double counting
          sessionStorage.setItem(cacheKey, "true");

          // Check related achievement
          if (achievementId) {
            await checkAndUnlockAchievement(achievementId, true);
          }
        } catch (error) {
          console.error(`Error incrementing ${counterType}:`, error);
        }
      }

      async function checkDailyStreak() {
        try {
          const { data: profile, error } = await supabase
            .from("profiles")
            .select("last_activity, current_streak, last_streak_date")
            .eq("id", currentUser.id)
            .single();

          if (error) throw error;

          const now = new Date();
          const today = now.toDateString();
          const lastActivity = profile.last_activity
            ? new Date(profile.last_activity)
            : null;
          const lastStreakDate = profile.last_streak_date
            ? new Date(profile.last_streak_date).toDateString()
            : null;

          let newStreak = profile.current_streak || 0;
          let shouldUpdateStreak = false;

          if (!lastActivity) {
            // First time user
            newStreak = 1;
            shouldUpdateStreak = true;
          } else {
            const daysSinceLastActivity = Math.floor(
              (now - lastActivity) / (1000 * 60 * 60 * 24)
            );

            if (lastStreakDate === today) {
              // Already counted today's streak
              return newStreak;
            } else if (
              daysSinceLastActivity === 1 ||
              (daysSinceLastActivity === 0 && lastStreakDate !== today)
            ) {
              // Consecutive day or same day but not counted yet
              newStreak += 1;
              shouldUpdateStreak = true;
            } else if (daysSinceLastActivity > 1) {
              // Streak broken
              newStreak = 1;
              shouldUpdateStreak = true;
            }
          }

          if (shouldUpdateStreak) {
            await supabase
              .from("profiles")
              .update({
                current_streak: newStreak,
                last_activity: now.toISOString(),
                last_streak_date: now.toISOString(),
              })
              .eq("id", currentUser.id);

            userStats.current_streak = newStreak;

            showToast(`Daily streak: ${newStreak} days!`, "success");
            await checkStreakAchievements(newStreak);
          }

          return newStreak;
        } catch (error) {
          console.error("Error checking daily streak:", error);
          return 0;
        }
      }

      async function checkStreakAchievements(currentStreak) {
        const streakMilestones = [3, 7, 14, 30, 100, 365];

        for (const milestone of streakMilestones) {
          if (currentStreak >= milestone) {
            await checkAndUnlockAchievement(`streak_${milestone}`);
          }
        }
      }

      // =====================================================
      // USER ACTIVITY LOGGING
      // =====================================================
      async function logUserActivity(activityType, metadata = {}) {
        try {
          const now = new Date();

          const activityData = {
            user_id: currentUser.id,
            activity_type: activityType,
            timestamp: now.toISOString(),
            course_id: COURSE_DATA.id,
            lesson_index: currentLessonIndex,
            session_duration: courseSession.totalStudyTime,
            metadata: JSON.stringify(metadata),
            created_at: now.toISOString(),
          };

          // Try to log to activities table
          const { error } = await supabase
            .from("user_activities")
            .insert([activityData]);

          if (error && error.code !== "42P01") {
            console.warn("Activity logging failed:", error.message);
          }

          // Always update last activity in profile
          await supabase
            .from("profiles")
            .update({ last_activity: now.toISOString() })
            .eq("id", currentUser.id);
        } catch (error) {
          console.error("Error logging user activity:", error);
        }
      }

      // =====================================================
      // NAVIGATION SYSTEM
      // =====================================================
      function updateNavigationButtons() {
        const prevBtn = document.getElementById("prevLessonBtn");
        const nextBtn = document.getElementById("nextLessonBtn");

        if (!prevBtn || !nextBtn) return;

        // Previous button
        prevBtn.disabled = currentLessonIndex === 0;

        // Next button logic
        const isLastLesson =
          currentLessonIndex === COURSE_DATA.lessons.length - 1;
        const canGoNext =
          currentLessonIndex < COURSE_DATA.lessons.length - 1 &&
          canAccessLesson(currentLessonIndex + 1);

        if (isLastLesson) {
          const isCurrentCompleted =
            courseProgress[COURSE_DATA.lessons[currentLessonIndex].id]
              ?.completed;
          nextBtn.disabled = !isCurrentCompleted;
          nextBtn.innerHTML = '<i class="fas fa-trophy"></i> Complete Course';
        } else {
          nextBtn.disabled = !canGoNext;
          nextBtn.innerHTML = 'Next <i class="fas fa-chevron-right"></i>';
        }
      }

      // Navigation button event handlers
      function goToPreviousLesson() {
        if (currentLessonIndex > 0) {
          trackLessonTime(); // Track time spent on current lesson
          currentLessonIndex--;
          loadLesson(currentLessonIndex);
        }
      }

      function goToNextLesson() {
        if (currentLessonIndex < COURSE_DATA.lessons.length - 1) {
          const canGoNext = canAccessLesson(currentLessonIndex + 1);
          if (canGoNext) {
            trackLessonTime();
            currentLessonIndex++;
            loadLesson(currentLessonIndex);
          } else {
            showToast("Complete the current lesson quiz to proceed", "warning");
          }
        } else {
          // Complete course
          completeCourse();
        }
      }

      // =====================================================
      // SIDEBAR FUNCTIONS
      // =====================================================
      function toggleSidebar() {
        const sidebar = document.getElementById("sidebar");
        const overlay = document.getElementById("sidebarOverlay");

        if (sidebar) sidebar.classList.toggle("open");
        if (overlay) overlay.classList.toggle("active");
      }

      function closeSidebar() {
        const sidebar = document.getElementById("sidebar");
        const overlay = document.getElementById("sidebarOverlay");

        if (sidebar) sidebar.classList.remove("open");
        if (overlay) overlay.classList.remove("active");
      }

      // =====================================================
      // ACHIEVEMENT NOTIFICATION SYSTEM
      // =====================================================
      function queueAchievementNotification(achievement) {
        notificationQueue.push(achievement);
        processNotificationQueue();
      }

      function processNotificationQueue() {
        if (isShowingNotification || notificationQueue.length === 0) return;

        isShowingNotification = true;
        const achievement = notificationQueue.shift();
        showAchievementNotification(achievement);

        const duration =
          achievement.rarity === "mythic"
            ? 8000
            : achievement.rarity === "legendary"
            ? 7000
            : 6000;

        setTimeout(() => {
          isShowingNotification = false;
          processNotificationQueue();
        }, duration + 500);
      }

      function showAchievementNotification(achievement) {
        const notification = document.getElementById("achievementNotification");
        if (!notification) return;

        const icon = document.getElementById("notificationIcon");
        const title = document.getElementById("notificationTitle");
        const description = document.getElementById("notificationDescription");
        const points = document.getElementById("notificationPoints");

        if (icon) {
          icon.innerHTML = `<i class="${achievement.icon}"></i>`;
          icon.className = `notification-icon ${achievement.rarity}`;
        }
        if (title) title.textContent = achievement.name;
        if (description) description.textContent = achievement.description;
        if (points) points.textContent = `+${achievement.points} Points`;

        notification.className = `achievement-notification ${achievement.rarity}`;
        notification.classList.add("show");

        const duration =
          achievement.rarity === "mythic"
            ? 8000
            : achievement.rarity === "legendary"
            ? 7000
            : 6000;

        setTimeout(() => {
          notification.classList.remove("show");
        }, duration);
      }

      // =====================================================
      // UTILITY FUNCTIONS
      // =====================================================
      function calculateAverageQuizScore() {
        const scores = Object.values(courseProgress)
          .filter((p) => p.completed && p.quizScore)
          .map((p) => p.quizScore);

        if (scores.length === 0) return 0;
        return Math.round(
          scores.reduce((sum, score) => sum + score, 0) / scores.length
        );
      }

      async function resetProgress() {
        if (
          !confirm(
            "Are you sure you want to reset your progress? This action cannot be undone."
          )
        ) {
          return;
        }

        try {
          // Track lesson time before reset
          trackLessonTime();

          // Reset local state
          courseProgress = {};
          currentLessonIndex = 0;
          courseSession = {
            startTime: new Date(),
            totalStudyTime: 0,
            lessonsStarted: 0,
            lessonsCompleted: 0,
            pageLoadTime: new Date(),
            interactionCount: 0,
            lastActivityTime: new Date(),
          };

          // Delete from database
          await supabase
            .from("course_progress")
            .delete()
            .eq("user_id", currentUser.id)
            .eq("course_id", COURSE_DATA.id);

          // Log reset activity
          logUserActivity("progress_reset", {
            course_id: COURSE_DATA.id,
            reset_reason: "manual",
          });

          // Reinitialize
          await saveProgress();
          renderSidebar();
          loadLesson(0);

          showToast("Progress reset successfully", "success");
        } catch (error) {
          console.error("Error resetting progress:", error);
          showToast("Failed to reset progress", "error");
        }
      }

      function copyCode(codeId) {
        const codeElement = document.getElementById(codeId);
        if (!codeElement) return;

        const text = codeElement.textContent;

        navigator.clipboard
          .writeText(text)
          .then(() => {
            showToast("Code copied to clipboard!", "success");

            // Track code copy for achievements
            logUserActivity("code_copied", {
              code_section: codeId,
              lesson_id: COURSE_DATA.lessons[currentLessonIndex].id,
            });
          })
          .catch((err) => {
            console.error("Failed to copy code:", err);
            showToast("Failed to copy code", "error");

            // Fallback for older browsers
            const textArea = document.createElement("textarea");
            textArea.value = text;
            document.body.appendChild(textArea);
            textArea.select();
            try {
              document.execCommand("copy");
              showToast("Code copied to clipboard!", "success");
            } catch (fallbackError) {
              showToast(
                "Copy failed - please select and copy manually",
                "error"
              );
            }
            document.body.removeChild(textArea);
          });
      }

      function escapeHtml(text) {
        const div = document.createElement("div");
        div.textContent = text;
        return div.innerHTML;
      }

      // =====================================================
      // UI FEEDBACK SYSTEMS
      // =====================================================
      function showToast(message, type = "success") {
        const toast = document.getElementById("toast");
        const messageEl = document.getElementById("toastMessage");

        if (!toast || !messageEl) {
          console.log(`Toast: ${message} (${type})`);
          return;
        }

        messageEl.textContent = message;
        toast.className = `toast ${type} show`;

        setTimeout(() => {
          toast.classList.remove("show");
        }, 4000);
      }

      function showLoadingScreen() {
        const loadingScreen = document.getElementById("loadingScreen");
        if (loadingScreen) loadingScreen.classList.remove("hidden");
      }

      function hideLoadingScreen() {
        const loadingScreen = document.getElementById("loadingScreen");
        if (loadingScreen) {
          setTimeout(() => {
            loadingScreen.classList.add("hidden");
          }, 1000);
        }
      }

      // =====================================================
      // MUSIC PLAYER INTEGRATION
      // =====================================================
      function initMusicPlayer() {
        const btnText = document.getElementById("music-button-text");
        const icon = document.getElementById("music-icon");
        const dropdown = document.getElementById("music-dropdown-content");

        if (!btnText || !icon || !dropdown) return;

        function setUI(state) {
          btnText.textContent =
            state === "Playing" ? "PAUSE MUSIC" : "STUDY MUSIC";
          icon.className =
            state === "Playing"
              ? "fa-solid fa-circle-pause"
              : "fa-solid fa-music";
        }

        // Load saved music state
        const savedSrc = localStorage.getItem("cybersec_music_src");
        const savedTime = parseFloat(
          localStorage.getItem("cybersec_music_time") || 0
        );

        if (savedSrc) {
          audioPlayer.src = savedSrc;
          audioPlayer.currentTime = savedTime;
          audioPlayer
            .play()
            .then(() => setUI("Playing"))
            .catch(() => setUI("Stopped"));
        }

        // Music button click handler
        document
          .getElementById("music-dropdown")
          .querySelector("button")
          .addEventListener("click", (e) => {
            e.stopPropagation();
            dropdown.style.display =
              dropdown.style.display === "block" ? "none" : "block";

            if (audioPlayer.src && !audioPlayer.paused) {
              audioPlayer.pause();
              setUI("Stopped");
            } else if (audioPlayer.src) {
              audioPlayer.play().then(() => setUI("Playing"));
            }
          });

        // Music selection handlers
        dropdown.querySelectorAll("a[data-src]").forEach((link) => {
          link.addEventListener("click", (e) => {
            e.preventDefault();
            audioPlayer.src = link.dataset.src;
            audioPlayer.play().then(() => setUI("Playing"));
            localStorage.setItem("cybersec_music_src", link.dataset.src);
            dropdown.style.display = "none";
          });
        });

        // Stop music handler
        const stopLink = document.getElementById("stop-music-link");
        if (stopLink) {
          stopLink.addEventListener("click", (e) => {
            e.preventDefault();
            audioPlayer.pause();
            audioPlayer.currentTime = 0;
            audioPlayer.removeAttribute("src");
            setUI("Stopped");
            localStorage.removeItem("cybersec_music_src");
            localStorage.removeItem("cybersec_music_time");
            dropdown.style.display = "none";
          });
        }

        // Save music state before page unload
        window.addEventListener("beforeunload", () => {
          if (!audioPlayer.paused && audioPlayer.src) {
            localStorage.setItem("cybersec_music_src", audioPlayer.src);
            localStorage.setItem(
              "cybersec_music_time",
              audioPlayer.currentTime
            );
          }
        });

        // Close dropdown when clicking outside
        window.addEventListener("click", (e) => {
          if (!e.target.closest("#music-dropdown")) {
            dropdown.style.display = "none";
          }
        });
      }

      // Show initial music indicator
      function addMusicIndicator() {
        const musicBtn = document.querySelector("#music-dropdown");
        if (musicBtn) {
          const indicator = document.createElement("div");
          indicator.className = "music-indicator";
          indicator.innerHTML = `<i class="fa-solid fa-music"></i> Try Study Music!`;

          musicBtn.style.position = "relative";
          musicBtn.appendChild(indicator);

          setTimeout(() => indicator.remove(), 3000);
        }
      }

      // Initialize Event Listeners
      function initializeEventListeners() {
        // Navigation buttons
        document
          .getElementById("prevLessonBtn")
          ?.addEventListener("click", goToPreviousLesson);
        document
          .getElementById("nextLessonBtn")
          ?.addEventListener("click", goToNextLesson);

        // Reset progress button
        document
          .getElementById("resetProgressBtn")
          ?.addEventListener("click", resetProgress);

        // Mobile menu toggle
        document
          .getElementById("menuToggle")
          ?.addEventListener("click", toggleSidebar);
        document
          .getElementById("sidebarOverlay")
          ?.addEventListener("click", closeSidebar);

        // Keyboard shortcuts
        document.addEventListener("keydown", handleKeyboardShortcuts);

        // Window resize handler
        window.addEventListener("resize", handleWindowResize);

        // Content interaction tracking
        document.getElementById("contentBody")?.addEventListener(
          "scroll",
          debounce(() => {
            trackUserInteraction();
          }, 1000)
        );
      }

      // Keyboard Shortcuts
      function handleKeyboardShortcuts(e) {
        if (document.querySelector(".quiz-question.active")) return;

        if (e.key === "ArrowLeft" && e.ctrlKey) {
          e.preventDefault();
          goToPreviousLesson();
        } else if (e.key === "ArrowRight" && e.ctrlKey) {
          e.preventDefault();
          goToNextLesson();
        }
      }

      // Window Resize Handler
      function handleWindowResize() {
        if (window.innerWidth > 768) {
          closeSidebar();
        }
      }

      // Debounce Helper
      function debounce(func, wait) {
        let timeout;
        return function executedFunction(...args) {
          const later = () => {
            clearTimeout(timeout);
            func(...args);
          };
          clearTimeout(timeout);
          timeout = setTimeout(later, wait);
        };
      }

      // Initialize responsive behavior
      if (window.innerWidth <= 768) {
        document.getElementById("menuToggle").style.display = "inline-flex";
      }

      // Auto-save progress periodically
      setInterval(async () => {
        if (currentUser && Object.keys(courseProgress).length > 0) {
          await saveProgress();
        }
      }, 60000); // Save every minute

      // System initialization logging
      console.log("CyberSec Academy Course System Initialized");
      console.log("Current Course:", COURSE_DATA.title);
      console.log("Total Lessons:", COURSE_DATA.lessons.length);

      // Google OAuth Integration
      const googleBtn = document.querySelector(".btn-google");
      if (googleBtn) {
        googleBtn.addEventListener("click", async () => {
          const { data, error } = await supabase.auth.signInWithOAuth({
            provider: "google",
            options: {
              redirectTo:
                window.location.origin +
                "/courses/aws-security-fundamentals.html",
            },
          });

          if (error) {
            console.error("Google login error:", error.message);
            showToast("Google login failed: " + error.message, "error");
          }
        });
      }

      // Check for existing session
      supabase.auth.getSession().then(({ data }) => {
        if (data.session) {
          console.log("User already logged in:", data.session.user);
          currentUser = data.session.user;
          startCourseSession();
        }
      });

      // Add missing auth modal functions
      function openAuthModal() {
        const modal = document.getElementById("authModal");
        if (modal) {
          modal.style.display = "flex";
        }
      }

      function closeAuthModal() {
        const modal = document.getElementById("authModal");
        if (modal) {
          modal.style.display = "none";
        }
      }

      // Add auth tab switching functionality
      document.getElementById("tabSignIn")?.addEventListener("click", () => {
        document.getElementById("tabSignIn").classList.add("active");
        document.getElementById("tabSignUp").classList.remove("active");
        document.getElementById("signInForm").style.display = "block";
        document.getElementById("signUpForm").style.display = "none";
      });

      document.getElementById("tabSignUp")?.addEventListener("click", () => {
        document.getElementById("tabSignUp").classList.add("active");
        document.getElementById("tabSignIn").classList.remove("active");
        document.getElementById("signUpForm").style.display = "block";
        document.getElementById("signInForm").style.display = "none";
      });

      document
        .getElementById("closeAuthModal")
        ?.addEventListener("click", closeAuthModal);

      // Improved error handling for auth session
      supabase.auth.onAuthStateChange((event, session) => {
        if (event === "SIGNED_IN") {
          currentUser = session.user;
          closeAuthModal();
          startCourseSession();
        } else if (event === "SIGNED_OUT") {
          currentUser = null;
          openAuthModal();
        }
      });

      // Add form submission handlers
      document
        .getElementById("emailSignInForm")
        ?.addEventListener("submit", async (e) => {
          e.preventDefault();
          const email = document.getElementById("signInEmail").value;
          const password = document.getElementById("signInPassword").value;

          try {
            const { data, error } = await supabase.auth.signInWithPassword({
              email,
              password,
            });

            if (error) throw error;

            closeAuthModal();
          } catch (error) {
            showToast(error.message, "error");
          }
        });

      document
        .getElementById("emailSignUpForm")
        ?.addEventListener("submit", async (e) => {
          e.preventDefault();
          const email = document.getElementById("signUpEmail").value;
          const password = document.getElementById("signUpPassword").value;
          const name = document.getElementById("signUpName").value;

          try {
            const { data, error } = await supabase.auth.signUp({
              email,
              password,
              options: {
                data: {
                  full_name: name,
                },
              },
            });

            if (error) throw error;

            showToast(
              "Account created successfully! Please check your email.",
              "success"
            );
          } catch (error) {
            showToast(error.message, "error");
          }
        });
    </script>
  </body>
</html>

